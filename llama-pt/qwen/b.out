[2024-06-09 13:37:53,885] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-09 13:37:56,911] [WARNING] [runner.py:203:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-06-09 13:37:56,958] [INFO] [runner.py:570:main] cmd = /home/nfs02/anaconda3/envs/wzjsz/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=9902 --enable_each_rank_log=None src/train_bash.py --deepspeed /home/wangzj/LLaMA-Factory-hx/llama-pt/config/ds_config.json --stage pt --model_name_or_path /home/nfs04/wangzj/models/Qwen1.5-1.8B --cutoff_len 1024 --finetuning_type moe --moe_every_k_layers 1 --moe_num_experts 2 --topk 2 --use_polarization_loss --polarization_coef 0.01 --polarization_func powsum --do_train --dataset ar_2b,de_2b,ru_2b --preprocessing_num_workers 16 --cutoff_len 512 --cache_path /home/nfs03/wangzj/dataset/pretrain/arderu6b --output_dir /home/nfs04/wangzj/checkpoints/moe/test --overwrite_output_dir --per_device_train_batch_size 16 --gradient_accumulation_steps 8 --lr_scheduler_type cosine --logging_steps 1 --save_total_limit 100 --save_steps 10000 --save_only_model --learning_rate 5e-5 --num_train_epochs 1.0 --plot_loss --bf16
[2024-06-09 13:37:59,180] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-09 13:38:01,373] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2024-06-09 13:38:01,374] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2024-06-09 13:38:01,374] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2024-06-09 13:38:01,374] [INFO] [launch.py:163:main] dist_world_size=4
[2024-06-09 13:38:01,374] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2024-06-09 13:38:07,075] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-09 13:38:07,076] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-09 13:38:07,077] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-09 13:38:07,077] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-09 13:38:14,780] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-09 13:38:14,781] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-09 13:38:14,781] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-09 13:38:14,796] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-09 13:38:14,796] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
06/09/2024 13:38:15 - INFO - llmtuner.hparams.parser - Process rank: 2, device: cuda:2, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
06/09/2024 13:38:15 - INFO - llmtuner.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
06/09/2024 13:38:15 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory-hx/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=8,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=2,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs04/wangzj/checkpoints/moe/test/runs/Jun09_13-38-14_2080ti-2,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs04/wangzj/checkpoints/moe/test,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs04/wangzj/checkpoints/moe/test,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=10000,
save_strategy=steps,
save_total_limit=100,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
06/09/2024 13:38:15 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory-hx/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=8,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=1,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs04/wangzj/checkpoints/moe/test/runs/Jun09_13-38-14_2080ti-2,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs04/wangzj/checkpoints/moe/test,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs04/wangzj/checkpoints/moe/test,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=10000,
save_strategy=steps,
save_total_limit=100,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
06/09/2024 13:38:15 - INFO - llmtuner.hparams.parser - Process rank: 3, device: cuda:3, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
06/09/2024 13:38:15 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory-hx/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=8,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=3,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs04/wangzj/checkpoints/moe/test/runs/Jun09_13-38-14_2080ti-2,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs04/wangzj/checkpoints/moe/test,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs04/wangzj/checkpoints/moe/test,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=10000,
save_strategy=steps,
save_total_limit=100,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
06/09/2024 13:38:15 - INFO - llmtuner.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
06/09/2024 13:38:15 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory-hx/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=8,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs04/wangzj/checkpoints/moe/test/runs/Jun09_13-38-14_2080ti-2,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs04/wangzj/checkpoints/moe/test,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs04/wangzj/checkpoints/moe/test,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=10000,
save_strategy=steps,
save_total_limit=100,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[INFO|tokenization_utils_base.py:2027] 2024-06-09 13:38:15,837 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2027] 2024-06-09 13:38:15,837 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2027] 2024-06-09 13:38:15,837 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2027] 2024-06-09 13:38:15,837 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2027] 2024-06-09 13:38:15,837 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2027] 2024-06-09 13:38:15,837 >> loading file tokenizer.json
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:314] 2024-06-09 13:38:16,204 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:727] 2024-06-09 13:38:16,205 >> loading configuration file /home/nfs04/wangzj/models/Qwen1.5-1.8B/config.json
[INFO|configuration_utils.py:792] 2024-06-09 13:38:16,207 >> Model config Qwen2Config {
  "_name_or_path": "/home/nfs04/wangzj/models/Qwen1.5-1.8B",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5504,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_key_value_heads": 16,
  "rms_norm_eps": 1e-06,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.38.0.dev0",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|modeling_utils.py:3334] 2024-06-09 13:38:16,305 >> loading weights file /home/nfs04/wangzj/models/Qwen1.5-1.8B/model.safetensors
[INFO|modeling_utils.py:1459] 2024-06-09 13:38:16,335 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:827] 2024-06-09 13:38:16,339 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151643
}

06/09/2024 13:38:20 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
06/09/2024 13:38:20 - INFO - llmtuner.model.adapter - Fine-tuning method: MOE
06/09/2024 13:38:20 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
06/09/2024 13:38:20 - INFO - llmtuner.model.adapter - Fine-tuning method: MOE
06/09/2024 13:38:20 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
06/09/2024 13:38:20 - INFO - llmtuner.model.adapter - Fine-tuning method: MOE
[INFO|modeling_utils.py:4070] 2024-06-09 13:38:20,600 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.

[INFO|modeling_utils.py:4078] 2024-06-09 13:38:20,600 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at /home/nfs04/wangzj/models/Qwen1.5-1.8B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.
[INFO|configuration_utils.py:780] 2024-06-09 13:38:20,609 >> loading configuration file /home/nfs04/wangzj/models/Qwen1.5-1.8B/generation_config.json
[INFO|configuration_utils.py:827] 2024-06-09 13:38:20,609 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "max_new_tokens": 2048
}

06/09/2024 13:38:20 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
06/09/2024 13:38:20 - INFO - llmtuner.model.adapter - Fine-tuning method: MOE
06/09/2024 13:38:21 - INFO - llmtuner.model.adapter - MoeConfig(peft_type=<PeftType.MOE: 'MOE'>, auto_mapping=None, base_model_name_or_path='/home/nfs04/wangzj/models/Qwen1.5-1.8B', revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, init_moe_weights=True, router_type='top1', save_router_logits=False, num_experts=2, num_heads=4, topk=2, layers_to_transform=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], save_all_params=False, polarization_coef=0.01, router_aux_loss_coef=0.01, use_polarization_loss=True, polarization_func='powsum')
06/09/2024 13:38:21 - INFO - llmtuner.model.loader - trainable params: 811696128 || all params: 2648524800 || trainable%: 30.6471
06/09/2024 13:38:21 - WARNING - llmtuner.data.loader - Loading dataset from disk will ignore other data arguments.
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 5872167
})
06/09/2024 13:38:21 - INFO - llmtuner.model.adapter - MoeConfig(peft_type=<PeftType.MOE: 'MOE'>, auto_mapping=None, base_model_name_or_path='/home/nfs04/wangzj/models/Qwen1.5-1.8B', revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, init_moe_weights=True, router_type='top1', save_router_logits=False, num_experts=2, num_heads=4, topk=2, layers_to_transform=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], save_all_params=False, polarization_coef=0.01, router_aux_loss_coef=0.01, use_polarization_loss=True, polarization_func='powsum')
06/09/2024 13:38:21 - INFO - llmtuner.model.loader - trainable params: 811696128 || all params: 2648524800 || trainable%: 30.6471
06/09/2024 13:38:21 - WARNING - llmtuner.data.loader - Loading dataset from disk will ignore other data arguments.
06/09/2024 13:38:21 - INFO - llmtuner.model.adapter - MoeConfig(peft_type=<PeftType.MOE: 'MOE'>, auto_mapping=None, base_model_name_or_path='/home/nfs04/wangzj/models/Qwen1.5-1.8B', revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, init_moe_weights=True, router_type='top1', save_router_logits=False, num_experts=2, num_heads=4, topk=2, layers_to_transform=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], save_all_params=False, polarization_coef=0.01, router_aux_loss_coef=0.01, use_polarization_loss=True, polarization_func='powsum')
06/09/2024 13:38:21 - INFO - llmtuner.model.loader - trainable params: 811696128 || all params: 2648524800 || trainable%: 30.6471
06/09/2024 13:38:21 - WARNING - llmtuner.data.loader - Loading dataset from disk will ignore other data arguments.
06/09/2024 13:38:21 - INFO - llmtuner.model.adapter - MoeConfig(peft_type=<PeftType.MOE: 'MOE'>, auto_mapping=None, base_model_name_or_path='/home/nfs04/wangzj/models/Qwen1.5-1.8B', revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, init_moe_weights=True, router_type='top1', save_router_logits=False, num_experts=2, num_heads=4, topk=2, layers_to_transform=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], save_all_params=False, polarization_coef=0.01, router_aux_loss_coef=0.01, use_polarization_loss=True, polarization_func='powsum')
06/09/2024 13:38:21 - INFO - llmtuner.model.loader - trainable params: 811696128 || all params: 2648524800 || trainable%: 30.6471
06/09/2024 13:38:21 - WARNING - llmtuner.data.loader - Loading dataset from disk will ignore other data arguments.
Loading cached shuffled indices for dataset at /home/nfs03/wangzj/dataset/pretrain/arderu6b/cache-32ee8c5574b2e83c.arrow
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 5872167
})
PeftModelForCausalLM(
  (base_model): MoeModel(
    (model): Qwen2ForCausalLM(
      (model): Qwen2Model(
        (embed_tokens): Embedding(151936, 2048)
        (layers): ModuleList(
          (0): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (1): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (2): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (3): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (4): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (5): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (6): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (7): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (8): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (9): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (10): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (11): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (12): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (13): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (14): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (15): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (16): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (17): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (18): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (19): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (20): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (21): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (22): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (23): Qwen2DecoderLayer(
            (self_attn): Qwen2Attention(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
        )
        (norm): Qwen2RMSNorm()
      )
      (lm_head): Linear(in_features=2048, out_features=151936, bias=False)
    )
  )
)
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 5872167
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 5872167
})
[INFO|trainer.py:586] 2024-06-09 13:38:22,134 >> Using auto half precision backend
[2024-06-09 13:38:22,416] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.3, git-hash=unknown, git-branch=unknown
[2024-06-09 13:38:27,138] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-06-09 13:38:27,141] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-06-09 13:38:27,141] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-06-09 13:38:27,148] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2024-06-09 13:38:27,149] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2024-06-09 13:38:27,149] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-06-09 13:38:27,149] [INFO] [stage_1_and_2.py:147:__init__] Reduce bucket size 500000000
[2024-06-09 13:38:27,149] [INFO] [stage_1_and_2.py:148:__init__] Allgather bucket size 500000000
[2024-06-09 13:38:27,149] [INFO] [stage_1_and_2.py:149:__init__] CPU Offload: False
[2024-06-09 13:38:27,149] [INFO] [stage_1_and_2.py:150:__init__] Round robin gradient partitioning: False
[2024-06-09 13:38:31,364] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states
[2024-06-09 13:38:31,365] [INFO] [utils.py:803:see_memory_usage] MA 6.1 GB         Max_MA 6.48 GB         CA 6.77 GB         Max_CA 7 GB 
[2024-06-09 13:38:31,365] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 65.55 GB, percent = 17.4%
[2024-06-09 13:38:31,600] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states
[2024-06-09 13:38:31,600] [INFO] [utils.py:803:see_memory_usage] MA 7.61 GB         Max_MA 9.88 GB         CA 10.55 GB         Max_CA 11 GB 
[2024-06-09 13:38:31,601] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 66.02 GB, percent = 17.5%
[2024-06-09 13:38:31,601] [INFO] [stage_1_and_2.py:514:__init__] optimizer state initialized
[2024-06-09 13:38:31,822] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer
[2024-06-09 13:38:31,823] [INFO] [utils.py:803:see_memory_usage] MA 7.61 GB         Max_MA 7.61 GB         CA 10.55 GB         Max_CA 11 GB 
[2024-06-09 13:38:31,823] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 66.12 GB, percent = 17.6%
[2024-06-09 13:38:31,824] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2024-06-09 13:38:31,825] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-06-09 13:38:31,825] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-06-09 13:38:31,825] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[(0.9, 0.999)]
[2024-06-09 13:38:31,826] [INFO] [config.py:974:print] DeepSpeedEngine configuration:
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   amp_enabled .................. False
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   amp_params ................... False
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   bfloat16_enabled ............. True
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   checkpoint_parallel_write_pipeline  False
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   checkpoint_tag_validation_enabled  True
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   checkpoint_tag_validation_fail  False
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7efeadf0b8b0>
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   communication_data_type ...... None
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   curriculum_enabled_legacy .... False
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   curriculum_params_legacy ..... False
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   data_efficiency_enabled ...... False
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   dataloader_drop_last ......... False
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   disable_allgather ............ False
[2024-06-09 13:38:31,827] [INFO] [config.py:978:print]   dump_state ................... False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   dynamic_loss_scale_args ...... None
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   eigenvalue_enabled ........... False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   eigenvalue_gas_boundary_resolution  1
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   eigenvalue_layer_num ......... 0
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   eigenvalue_max_iter .......... 100
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   eigenvalue_stability ......... 1e-06
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   eigenvalue_tol ............... 0.01
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   eigenvalue_verbose ........... False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   elasticity_enabled ........... False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   fp16_auto_cast ............... None
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   fp16_enabled ................. False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   fp16_master_weights_and_gradients  False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   global_rank .................. 0
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   grad_accum_dtype ............. None
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   gradient_accumulation_steps .. 8
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   gradient_clipping ............ 1.0
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   gradient_predivide_factor .... 1.0
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   initial_dynamic_scale ........ 1
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   load_universal_checkpoint .... False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   loss_scale ................... 1.0
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   memory_breakdown ............. False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   mics_hierarchial_params_gather  False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   mics_shard_size .............. -1
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   optimizer_legacy_fusion ...... False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   optimizer_name ............... None
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   optimizer_params ............. None
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   pld_enabled .................. False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   pld_params ................... False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   prescale_gradients ........... False
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   scheduler_name ............... None
[2024-06-09 13:38:31,828] [INFO] [config.py:978:print]   scheduler_params ............. None
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   seq_parallel_communication_data_type  torch.float32
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   sparse_attention ............. None
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   sparse_gradients_enabled ..... False
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   steps_per_print .............. inf
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   train_batch_size ............. 512
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   train_micro_batch_size_per_gpu  16
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   use_node_local_storage ....... False
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   wall_clock_breakdown ......... False
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   weight_quantization_config ... None
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   world_size ................... 4
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   zero_allow_untested_optimizer  True
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   zero_enabled ................. True
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   zero_force_ds_cpu_optimizer .. True
[2024-06-09 13:38:31,829] [INFO] [config.py:978:print]   zero_optimization_stage ...... 2
[2024-06-09 13:38:31,829] [INFO] [config.py:964:print_user_config]   json = {
    "train_batch_size": 512, 
    "train_micro_batch_size_per_gpu": 16, 
    "gradient_accumulation_steps": 8, 
    "gradient_clipping": 1.0, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "initial_scale_power": 16, 
        "loss_scale_window": 1000, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 5.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 5.000000e+08, 
        "contiguous_gradients": true
    }, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }
}
[INFO|trainer.py:1748] 2024-06-09 13:38:31,829 >> ***** Running training *****
[INFO|trainer.py:1749] 2024-06-09 13:38:31,829 >>   Num examples = 5,872,167
[INFO|trainer.py:1750] 2024-06-09 13:38:31,829 >>   Num Epochs = 1
[INFO|trainer.py:1751] 2024-06-09 13:38:31,829 >>   Instantaneous batch size per device = 16
[INFO|trainer.py:1754] 2024-06-09 13:38:31,829 >>   Total train batch size (w. parallel, distributed & accumulation) = 512
[INFO|trainer.py:1755] 2024-06-09 13:38:31,829 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:1756] 2024-06-09 13:38:31,829 >>   Total optimization steps = 11,469
[INFO|trainer.py:1757] 2024-06-09 13:38:31,831 >>   Number of trainable parameters = 811,696,128
  0%|          | 0/11469 [00:00<?, ?it/s]sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
ssssssssssssssssssssssssssssssssssssssssssssssssssssss

sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
ssssssssssssssssssssssssssssssssssssssssssssssssssssss

sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
ssssssssssssssssssssssssssssssssssssssssssssssssssssss

sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
  0%|          | 1/11469 [00:40<127:57:27, 40.17s/it]                                                     {'loss': 3.2668, 'learning_rate': 4.9999999062095436e-05, 'epoch': 0.0}
  0%|          | 1/11469 [00:40<127:57:27, 40.17s/it]ssssssssssssssssssssssssssssssssssssssssssssssssssssss

sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
                                                     {'polar__loss': -0.6231688261032104, 'experts_info_per_layer': '0.0 0.0 0.0 0.01 0.01 0.02 0.03 0.03 0.03 0.07 0.07 0.03 0.04 0.08 0.09 0.07 0.17 0.13 0.16 0.19 0.29 0.45 0.27 0.78', 'epoch': 0.0}
  0%|          | 1/11469 [00:41<127:57:27, 40.17s/it]sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
ssssssssssssssssssssssssssssssssssssssssssssssssssssss

sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
test.sh: line 32: 289844 Killed                  deepspeed --num_gpus 4 --master_port=9902 src/train_bash.py --deepspeed /home/wangzj/LLaMA-Factory-hx/llama-pt/config/ds_config.json --stage pt --model_name_or_path /home/nfs04/wangzj/models/Qwen1.5-1.8B --cutoff_len 1024 --finetuning_type moe --moe_every_k_layers 1 --moe_num_experts 2 --topk 2 --use_polarization_loss --polarization_coef 0.01 --polarization_func powsum --do_train --dataset ar_2b,de_2b,ru_2b --preprocessing_num_workers 16 --cutoff_len 512 --cache_path /home/nfs03/wangzj/dataset/pretrain/arderu6b --output_dir /home/nfs04/wangzj/checkpoints/moe/test --overwrite_output_dir --per_device_train_batch_size 16 --gradient_accumulation_steps 8 --lr_scheduler_type cosine --logging_steps 1 --save_total_limit 100 --save_steps 10000 --save_only_model --learning_rate 5e-5 --num_train_epochs 1.0 --plot_loss --bf16
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
ssssssssssssssssssssssssssssssssssssssssssssssssssssss

sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
sssssssssssssssssssssssssss
