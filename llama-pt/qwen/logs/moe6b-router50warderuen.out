[2024-04-18 15:39:11,211] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-18 15:39:13,514] [WARNING] [runner.py:203:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-04-18 15:39:13,561] [INFO] [runner.py:570:main] cmd = /home/nfs02/anaconda3/envs/wzjsz/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=9902 --enable_each_rank_log=None src/train_bash.py --deepspeed /home/wangzj/LLaMA-Factory/llama-pt/config/ds_config.json --stage pt --model_name_or_path /home/nfs02/wangzj/models/Qwen1.5-1.8B --do_train --flash_attn --dataset de_2b,ar_2b,ru_2b,slimpajam_1b --max_samples 500000 --preprocessing_num_workers 16 --mix_strategy concat --cutoff_len 1024 --finetuning_type moe --adapter_name_or_path /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe --train_only_router --output_dir /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter --overwrite_output_dir --per_device_train_batch_size 16 --gradient_accumulation_steps 8 --lr_scheduler_type cosine --logging_steps 10 --save_total_limit 1 --save_only_model --save_steps 1000 --learning_rate 2e-5 --num_train_epochs 1.0 --plot_loss --bf16
[2024-04-18 15:39:15,041] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-18 15:39:17,364] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2024-04-18 15:39:17,364] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2024-04-18 15:39:17,364] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2024-04-18 15:39:17,364] [INFO] [launch.py:163:main] dist_world_size=4
[2024-04-18 15:39:17,364] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2024-04-18 15:39:22,560] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-18 15:39:22,587] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-18 15:39:22,701] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-18 15:39:22,805] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-18 15:39:29,246] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-18 15:39:29,270] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-18 15:39:29,270] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-04-18 15:39:29,328] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-18 15:39:29,385] [INFO] [comm.py:637:init_distributed] cdb=None
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
04/18/2024 15:39:30 - INFO - llmtuner.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
04/18/2024 15:39:30 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=8,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/runs/Apr18_15-39-29_2080ti-1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=1,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
[INFO|tokenization_utils_base.py:2027] 2024-04-18 15:39:30,264 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2027] 2024-04-18 15:39:30,264 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2027] 2024-04-18 15:39:30,264 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2027] 2024-04-18 15:39:30,264 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2027] 2024-04-18 15:39:30,264 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2027] 2024-04-18 15:39:30,264 >> loading file tokenizer.json
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
04/18/2024 15:39:30 - INFO - llmtuner.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
04/18/2024 15:39:30 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=8,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=1,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/runs/Apr18_15-39-29_2080ti-1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=1,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
04/18/2024 15:39:30 - INFO - llmtuner.hparams.parser - Process rank: 3, device: cuda:3, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
04/18/2024 15:39:30 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=8,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=3,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/runs/Apr18_15-39-29_2080ti-1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=1,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
04/18/2024 15:39:30 - INFO - llmtuner.hparams.parser - Process rank: 2, device: cuda:2, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
04/18/2024 15:39:30 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=8,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=2,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/runs/Apr18_15-39-29_2080ti-1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=1000,
save_strategy=steps,
save_total_limit=1,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
04/18/2024 15:39:30 - INFO - llmtuner.model.patcher - Using FlashAttention-2 for faster training and inference.
04/18/2024 15:39:30 - INFO - llmtuner.model.patcher - Using FlashAttention-2 for faster training and inference.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
04/18/2024 15:39:30 - INFO - llmtuner.model.patcher - Using FlashAttention-2 for faster training and inference.
[WARNING|logging.py:314] 2024-04-18 15:39:30,572 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:727] 2024-04-18 15:39:30,573 >> loading configuration file /home/nfs02/wangzj/models/Qwen1.5-1.8B/config.json
[INFO|configuration_utils.py:792] 2024-04-18 15:39:30,579 >> Model config Qwen2Config {
  "_name_or_path": "/home/nfs02/wangzj/models/Qwen1.5-1.8B",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5504,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_key_value_heads": 16,
  "rms_norm_eps": 1e-06,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.38.0.dev0",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

04/18/2024 15:39:30 - INFO - llmtuner.model.patcher - Using FlashAttention-2 for faster training and inference.
The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[INFO|modeling_utils.py:3334] 2024-04-18 15:39:30,654 >> loading weights file /home/nfs02/wangzj/models/Qwen1.5-1.8B/model.safetensors.index.json
[INFO|modeling_utils.py:1459] 2024-04-18 15:39:30,655 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.
[WARNING|logging.py:329] 2024-04-18 15:39:30,655 >> The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
[WARNING|logging.py:329] 2024-04-18 15:39:30,658 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[INFO|configuration_utils.py:827] 2024-04-18 15:39:30,660 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151643
}

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:02<00:02,  2.54s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.39s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.59s/it]
04/18/2024 15:39:36 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
04/18/2024 15:39:36 - INFO - llmtuner.model.adapter - Fine-tuning method: MOE
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.71s/it]
04/18/2024 15:39:37 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
04/18/2024 15:39:37 - INFO - llmtuner.model.adapter - Fine-tuning method: MOE
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.69s/it]
[INFO|modeling_utils.py:4070] 2024-04-18 15:39:37,311 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.

[INFO|modeling_utils.py:4078] 2024-04-18 15:39:37,312 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at /home/nfs02/wangzj/models/Qwen1.5-1.8B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.
[INFO|configuration_utils.py:780] 2024-04-18 15:39:37,317 >> loading configuration file /home/nfs02/wangzj/models/Qwen1.5-1.8B/generation_config.json
[INFO|configuration_utils.py:827] 2024-04-18 15:39:37,317 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151643
}

04/18/2024 15:39:37 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
04/18/2024 15:39:37 - INFO - llmtuner.model.adapter - Fine-tuning method: MOE
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.91s/it]
04/18/2024 15:39:37 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
04/18/2024 15:39:37 - INFO - llmtuner.model.adapter - Fine-tuning method: MOE
04/18/2024 15:40:01 - INFO - llmtuner.model.adapter - Loaded adapter(s): /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe
04/18/2024 15:40:01 - INFO - llmtuner.model.loader - trainable params: 98304 || all params: 2648524800 || trainable%: 0.0037
04/18/2024 15:40:01 - INFO - llmtuner.model.adapter - Loaded adapter(s): /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe
04/18/2024 15:40:01 - INFO - llmtuner.model.loader - trainable params: 98304 || all params: 2648524800 || trainable%: 0.0037
04/18/2024 15:40:01 - INFO - llmtuner.model.adapter - Loaded adapter(s): /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe
04/18/2024 15:40:01 - INFO - llmtuner.model.loader - trainable params: 98304 || all params: 2648524800 || trainable%: 0.0037
04/18/2024 15:40:01 - INFO - llmtuner.model.adapter - Loaded adapter(s): /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe
04/18/2024 15:40:01 - INFO - llmtuner.model.loader - trainable params: 98304 || all params: 2648524800 || trainable%: 0.0037
04/18/2024 15:41:21 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/de_2b.jsonl.
Using custom data configuration default-22ad102cdc2aaff8
Loading Dataset Infos from /home/nfs02/anaconda3/envs/wzjsz/lib/python3.10/site-packages/datasets/packaged_modules/json
Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
Found cached dataset json (/home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)
Loading Dataset info from /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
Dataset({
    features: ['text'],
    num_rows: 500000
})
{'text': '[Buchvorstellung] Die Frau im hellblauen Kleid - BEATE MAXIAN - MonerlS-bunte-Welt\n[Buchvorstellung] Die Frau im hellblauen Kleid â€“ BEATE MAXIAN\n8. Dezember 2017 Monerl\n#166 Rezension\nWien. Marianne Altmann, einst ein gefeierter Filmstar, ist schockiert, als sie von PlÃ¤nen ihrer Tochter Vera erfÃ¤hrt. Diese mÃ¶chte einen Film Ã¼ber ihre Familie drehen. Marianne fÃ¼rchtet, dass nun auch die AbgrÃ¼nde der Familie ans Tageslicht kommen kÃ¶nnten, und mit ihnen ein lange\nzurÃ¼ckliegendes Vergehen. Es reicht zurÃ¼ck ins Jahr 1927, als ihre Mutter KÃ¤the in einem geliehenen Kleid am Theater vorsprach. Der Beginn einer beispiellosen Karriere â€“ und einer verhÃ¤ngnisvollen Bekanntschaft mit Hans Bleck, der zum mÃ¤chtigen Produzenten der Ufa aufsteigen sollte â€¦\nEine Familiengeschichte Ã¼ber vier Generationen, von Ur-GroÃŸmutter zur Enkelin, verwoben mit tiefen Geheimnissen, beginnend in Wien, als 1927 das MÃ¤dchen KÃ¤the den Mut aufbrachte, sich ihren Traum zu erfÃ¼llen.\nEs versprach eine spannende Familiengeschichte zu werden. Vier Frauen, die sich vom Schicksal, das der 2. Weltkrieg Ã¼ber sie gebracht hat, nicht von ihrem Weg haben abbringen lassen und letztendlich eine Schauspieler-Dynastie begrÃ¼ndeten, wie es in Ã–sterreich vorher keine gegeben hat. Dabei kommt einiges ans Licht, das lange Zeit verborgen geblieben war.\nDer Rahmen des Romans ist sehr gelungen. Leider schafft es Beate Maxian aber nicht, ihre Geschichte sprachlich so umzusetzten, das man von ihr durchweg gefesselt ist. Der ErzÃ¤hl- und Schreibstil ist sehr unrund. Oftmals wunderte ich mich Ã¼ber holprige und flache Dialoge. Inhaltlich enthÃ¼llten sie ein groÃŸes Geheimnis, doch Beate Maxians Charaktere nahmen dies einfach an ohne eine gewichtige EmotionalitÃ¤t, dich ich von den Figuren zur jeweiligen EnthÃ¼llung erwartet hÃ¤tte. Somit wuchs zunehmend meine Distanz zu den Protagonistinnen. Ich konnte nicht mit ihnen fÃ¼hlen, "sah" ihnen lediglich kopfschÃ¼ttelnd zu.\nDas Beziehungs-Hin-und-Her von Sophie, der letzten in der Reihe der "Altmann-Frauen", das groÃŸe Herzschmerzdrama und eine andauernde Sturheit ohne Einsicht, zerrte mehr und mehr an meinen Nerven. Die stÃ¤ndigen Wiederholungen zu Marianne, wie "Diva" und "betagte Dame", Ã¼ber die ich vermehrt stolperte, stÃ¶rten meinen Lesefluss. Ich hangelte mich von Kapitel zu Kapitel und freute mich immer auf ein Kapitel zur Vergangenheit, das Ã¼ber KÃ¤the, die Ur-GroÃŸmutter, berichtete. Diese RÃ¼ckblicke in die Vergangenheit waren es, die die Spannung aufrecht hielten und mich bis zum Ende haben durchhalten lassen.\nNach Beendigung der LektÃ¼re denke ich, hÃ¤tte sich die Autorin ausschlieÃŸlich auf die historische Geschichte eingelassen, wÃ¤re ihr wahrscheinlich ein sehr guter Roman gelungen. Denn dieser ErzÃ¤hlstrang war gut recherchiert, mit einer wundervollen und fÃ¼r sich einnehmenden Protagonistin ausgearbeitet und einer Liebesgeschichte, die viel Potential gehabt hÃ¤tte. So wÃ¤re auch der Konflikt mit und von Jakob, der Jude war, noch besser zur Geltung gekommen und es wÃ¤ren die Emotionen und Erwartungen des Lesers, die das wunderschÃ¶ne Cover geweckt hatte, erfÃ¼llt worden.\nEin thematisch sehr interessantes Buch, mit einem tollen Handlungsumfeld, spannenden Geheimnissen und vielversprechenden Charakteren, das leider an der Umsetzung scheiterte.\nIch danke dem Heyne Verlag, der mir freundlicherweise dieses Buch als Rezensionsexemplar zur VerfÃ¼gung gestellt hat.\nBeate Maxian Familiensaga Flop Heyne Verlag Ã–sterreich Rezension Rezensionsexemplar Wien\nPrevious Post Buchvorstellung â€“ Das Fundament der Ewigkeit â€“ KEN FOLLETT\nNext Post [Buchvorstellung] Das Geheimnis des Kalligraphen â€“ RAFIK SCHAMI\nIch schau ja bei solchen BÃ¼chern nach den Kritiken, um zu erfahren, ob es was fÃ¼r meine Mutter wÃ¤re. Die liest nÃ¤mlich eher diese Richtung, aber das hier kann ich wohl streichen ðŸ˜‰\n16. Dezember 2017 um 13:33 Uhr\nHey,Wenn du dich so bei den Rezis zu dem Buch umhÃ¶rst, wirst du sehen, dass meine eher schlechte Meinung nicht so durchschnittlich ist. Die meisten waren von dem Buch sehr begeistert. Ich kenne deine Mutte jetzt nicht, ich hoffe, damit entgeht ihr nicht eine Geschichte, die ihr gefallen hÃ¤tte. ðŸ˜‰ :-PGlG, monerl\n21. Dezember 2017 um 9:57 Uhr\nAlso wenn ich deine Kritikpunkte so sehe, dann bleib ich bei meiner Entscheidung ðŸ˜› In der Hinsicht weiÃŸ ich dann doch, was sie mag bzw wir sind uns da recht Ã¤hnlich.\n8. Dezember 2017 um 21:41 Uhr\nHallo liebe Andrea,ja, ich hatte mir viel von diesem Buch versprochen! Wenn deine Mama solche Geschichten liebt, dann empfehle ich dir die von TERESA SIMON oder auch BEATE RÃ–SLER z.B., siehe meine Rezis zu den BÃ¼cher der Autorinnen! Die sind klasse!GlG, monerl\nHallo liebes Monerl,der Klappentext hÃ¶rt sich ja sehr interessant an und lÃ¤sst viel erhoffen, aber da Du nicht wirklich von dem Buch Ã¼berzeugt bist, werde ich das als Geschenk ausschlieÃŸen. Meine Mutter mag gerne solche BÃ¼cher und wÃ¤re natÃ¼rlich fÃ¼r Weihnachten perfekt gewesen. Dann werde ich mich noch ein wenig umsehen. Herzlichen Dank fÃ¼r die Rezi. Liebe GrÃ¼ÃŸeAndrae\nLiebe monerl,"Hitorische Geschichte" â€“ kommt es mir nur so vor oder gibt es derzeit vermehrt derartige Geschichten, die in dieser Zeit spielen? Manchmal habe ich das GefÃ¼hl, es ist besser, eine Biografie aus dieser Zeit zu lesen. Danke fÃ¼r die ehrliche EinschÃ¤tzung.Liebe GrÃ¼ÃŸe, Anne\nLiebe Anne,ja, da hast du gar nicht Unrecht. Manch Biografie kann einem historisch die Zeit viel nÃ¤her bringen. Es gibt sehr gute Romane aus der Zeit. Ich kann jetzt gar nicht sagen, dass mir aufgefallen wÃ¤re, dass es zurzeit vermehrt Geschichten aus dieser Zeit gibt. Ich lese ja breit gefÃ¤chert und bin nicht immer im Bilde. Aber zu viele gleiche Geschichten stehen sich gegenseitig im Weg.GlG vom monerl'}
Process #0 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00000_of_00016.arrow
Process #1 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00001_of_00016.arrow
Process #2 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00002_of_00016.arrow
Process #3 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00003_of_00016.arrow
Process #4 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00004_of_00016.arrow
Process #5 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00005_of_00016.arrow
Process #6 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00006_of_00016.arrow
Process #7 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00007_of_00016.arrow
Process #8 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00008_of_00016.arrow
Process #9 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00009_of_00016.arrow
Process #10 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00010_of_00016.arrow
Process #11 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00011_of_00016.arrow
Process #12 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00012_of_00016.arrow
Process #13 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00013_of_00016.arrow
Process #14 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00014_of_00016.arrow
Process #15 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00015_of_00016.arrow
Spawning 16 processes
Converting format of dataset (num_proc=16):   0%|          | 0/500000 [00:00<?, ? examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00015_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00012_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00003_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00008_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00014_of_00016.arrow
Converting format of dataset (num_proc=16):   0%|          | 1000/500000 [00:02<16:45, 496.41 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00002_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00011_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00009_of_00016.arrow
Converting format of dataset (num_proc=16):   2%|â–         | 8000/500000 [00:02<01:36, 5072.74 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00000_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00001_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00006_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00007_of_00016.arrow
Converting format of dataset (num_proc=16):   2%|â–         | 12000/500000 [00:02<01:39, 4918.52 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00010_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00004_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00013_of_00016.arrow
Converting format of dataset (num_proc=16):   3%|â–Ž         | 15000/500000 [00:03<01:25, 5691.79 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-5a147656324420cc_00005_of_00016.arrow
Converting format of dataset (num_proc=16):   3%|â–Ž         | 17000/500000 [00:03<01:25, 5629.38 examples/s]Converting format of dataset (num_proc=16):   4%|â–         | 21000/500000 [00:03<00:56, 8449.74 examples/s]Converting format of dataset (num_proc=16):   5%|â–         | 24000/500000 [00:04<01:09, 6811.81 examples/s]Converting format of dataset (num_proc=16):   5%|â–Œ         | 26000/500000 [00:05<01:28, 5341.12 examples/s]Converting format of dataset (num_proc=16):   6%|â–Œ         | 28000/500000 [00:05<01:17, 6052.46 examples/s]Converting format of dataset (num_proc=16):   6%|â–‹         | 32000/500000 [00:05<00:57, 8154.62 examples/s]Converting format of dataset (num_proc=16):   7%|â–‹         | 34000/500000 [00:05<00:50, 9294.12 examples/s]Converting format of dataset (num_proc=16):   7%|â–‹         | 37000/500000 [00:06<01:26, 5342.00 examples/s]Converting format of dataset (num_proc=16):   8%|â–Š         | 40000/500000 [00:07<01:15, 6118.72 examples/s]Converting format of dataset (num_proc=16):   8%|â–Š         | 42000/500000 [00:07<01:13, 6219.25 examples/s]Converting format of dataset (num_proc=16):   9%|â–‰         | 44000/500000 [00:07<01:13, 6222.41 examples/s]Converting format of dataset (num_proc=16):   9%|â–‰         | 47000/500000 [00:07<01:00, 7501.74 examples/s]Converting format of dataset (num_proc=16):  10%|â–ˆ         | 50000/500000 [00:08<00:50, 8974.43 examples/s]Converting format of dataset (num_proc=16):  10%|â–ˆ         | 52000/500000 [00:08<00:45, 9881.44 examples/s]Converting format of dataset (num_proc=16):  11%|â–ˆ         | 54000/500000 [00:09<01:25, 5239.84 examples/s]Converting format of dataset (num_proc=16):  11%|â–ˆ         | 55000/500000 [00:09<01:20, 5561.97 examples/s]Converting format of dataset (num_proc=16):  11%|â–ˆ         | 56000/500000 [00:09<01:28, 5044.09 examples/s]Converting format of dataset (num_proc=16):  11%|â–ˆâ–        | 57000/500000 [00:09<01:20, 5475.51 examples/s]Converting format of dataset (num_proc=16):  12%|â–ˆâ–        | 59000/500000 [00:09<01:10, 6299.55 examples/s]Converting format of dataset (num_proc=16):  12%|â–ˆâ–        | 62000/500000 [00:10<00:47, 9213.40 examples/s]Converting format of dataset (num_proc=16):  13%|â–ˆâ–Ž        | 64000/500000 [00:10<00:53, 8212.36 examples/s]Converting format of dataset (num_proc=16):  13%|â–ˆâ–Ž        | 66000/500000 [00:10<00:50, 8556.48 examples/s]Converting format of dataset (num_proc=16):  14%|â–ˆâ–Ž        | 68000/500000 [00:10<00:47, 9126.06 examples/s]Converting format of dataset (num_proc=16):  14%|â–ˆâ–        | 70000/500000 [00:11<01:01, 6997.52 examples/s]Converting format of dataset (num_proc=16):  14%|â–ˆâ–        | 71000/500000 [00:11<01:36, 4441.14 examples/s]Converting format of dataset (num_proc=16):  15%|â–ˆâ–        | 74000/500000 [00:12<01:21, 5230.95 examples/s]Converting format of dataset (num_proc=16):  16%|â–ˆâ–Œ        | 81000/500000 [00:12<00:38, 10839.59 examples/s]Converting format of dataset (num_proc=16):  17%|â–ˆâ–‹        | 83000/500000 [00:13<01:04, 6482.81 examples/s] Converting format of dataset (num_proc=16):  17%|â–ˆâ–‹        | 86000/500000 [00:13<01:04, 6416.51 examples/s]Converting format of dataset (num_proc=16):  18%|â–ˆâ–Š        | 88000/500000 [00:13<00:56, 7286.63 examples/s]Converting format of dataset (num_proc=16):  18%|â–ˆâ–Š        | 91000/500000 [00:13<00:43, 9476.23 examples/s]Converting format of dataset (num_proc=16):  19%|â–ˆâ–Š        | 93000/500000 [00:14<00:49, 8214.15 examples/s]Converting format of dataset (num_proc=16):  19%|â–ˆâ–‰        | 95000/500000 [00:14<00:51, 7927.10 examples/s]Converting format of dataset (num_proc=16):  19%|â–ˆâ–‰        | 97000/500000 [00:15<01:02, 6407.19 examples/s]Converting format of dataset (num_proc=16):  20%|â–ˆâ–‰        | 98000/500000 [00:15<00:59, 6773.90 examples/s]Converting format of dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 101000/500000 [00:15<00:43, 9162.67 examples/s]Converting format of dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 103000/500000 [00:15<00:44, 8983.86 examples/s]Converting format of dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 105000/500000 [00:16<01:07, 5823.38 examples/s]Converting format of dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 106000/500000 [00:16<01:09, 5655.82 examples/s]Converting format of dataset (num_proc=16):  21%|â–ˆâ–ˆâ–       | 107000/500000 [00:16<01:20, 4893.39 examples/s]Converting format of dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 110000/500000 [00:16<00:54, 7156.10 examples/s]Converting format of dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 113000/500000 [00:17<01:13, 5285.92 examples/s]Converting format of dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 114000/500000 [00:17<01:08, 5643.95 examples/s]Converting format of dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 116000/500000 [00:18<01:04, 5959.78 examples/s]Converting format of dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 117000/500000 [00:18<01:05, 5828.16 examples/s]Converting format of dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 119000/500000 [00:18<00:56, 6747.60 examples/s]Converting format of dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 120000/500000 [00:18<00:53, 7066.25 examples/s]Converting format of dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 121000/500000 [00:19<01:21, 4662.01 examples/s]Converting format of dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 122000/500000 [00:19<01:26, 4349.16 examples/s]Converting format of dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 125000/500000 [00:19<00:51, 7306.81 examples/s]Converting format of dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 128000/500000 [00:19<00:46, 8018.99 examples/s]Converting format of dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 130000/500000 [00:19<00:39, 9388.50 examples/s]Converting format of dataset (num_proc=16):  26%|â–ˆâ–ˆâ–‹       | 132000/500000 [00:20<00:51, 7189.87 examples/s]Converting format of dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 133000/500000 [00:20<01:13, 4988.09 examples/s]Converting format of dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 134000/500000 [00:21<01:07, 5400.54 examples/s]Converting format of dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 136000/500000 [00:21<00:55, 6600.22 examples/s]Converting format of dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 137000/500000 [00:21<00:51, 7050.00 examples/s]Converting format of dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 138000/500000 [00:21<00:49, 7254.67 examples/s]Converting format of dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 140000/500000 [00:21<00:37, 9566.26 examples/s]Converting format of dataset (num_proc=16):  29%|â–ˆâ–ˆâ–Š       | 143000/500000 [00:21<00:27, 12750.93 examples/s]Converting format of dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 145000/500000 [00:21<00:25, 13842.10 examples/s]Converting format of dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 147000/500000 [00:23<01:30, 3904.51 examples/s] Converting format of dataset (num_proc=16):  30%|â–ˆâ–ˆâ–‰       | 149000/500000 [00:23<01:14, 4685.72 examples/s]Converting format of dataset (num_proc=16):  30%|â–ˆâ–ˆâ–ˆ       | 151000/500000 [00:23<00:59, 5875.22 examples/s]Converting format of dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 153000/500000 [00:23<00:54, 6390.85 examples/s]Converting format of dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 155000/500000 [00:23<00:45, 7591.86 examples/s]Converting format of dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆâ–      | 157000/500000 [00:24<00:58, 5877.48 examples/s]Converting format of dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 159000/500000 [00:24<00:47, 7217.47 examples/s]Converting format of dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 161000/500000 [00:24<00:39, 8648.01 examples/s]Converting format of dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 163000/500000 [00:25<01:08, 4900.59 examples/s]Converting format of dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 166000/500000 [00:25<00:59, 5646.90 examples/s]Converting format of dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 169000/500000 [00:26<00:43, 7648.74 examples/s]Converting format of dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 171000/500000 [00:26<00:44, 7346.76 examples/s]Converting format of dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–      | 173000/500000 [00:26<00:56, 5769.55 examples/s]Converting format of dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177000/500000 [00:27<00:58, 5518.76 examples/s]Converting format of dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178000/500000 [00:27<00:58, 5509.67 examples/s]Converting format of dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180000/500000 [00:28<00:59, 5373.12 examples/s]Converting format of dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 182000/500000 [00:28<01:06, 4814.27 examples/s]Converting format of dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 184000/500000 [00:28<00:51, 6159.16 examples/s]Converting format of dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 186000/500000 [00:29<00:51, 6123.02 examples/s]Converting format of dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 187000/500000 [00:29<00:51, 6109.59 examples/s]Converting format of dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 189000/500000 [00:29<00:40, 7661.40 examples/s]Converting format of dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 191000/500000 [00:29<00:34, 8886.74 examples/s]Converting format of dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 193000/500000 [00:30<00:50, 6070.18 examples/s]Converting format of dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 195000/500000 [00:30<00:40, 7479.35 examples/s]Converting format of dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 197000/500000 [00:30<00:43, 7019.07 examples/s]Converting format of dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 198000/500000 [00:31<01:05, 4625.08 examples/s]Converting format of dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 199000/500000 [00:31<01:04, 4679.70 examples/s]Converting format of dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202000/500000 [00:31<00:38, 7676.31 examples/s]Converting format of dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204000/500000 [00:31<00:35, 8329.10 examples/s]Converting format of dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207000/500000 [00:31<00:26, 10860.56 examples/s]Converting format of dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209000/500000 [00:32<00:56, 5148.78 examples/s] Converting format of dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211000/500000 [00:33<01:10, 4120.71 examples/s]Converting format of dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 213000/500000 [00:33<01:00, 4733.00 examples/s]Converting format of dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 216000/500000 [00:33<00:41, 6861.88 examples/s]Converting format of dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 218000/500000 [00:34<00:43, 6488.18 examples/s]Converting format of dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220000/500000 [00:34<00:35, 7871.84 examples/s]Converting format of dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222000/500000 [00:34<00:30, 9022.16 examples/s]Converting format of dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224000/500000 [00:34<00:34, 8096.97 examples/s]Converting format of dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226000/500000 [00:35<00:50, 5389.09 examples/s]Converting format of dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228000/500000 [00:35<00:39, 6818.88 examples/s]Converting format of dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230000/500000 [00:35<00:32, 8302.43 examples/s]Converting format of dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232000/500000 [00:35<00:32, 8124.88 examples/s]Converting format of dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234000/500000 [00:36<00:39, 6765.55 examples/s]Converting format of dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235000/500000 [00:36<00:55, 4811.00 examples/s]Converting format of dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 236000/500000 [00:37<01:14, 3564.27 examples/s]Converting format of dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238000/500000 [00:37<00:58, 4483.50 examples/s]Converting format of dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241000/500000 [00:37<00:37, 6954.58 examples/s]Converting format of dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243000/500000 [00:38<00:34, 7499.78 examples/s]Converting format of dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245000/500000 [00:38<00:36, 6911.28 examples/s]Converting format of dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247000/500000 [00:38<00:32, 7870.39 examples/s]Converting format of dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249000/500000 [00:38<00:28, 8903.58 examples/s]Converting format of dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251000/500000 [00:39<00:42, 5859.26 examples/s]Converting format of dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252000/500000 [00:39<00:57, 4303.97 examples/s]Converting format of dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253000/500000 [00:39<00:52, 4730.46 examples/s]Converting format of dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255000/500000 [00:40<00:38, 6413.83 examples/s]Converting format of dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258000/500000 [00:40<00:29, 8074.36 examples/s]Converting format of dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260000/500000 [00:41<00:45, 5288.14 examples/s]Converting format of dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 263000/500000 [00:41<00:34, 6868.23 examples/s]Converting format of dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 265000/500000 [00:41<00:30, 7657.07 examples/s]Converting format of dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 267000/500000 [00:42<00:43, 5340.88 examples/s]Converting format of dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272000/500000 [00:42<00:32, 7102.70 examples/s]Converting format of dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 274000/500000 [00:43<00:35, 6299.91 examples/s]Converting format of dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 275000/500000 [00:43<00:34, 6468.54 examples/s]Converting format of dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276000/500000 [00:43<00:44, 4992.83 examples/s]Converting format of dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278000/500000 [00:43<00:36, 6099.07 examples/s]Converting format of dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280000/500000 [00:44<00:37, 5904.05 examples/s]Converting format of dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282000/500000 [00:44<00:30, 7259.40 examples/s]Converting format of dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283000/500000 [00:44<00:31, 6871.32 examples/s]Converting format of dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286000/500000 [00:45<00:35, 6013.05 examples/s]Converting format of dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289000/500000 [00:45<00:24, 8623.57 examples/s]Converting format of dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291000/500000 [00:45<00:22, 9173.99 examples/s]Converting format of dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293000/500000 [00:45<00:23, 8892.38 examples/s]Converting format of dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295000/500000 [00:46<00:32, 6363.34 examples/s]Converting format of dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299000/500000 [00:46<00:19, 10168.03 examples/s]Converting format of dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301000/500000 [00:47<00:34, 5798.38 examples/s] Converting format of dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303000/500000 [00:47<00:41, 4699.21 examples/s]Converting format of dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305000/500000 [00:48<00:39, 4898.18 examples/s]Converting format of dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 306000/500000 [00:48<00:36, 5260.09 examples/s]Converting format of dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307000/500000 [00:48<00:35, 5471.08 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308000/500000 [00:48<00:33, 5660.41 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309000/500000 [00:48<00:30, 6173.01 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311000/500000 [00:48<00:27, 6943.64 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312000/500000 [00:48<00:26, 7070.32 examples/s]Converting format of dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 313000/500000 [00:49<00:33, 5569.47 examples/s]Converting format of dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 316000/500000 [00:49<00:25, 7333.50 examples/s]Converting format of dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 318000/500000 [00:49<00:22, 8159.23 examples/s]Converting format of dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319000/500000 [00:49<00:23, 7861.41 examples/s]Converting format of dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320000/500000 [00:49<00:22, 7950.13 examples/s]Converting format of dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 323000/500000 [00:50<00:19, 9222.57 examples/s]Converting format of dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324000/500000 [00:50<00:27, 6401.06 examples/s]Converting format of dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326000/500000 [00:50<00:26, 6667.79 examples/s]Converting format of dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328000/500000 [00:51<00:31, 5544.17 examples/s]Converting format of dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330000/500000 [00:51<00:23, 7120.91 examples/s]Converting format of dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331000/500000 [00:51<00:23, 7294.61 examples/s]Converting format of dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334000/500000 [00:51<00:15, 10721.91 examples/s]Converting format of dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336000/500000 [00:52<00:23, 7062.34 examples/s] Converting format of dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 339000/500000 [00:53<00:42, 3832.17 examples/s]Converting format of dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342000/500000 [00:53<00:29, 5321.24 examples/s]Converting format of dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 344000/500000 [00:53<00:26, 5983.63 examples/s]Converting format of dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346000/500000 [00:54<00:23, 6647.03 examples/s]Converting format of dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348000/500000 [00:54<00:21, 6970.91 examples/s]Converting format of dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349000/500000 [00:54<00:22, 6838.85 examples/s]Converting format of dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352000/500000 [00:54<00:19, 7736.90 examples/s]Converting format of dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353000/500000 [00:55<00:18, 7796.70 examples/s]Converting format of dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354000/500000 [00:55<00:28, 5138.64 examples/s]Converting format of dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355000/500000 [00:55<00:31, 4570.95 examples/s]Converting format of dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357000/500000 [00:56<00:26, 5451.50 examples/s]Converting format of dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361000/500000 [00:56<00:20, 6797.86 examples/s]Converting format of dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362000/500000 [00:56<00:20, 6778.51 examples/s]Converting format of dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 364000/500000 [00:56<00:16, 8214.08 examples/s]Converting format of dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 365000/500000 [00:57<00:19, 7057.07 examples/s]Converting format of dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 367000/500000 [00:57<00:21, 6120.92 examples/s]Converting format of dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369000/500000 [00:58<00:27, 4820.23 examples/s]Converting format of dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371000/500000 [00:58<00:28, 4462.58 examples/s]Converting format of dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372000/500000 [00:58<00:28, 4514.83 examples/s]Converting format of dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 374000/500000 [00:58<00:20, 6035.02 examples/s]Converting format of dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379000/500000 [00:59<00:10, 11252.62 examples/s]Converting format of dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381000/500000 [00:59<00:18, 6406.39 examples/s] Converting format of dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383000/500000 [01:00<00:17, 6565.04 examples/s]Converting format of dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385000/500000 [01:00<00:18, 6087.01 examples/s]Converting format of dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386000/500000 [01:00<00:20, 5554.58 examples/s]Converting format of dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389000/500000 [01:01<00:16, 6572.53 examples/s]Converting format of dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391000/500000 [01:01<00:13, 7910.91 examples/s]Converting format of dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393000/500000 [01:01<00:12, 8238.73 examples/s]Converting format of dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395000/500000 [01:01<00:11, 8833.38 examples/s]Converting format of dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397000/500000 [01:01<00:13, 7611.26 examples/s]Converting format of dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398000/500000 [01:01<00:12, 7932.13 examples/s]Converting format of dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399000/500000 [01:02<00:14, 6796.39 examples/s]Converting format of dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400000/500000 [01:02<00:16, 6053.77 examples/s]Converting format of dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402000/500000 [01:02<00:14, 6826.54 examples/s]Converting format of dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403000/500000 [01:02<00:14, 6793.88 examples/s]Converting format of dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405000/500000 [01:03<00:26, 3617.46 examples/s]Converting format of dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406000/500000 [01:03<00:22, 4183.68 examples/s]Converting format of dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407000/500000 [01:04<00:22, 4150.10 examples/s]Converting format of dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408000/500000 [01:04<00:23, 3973.05 examples/s]Converting format of dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410000/500000 [01:04<00:15, 5752.87 examples/s]Converting format of dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411000/500000 [01:04<00:15, 5647.77 examples/s]Converting format of dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 413000/500000 [01:04<00:12, 7130.35 examples/s]Converting format of dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 415000/500000 [01:05<00:09, 9206.15 examples/s]Converting format of dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 417000/500000 [01:05<00:08, 9397.00 examples/s]Converting format of dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419000/500000 [01:05<00:09, 8614.92 examples/s]Converting format of dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421000/500000 [01:05<00:12, 6431.23 examples/s]Converting format of dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423000/500000 [01:06<00:11, 6949.06 examples/s]Converting format of dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425000/500000 [01:06<00:10, 7164.40 examples/s]Converting format of dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426000/500000 [01:06<00:10, 7198.92 examples/s]Converting format of dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 427000/500000 [01:06<00:10, 7173.54 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428000/500000 [01:06<00:09, 7630.25 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429000/500000 [01:07<00:10, 6657.33 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430250/500000 [01:07<00:10, 6814.45 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 431250/500000 [01:07<00:18, 3730.18 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432250/500000 [01:07<00:15, 4486.56 examples/s]Converting format of dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433250/500000 [01:08<00:20, 3227.91 examples/s]Converting format of dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 434250/500000 [01:08<00:18, 3636.69 examples/s]Converting format of dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438250/500000 [01:08<00:08, 6962.89 examples/s]Converting format of dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441500/500000 [01:09<00:05, 10355.01 examples/s]Converting format of dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443250/500000 [01:09<00:05, 10694.61 examples/s]Converting format of dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445250/500000 [01:09<00:06, 8533.68 examples/s] Converting format of dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447250/500000 [01:10<00:08, 6102.78 examples/s]Converting format of dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451250/500000 [01:10<00:05, 9105.14 examples/s]Converting format of dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453500/500000 [01:10<00:05, 8651.61 examples/s]Converting format of dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 455500/500000 [01:10<00:04, 9520.17 examples/s]Converting format of dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 457500/500000 [01:11<00:06, 6971.19 examples/s]Converting format of dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459500/500000 [01:11<00:04, 8339.67 examples/s]Converting format of dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461500/500000 [01:11<00:05, 7564.95 examples/s]Converting format of dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 463750/500000 [01:11<00:04, 8221.25 examples/s]Converting format of dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 465750/500000 [01:12<00:04, 7343.07 examples/s]Converting format of dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 466750/500000 [01:12<00:04, 7406.30 examples/s]Converting format of dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 467750/500000 [01:12<00:04, 7367.01 examples/s]Converting format of dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468750/500000 [01:13<00:07, 3916.42 examples/s]Converting format of dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477000/500000 [01:14<00:03, 6218.30 examples/s]Converting format of dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478000/500000 [01:14<00:03, 5629.73 examples/s]Converting format of dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480000/500000 [01:14<00:02, 6715.20 examples/s]Converting format of dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 481250/500000 [01:14<00:02, 7297.07 examples/s]Converting format of dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483250/500000 [01:14<00:02, 7857.99 examples/s]Converting format of dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484500/500000 [01:15<00:01, 8335.35 examples/s]Converting format of dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486500/500000 [01:15<00:01, 8780.60 examples/s]Converting format of dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488500/500000 [01:15<00:01, 10155.18 examples/s]Converting format of dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490500/500000 [01:15<00:00, 11447.94 examples/s]Converting format of dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492750/500000 [01:16<00:01, 5124.49 examples/s] Converting format of dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495000/500000 [01:16<00:00, 5238.31 examples/s]Converting format of dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496000/500000 [01:17<00:00, 4516.10 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498000/500000 [01:17<00:00, 5807.00 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499250/500000 [01:17<00:00, 5767.43 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499500/500000 [01:32<00:00, 5767.43 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499500/500000 [01:33<00:02, 247.27 examples/s] Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499750/500000 [01:37<00:01, 198.77 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500000/500000 [01:38<00:00, 5098.24 examples/s]
Concatenating 16 shards
04/18/2024 15:44:55 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ar_2b.jsonl.
Using custom data configuration default-267d30c74527a6d3
Loading Dataset Infos from /home/nfs02/anaconda3/envs/wzjsz/lib/python3.10/site-packages/datasets/packaged_modules/json
Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
Found cached dataset json (/home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)
Loading Dataset info from /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
Dataset({
    features: ['text'],
    num_rows: 500000
})
{'text': 'ØºØµÙ† Ø§Ù„Ø²ÙŠØªÙˆÙ† ÙˆØ§Ù„Ø¨Ù†Ø¯Ù‚ÙŠØ© // ANONYMOUS â€” Ø¬ÙØª Ø§Ù„Ø£Ù‚Ù„Ø§Ù…\nØºØµÙ† Ø§Ù„Ø²ÙŠØªÙˆÙ† ÙˆØ§Ù„Ø¨Ù†Ø¯Ù‚ÙŠØ© // ANONYMOUS\nAugust 08, 2014 in INTERVIEW, TEXT\nØ¥Ø³ØªÙŠÙ‚Ø¸ Ø±Ø¤ÙˆÙ Ù…Ù† Ø³Ø¨Ø§ØªÙ‡ Ø¹Ù„Ù‰ ØµÙˆØª ØµÙØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø±. ÙˆÙ„ÙƒÙ† Ù…Ù† Ø£ÙŠÙ† Ø£ØªØªØŸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØµÙØ§Ø±Ø§Øª Ø¥Ù†Ø°Ø§Ø± ÙÙŠ Ø§Ù„Ø£Ø­ÙŠØ§Ø¡ Ø§Ù„ÙÙ‚ÙŠØ±Ø© Ø§Ù„ØªÙŠ ØªÙ‚Ø¹ Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø§Ø¦Ø· Ø§Ù„Ø¹Ø§Ø²Ù„.\nØ¥ØªØ¶Ø­ Ù„Ø±Ø¤ÙˆÙØŒ ÙˆÙ‡Ùˆ ÙÙŠ Ø­Ø§Ù„Ø© Ø¨ÙŠÙ† Ø§Ù„Ù†ÙˆÙ… Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆØ§Ù„ÙŠÙ‚Ø¸Ø© Ø§Ù„Ø´Ø¯ÙŠØ¯Ø©ØŒ Ø£Ù† ØµÙØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø± Ù‡ÙŠ ØµÙˆØª Ø£Ù…Ù‡ ÙˆÙ‡ÙŠ ØªÙ†Ø§Ø¯ÙŠ:\n"Ø±Ø¤ÙˆÙ!\nÙŠØ§ Ø±Ø¤ÙˆÙ!\nÙ‚ØµÙ! Ù‚ØµÙ! Ù‚Øµ-\nÙ‚Ø¨Ù„ Ø£Ù† ØªØ³ØªØ·ÙŠØ¹ Ø£Ù† ØªÙƒÙ…Ù„ Ø£Ù… Ø±Ø¤ÙˆÙ ÙƒÙ„Ø§Ù…Ù‡Ø§ ØŒ Ø³Ø§Ø¯ Ø§Ù„ØµÙ…Øª Ø¨Ø¹Ø¯ Ø£Ù† ÙˆÙ‚Ø¹ Ø¥Ù†ÙØ¬Ø§Ø± Ø¶Ø®Ù…ØŒ Ù…Ù† Ø³Ù…Ø¹Ù‡ Ù‚Ø¯ ÙŠØ¹ØªÙ‚Ø¯ Ø£Ù† Ø§Ù„Ù‡Ø²Ù‘Ø© Ø§Ù„ØªÙŠ Ø®Ù„ÙÙ‡Ø§ ÙˆØµÙ„Øª- Ø¨ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù‚Ù„- Ø±Ø§Ø¨Ø¹ Ø§Ù„Ø³Ù…Ø§ÙˆØ§Øª Ø§Ù„Ø³Ø¨Ø¹.\nÙƒØ§Ù† Ø±Ø¤ÙˆÙ ÙˆØ­ÙŠØ¯ Ø£Ù…Ù‡ ÙˆØ£Ø¨ÙŠÙ‡ØŒ ÙŠØ³ÙƒÙ† Ù…Ø¹Ù‡Ù…Ø§ ÙÙŠ Ø¨ÙŠØª Ø´Ø¯ÙŠØ¯ Ø§Ù„ØªÙˆØ§Ø¶Ø¹ ÙŠÙ‚Ø¹ Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø§Ø¦Ø· Ø§Ù„Ø¹Ø§Ø²Ù„. ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ù„Ùƒ Ø´Ø¬Ø±Ø© Ø²ÙŠØªÙˆÙ† ØªÙ‚Ø¹ ØªÙ…Ø§Ù…Ø§Ù‹ Ø£Ù…Ø§Ù… Ù†Ø§ÙØ°Ø© Ø¯ÙŠØ§Ø± Ø±Ø¤ÙˆÙØŒ Ù‚Ø¯ Ø²Ø±Ø¹Ù‡Ø§ Ø£Ø¨Ø§Ù‡ ÙŠÙˆÙ… Ø£Ø®Ø° Ø±Ø¤ÙˆÙ Ø£ÙˆÙ„ Ø¥Ø³ØªÙ†Ø´Ø§Ù‚Ø© Ù„Ù‡ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ù†ÙŠØ§ØŒ ÙŠÙˆÙ… ÙŠÙ‚Ø¹ ÙÙŠ Ø£ÙƒØ«Ø± Ø£ÙŠØ§Ù… Ø§Ù„Ø±Ø¨ÙŠØ¹ Ø±Ø¨ÙŠØ¹Ø§Ù‹.\nÙƒØ§Ù†Øª Ø§Ù„Ø±ÙŠØ§Ø­ØŒ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙŠÙˆÙ…ØŒ Ù„Ø·ÙŠÙØ© Ø¨Ø´Ø¯Ø©. Ø¨Ø±ÙˆØ¯ØªÙ‡Ø§ ØªÙ‚Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø±Ø¡ ÙƒØ§Ù„Ø¨Ø´Ø±Ù‰ Ø§Ù„Ø³Ø§Ø±Ø©ØŒ Ù„Ø§ ØªÙ‚Ø³Ùˆ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¸Ø§Ù… ÙˆÙ„Ø§ ÙŠÙ‚Ø´Ø¹Ø± Ù„Ù‡Ø§ Ø§Ù„Ø¨Ø¯Ù†.\nØ¥Ø³ØªÙŠÙ‚Ø¸ Ø±Ø¤ÙˆÙ Ù…Ù† Ø³Ø¨Ø§ØªÙ‡ØŒ ÙˆÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø© ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¨Ø§Øª Ù†ØªÙŠØ¬Ø© Ø¥Ù†Ù‡ÙŠØ§Ø± Ø¯ÙŠØ§Ø±Ù‡ Ø¹Ù„Ù‰ Ø±Ø£Ø³Ù‡. ØªÙÙ‚Ø¯ Ø£Ø¹Ø¶Ø§Ø¡ Ø¬Ø³Ù…Ù‡ ÙˆØ§ÙƒØªØ´Ù Ø£Ù†Ù‡Ø§ Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù…ØŒ Ù…Ù† Ø§Ù„Ù†Ø¸Ø±Ø© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„. Ù„Ù… ØªØ¨ØªØ± Ù„Ù‡ Ø³Ø§Ù‚ Ø£Ùˆ Ø°Ø±Ø§Ø¹ØŒ ÙˆÙ„Ø§ Ø²Ø§Ù„Øª Ø£ØµØ§Ø¨Ø¹Ù‡ ÙƒÙ„Ù‡Ø§ Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ø­ØªÙ‰ Ø§Ù„ØªÙŠ Ø¹Ù„Ù‰ Ø£Ù‚Ø¯Ø§Ù…Ù‡ Ø§Ù„Ø­Ø§ÙÙŠØ©. ÙƒØ§Ù† Ø§Ù„Ø®Ø¯Ø± Ù…Ù†ØªØ´Ø± ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø¬Ø³Ù…Ù‡ØŒ ÙŠØ®Ø·Ùˆ Ø®Ø·Ùˆ Ø§Ù„Ù†Ù…Ù„Ø© Ù…Ù† Ù‚Ù…Ø© Ø±Ø£Ø³Ù‡ Ø¥Ù„Ù‰ Ù†Ù‡Ø§ÙŠØ© Ø£Ø·Ø±Ø§Ù Ø£ØµØ§Ø¨Ø¹ Ù‚Ø¯Ù…ÙŠÙ‡. Ù„Ø­Ø¸Ø© Ø£Ù† Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ­Ø±Ù‘ÙƒØŒ Ø²Ø§Ù„ Ø§Ù„Ø®Ø¯Ø± ÙƒØ§Ù„Ù‚Ù…Ø§Ø´ Ø§Ù„Ø®ÙÙŠÙ Ø§Ù„Ø°ÙŠ ÙŠØ²Ø§Ù„ Ù…Ù† Ø¹Ù„Ù‰ ÙÙˆÙ‚ Ø§Ù„Ø·Ø§ÙˆÙ„Ø©ØŒ ÙˆØ¨Ø¹Ø« Ø¯Ù…Ø§ØºÙ‡ Ù„Ø¬Ø³Ù…Ù‡ ØµÙØ§Ø±Ø© Ø¥Ù†Ø°Ø§Ø± Ù…Ù† Ù†ÙˆØ¹ Ø¢Ø®Ø±ØŒ ÙƒØ§Ù†Øª Ù†ÙˆØ¹Ø§Ù‹ Ù…Ø§ ÙƒØµØ¹Ù‚Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¡ Ø§Ù„ØªÙŠ Ø¬Ø¹Ù„ØªÙ‡ ÙŠØªÙŠÙ‚Ù† Ø£Ù† Ø¨Ø¯Ù†Ù‡ Ù„ÙŠØ³ Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù….\nØ£Ø²Ø§Ø­ Ø§Ù„Ø£Ù†Ù‚Ø§Ø¶ Ù…Ù† ÙÙˆÙ‚Ù‡ ÙˆØ£Ø¯Ø§Ø± Ø¨Ù†Ø¸Ø±Ù‡ ÙŠÙ…ÙŠÙ†Ø§ Ø«Ù… Ø´Ù…Ø§Ù„ ØªØ¬Ø§Ù‡ Ø²ÙˆØ§ÙŠØ§ Ø§Ù„Ø¨ÙŠØª Ø§Ù„ØµØºÙŠØ±ØŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù…Ø§ ØªØ¨Ù‚Ù‰ Ù…Ù† Ø§Ù„Ø¨ÙŠØª Ø§Ù„ØµØºÙŠØ±ØŒ ÙˆÙ„Ù… ÙŠØ±Ù‰ ØºÙŠØ± Ø§Ù„Ø¸Ù„Ø§Ù…. ØªØ­ÙˆÙ„ Ø§Ù„Ø¨ÙŠØª Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ ÙˆØ¸Ù„ Ø­Ø§Ø¦Ø· ÙˆØ§Ø­Ø¯ Ù‡Ùˆ Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ø°ÙŠ Ù„Ø§ ÙŠØ²Ø§Ù„ ÙˆØ§Ù‚Ù Ø¹Ù„Ù‰ Ù‚Ø¯Ù…ÙŠÙ‡. Ø­Ø§ÙˆÙ„ Ø£Ù† ÙŠØ·Ù„Ù‚ Ù…Ù† Ø­Ù†Ø¬Ø±ØªÙ‡ ØµÙˆØªØ§Ù‹ ÙŠÙ†Ø§Ø¯ÙŠ Ø¨Ù‡ Ø£Ù…Ù‡ ÙˆØ£Ø¨Ø§Ù‡ØŒ ÙˆØ¹Ù†Ø¯Ù…Ø§ ØªØ­Ø±ÙƒØª Ø´ÙØªØ§Ù‡ØŒ Ø­Ø³Ù‘ Ø±Ø¤ÙˆÙ ÙÙ‚Ø· Ø¨Ø°Ø¨Ø°Ø¨Ø© ØµØ§Ù…ØªØ© Ø®ÙÙŠÙØ© ØªÙ†Ø¨Ø¹Ø« Ù…Ù† Ø­Ù†Ø¬Ø±ØªÙ‡ØŒ ÙˆØ¹Ù†Ø¯Ù‡Ø§ Ù„Ø§Ø­Ø¸ ÙƒÙŠÙ ÙƒØ§Ù† Ø§Ù„Ø³ÙƒÙˆØª ÙŠØ®Ù„Ø¯ Ø¨Ø«Ù‚Ù„ Ø´Ø¯ÙŠØ¯ ÙÙˆÙ‚ Ø³Ù…Ø¹Ù‡.\nØ¹Ø¨Ø± ÙÙˆÙ‚ Ø£Ù†Ù‚Ø§Ø¶ Ø³Ù‚Ù Ø¨ÙŠØªÙ‡ Ø§Ù„Ø°ÙŠ Ø¨Ø§Øª Ø§Ù„Ø¢Ù† ÙŠØªÙˆØ³Ù‘Ø¯ Ø§Ù„Ø£Ø±Ø¶ ØªØ­Øª Ù‚Ø¯Ù…ÙŠÙ‡ØŒ ÙˆØ¹Ù†Ø¯Ù‡Ø§ Ø®Ø·ÙØª Ø¹ÙŠÙ†Ù‡ Ù„Ù…Ø­Ø© Ø°Ø±Ø§Ø¹ Ù…Ø®Ù‘ØªÙ…Ø© Ø¨Ø®Ø§ØªÙ… Ù†Ø­Ø§Ø³ÙŠ Ù…Ø·Ù„ÙŠ Ø¨Ø§Ù„Ø°Ù‡Ø¨ØŒ Ù…Ù†Ø¨Ø¹Ø«Ø© Ù…Ù† Ø¨ÙŠÙ† Ø£Ù†Ù‚Ø§Ø¶Ù Ù…ØµÙÙˆÙØ© ÙÙˆÙ‚ Ø£Ù†Ù‚Ø§Ø¶. Ø­Ø³Ù‘ Ø±Ø¤ÙˆÙ Ø¨ÙˆØ®Ø²Ø© ÙÙŠ Ø­Ù†Ø¬Ø±ØªÙ‡ØŒ Ø£Ø®Ø°Øª Ø·Ø±ÙŠÙ‚Ù‡Ø§ Ù„Ù…Ù†ØªØµÙ ØµØ¯Ø±Ù‡ Ù…Ø¹ Ø¥Ø¨ØªÙ„Ø§Ø¹ Ø§Ù„Ø±ÙŠÙ‚. ØªØ­ÙˆÙ„Øª Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ®Ø²Ø© Ø¥Ù„Ù‰ Ø­Ø±Ø§Ø±Ø© Ø´Ø¯ÙŠØ¯Ø© ØªÙƒØ§Ø¯ Ø£Ù† ØªØ°ÙŠØ¨ Ø¬Ù„Ø¯Ù‡ ÙˆØªÙ†Ø¨Ø¹Ø« Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø¬Ø³Ù…Ù‡ Ø§Ù„Ù…ØºØ·Ù‰ Ø¨Ø§Ù„Ø¯Ù… ÙˆØ§Ù„ØºØ¨Ø§Ø± ÙˆØ§Ù„Ù…Ù„Ø§Ø¨Ø³ Ø§Ù„Ù…Ù…Ø²Ù‚Ø©.\nØ¥Ù„ØªÙØª Ø±Ø¤ÙˆÙ ÙˆØ±Ø£Ù‰ Ù…Ø³Ø¨Ø§Ø­ Ù…Ù„Ù‚Ù‰ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¶ØŒ ØºØ§Ø±Ù‚ ÙÙŠ Ø¨Ù‚Ø¹Ø© Ù…Ù† Ø§Ù„Ø¯Ù…ØŒ ÙˆØ­ÙŠÙ†Ù‡Ø§ Ø£Ø¯Ø±Ùƒ Ø£Ù† Ø£Ù…Ù‡ ÙˆØ£Ø¨Ø§Ù‡ Ù‚Ø¯ ÙØ§Ø±Ù‚Ø§Ù‡ ÙˆØ¥Ø±ØªØ­Ù„Ø§ Ø¥Ù„Ù‰ Ù…ÙƒØ§Ù† Ø¢Ø®Ø±ØŒ Ù…ÙƒØ§Ù† Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙÙŠÙ‡ ØµÙØ§Ø±Ø§Øª Ø¥Ù†Ø°Ø§Ø±ØŒ ÙˆÙ„Ø§ Ø­Ø§Ø¦Ø· Ø¹Ø§Ø²Ù„. ÙˆÙ‚Ù Ø£Ù…Ø§Ù… Ø§Ù„Ù†Ø¬Ù…ØªÙŠÙ† Ø§Ù„Ù‡Ø§ÙˆÙŠØªØ§Ù† Ø§Ù„Ù„ØªØ§Ù† ÙŠØºØ·ÙŠÙ‡Ù…Ø§ Ø§Ù„Ø³Ù‚Ù Ø§Ù„Ù…Ù†Ù‚Ø¶ØŒ Ø¨ØµÙ…Øª.\nÙˆØ¬Ø¯ Ø±Ø¤ÙˆÙ Ø±ÙØ´ ÙˆØ§Ù„Ø¯Ù‡ ÙÙŠ Ù…ÙƒØ§Ù† Ù…Ø§ ØªØ­Øª Ø§Ù„Ø£Ù†Ù‚Ø§Ø¶ØŒ ÙˆØ¨Ø¹Ø¯Ù…Ø§ Ø£ÙƒÙ…Ù„ Ø¯ÙÙ† ÙˆØ§Ù„Ø¯ÙŠÙ‡ØŒ Ø£Ø®Ø° ÙŠØ­ÙØ± Ø§Ù„Ø¨Ù‚Ø¹Ø© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© Ù„Ø´Ø¬Ø±Ø© Ø§Ù„Ø²ÙŠØªÙˆÙ†ØŒ Ø§Ù„ØªÙŠ Ù„Ù… ÙŠØªØ¨Ù‚Ù‰ Ù…Ù†Ù‡Ø§ Ø¥Ù„Ø§ ØºØµÙ† ÙˆØ§Ø­Ø¯. Ø¹Ù†Ø¯Ù…Ø§ Ø³Ù…Ø¹ ØµÙˆØª Ø§Ù„Ø±ÙØ´ ÙŠØµØ·Ø¯Ù… Ø¨Ø´ÙŠØ¡ Ù…Ø§ ØªØ­Øª Ø§Ù„ØªØ±Ø§Ø¨ØŒ Ø¨Ø¹Ø« ÙŠØ¯Ù‡ ÙÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­ÙØ±Ø© ÙˆØ¥Ø¬ØªØ« Ø§Ù„Ø¨Ù†Ø¯Ù‚ÙŠØ©. Ø£Ù…Ø³Ùƒ Ø¨ØºØµÙ† Ø§Ù„Ø²ÙŠØªÙˆÙ† ÙˆØ±Ù…Ø§Ù‡ ÙÙŠ Ø§Ù„Ù†ÙŠØ±Ø§Ù† Ø§Ù„ØªÙŠ Ø¥Ø´ØªØ¹Ù„Øª Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¶ÙˆØ¡ Ø§Ù„Ø°ÙŠ Ù‡ÙˆÙ‰ ÙÙˆÙ‚ Ø³Ù‚Ù Ø¯ÙŠØ§Ø±Ù‡ ÙˆØ£Ø³Ø±Ù‰ Ø¨Ø£Ù…Ù‡ ÙˆØ£Ø¨Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ø°ÙŠ ÙŠØ®Ù„Ùˆ Ù…Ù† ØµÙØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø±.'}
Process #0 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00000_of_00016.arrow
Process #1 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00001_of_00016.arrow
Process #2 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00002_of_00016.arrow
Process #3 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00003_of_00016.arrow
Process #4 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00004_of_00016.arrow
Process #5 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00005_of_00016.arrow
Process #6 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00006_of_00016.arrow
Process #7 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00007_of_00016.arrow
Process #8 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00008_of_00016.arrow
Process #9 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00009_of_00016.arrow
Process #10 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00010_of_00016.arrow
Process #11 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00011_of_00016.arrow
Process #12 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00012_of_00016.arrow
Process #13 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00013_of_00016.arrow
Process #14 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00014_of_00016.arrow
Process #15 will write at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00015_of_00016.arrow
Spawning 16 processes
Converting format of dataset (num_proc=16):   0%|          | 0/500000 [00:00<?, ? examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00006_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00011_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00014_of_00016.arrow
Converting format of dataset (num_proc=16):   0%|          | 1000/500000 [00:02<21:57, 378.83 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00003_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00004_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00008_of_00016.arrow
Converting format of dataset (num_proc=16):   1%|          | 6000/500000 [00:02<02:51, 2875.07 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00000_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00009_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00001_of_00016.arrow
Converting format of dataset (num_proc=16):   2%|â–         | 9000/500000 [00:03<01:59, 4109.51 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00012_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00010_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00007_of_00016.arrow
Converting format of dataset (num_proc=16):   2%|â–         | 11000/500000 [00:03<01:40, 4843.76 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00005_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00013_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00002_of_00016.arrow
Converting format of dataset (num_proc=16):   3%|â–Ž         | 15000/500000 [00:03<01:00, 7991.24 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-267d30c74527a6d3/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-a4e0437ddb529d28_00015_of_00016.arrow
Converting format of dataset (num_proc=16):   4%|â–Ž         | 18000/500000 [00:05<02:08, 3739.82 examples/s]Converting format of dataset (num_proc=16):   4%|â–         | 20000/500000 [00:05<01:49, 4371.15 examples/s]Converting format of dataset (num_proc=16):   4%|â–         | 22000/500000 [00:05<01:28, 5427.57 examples/s]Converting format of dataset (num_proc=16):   5%|â–         | 24000/500000 [00:05<01:18, 6039.66 examples/s]Converting format of dataset (num_proc=16):   5%|â–Œ         | 26000/500000 [00:05<01:08, 6953.94 examples/s]Converting format of dataset (num_proc=16):   6%|â–Œ         | 28000/500000 [00:06<01:02, 7522.68 examples/s]Converting format of dataset (num_proc=16):   6%|â–Œ         | 30000/500000 [00:06<01:40, 4655.63 examples/s]Converting format of dataset (num_proc=16):   6%|â–‹         | 32000/500000 [00:07<01:26, 5433.55 examples/s]Converting format of dataset (num_proc=16):   7%|â–‹         | 34000/500000 [00:07<01:09, 6660.02 examples/s]Converting format of dataset (num_proc=16):   7%|â–‹         | 36000/500000 [00:07<01:33, 4955.45 examples/s]Converting format of dataset (num_proc=16):   7%|â–‹         | 37000/500000 [00:08<01:31, 5077.12 examples/s]Converting format of dataset (num_proc=16):   8%|â–Š         | 39000/500000 [00:08<01:10, 6503.95 examples/s]Converting format of dataset (num_proc=16):   8%|â–Š         | 40000/500000 [00:08<01:12, 6352.34 examples/s]Converting format of dataset (num_proc=16):   8%|â–Š         | 41000/500000 [00:08<01:09, 6580.06 examples/s]Converting format of dataset (num_proc=16):   9%|â–Š         | 43000/500000 [00:08<00:59, 7679.96 examples/s]Converting format of dataset (num_proc=16):   9%|â–‰         | 44000/500000 [00:09<02:14, 3394.25 examples/s]Converting format of dataset (num_proc=16):   9%|â–‰         | 45000/500000 [00:09<02:10, 3481.59 examples/s]Converting format of dataset (num_proc=16):   9%|â–‰         | 47000/500000 [00:09<01:30, 5015.23 examples/s]Converting format of dataset (num_proc=16):  10%|â–‰         | 49000/500000 [00:10<01:22, 5437.76 examples/s]Converting format of dataset (num_proc=16):  10%|â–ˆ         | 50000/500000 [00:10<01:28, 5071.87 examples/s]Converting format of dataset (num_proc=16):  10%|â–ˆ         | 52000/500000 [00:10<01:05, 6843.67 examples/s]Converting format of dataset (num_proc=16):  11%|â–ˆ         | 53000/500000 [00:10<01:01, 7315.48 examples/s]Converting format of dataset (num_proc=16):  11%|â–ˆ         | 55000/500000 [00:10<00:48, 9267.13 examples/s]Converting format of dataset (num_proc=16):  11%|â–ˆâ–        | 57000/500000 [00:11<00:50, 8713.69 examples/s]Converting format of dataset (num_proc=16):  12%|â–ˆâ–        | 59000/500000 [00:11<01:12, 6051.45 examples/s]Converting format of dataset (num_proc=16):  12%|â–ˆâ–        | 60000/500000 [00:12<01:35, 4613.42 examples/s]Converting format of dataset (num_proc=16):  12%|â–ˆâ–        | 62000/500000 [00:12<01:55, 3801.12 examples/s]Converting format of dataset (num_proc=16):  13%|â–ˆâ–Ž        | 64000/500000 [00:13<01:39, 4373.69 examples/s]Converting format of dataset (num_proc=16):  13%|â–ˆâ–Ž        | 67000/500000 [00:13<01:29, 4832.71 examples/s]Converting format of dataset (num_proc=16):  14%|â–ˆâ–Ž        | 68000/500000 [00:13<01:26, 4968.94 examples/s]Converting format of dataset (num_proc=16):  14%|â–ˆâ–        | 69000/500000 [00:13<01:18, 5457.26 examples/s]Converting format of dataset (num_proc=16):  14%|â–ˆâ–        | 71000/500000 [00:14<01:25, 5015.42 examples/s]Converting format of dataset (num_proc=16):  15%|â–ˆâ–        | 73000/500000 [00:14<01:40, 4253.73 examples/s]Converting format of dataset (num_proc=16):  15%|â–ˆâ–Œ        | 75000/500000 [00:15<01:25, 4978.13 examples/s]Converting format of dataset (num_proc=16):  15%|â–ˆâ–Œ        | 77000/500000 [00:15<01:27, 4844.03 examples/s]Converting format of dataset (num_proc=16):  16%|â–ˆâ–Œ        | 78000/500000 [00:16<01:41, 4165.06 examples/s]Converting format of dataset (num_proc=16):  16%|â–ˆâ–Œ        | 79000/500000 [00:16<01:49, 3851.90 examples/s]Converting format of dataset (num_proc=16):  16%|â–ˆâ–Œ        | 81000/500000 [00:16<01:16, 5504.49 examples/s]Converting format of dataset (num_proc=16):  17%|â–ˆâ–‹        | 83000/500000 [00:16<01:02, 6696.11 examples/s]Converting format of dataset (num_proc=16):  17%|â–ˆâ–‹        | 84000/500000 [00:16<01:10, 5901.13 examples/s]Converting format of dataset (num_proc=16):  17%|â–ˆâ–‹        | 86000/500000 [00:17<01:44, 3975.64 examples/s]Converting format of dataset (num_proc=16):  18%|â–ˆâ–Š        | 88000/500000 [00:17<01:20, 5140.49 examples/s]Converting format of dataset (num_proc=16):  18%|â–ˆâ–Š        | 91000/500000 [00:18<01:08, 5974.39 examples/s]Converting format of dataset (num_proc=16):  18%|â–ˆâ–Š        | 92000/500000 [00:18<01:38, 4138.36 examples/s]Converting format of dataset (num_proc=16):  19%|â–ˆâ–Š        | 93000/500000 [00:19<01:29, 4554.33 examples/s]Converting format of dataset (num_proc=16):  19%|â–ˆâ–‰        | 95000/500000 [00:19<01:16, 5324.39 examples/s]Converting format of dataset (num_proc=16):  19%|â–ˆâ–‰        | 97000/500000 [00:19<01:33, 4314.75 examples/s]Converting format of dataset (num_proc=16):  20%|â–ˆâ–‰        | 99000/500000 [00:20<01:11, 5635.87 examples/s]Converting format of dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 101000/500000 [00:20<01:39, 3992.52 examples/s]Converting format of dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 102000/500000 [00:21<01:37, 4071.09 examples/s]Converting format of dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 103000/500000 [00:21<01:31, 4354.79 examples/s]Converting format of dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 104000/500000 [00:21<01:21, 4852.83 examples/s]Converting format of dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 105000/500000 [00:21<01:13, 5369.98 examples/s]Converting format of dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 106000/500000 [00:21<01:10, 5625.97 examples/s]Converting format of dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 108000/500000 [00:21<00:49, 7898.60 examples/s]Converting format of dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 110000/500000 [00:22<00:50, 7706.88 examples/s]Converting format of dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 112000/500000 [00:22<00:43, 8996.68 examples/s]Converting format of dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 114000/500000 [00:22<01:01, 6302.65 examples/s]Converting format of dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 115000/500000 [00:23<01:22, 4682.07 examples/s]Converting format of dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 116000/500000 [00:23<01:35, 4019.52 examples/s]Converting format of dataset (num_proc=16):  24%|â–ˆâ–ˆâ–Ž       | 118000/500000 [00:23<01:23, 4571.35 examples/s]Converting format of dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 119000/500000 [00:24<01:16, 4992.35 examples/s]Converting format of dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 121000/500000 [00:24<01:00, 6234.26 examples/s]Converting format of dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 122000/500000 [00:24<01:46, 3542.74 examples/s]Converting format of dataset (num_proc=16):  25%|â–ˆâ–ˆâ–       | 123000/500000 [00:25<01:30, 4147.14 examples/s]Converting format of dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 125000/500000 [00:25<01:57, 3194.21 examples/s]Converting format of dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 126000/500000 [00:25<01:40, 3737.93 examples/s]Converting format of dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 128000/500000 [00:26<01:28, 4221.03 examples/s]Converting format of dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 130000/500000 [00:26<01:16, 4834.25 examples/s]Converting format of dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 131000/500000 [00:26<01:13, 5038.49 examples/s]Converting format of dataset (num_proc=16):  26%|â–ˆâ–ˆâ–‹       | 132000/500000 [00:26<01:08, 5368.80 examples/s]Converting format of dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 134000/500000 [00:27<00:59, 6128.65 examples/s]Converting format of dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 135000/500000 [00:27<01:02, 5865.05 examples/s]Converting format of dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 137000/500000 [00:27<00:56, 6448.54 examples/s]Converting format of dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 138000/500000 [00:28<01:08, 5310.49 examples/s]Converting format of dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 139000/500000 [00:28<01:31, 3951.80 examples/s]Converting format of dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 140000/500000 [00:28<01:47, 3353.76 examples/s]Converting format of dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 141000/500000 [00:29<01:28, 4046.08 examples/s]Converting format of dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 142000/500000 [00:29<01:26, 4153.32 examples/s]Converting format of dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 145000/500000 [00:29<00:53, 6674.13 examples/s]Converting format of dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 146000/500000 [00:30<01:56, 3040.66 examples/s]Converting format of dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 147000/500000 [00:30<01:39, 3550.23 examples/s]Converting format of dataset (num_proc=16):  30%|â–ˆâ–ˆâ–‰       | 148000/500000 [00:31<02:08, 2744.18 examples/s]Converting format of dataset (num_proc=16):  30%|â–ˆâ–ˆâ–ˆ       | 150000/500000 [00:31<01:36, 3640.72 examples/s]Converting format of dataset (num_proc=16):  30%|â–ˆâ–ˆâ–ˆ       | 151000/500000 [00:31<01:33, 3740.74 examples/s]Converting format of dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 153000/500000 [00:31<01:06, 5217.27 examples/s]Converting format of dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 155000/500000 [00:32<00:58, 5948.28 examples/s]Converting format of dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 156000/500000 [00:32<00:53, 6471.09 examples/s]Converting format of dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 159000/500000 [00:32<00:38, 8764.73 examples/s]Converting format of dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 161000/500000 [00:33<01:05, 5187.21 examples/s]Converting format of dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 163000/500000 [00:33<00:56, 5937.57 examples/s]Converting format of dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 164000/500000 [00:34<01:47, 3125.97 examples/s]Converting format of dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 166000/500000 [00:34<01:29, 3720.27 examples/s]Converting format of dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 167000/500000 [00:35<01:51, 2980.30 examples/s]Converting format of dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 168000/500000 [00:35<01:35, 3481.32 examples/s]Converting format of dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 170000/500000 [00:36<01:30, 3654.61 examples/s]Converting format of dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 172000/500000 [00:36<01:06, 4935.07 examples/s]Converting format of dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–      | 174000/500000 [00:36<00:51, 6337.18 examples/s]Converting format of dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176000/500000 [00:36<00:44, 7207.34 examples/s]Converting format of dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177000/500000 [00:36<00:51, 6298.34 examples/s]Converting format of dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178000/500000 [00:37<01:45, 3055.96 examples/s]Converting format of dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179000/500000 [00:38<01:44, 3067.19 examples/s]Converting format of dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180000/500000 [00:38<01:36, 3313.80 examples/s]Converting format of dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 181000/500000 [00:38<01:24, 3794.07 examples/s]Converting format of dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 182000/500000 [00:38<01:21, 3908.91 examples/s]Converting format of dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 183000/500000 [00:38<01:30, 3500.50 examples/s]Converting format of dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 184000/500000 [00:39<01:20, 3924.24 examples/s]Converting format of dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 186000/500000 [00:39<00:52, 5968.47 examples/s]Converting format of dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 188000/500000 [00:39<00:45, 6797.89 examples/s]Converting format of dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 190000/500000 [00:39<00:40, 7636.04 examples/s]Converting format of dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 191000/500000 [00:40<01:09, 4457.17 examples/s]Converting format of dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 193000/500000 [00:40<01:00, 5040.58 examples/s]Converting format of dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 194000/500000 [00:41<01:24, 3613.76 examples/s]Converting format of dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 195000/500000 [00:41<01:59, 2555.83 examples/s]Converting format of dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 196000/500000 [00:42<01:50, 2759.94 examples/s]Converting format of dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 197000/500000 [00:42<01:31, 3301.46 examples/s]Converting format of dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 199000/500000 [00:42<01:02, 4831.34 examples/s]Converting format of dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 200000/500000 [00:42<00:58, 5147.90 examples/s]Converting format of dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202000/500000 [00:42<00:44, 6719.12 examples/s]Converting format of dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 203000/500000 [00:43<00:46, 6327.21 examples/s]Converting format of dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205000/500000 [00:43<00:37, 7807.32 examples/s]Converting format of dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206000/500000 [00:43<00:37, 7789.91 examples/s]Converting format of dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208000/500000 [00:43<00:55, 5276.86 examples/s]Converting format of dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209000/500000 [00:44<01:02, 4644.05 examples/s]Converting format of dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210000/500000 [00:44<00:54, 5280.45 examples/s]Converting format of dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211000/500000 [00:45<01:31, 3145.02 examples/s]Converting format of dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212000/500000 [00:45<02:03, 2329.05 examples/s]Converting format of dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 213000/500000 [00:46<01:49, 2609.14 examples/s]Converting format of dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 216000/500000 [00:46<01:03, 4488.06 examples/s]Converting format of dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219000/500000 [00:46<00:45, 6207.04 examples/s]Converting format of dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220000/500000 [00:46<00:50, 5545.15 examples/s]Converting format of dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221000/500000 [00:47<01:06, 4197.23 examples/s]Converting format of dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224000/500000 [00:47<00:55, 4973.20 examples/s]Converting format of dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 225000/500000 [00:48<00:58, 4669.46 examples/s]Converting format of dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228000/500000 [00:48<01:06, 4084.96 examples/s]Converting format of dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230000/500000 [00:49<00:51, 5195.53 examples/s]Converting format of dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231000/500000 [00:49<00:48, 5561.01 examples/s]Converting format of dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232000/500000 [00:49<00:44, 6060.98 examples/s]Converting format of dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 233000/500000 [00:49<01:09, 3837.55 examples/s]Converting format of dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237000/500000 [00:50<00:51, 5128.24 examples/s]Converting format of dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 238000/500000 [00:51<01:13, 3553.98 examples/s]Converting format of dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 239000/500000 [00:51<01:22, 3149.24 examples/s]Converting format of dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241000/500000 [00:51<00:57, 4482.89 examples/s]Converting format of dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242000/500000 [00:52<01:14, 3464.56 examples/s]Converting format of dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244000/500000 [00:52<01:00, 4226.80 examples/s]Converting format of dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246000/500000 [00:52<00:44, 5694.27 examples/s]Converting format of dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247000/500000 [00:52<00:47, 5287.18 examples/s]Converting format of dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248000/500000 [00:53<00:57, 4396.76 examples/s]Converting format of dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250000/500000 [00:53<00:48, 5190.72 examples/s]Converting format of dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 252000/500000 [00:53<00:39, 6349.43 examples/s]Converting format of dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253000/500000 [00:54<00:45, 5430.48 examples/s]Converting format of dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254000/500000 [00:55<01:57, 2101.14 examples/s]Converting format of dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257000/500000 [00:56<01:28, 2731.16 examples/s]Converting format of dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258000/500000 [00:56<01:18, 3100.11 examples/s]Converting format of dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260000/500000 [00:56<00:57, 4171.49 examples/s]Converting format of dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261000/500000 [00:56<00:51, 4613.08 examples/s]Converting format of dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262000/500000 [00:56<00:47, 4978.12 examples/s]Converting format of dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 264000/500000 [00:56<00:36, 6415.80 examples/s]Converting format of dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 266000/500000 [00:57<00:34, 6853.98 examples/s]Converting format of dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 267000/500000 [00:57<00:32, 7163.54 examples/s]Converting format of dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 268000/500000 [00:57<00:37, 6253.83 examples/s]Converting format of dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269000/500000 [00:57<00:44, 5241.87 examples/s]Converting format of dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 270000/500000 [00:58<01:28, 2584.40 examples/s]Converting format of dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 271000/500000 [00:58<01:12, 3142.57 examples/s]Converting format of dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 272000/500000 [00:59<01:13, 3110.02 examples/s]Converting format of dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273000/500000 [00:59<01:12, 3131.51 examples/s]Converting format of dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276000/500000 [01:00<00:50, 4479.40 examples/s]Converting format of dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277000/500000 [01:00<00:46, 4819.79 examples/s]Converting format of dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278000/500000 [01:00<00:56, 3932.93 examples/s]Converting format of dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 280000/500000 [01:00<00:39, 5585.17 examples/s]Converting format of dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 284000/500000 [01:01<00:46, 4687.28 examples/s]Converting format of dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 285000/500000 [01:02<01:08, 3139.89 examples/s]Converting format of dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286000/500000 [01:02<01:04, 3309.33 examples/s]Converting format of dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287000/500000 [01:03<01:17, 2735.98 examples/s]Converting format of dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289000/500000 [01:03<00:52, 3986.24 examples/s]Converting format of dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 291000/500000 [01:04<00:52, 3974.12 examples/s]Converting format of dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293000/500000 [01:04<00:46, 4467.01 examples/s]Converting format of dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294000/500000 [01:04<00:41, 4937.04 examples/s]Converting format of dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295000/500000 [01:04<00:39, 5146.72 examples/s]Converting format of dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 296000/500000 [01:04<00:41, 4905.78 examples/s]Converting format of dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 298000/500000 [01:05<00:31, 6329.49 examples/s]Converting format of dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299000/500000 [01:05<00:30, 6626.53 examples/s]Converting format of dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 301000/500000 [01:05<00:23, 8561.34 examples/s]Converting format of dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 303000/500000 [01:06<01:10, 2797.60 examples/s]Converting format of dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305000/500000 [01:07<00:55, 3538.35 examples/s]Converting format of dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307000/500000 [01:07<00:42, 4489.97 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308000/500000 [01:07<00:40, 4692.24 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310000/500000 [01:07<00:35, 5405.72 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311000/500000 [01:08<00:38, 4864.78 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312000/500000 [01:08<00:45, 4127.80 examples/s]Converting format of dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 314000/500000 [01:08<00:37, 5006.27 examples/s]Converting format of dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 315000/500000 [01:08<00:32, 5610.20 examples/s]Converting format of dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 316000/500000 [01:09<00:47, 3840.46 examples/s]Converting format of dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319000/500000 [01:09<00:35, 5050.09 examples/s]Converting format of dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321000/500000 [01:09<00:27, 6501.60 examples/s]Converting format of dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322000/500000 [01:10<00:31, 5641.04 examples/s]Converting format of dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324000/500000 [01:10<00:30, 5845.57 examples/s]Converting format of dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325000/500000 [01:10<00:33, 5283.61 examples/s]Converting format of dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327000/500000 [01:11<00:44, 3884.99 examples/s]Converting format of dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 328000/500000 [01:11<00:43, 3970.10 examples/s]Converting format of dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 329000/500000 [01:12<00:47, 3626.51 examples/s]Converting format of dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330000/500000 [01:12<00:40, 4248.60 examples/s]Converting format of dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331000/500000 [01:12<00:37, 4488.63 examples/s]Converting format of dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 332000/500000 [01:12<00:37, 4504.66 examples/s]Converting format of dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333000/500000 [01:12<00:43, 3830.08 examples/s]Converting format of dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334000/500000 [01:13<00:37, 4447.48 examples/s]Converting format of dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335000/500000 [01:13<00:32, 5132.91 examples/s]Converting format of dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336000/500000 [01:13<00:30, 5439.29 examples/s]Converting format of dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338000/500000 [01:13<00:24, 6650.26 examples/s]Converting format of dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 340000/500000 [01:13<00:18, 8785.84 examples/s]Converting format of dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343000/500000 [01:14<00:31, 4997.06 examples/s]Converting format of dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 346000/500000 [01:14<00:25, 6120.75 examples/s]Converting format of dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 348000/500000 [01:15<00:21, 7107.01 examples/s]Converting format of dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349000/500000 [01:15<00:27, 5432.21 examples/s]Converting format of dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350000/500000 [01:15<00:33, 4542.45 examples/s]Converting format of dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351000/500000 [01:16<00:44, 3314.17 examples/s]Converting format of dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 353000/500000 [01:16<00:31, 4701.50 examples/s]Converting format of dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355000/500000 [01:16<00:27, 5317.83 examples/s]Converting format of dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356000/500000 [01:17<00:37, 3797.70 examples/s]Converting format of dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359000/500000 [01:18<00:33, 4190.60 examples/s]Converting format of dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 360000/500000 [01:18<00:32, 4339.84 examples/s]Converting format of dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362000/500000 [01:18<00:27, 5088.49 examples/s]Converting format of dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 363000/500000 [01:18<00:25, 5463.49 examples/s]Converting format of dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 366000/500000 [01:19<00:20, 6510.00 examples/s]Converting format of dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 367000/500000 [01:19<00:21, 6141.08 examples/s]Converting format of dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369000/500000 [01:19<00:18, 7261.77 examples/s]Converting format of dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 370000/500000 [01:19<00:26, 4870.70 examples/s]Converting format of dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371000/500000 [01:20<00:28, 4453.22 examples/s]Converting format of dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373000/500000 [01:21<00:37, 3391.27 examples/s]Converting format of dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 378000/500000 [01:21<00:23, 5196.37 examples/s]Converting format of dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379000/500000 [01:21<00:22, 5459.63 examples/s]Converting format of dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 380000/500000 [01:22<00:27, 4405.31 examples/s]Converting format of dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381000/500000 [01:22<00:24, 4912.89 examples/s]Converting format of dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382000/500000 [01:22<00:23, 5065.05 examples/s]Converting format of dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383000/500000 [01:22<00:27, 4231.00 examples/s]Converting format of dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385000/500000 [01:23<00:23, 4939.16 examples/s]Converting format of dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388000/500000 [01:23<00:25, 4362.18 examples/s]Converting format of dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389000/500000 [01:24<00:22, 4835.77 examples/s]Converting format of dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 392000/500000 [01:24<00:17, 6081.96 examples/s]Converting format of dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395000/500000 [01:24<00:17, 6142.37 examples/s]Converting format of dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 396000/500000 [01:25<00:18, 5722.03 examples/s]Converting format of dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397000/500000 [01:25<00:18, 5596.84 examples/s]Converting format of dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399000/500000 [01:25<00:15, 6442.37 examples/s]Converting format of dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401000/500000 [01:25<00:15, 6342.22 examples/s]Converting format of dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402000/500000 [01:26<00:17, 5548.80 examples/s]Converting format of dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403000/500000 [01:26<00:27, 3465.98 examples/s]Converting format of dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 404000/500000 [01:26<00:24, 3888.92 examples/s]Converting format of dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405000/500000 [01:27<00:23, 4121.23 examples/s]Converting format of dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 406000/500000 [01:27<00:23, 4059.48 examples/s]Converting format of dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407000/500000 [01:27<00:19, 4780.04 examples/s]Converting format of dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408000/500000 [01:27<00:18, 5091.24 examples/s]Converting format of dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409000/500000 [01:28<00:22, 4025.32 examples/s]Converting format of dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410000/500000 [01:28<00:29, 3066.04 examples/s]Converting format of dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411000/500000 [01:28<00:27, 3208.47 examples/s]Converting format of dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 414000/500000 [01:29<00:15, 5693.64 examples/s]Converting format of dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 416000/500000 [01:29<00:12, 6493.74 examples/s]Converting format of dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 418000/500000 [01:29<00:09, 8342.36 examples/s]Converting format of dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420000/500000 [01:29<00:10, 7464.60 examples/s]Converting format of dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421000/500000 [01:30<00:15, 5205.96 examples/s]Converting format of dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422000/500000 [01:30<00:13, 5788.91 examples/s]Converting format of dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423000/500000 [01:30<00:14, 5318.41 examples/s]Converting format of dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 424000/500000 [01:30<00:13, 5815.44 examples/s]Converting format of dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425000/500000 [01:30<00:17, 4342.21 examples/s]Converting format of dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426000/500000 [01:31<00:18, 4083.11 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429000/500000 [01:31<00:15, 4628.34 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430250/500000 [01:32<00:15, 4462.02 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 431250/500000 [01:32<00:14, 4828.55 examples/s]Converting format of dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433250/500000 [01:32<00:12, 5453.38 examples/s]Converting format of dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436250/500000 [01:33<00:11, 5585.85 examples/s]Converting format of dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438250/500000 [01:33<00:15, 4039.06 examples/s]Converting format of dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441250/500000 [01:34<00:10, 5763.79 examples/s]Converting format of dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442250/500000 [01:34<00:09, 5835.84 examples/s]Converting format of dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 443250/500000 [01:34<00:09, 5859.89 examples/s]Converting format of dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 446250/500000 [01:34<00:06, 7946.14 examples/s]Converting format of dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 447250/500000 [01:34<00:07, 6739.01 examples/s]Converting format of dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448500/500000 [01:35<00:07, 7056.17 examples/s]Converting format of dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 451500/500000 [01:35<00:06, 7121.83 examples/s]Converting format of dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452500/500000 [01:35<00:09, 5037.39 examples/s]Converting format of dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453500/500000 [01:36<00:14, 3113.58 examples/s]Converting format of dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 463500/500000 [01:37<00:04, 7937.16 examples/s]Converting format of dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 465000/500000 [01:38<00:06, 5164.39 examples/s]Converting format of dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 466000/500000 [01:38<00:06, 5065.21 examples/s]Converting format of dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 467250/500000 [01:39<00:07, 4135.56 examples/s]Converting format of dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469250/500000 [01:39<00:06, 4998.82 examples/s]Converting format of dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 471500/500000 [01:39<00:04, 6404.63 examples/s]Converting format of dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472750/500000 [01:39<00:03, 6919.08 examples/s]Converting format of dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475000/500000 [01:39<00:02, 8769.85 examples/s]Converting format of dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 477000/500000 [01:39<00:02, 7903.11 examples/s]Converting format of dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478500/500000 [01:40<00:03, 5782.27 examples/s]Converting format of dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480500/500000 [01:40<00:02, 7385.11 examples/s]Converting format of dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 483500/500000 [01:40<00:02, 8195.95 examples/s]Converting format of dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485500/500000 [01:41<00:02, 6134.82 examples/s]Converting format of dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 486500/500000 [01:41<00:02, 6358.05 examples/s]Converting format of dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488000/500000 [01:41<00:01, 6943.84 examples/s]Converting format of dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 489000/500000 [01:42<00:04, 2726.85 examples/s]Converting format of dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492250/500000 [01:44<00:02, 2738.84 examples/s]Converting format of dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493250/500000 [01:44<00:02, 3036.06 examples/s]Converting format of dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495250/500000 [01:44<00:01, 3970.17 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498250/500000 [01:44<00:00, 5693.45 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499750/500000 [01:45<00:00, 5228.59 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 499750/500000 [01:56<00:00, 5228.59 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500000/500000 [02:18<00:00, 138.88 examples/s] Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500000/500000 [02:19<00:00, 3588.86 examples/s]
Concatenating 16 shards
04/18/2024 15:49:21 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ru_2b.jsonl.
Using custom data configuration default-09da74b050e9ac1e
Loading Dataset Infos from /home/nfs02/anaconda3/envs/wzjsz/lib/python3.10/site-packages/datasets/packaged_modules/json
Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
Found cached dataset json (/home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)
Loading Dataset info from /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
Dataset({
    features: ['text'],
    num_rows: 500000
})
{'text': 'ÐœÐ¾ÑÐºÐ²Ð° Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚ Ð®Ð¶Ð½Ð¾Ð¹ ÐžÑÐµÑ‚Ð¸Ð¸ â€“ Ð£Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÑÐºÐ°Ñ Ð³Ð°Ð·ÐµÑ‚Ð°\nÐœÐ¾ÑÐºÐ²Ð° Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚ Ð®Ð¶Ð½Ð¾Ð¹ ÐžÑÐµÑ‚Ð¸Ð¸\nÐ’Ð»Ð°ÑÑ‚Ð¸ ÐœÐ¾ÑÐºÐ²Ñ‹ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÑÑŽÑ‚ Ð¿Ð¾ÑÑ‚Ñ€Ð°Ð´Ð°Ð²ÑˆÐ¸Ð¼ Ð² Ð²Ð¾Ð¾Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð¾Ð¼ ÐºÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚Ðµ Ð² Ð®Ð¶Ð½Ð¾Ð¹ ÐžÑÐµÑ‚Ð¸Ð¸ Ð³ÑƒÐ¼Ð°Ð½Ð¸Ñ‚Ð°Ñ€Ð½Ñ‹Ðµ Ð³Ñ€ÑƒÐ·Ñ‹: Ð¿ÐµÑ€Ð²Ð°Ñ Ð¿Ð°Ñ€Ñ‚Ð¸Ñ Ð±Ñ‹Ð»Ð° Ð²ÐµÑÐ¾Ð¼ Ð±Ð¾Ð»ÐµÐµ 100 Ñ‚Ð¾Ð½Ð½ Ð½Ð° Ð¾Ð±Ñ‰ÑƒÑŽ ÑÑƒÐ¼Ð¼Ñƒ 2,5 Ð¼Ð¸Ð»Ð»Ð¸Ð°Ñ€Ð´Ð° Ñ€ÑƒÐ±Ð»ÐµÐ¹, Ð²Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð´Ð²Ðµ â€“ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒÑŽ Ð¾ÐºÐ¾Ð»Ð¾ 35 Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½Ð¾Ð² Ñ€ÑƒÐ±Ð»ÐµÐ¹.\nÐ’ Ð³ÑƒÐ¼Ð°Ð½Ð¸Ñ‚Ð°Ñ€Ð½Ñ‹Ðµ Ð³Ñ€ÑƒÐ·Ñ‹ Ð²Ð¾ÑˆÐ»Ð¸ Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¾Ð»ÑŒÑÑ‚Ð²Ð¸Ðµ (Ð¼ÑƒÐºÐ° Ð¸ ÐºÑ€ÑƒÐ¿Ñ‹), ÐºÐ¾Ð¼Ð¼ÑƒÐ½Ð°Ð»ÑŒÐ½Ð°Ñ Ð¸ ÑÑ‚Ñ€Ð¾Ð¹Ñ‚ÐµÑ…Ð½Ð¸ÐºÐ°, ÑƒÐ±Ð¾Ñ€Ð¾Ñ‡Ð½Ñ‹Ðµ Ð¼Ð°ÑˆÐ¸Ð½Ñ‹. Ð¡Ñ‚Ð¾Ð»Ð¸Ñ†Ð° Ð Ð¾ÑÑÐ¸Ð¸ Ð·Ð°ÐºÐ°Ð·Ð°Ð»Ð° Ð´Ð»Ñ Ð¦Ñ…Ð¸Ð½Ð²Ð°Ð»Ð¸ Ð´ÐµÑÑÑ‚ÑŒ Ð¿Ð°ÑÑÐ°Ð¶Ð¸Ñ€ÑÐºÐ¸Ñ… Ð°Ð²Ñ‚Ð¾Ð±ÑƒÑÐ¾Ð², 30 Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¾Ñ‡Ð½Ñ‹Ñ… Ð¿ÑƒÐ½ÐºÑ‚Ð¾Ð². Ð’ÑÐµ ÑÑ‚Ð¾ Ð´Ð¾ÑÑ‚Ð°Ð²ÑÑ‚ Ð² Ð®Ð¶Ð½ÑƒÑŽ ÐžÑÐµÑ‚Ð¸ÑŽ Ð¿Ð¾ Ð¶ÐµÐ»ÐµÐ·Ð½Ð¾Ð¹ Ð´Ð¾Ñ€Ð¾Ð³Ðµ.'}
Process #0 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00000_of_00016.arrow
Process #1 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00001_of_00016.arrow
Process #2 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00002_of_00016.arrow
Process #3 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00003_of_00016.arrow
Process #4 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00004_of_00016.arrow
Process #5 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00005_of_00016.arrow
Process #6 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00006_of_00016.arrow
Process #7 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00007_of_00016.arrow
Process #8 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00008_of_00016.arrow
Process #9 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00009_of_00016.arrow
Process #10 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00010_of_00016.arrow
Process #11 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00011_of_00016.arrow
Process #12 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00012_of_00016.arrow
Process #13 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00013_of_00016.arrow
Process #14 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00014_of_00016.arrow
Process #15 will write at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00015_of_00016.arrow
Spawning 16 processes
Converting format of dataset (num_proc=16):   0%|          | 0/500000 [00:00<?, ? examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00006_of_00016.arrow
Converting format of dataset (num_proc=16):   0%|          | 1000/500000 [00:03<25:20, 328.21 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00001_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00003_of_00016.arrow
Converting format of dataset (num_proc=16):   0%|          | 2000/500000 [00:03<11:50, 700.54 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00015_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00012_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00010_of_00016.arrow
Converting format of dataset (num_proc=16):   1%|          | 5000/500000 [00:03<03:32, 2326.57 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00008_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00009_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00011_of_00016.arrow
Converting format of dataset (num_proc=16):   2%|â–         | 8000/500000 [00:03<01:54, 4314.00 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00000_of_00016.arrow
Converting format of dataset (num_proc=16):   2%|â–         | 10000/500000 [00:03<01:31, 5379.27 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00014_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00005_of_00016.arrow
Converting format of dataset (num_proc=16):   2%|â–         | 12000/500000 [00:04<01:49, 4459.27 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00004_of_00016.arrow
Converting format of dataset (num_proc=16):   3%|â–Ž         | 14000/500000 [00:06<04:09, 1944.04 examples/s]Converting format of dataset (num_proc=16):   3%|â–Ž         | 17000/500000 [00:06<02:43, 2952.41 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00013_of_00016.arrow
Converting format of dataset (num_proc=16):   4%|â–Ž         | 18000/500000 [00:07<02:30, 3207.04 examples/s]Converting format of dataset (num_proc=16):   4%|â–         | 20000/500000 [00:07<01:58, 4043.53 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00007_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-09da74b050e9ac1e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-7e4f822428743414_00002_of_00016.arrow
Converting format of dataset (num_proc=16):   5%|â–         | 23000/500000 [00:07<01:34, 5054.85 examples/s]Converting format of dataset (num_proc=16):   5%|â–         | 24000/500000 [00:07<01:38, 4845.05 examples/s]Converting format of dataset (num_proc=16):   5%|â–Œ         | 25000/500000 [00:08<02:13, 3546.44 examples/s]Converting format of dataset (num_proc=16):   5%|â–Œ         | 26000/500000 [00:09<02:57, 2676.18 examples/s]Converting format of dataset (num_proc=16):   5%|â–Œ         | 27000/500000 [00:09<02:46, 2847.95 examples/s]Converting format of dataset (num_proc=16):   6%|â–Œ         | 28000/500000 [00:10<04:08, 1896.44 examples/s]Converting format of dataset (num_proc=16):   6%|â–Œ         | 29000/500000 [00:10<03:32, 2213.96 examples/s]Converting format of dataset (num_proc=16):   6%|â–Œ         | 30000/500000 [00:10<02:51, 2743.56 examples/s]Converting format of dataset (num_proc=16):   6%|â–‹         | 32000/500000 [00:11<01:59, 3904.53 examples/s]Converting format of dataset (num_proc=16):   7%|â–‹         | 34000/500000 [00:11<01:29, 5221.55 examples/s]Converting format of dataset (num_proc=16):   7%|â–‹         | 35000/500000 [00:11<01:45, 4419.00 examples/s]Converting format of dataset (num_proc=16):   8%|â–Š         | 39000/500000 [00:11<00:53, 8652.68 examples/s]Converting format of dataset (num_proc=16):   8%|â–Š         | 41000/500000 [00:12<01:33, 4896.50 examples/s]Converting format of dataset (num_proc=16):   9%|â–Š         | 43000/500000 [00:13<02:07, 3584.34 examples/s]Converting format of dataset (num_proc=16):   9%|â–‰         | 45000/500000 [00:14<02:30, 3015.80 examples/s]Converting format of dataset (num_proc=16):   9%|â–‰         | 47000/500000 [00:14<01:57, 3853.01 examples/s]Converting format of dataset (num_proc=16):  10%|â–‰         | 49000/500000 [00:14<01:32, 4857.87 examples/s]Converting format of dataset (num_proc=16):  10%|â–ˆ         | 50000/500000 [00:15<01:36, 4643.37 examples/s]Converting format of dataset (num_proc=16):  10%|â–ˆ         | 52000/500000 [00:15<01:19, 5664.86 examples/s]Converting format of dataset (num_proc=16):  11%|â–ˆ         | 53000/500000 [00:15<01:41, 4418.04 examples/s]Converting format of dataset (num_proc=16):  11%|â–ˆ         | 54000/500000 [00:15<01:41, 4402.91 examples/s]Converting format of dataset (num_proc=16):  11%|â–ˆ         | 55000/500000 [00:17<03:50, 1930.69 examples/s]Converting format of dataset (num_proc=16):  11%|â–ˆ         | 56000/500000 [00:17<03:27, 2140.76 examples/s]Converting format of dataset (num_proc=16):  11%|â–ˆâ–        | 57000/500000 [00:18<03:03, 2412.20 examples/s]Converting format of dataset (num_proc=16):  12%|â–ˆâ–        | 58000/500000 [00:18<02:29, 2958.61 examples/s]Converting format of dataset (num_proc=16):  12%|â–ˆâ–        | 60000/500000 [00:18<01:42, 4308.29 examples/s]Converting format of dataset (num_proc=16):  12%|â–ˆâ–        | 62000/500000 [00:18<01:18, 5596.28 examples/s]Converting format of dataset (num_proc=16):  13%|â–ˆâ–Ž        | 63000/500000 [00:18<01:46, 4103.11 examples/s]Converting format of dataset (num_proc=16):  13%|â–ˆâ–Ž        | 64000/500000 [00:19<01:31, 4748.24 examples/s]Converting format of dataset (num_proc=16):  13%|â–ˆâ–Ž        | 65000/500000 [00:19<01:22, 5240.98 examples/s]Converting format of dataset (num_proc=16):  13%|â–ˆâ–Ž        | 66000/500000 [00:19<01:58, 3650.21 examples/s]Converting format of dataset (num_proc=16):  13%|â–ˆâ–Ž        | 67000/500000 [00:19<01:54, 3765.59 examples/s]Converting format of dataset (num_proc=16):  14%|â–ˆâ–        | 69000/500000 [00:20<01:51, 3856.28 examples/s]Converting format of dataset (num_proc=16):  14%|â–ˆâ–        | 70000/500000 [00:20<02:12, 3235.48 examples/s]Converting format of dataset (num_proc=16):  14%|â–ˆâ–        | 72000/500000 [00:21<01:35, 4461.91 examples/s]Converting format of dataset (num_proc=16):  15%|â–ˆâ–        | 73000/500000 [00:21<01:33, 4570.85 examples/s]Converting format of dataset (num_proc=16):  15%|â–ˆâ–Œ        | 75000/500000 [00:22<02:05, 3377.02 examples/s]Converting format of dataset (num_proc=16):  15%|â–ˆâ–Œ        | 76000/500000 [00:22<02:50, 2489.18 examples/s]Converting format of dataset (num_proc=16):  16%|â–ˆâ–Œ        | 79000/500000 [00:23<01:48, 3888.75 examples/s]Converting format of dataset (num_proc=16):  16%|â–ˆâ–Œ        | 80000/500000 [00:23<01:52, 3733.93 examples/s]Converting format of dataset (num_proc=16):  16%|â–ˆâ–Œ        | 81000/500000 [00:23<01:42, 4096.08 examples/s]Converting format of dataset (num_proc=16):  16%|â–ˆâ–‹        | 82000/500000 [00:23<01:35, 4372.61 examples/s]Converting format of dataset (num_proc=16):  17%|â–ˆâ–‹        | 83000/500000 [00:24<01:46, 3921.20 examples/s]Converting format of dataset (num_proc=16):  17%|â–ˆâ–‹        | 85000/500000 [00:24<01:13, 5611.81 examples/s]Converting format of dataset (num_proc=16):  17%|â–ˆâ–‹        | 86000/500000 [00:24<01:33, 4406.80 examples/s]Converting format of dataset (num_proc=16):  17%|â–ˆâ–‹        | 87000/500000 [00:25<01:34, 4385.12 examples/s]Converting format of dataset (num_proc=16):  18%|â–ˆâ–Š        | 89000/500000 [00:25<01:15, 5436.47 examples/s]Converting format of dataset (num_proc=16):  18%|â–ˆâ–Š        | 90000/500000 [00:26<02:26, 2791.77 examples/s]Converting format of dataset (num_proc=16):  18%|â–ˆâ–Š        | 91000/500000 [00:26<02:10, 3123.23 examples/s]Converting format of dataset (num_proc=16):  19%|â–ˆâ–Š        | 93000/500000 [00:27<02:56, 2302.14 examples/s]Converting format of dataset (num_proc=16):  19%|â–ˆâ–‰        | 94000/500000 [00:27<02:29, 2709.77 examples/s]Converting format of dataset (num_proc=16):  19%|â–ˆâ–‰        | 96000/500000 [00:28<02:03, 3274.70 examples/s]Converting format of dataset (num_proc=16):  20%|â–ˆâ–‰        | 98000/500000 [00:28<02:09, 3115.78 examples/s]Converting format of dataset (num_proc=16):  20%|â–ˆâ–‰        | 99000/500000 [00:29<02:15, 2962.45 examples/s]Converting format of dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 100000/500000 [00:29<01:59, 3339.24 examples/s]Converting format of dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 102000/500000 [00:29<01:24, 4717.38 examples/s]Converting format of dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 104000/500000 [00:29<01:19, 4986.53 examples/s]Converting format of dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 105000/500000 [00:31<02:35, 2535.92 examples/s]Converting format of dataset (num_proc=16):  21%|â–ˆâ–ˆâ–       | 107000/500000 [00:31<02:03, 3186.28 examples/s]Converting format of dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 108000/500000 [00:32<02:34, 2540.55 examples/s]Converting format of dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 110000/500000 [00:32<01:48, 3587.63 examples/s]Converting format of dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 111000/500000 [00:32<02:14, 2900.19 examples/s]Converting format of dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 112000/500000 [00:33<02:06, 3076.60 examples/s]Converting format of dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 113000/500000 [00:33<01:57, 3283.40 examples/s]Converting format of dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 114000/500000 [00:33<01:37, 3945.69 examples/s]Converting format of dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 115000/500000 [00:33<01:51, 3438.25 examples/s]Converting format of dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 116000/500000 [00:34<01:46, 3603.33 examples/s]Converting format of dataset (num_proc=16):  24%|â–ˆâ–ˆâ–Ž       | 118000/500000 [00:34<01:34, 4037.66 examples/s]Converting format of dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 119000/500000 [00:34<01:34, 4048.67 examples/s]Converting format of dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 122000/500000 [00:35<01:07, 5621.54 examples/s]Converting format of dataset (num_proc=16):  25%|â–ˆâ–ˆâ–       | 123000/500000 [00:35<01:37, 3880.26 examples/s]Converting format of dataset (num_proc=16):  25%|â–ˆâ–ˆâ–       | 124000/500000 [00:35<01:32, 4065.06 examples/s]Converting format of dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 125000/500000 [00:36<01:33, 3993.14 examples/s]Converting format of dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 126000/500000 [00:37<02:33, 2433.29 examples/s]Converting format of dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 127000/500000 [00:37<02:10, 2849.33 examples/s]Converting format of dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 129000/500000 [00:37<02:10, 2839.92 examples/s]Converting format of dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 130000/500000 [00:38<02:13, 2774.60 examples/s]Converting format of dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 131000/500000 [00:38<02:33, 2407.74 examples/s]Converting format of dataset (num_proc=16):  26%|â–ˆâ–ˆâ–‹       | 132000/500000 [00:39<02:08, 2852.74 examples/s]Converting format of dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 133000/500000 [00:39<01:53, 3243.76 examples/s]Converting format of dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 135000/500000 [00:39<01:38, 3700.19 examples/s]Converting format of dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 137000/500000 [00:40<01:19, 4567.89 examples/s]Converting format of dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 138000/500000 [00:40<01:13, 4909.20 examples/s]Converting format of dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 139000/500000 [00:40<01:23, 4303.53 examples/s]Converting format of dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 140000/500000 [00:40<01:29, 4040.89 examples/s]Converting format of dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 141000/500000 [00:41<01:46, 3380.99 examples/s]Converting format of dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 142000/500000 [00:41<01:27, 4078.98 examples/s]Converting format of dataset (num_proc=16):  29%|â–ˆâ–ˆâ–Š       | 143000/500000 [00:41<01:58, 3015.92 examples/s]Converting format of dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 144000/500000 [00:42<01:38, 3609.93 examples/s]Converting format of dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 145000/500000 [00:42<02:10, 2730.11 examples/s]Converting format of dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 146000/500000 [00:43<03:14, 1816.81 examples/s]Converting format of dataset (num_proc=16):  30%|â–ˆâ–ˆâ–‰       | 149000/500000 [00:43<01:37, 3597.22 examples/s]Converting format of dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 153000/500000 [00:44<01:05, 5298.54 examples/s]Converting format of dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 154000/500000 [00:45<01:38, 3497.77 examples/s]Converting format of dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 155000/500000 [00:45<01:46, 3229.70 examples/s]Converting format of dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 156000/500000 [00:45<01:34, 3629.03 examples/s]Converting format of dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆâ–      | 157000/500000 [00:46<02:34, 2226.31 examples/s]Converting format of dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 158000/500000 [00:47<02:59, 1902.12 examples/s]Converting format of dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 160000/500000 [00:47<01:56, 2921.99 examples/s]Converting format of dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 163000/500000 [00:47<01:15, 4473.03 examples/s]Converting format of dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 164000/500000 [00:47<01:10, 4737.15 examples/s]Converting format of dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 166000/500000 [00:48<01:09, 4778.09 examples/s]Converting format of dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 167000/500000 [00:48<01:21, 4093.04 examples/s]Converting format of dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 169000/500000 [00:48<01:01, 5418.56 examples/s]Converting format of dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 170000/500000 [00:49<01:13, 4481.84 examples/s]Converting format of dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 171000/500000 [00:49<01:45, 3123.84 examples/s]Converting format of dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 172000/500000 [00:50<02:07, 2581.24 examples/s]Converting format of dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–      | 173000/500000 [00:51<02:23, 2272.47 examples/s]Converting format of dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 175000/500000 [00:52<02:22, 2279.77 examples/s]Converting format of dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 176000/500000 [00:52<01:59, 2703.52 examples/s]Converting format of dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 177000/500000 [00:52<01:41, 3179.15 examples/s]Converting format of dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 178000/500000 [00:52<01:59, 2694.48 examples/s]Converting format of dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 179000/500000 [00:53<01:41, 3174.65 examples/s]Converting format of dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 180000/500000 [00:53<01:25, 3728.12 examples/s]Converting format of dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 182000/500000 [00:53<01:04, 4930.47 examples/s]Converting format of dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 183000/500000 [00:53<01:04, 4877.73 examples/s]Converting format of dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 184000/500000 [00:54<01:34, 3337.83 examples/s]Converting format of dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 186000/500000 [00:54<01:05, 4789.94 examples/s]Converting format of dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 187000/500000 [00:55<01:46, 2945.29 examples/s]Converting format of dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 188000/500000 [00:55<01:48, 2878.28 examples/s]Converting format of dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 190000/500000 [00:56<01:40, 3084.78 examples/s]Converting format of dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 191000/500000 [00:56<01:40, 3076.05 examples/s]Converting format of dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 192000/500000 [00:56<01:56, 2643.89 examples/s]Converting format of dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 194000/500000 [00:57<01:18, 3883.08 examples/s]Converting format of dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 195000/500000 [00:57<01:24, 3608.92 examples/s]Converting format of dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 196000/500000 [00:57<01:12, 4214.30 examples/s]Converting format of dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 197000/500000 [00:57<01:06, 4578.59 examples/s]Converting format of dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 198000/500000 [00:57<01:05, 4598.64 examples/s]Converting format of dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 199000/500000 [00:58<01:16, 3958.24 examples/s]Converting format of dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 202000/500000 [00:59<01:19, 3757.70 examples/s]Converting format of dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 204000/500000 [00:59<01:19, 3743.69 examples/s]Converting format of dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 205000/500000 [01:00<01:31, 3238.98 examples/s]Converting format of dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 206000/500000 [01:00<01:24, 3494.06 examples/s]Converting format of dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 207000/500000 [01:00<01:22, 3538.70 examples/s]Converting format of dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 208000/500000 [01:00<01:11, 4067.02 examples/s]Converting format of dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 209000/500000 [01:01<01:44, 2779.63 examples/s]Converting format of dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 211000/500000 [01:02<01:43, 2783.01 examples/s]Converting format of dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212000/500000 [01:02<01:34, 3049.03 examples/s]Converting format of dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 214000/500000 [01:02<01:18, 3620.39 examples/s]Converting format of dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 215000/500000 [01:02<01:12, 3950.53 examples/s]Converting format of dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 216000/500000 [01:03<01:10, 4045.51 examples/s]Converting format of dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 217000/500000 [01:03<01:06, 4265.40 examples/s]Converting format of dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 218000/500000 [01:03<00:59, 4738.22 examples/s]Converting format of dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 219000/500000 [01:03<00:54, 5201.04 examples/s]Converting format of dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220000/500000 [01:03<00:53, 5230.92 examples/s]Converting format of dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 221000/500000 [01:04<00:57, 4849.30 examples/s]Converting format of dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 222000/500000 [01:04<01:42, 2716.51 examples/s]Converting format of dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224000/500000 [01:05<01:16, 3605.07 examples/s]Converting format of dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 226000/500000 [01:05<00:58, 4709.44 examples/s]Converting format of dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 227000/500000 [01:05<01:10, 3867.09 examples/s]Converting format of dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 228000/500000 [01:06<01:03, 4282.26 examples/s]Converting format of dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 229000/500000 [01:06<01:16, 3543.70 examples/s]Converting format of dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 230000/500000 [01:06<01:03, 4267.03 examples/s]Converting format of dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 231000/500000 [01:07<01:29, 2989.69 examples/s]Converting format of dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 232000/500000 [01:07<01:46, 2516.30 examples/s]Converting format of dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 234000/500000 [01:08<01:42, 2585.05 examples/s]Converting format of dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 235000/500000 [01:08<01:28, 3000.54 examples/s]Converting format of dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237000/500000 [01:09<01:33, 2800.87 examples/s]Converting format of dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 240000/500000 [01:09<00:57, 4559.40 examples/s]Converting format of dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241000/500000 [01:09<00:54, 4744.25 examples/s]Converting format of dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 242000/500000 [01:10<01:02, 4120.22 examples/s]Converting format of dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 243000/500000 [01:10<00:54, 4720.43 examples/s]Converting format of dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 244000/500000 [01:10<00:49, 5170.78 examples/s]Converting format of dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 245000/500000 [01:11<01:22, 3087.38 examples/s]Converting format of dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 246000/500000 [01:11<01:13, 3435.23 examples/s]Converting format of dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 247000/500000 [01:11<01:13, 3464.36 examples/s]Converting format of dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248000/500000 [01:12<01:27, 2884.91 examples/s]Converting format of dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 249000/500000 [01:12<01:50, 2274.53 examples/s]Converting format of dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250000/500000 [01:12<01:35, 2605.71 examples/s]Converting format of dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 251000/500000 [01:13<01:25, 2898.17 examples/s]Converting format of dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 253000/500000 [01:13<00:51, 4753.53 examples/s]Converting format of dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 254000/500000 [01:13<00:54, 4477.66 examples/s]Converting format of dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 255000/500000 [01:13<00:52, 4678.23 examples/s]Converting format of dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 257000/500000 [01:14<01:02, 3866.13 examples/s]Converting format of dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 258000/500000 [01:14<00:59, 4052.96 examples/s]Converting format of dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260000/500000 [01:14<00:49, 4818.21 examples/s]Converting format of dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 261000/500000 [01:15<00:49, 4820.98 examples/s]Converting format of dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 262000/500000 [01:15<01:01, 3896.82 examples/s]Converting format of dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 263000/500000 [01:15<00:52, 4533.61 examples/s]Converting format of dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 265000/500000 [01:15<00:34, 6718.52 examples/s]Converting format of dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 266000/500000 [01:16<00:43, 5412.15 examples/s]Converting format of dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 267000/500000 [01:17<01:44, 2237.91 examples/s]Converting format of dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 269000/500000 [01:18<01:35, 2415.33 examples/s]Converting format of dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273000/500000 [01:18<01:07, 3340.69 examples/s]Converting format of dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 276000/500000 [01:19<00:49, 4534.64 examples/s]Converting format of dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 277000/500000 [01:19<00:47, 4646.74 examples/s]Converting format of dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 278000/500000 [01:19<00:51, 4276.93 examples/s]Converting format of dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 279000/500000 [01:20<01:06, 3300.92 examples/s]Converting format of dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 282000/500000 [01:20<00:57, 3777.46 examples/s]Converting format of dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 283000/500000 [01:21<01:05, 3299.30 examples/s]Converting format of dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 286000/500000 [01:21<00:42, 4979.19 examples/s]Converting format of dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 287000/500000 [01:22<01:03, 3359.92 examples/s]Converting format of dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 289000/500000 [01:22<01:02, 3392.37 examples/s]Converting format of dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290000/500000 [01:22<00:55, 3769.54 examples/s]Converting format of dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292000/500000 [01:23<00:39, 5205.80 examples/s]Converting format of dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 293000/500000 [01:23<00:41, 5038.31 examples/s]Converting format of dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 294000/500000 [01:24<01:13, 2794.57 examples/s]Converting format of dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 295000/500000 [01:24<01:27, 2355.88 examples/s]Converting format of dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 297000/500000 [01:25<00:58, 3479.73 examples/s]Converting format of dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 299000/500000 [01:25<00:40, 4948.39 examples/s]Converting format of dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 300000/500000 [01:25<00:39, 5007.84 examples/s]Converting format of dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 302000/500000 [01:25<00:31, 6217.96 examples/s]Converting format of dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 304000/500000 [01:25<00:26, 7328.79 examples/s]Converting format of dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 305000/500000 [01:25<00:29, 6687.29 examples/s]Converting format of dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307000/500000 [01:27<01:10, 2747.23 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308000/500000 [01:27<01:14, 2561.65 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 309000/500000 [01:28<01:09, 2729.04 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 310000/500000 [01:28<00:57, 3283.53 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311000/500000 [01:28<00:52, 3622.10 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 312000/500000 [01:28<00:54, 3424.04 examples/s]Converting format of dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 313000/500000 [01:29<00:51, 3615.16 examples/s]Converting format of dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 314000/500000 [01:29<00:44, 4179.19 examples/s]Converting format of dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 316000/500000 [01:29<00:35, 5118.74 examples/s]Converting format of dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 317000/500000 [01:29<00:40, 4466.11 examples/s]Converting format of dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 318000/500000 [01:29<00:38, 4717.43 examples/s]Converting format of dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 319000/500000 [01:30<00:32, 5490.35 examples/s]Converting format of dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 320000/500000 [01:30<00:39, 4614.77 examples/s]Converting format of dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 321000/500000 [01:30<00:33, 5331.46 examples/s]Converting format of dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 322000/500000 [01:31<00:52, 3415.99 examples/s]Converting format of dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 324000/500000 [01:32<01:19, 2215.30 examples/s]Converting format of dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 325000/500000 [01:32<01:06, 2626.28 examples/s]Converting format of dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 326000/500000 [01:33<01:17, 2255.03 examples/s]Converting format of dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 327000/500000 [01:33<01:02, 2779.68 examples/s]Converting format of dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 330000/500000 [01:33<00:37, 4543.49 examples/s]Converting format of dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 331000/500000 [01:33<00:34, 4961.63 examples/s]Converting format of dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333000/500000 [01:33<00:26, 6338.05 examples/s]Converting format of dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 334000/500000 [01:34<00:39, 4187.31 examples/s]Converting format of dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 335000/500000 [01:34<00:44, 3735.55 examples/s]Converting format of dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 336000/500000 [01:35<00:53, 3048.68 examples/s]Converting format of dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 337000/500000 [01:35<00:59, 2739.04 examples/s]Converting format of dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 338000/500000 [01:36<00:55, 2915.01 examples/s]Converting format of dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 341000/500000 [01:36<00:29, 5377.36 examples/s]Converting format of dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 342000/500000 [01:37<00:50, 3151.58 examples/s]Converting format of dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 343000/500000 [01:37<00:47, 3340.31 examples/s]Converting format of dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 345000/500000 [01:37<00:37, 4079.89 examples/s]Converting format of dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 347000/500000 [01:38<00:36, 4180.40 examples/s]Converting format of dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 349000/500000 [01:38<00:27, 5491.42 examples/s]Converting format of dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 350000/500000 [01:38<00:32, 4676.59 examples/s]Converting format of dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 351000/500000 [01:39<00:41, 3620.05 examples/s]Converting format of dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 352000/500000 [01:39<00:47, 3121.36 examples/s]Converting format of dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 354000/500000 [01:39<00:33, 4340.80 examples/s]Converting format of dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 355000/500000 [01:40<00:41, 3514.68 examples/s]Converting format of dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 356000/500000 [01:40<00:47, 3027.58 examples/s]Converting format of dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 357000/500000 [01:40<00:39, 3609.16 examples/s]Converting format of dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 358000/500000 [01:40<00:36, 3874.89 examples/s]Converting format of dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 361000/500000 [01:41<00:22, 6281.97 examples/s]Converting format of dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362000/500000 [01:42<00:51, 2698.37 examples/s]Converting format of dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 364000/500000 [01:42<00:41, 3307.24 examples/s]Converting format of dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 365000/500000 [01:42<00:36, 3687.00 examples/s]Converting format of dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 366000/500000 [01:43<00:33, 4035.20 examples/s]Converting format of dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 367000/500000 [01:43<00:49, 2664.81 examples/s]Converting format of dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 368000/500000 [01:43<00:41, 3183.59 examples/s]Converting format of dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 369000/500000 [01:44<00:34, 3785.39 examples/s]Converting format of dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371000/500000 [01:44<00:29, 4380.10 examples/s]Converting format of dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 372000/500000 [01:44<00:30, 4150.76 examples/s]Converting format of dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 373000/500000 [01:45<00:40, 3166.86 examples/s]Converting format of dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375000/500000 [01:45<00:27, 4501.57 examples/s]Converting format of dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 376000/500000 [01:45<00:28, 4375.10 examples/s]Converting format of dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 377000/500000 [01:46<00:38, 3186.18 examples/s]Converting format of dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 379000/500000 [01:46<00:26, 4557.74 examples/s]Converting format of dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 381000/500000 [01:47<00:32, 3644.01 examples/s]Converting format of dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 382000/500000 [01:47<00:32, 3609.13 examples/s]Converting format of dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 383000/500000 [01:48<00:40, 2886.25 examples/s]Converting format of dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 385000/500000 [01:48<00:32, 3589.72 examples/s]Converting format of dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 386000/500000 [01:48<00:33, 3413.81 examples/s]Converting format of dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 387000/500000 [01:49<00:32, 3478.14 examples/s]Converting format of dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 388000/500000 [01:49<00:36, 3080.89 examples/s]Converting format of dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 389000/500000 [01:49<00:39, 2804.69 examples/s]Converting format of dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 390000/500000 [01:50<00:43, 2543.61 examples/s]Converting format of dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 391000/500000 [01:50<00:40, 2694.92 examples/s]Converting format of dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 393000/500000 [01:50<00:27, 3889.70 examples/s]Converting format of dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 395000/500000 [01:51<00:20, 5209.21 examples/s]Converting format of dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 397000/500000 [01:51<00:16, 6193.41 examples/s]Converting format of dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 398000/500000 [01:52<00:31, 3200.31 examples/s]Converting format of dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 399000/500000 [01:52<00:30, 3285.97 examples/s]Converting format of dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 400000/500000 [01:52<00:27, 3628.49 examples/s]Converting format of dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 401000/500000 [01:53<00:39, 2503.12 examples/s]Converting format of dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 402000/500000 [01:53<00:36, 2698.87 examples/s]Converting format of dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 403000/500000 [01:54<00:35, 2708.34 examples/s]Converting format of dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 405000/500000 [01:54<00:29, 3275.32 examples/s]Converting format of dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 407000/500000 [01:54<00:20, 4582.04 examples/s]Converting format of dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 408000/500000 [01:54<00:17, 5136.24 examples/s]Converting format of dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 409000/500000 [01:54<00:16, 5686.96 examples/s]Converting format of dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 410000/500000 [01:55<00:16, 5439.20 examples/s]Converting format of dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 411000/500000 [01:55<00:23, 3744.89 examples/s]Converting format of dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 413000/500000 [01:55<00:18, 4658.29 examples/s]Converting format of dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 414000/500000 [01:56<00:28, 2979.29 examples/s]Converting format of dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 416000/500000 [01:57<00:32, 2589.79 examples/s]Converting format of dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 417000/500000 [01:58<00:33, 2449.48 examples/s]Converting format of dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 419000/500000 [01:58<00:25, 3232.92 examples/s]Converting format of dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 420000/500000 [01:58<00:21, 3732.06 examples/s]Converting format of dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 421000/500000 [01:58<00:18, 4331.05 examples/s]Converting format of dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 422000/500000 [01:58<00:20, 3848.01 examples/s]Converting format of dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 423000/500000 [01:59<00:17, 4458.58 examples/s]Converting format of dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 425000/500000 [01:59<00:13, 5728.66 examples/s]Converting format of dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 426250/500000 [02:00<00:22, 3229.04 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428250/500000 [02:00<00:18, 3953.62 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 429250/500000 [02:00<00:16, 4180.74 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 430250/500000 [02:01<00:30, 2318.40 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 432250/500000 [02:02<00:33, 2047.31 examples/s]Converting format of dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 433500/500000 [02:02<00:25, 2617.42 examples/s]Converting format of dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 436500/500000 [02:03<00:13, 4609.05 examples/s]Converting format of dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 438500/500000 [02:03<00:16, 3650.16 examples/s]Converting format of dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 439500/500000 [02:04<00:15, 3864.07 examples/s]Converting format of dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 440500/500000 [02:04<00:16, 3685.71 examples/s]Converting format of dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 441500/500000 [02:04<00:18, 3228.14 examples/s]Converting format of dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 442750/500000 [02:05<00:15, 3580.86 examples/s]Converting format of dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 444750/500000 [02:05<00:13, 4159.13 examples/s]Converting format of dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 445750/500000 [02:05<00:11, 4749.04 examples/s]Converting format of dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 448000/500000 [02:05<00:09, 5396.07 examples/s]Converting format of dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 450000/500000 [02:06<00:08, 6055.35 examples/s]Converting format of dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 452000/500000 [02:06<00:06, 7543.92 examples/s]Converting format of dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 453250/500000 [02:07<00:14, 3192.32 examples/s]Converting format of dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 458500/500000 [02:08<00:10, 3924.41 examples/s]Converting format of dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 459500/500000 [02:08<00:10, 3961.76 examples/s]Converting format of dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 461500/500000 [02:08<00:07, 4890.14 examples/s]Converting format of dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 463500/500000 [02:09<00:08, 4093.25 examples/s]Converting format of dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 466500/500000 [02:09<00:05, 6046.77 examples/s]Converting format of dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 468750/500000 [02:10<00:07, 4439.59 examples/s]Converting format of dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469750/500000 [02:10<00:06, 4830.59 examples/s]Converting format of dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 472750/500000 [02:10<00:04, 5973.18 examples/s]Converting format of dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474000/500000 [02:11<00:05, 4462.80 examples/s]Converting format of dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 475250/500000 [02:11<00:04, 5054.11 examples/s]Converting format of dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 476250/500000 [02:11<00:04, 5390.16 examples/s]Converting format of dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 478500/500000 [02:12<00:03, 5700.49 examples/s]Converting format of dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 480500/500000 [02:12<00:02, 7150.67 examples/s]Converting format of dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 481500/500000 [02:12<00:03, 5168.38 examples/s]Converting format of dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 482500/500000 [02:13<00:06, 2530.13 examples/s]Converting format of dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 484500/500000 [02:14<00:04, 3395.67 examples/s]Converting format of dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485750/500000 [02:14<00:03, 3999.00 examples/s]Converting format of dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 487750/500000 [02:14<00:02, 4390.57 examples/s]Converting format of dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 488750/500000 [02:14<00:02, 4848.86 examples/s]Converting format of dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 490000/500000 [02:14<00:01, 5769.37 examples/s]Converting format of dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491000/500000 [02:15<00:01, 6280.37 examples/s]Converting format of dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 493000/500000 [02:15<00:01, 3718.38 examples/s]Converting format of dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 494000/500000 [02:16<00:01, 3204.24 examples/s]Converting format of dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 495000/500000 [02:16<00:01, 3122.29 examples/s]Converting format of dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 496000/500000 [02:16<00:01, 3647.56 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 497500/500000 [02:18<00:01, 1579.98 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 498750/500000 [02:20<00:00, 1273.07 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500000/500000 [02:20<00:00, 1703.62 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500000/500000 [02:33<00:00, 1703.62 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500000/500000 [02:53<00:00, 2886.41 examples/s]
Concatenating 16 shards
04/18/2024 15:53:28 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/slimpajam_1b.jsonl.
Using custom data configuration default-fd8d5f83c6d4fc15
Loading Dataset Infos from /home/nfs02/anaconda3/envs/wzjsz/lib/python3.10/site-packages/datasets/packaged_modules/json
Generating dataset json (/home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)
Downloading and preparing dataset json/default to /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10645.44it/s]
Downloading took 0.0 min
Checksum Computation took 0.0 min
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 181.09it/s]
Generating train split
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 7174 examples [00:00, 56865.09 examples/s]Generating train split: 15798 examples [00:00, 44162.18 examples/s]Generating train split: 22470 examples [00:00, 45558.22 examples/s]Generating train split: 31744 examples [00:00, 49079.92 examples/s]Generating train split: 40614 examples [00:00, 50873.17 examples/s]Generating train split: 47390 examples [00:00, 50883.01 examples/s]Generating train split: 54006 examples [00:01, 47824.22 examples/s]Generating train split: 63183 examples [00:01, 51428.57 examples/s]Generating train split: 72499 examples [00:01, 52759.76 examples/s]Generating train split: 79342 examples [00:01, 51275.55 examples/s]Generating train split: 88543 examples [00:01, 52595.37 examples/s]Generating train split: 97257 examples [00:01, 52181.95 examples/s]Generating train split: 106930 examples [00:02, 51954.92 examples/s]Generating train split: 114065 examples [00:02, 49991.08 examples/s]Generating train split: 121255 examples [00:02, 48973.27 examples/s]Generating train split: 130120 examples [00:02, 48480.93 examples/s]Generating train split: 136959 examples [00:02, 48292.52 examples/s]Generating train split: 146214 examples [00:02, 49462.61 examples/s]Generating train split: 153498 examples [00:03, 48850.48 examples/s]Generating train split: 162600 examples [00:03, 49054.98 examples/s]Generating train split: 172133 examples [00:03, 49703.16 examples/s]Generating train split: 181544 examples [00:03, 49086.18 examples/s]Generating train split: 188490 examples [00:03, 48956.06 examples/s]Generating train split: 197796 examples [00:03, 47581.64 examples/s]Generating train split: 204678 examples [00:04, 47508.14 examples/s]Generating train split: 213821 examples [00:04, 47902.22 examples/s]Generating train split: 220612 examples [00:04, 46465.75 examples/s]Generating train split: 225535 examples [00:04, 46392.75 examples/s]Generating train split: 232119 examples [00:04, 42927.97 examples/s]Generating train split: 241247 examples [00:04, 45297.99 examples/s]Generating train split: 250163 examples [00:05, 44823.49 examples/s]Generating train split: 256750 examples [00:05, 45018.32 examples/s]Generating train split: 266174 examples [00:05, 47031.86 examples/s]Generating train split: 272721 examples [00:05, 45593.20 examples/s]Generating train split: 281976 examples [00:05, 46715.09 examples/s]Generating train split: 288977 examples [00:05, 46296.55 examples/s]Generating train split: 293719 examples [00:06, 45226.39 examples/s]Generating train split: 302352 examples [00:06, 45036.94 examples/s]Generating train split: 307033 examples [00:06, 40628.03 examples/s]Generating train split: 311391 examples [00:06, 41242.98 examples/s]Generating train split: 318280 examples [00:06, 42258.44 examples/s]Generating train split: 325214 examples [00:06, 43296.24 examples/s]Generating train split: 333994 examples [00:07, 44179.18 examples/s]Generating train split: 343112 examples [00:07, 47035.20 examples/s]Generating train split: 352346 examples [00:07, 49756.61 examples/s]Generating train split: 361518 examples [00:07, 51526.45 examples/s]Generating train split: 370876 examples [00:07, 51849.28 examples/s]Generating train split: 380428 examples [00:07, 53046.66 examples/s]Generating train split: 389575 examples [00:08, 54341.48 examples/s]Generating train split: 398595 examples [00:08, 52785.28 examples/s]Generating train split: 408824 examples [00:08, 54829.94 examples/s]Generating train split: 417745 examples [00:08, 53667.12 examples/s]Generating train split: 426959 examples [00:08, 53663.56 examples/s]Generating train split: 436316 examples [00:08, 54851.19 examples/s]Generating train split: 445896 examples [00:09, 56330.66 examples/s]Generating train split: 454725 examples [00:09, 54746.35 examples/s]Generating train split: 462060 examples [00:09, 54960.95 examples/s]Generating train split: 469064 examples [00:09, 54839.09 examples/s]Generating train split: 478170 examples [00:09, 54391.72 examples/s]Generating train split: 487696 examples [00:09, 56539.40 examples/s]Generating train split: 497230 examples [00:10, 56578.23 examples/s]Generating train split: 506548 examples [00:10, 56147.88 examples/s]Generating train split: 515536 examples [00:10, 56360.86 examples/s]Generating train split: 525605 examples [00:10, 57012.14 examples/s]Generating train split: 535107 examples [00:10, 57523.99 examples/s]Generating train split: 544568 examples [00:10, 54180.95 examples/s]Generating train split: 551469 examples [00:11, 52428.12 examples/s]Generating train split: 561011 examples [00:11, 52501.22 examples/s]Generating train split: 571019 examples [00:11, 53452.66 examples/s]Generating train split: 577876 examples [00:11, 50446.33 examples/s]Generating train split: 584692 examples [00:11, 47590.98 examples/s]Generating train split: 594291 examples [00:11, 48603.06 examples/s]Generating train split: 604182 examples [00:12, 50847.30 examples/s]Generating train split: 610779 examples [00:12, 49846.15 examples/s]Generating train split: 619982 examples [00:12, 51859.84 examples/s]Generating train split: 629002 examples [00:12, 50064.27 examples/s]Generating train split: 636357 examples [00:12, 49598.09 examples/s]Generating train split: 645795 examples [00:12, 51969.42 examples/s]Generating train split: 654424 examples [00:13, 50624.91 examples/s]Generating train split: 663716 examples [00:13, 52526.93 examples/s]Generating train split: 673161 examples [00:13, 55462.77 examples/s]Generating train split: 682663 examples [00:13, 54758.48 examples/s]Generating train split: 691932 examples [00:13, 53278.09 examples/s]Generating train split: 701527 examples [00:13, 53366.58 examples/s]Generating train split: 711144 examples [00:14, 52772.42 examples/s]Generating train split: 720762 examples [00:14, 51130.36 examples/s]Generating train split: 729696 examples [00:14, 49320.58 examples/s]Generating train split: 736252 examples [00:14, 47053.65 examples/s]Generating train split: 743341 examples [00:14, 47811.86 examples/s]Generating train split: 753052 examples [00:14, 49665.77 examples/s]Generating train split: 759234 examples [00:15, 48192.75 examples/s]Generating train split: 768783 examples [00:15, 48093.18 examples/s]Generating train split: 778233 examples [00:15, 48668.53 examples/s]Generating train split: 784587 examples [00:15, 45716.09 examples/s]Generating train split: 793526 examples [00:15, 46978.46 examples/s]Generating train split: 803063 examples [00:16, 48282.50 examples/s]Generating train split: 812343 examples [00:16, 48278.06 examples/s]Generating train split: 819110 examples [00:16, 47554.94 examples/s]Generating train split: 828796 examples [00:16, 49501.30 examples/s]Generating train split: 837737 examples [00:16, 48345.20 examples/s]Generating train split: 844273 examples [00:16, 47618.67 examples/s]Generating train split: 850994 examples [00:17, 47280.81 examples/s]Generating train split: 855529 examples [00:17, 49892.06 examples/s]
Unable to verify splits sizes.
Dataset json downloaded and prepared to /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.
Dataset({
    features: ['text', 'meta', '__index_level_0__'],
    num_rows: 500000
})
{'text': '@interface PodsDummy_XCDLumberjackNSLogger_OSX : NSObject\n@end\n@implementation PodsDummy_XCDLumberjackNSLogger_OSX\n@end\n', 'meta': {'redpajama_set_name': 'RedPajamaGithub'}, '__index_level_0__': 3706}
Process #0 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00000_of_00016.arrow
Process #1 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00001_of_00016.arrow
Process #2 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00002_of_00016.arrow
Process #3 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00003_of_00016.arrow
Process #4 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00004_of_00016.arrow
Process #5 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00005_of_00016.arrow
Process #6 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00006_of_00016.arrow
Process #7 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00007_of_00016.arrow
Process #8 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00008_of_00016.arrow
Process #9 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00009_of_00016.arrow
Process #10 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00010_of_00016.arrow
Process #11 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00011_of_00016.arrow
Process #12 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00012_of_00016.arrow
Process #13 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00013_of_00016.arrow
Process #14 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00014_of_00016.arrow
Process #15 will write at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00015_of_00016.arrow
Spawning 16 processes
Converting format of dataset (num_proc=16):   0%|          | 0/500000 [00:00<?, ? examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00000_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00001_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00007_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00005_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00011_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00003_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00010_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00013_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00002_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00009_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00004_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00006_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00012_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00015_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00014_of_00016.arrow
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-fd8d5f83c6d4fc15/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3c06931a010b14c9_00008_of_00016.arrow
Converting format of dataset (num_proc=16):   0%|          | 1000/500000 [00:00<02:06, 3939.23 examples/s]Converting format of dataset (num_proc=16):   7%|â–‹         | 33000/500000 [00:00<00:03, 116939.46 examples/s]Converting format of dataset (num_proc=16):  15%|â–ˆâ–Œ        | 76000/500000 [00:00<00:01, 221778.77 examples/s]Converting format of dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 126000/500000 [00:00<00:01, 310362.80 examples/s]Converting format of dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 188000/500000 [00:00<00:00, 404727.30 examples/s]Converting format of dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 248000/500000 [00:00<00:00, 460381.21 examples/s]Converting format of dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 308000/500000 [00:00<00:00, 502594.32 examples/s]Converting format of dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 362000/500000 [00:00<00:00, 499969.35 examples/s]Converting format of dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 428000/500000 [00:01<00:00, 546169.87 examples/s]Converting format of dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 485000/500000 [00:01<00:00, 465476.45 examples/s]Converting format of dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491000/500000 [00:14<00:00, 465476.45 examples/s]Converting format of dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 491250/500000 [00:29<00:01, 4710.90 examples/s]  Converting format of dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 492500/500000 [00:30<00:01, 4737.38 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500000/500000 [00:32<00:00, 15345.01 examples/s]
Concatenating 16 shards
Process #0 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00000_of_00016.arrow
Process #1 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00001_of_00016.arrow
Process #2 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00002_of_00016.arrow
Process #3 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00003_of_00016.arrow
Process #4 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00004_of_00016.arrow
Process #5 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00005_of_00016.arrow
Process #6 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00006_of_00016.arrow
Process #7 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00007_of_00016.arrow
Process #8 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00008_of_00016.arrow
Process #9 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00009_of_00016.arrow
Process #10 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00010_of_00016.arrow
Process #11 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00011_of_00016.arrow
Process #12 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00012_of_00016.arrow
Process #13 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00013_of_00016.arrow
Process #14 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00014_of_00016.arrow
Process #15 will write at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00015_of_00016.arrow
Spawning 16 processes
Running tokenizer on dataset (num_proc=16):   0%|          | 0/2000000 [00:00<?, ? examples/s]04/18/2024 15:54:38 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/de_2b.jsonl.
04/18/2024 15:54:38 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/de_2b.jsonl.
04/18/2024 15:54:38 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/de_2b.jsonl.
Dataset({
    features: ['text'],
    num_rows: 500000
})
{'text': '[Buchvorstellung] Die Frau im hellblauen Kleid - BEATE MAXIAN - MonerlS-bunte-Welt\n[Buchvorstellung] Die Frau im hellblauen Kleid â€“ BEATE MAXIAN\n8. Dezember 2017 Monerl\n#166 Rezension\nWien. Marianne Altmann, einst ein gefeierter Filmstar, ist schockiert, als sie von PlÃ¤nen ihrer Tochter Vera erfÃ¤hrt. Diese mÃ¶chte einen Film Ã¼ber ihre Familie drehen. Marianne fÃ¼rchtet, dass nun auch die AbgrÃ¼nde der Familie ans Tageslicht kommen kÃ¶nnten, und mit ihnen ein lange\nzurÃ¼ckliegendes Vergehen. Es reicht zurÃ¼ck ins Jahr 1927, als ihre Mutter KÃ¤the in einem geliehenen Kleid am Theater vorsprach. Der Beginn einer beispiellosen Karriere â€“ und einer verhÃ¤ngnisvollen Bekanntschaft mit Hans Bleck, der zum mÃ¤chtigen Produzenten der Ufa aufsteigen sollte â€¦\nEine Familiengeschichte Ã¼ber vier Generationen, von Ur-GroÃŸmutter zur Enkelin, verwoben mit tiefen Geheimnissen, beginnend in Wien, als 1927 das MÃ¤dchen KÃ¤the den Mut aufbrachte, sich ihren Traum zu erfÃ¼llen.\nEs versprach eine spannende Familiengeschichte zu werden. Vier Frauen, die sich vom Schicksal, das der 2. Weltkrieg Ã¼ber sie gebracht hat, nicht von ihrem Weg haben abbringen lassen und letztendlich eine Schauspieler-Dynastie begrÃ¼ndeten, wie es in Ã–sterreich vorher keine gegeben hat. Dabei kommt einiges ans Licht, das lange Zeit verborgen geblieben war.\nDer Rahmen des Romans ist sehr gelungen. Leider schafft es Beate Maxian aber nicht, ihre Geschichte sprachlich so umzusetzten, das man von ihr durchweg gefesselt ist. Der ErzÃ¤hl- und Schreibstil ist sehr unrund. Oftmals wunderte ich mich Ã¼ber holprige und flache Dialoge. Inhaltlich enthÃ¼llten sie ein groÃŸes Geheimnis, doch Beate Maxians Charaktere nahmen dies einfach an ohne eine gewichtige EmotionalitÃ¤t, dich ich von den Figuren zur jeweiligen EnthÃ¼llung erwartet hÃ¤tte. Somit wuchs zunehmend meine Distanz zu den Protagonistinnen. Ich konnte nicht mit ihnen fÃ¼hlen, "sah" ihnen lediglich kopfschÃ¼ttelnd zu.\nDas Beziehungs-Hin-und-Her von Sophie, der letzten in der Reihe der "Altmann-Frauen", das groÃŸe Herzschmerzdrama und eine andauernde Sturheit ohne Einsicht, zerrte mehr und mehr an meinen Nerven. Die stÃ¤ndigen Wiederholungen zu Marianne, wie "Diva" und "betagte Dame", Ã¼ber die ich vermehrt stolperte, stÃ¶rten meinen Lesefluss. Ich hangelte mich von Kapitel zu Kapitel und freute mich immer auf ein Kapitel zur Vergangenheit, das Ã¼ber KÃ¤the, die Ur-GroÃŸmutter, berichtete. Diese RÃ¼ckblicke in die Vergangenheit waren es, die die Spannung aufrecht hielten und mich bis zum Ende haben durchhalten lassen.\nNach Beendigung der LektÃ¼re denke ich, hÃ¤tte sich die Autorin ausschlieÃŸlich auf die historische Geschichte eingelassen, wÃ¤re ihr wahrscheinlich ein sehr guter Roman gelungen. Denn dieser ErzÃ¤hlstrang war gut recherchiert, mit einer wundervollen und fÃ¼r sich einnehmenden Protagonistin ausgearbeitet und einer Liebesgeschichte, die viel Potential gehabt hÃ¤tte. So wÃ¤re auch der Konflikt mit und von Jakob, der Jude war, noch besser zur Geltung gekommen und es wÃ¤ren die Emotionen und Erwartungen des Lesers, die das wunderschÃ¶ne Cover geweckt hatte, erfÃ¼llt worden.\nEin thematisch sehr interessantes Buch, mit einem tollen Handlungsumfeld, spannenden Geheimnissen und vielversprechenden Charakteren, das leider an der Umsetzung scheiterte.\nIch danke dem Heyne Verlag, der mir freundlicherweise dieses Buch als Rezensionsexemplar zur VerfÃ¼gung gestellt hat.\nBeate Maxian Familiensaga Flop Heyne Verlag Ã–sterreich Rezension Rezensionsexemplar Wien\nPrevious Post Buchvorstellung â€“ Das Fundament der Ewigkeit â€“ KEN FOLLETT\nNext Post [Buchvorstellung] Das Geheimnis des Kalligraphen â€“ RAFIK SCHAMI\nIch schau ja bei solchen BÃ¼chern nach den Kritiken, um zu erfahren, ob es was fÃ¼r meine Mutter wÃ¤re. Die liest nÃ¤mlich eher diese Richtung, aber das hier kann ich wohl streichen ðŸ˜‰\n16. Dezember 2017 um 13:33 Uhr\nHey,Wenn du dich so bei den Rezis zu dem Buch umhÃ¶rst, wirst du sehen, dass meine eher schlechte Meinung nicht so durchschnittlich ist. Die meisten waren von dem Buch sehr begeistert. Ich kenne deine Mutte jetzt nicht, ich hoffe, damit entgeht ihr nicht eine Geschichte, die ihr gefallen hÃ¤tte. ðŸ˜‰ :-PGlG, monerl\n21. Dezember 2017 um 9:57 Uhr\nAlso wenn ich deine Kritikpunkte so sehe, dann bleib ich bei meiner Entscheidung ðŸ˜› In der Hinsicht weiÃŸ ich dann doch, was sie mag bzw wir sind uns da recht Ã¤hnlich.\n8. Dezember 2017 um 21:41 Uhr\nHallo liebe Andrea,ja, ich hatte mir viel von diesem Buch versprochen! Wenn deine Mama solche Geschichten liebt, dann empfehle ich dir die von TERESA SIMON oder auch BEATE RÃ–SLER z.B., siehe meine Rezis zu den BÃ¼cher der Autorinnen! Die sind klasse!GlG, monerl\nHallo liebes Monerl,der Klappentext hÃ¶rt sich ja sehr interessant an und lÃ¤sst viel erhoffen, aber da Du nicht wirklich von dem Buch Ã¼berzeugt bist, werde ich das als Geschenk ausschlieÃŸen. Meine Mutter mag gerne solche BÃ¼cher und wÃ¤re natÃ¼rlich fÃ¼r Weihnachten perfekt gewesen. Dann werde ich mich noch ein wenig umsehen. Herzlichen Dank fÃ¼r die Rezi. Liebe GrÃ¼ÃŸeAndrae\nLiebe monerl,"Hitorische Geschichte" â€“ kommt es mir nur so vor oder gibt es derzeit vermehrt derartige Geschichten, die in dieser Zeit spielen? Manchmal habe ich das GefÃ¼hl, es ist besser, eine Biografie aus dieser Zeit zu lesen. Danke fÃ¼r die ehrliche EinschÃ¤tzung.Liebe GrÃ¼ÃŸe, Anne\nLiebe Anne,ja, da hast du gar nicht Unrecht. Manch Biografie kann einem historisch die Zeit viel nÃ¤her bringen. Es gibt sehr gute Romane aus der Zeit. Ich kann jetzt gar nicht sagen, dass mir aufgefallen wÃ¤re, dass es zurzeit vermehrt Geschichten aus dieser Zeit gibt. Ich lese ja breit gefÃ¤chert und bin nicht immer im Bilde. Aber zu viele gleiche Geschichten stehen sich gegenseitig im Weg.GlG vom monerl'}
Dataset({
    features: ['text'],
    num_rows: 500000
})
{'text': '[Buchvorstellung] Die Frau im hellblauen Kleid - BEATE MAXIAN - MonerlS-bunte-Welt\n[Buchvorstellung] Die Frau im hellblauen Kleid â€“ BEATE MAXIAN\n8. Dezember 2017 Monerl\n#166 Rezension\nWien. Marianne Altmann, einst ein gefeierter Filmstar, ist schockiert, als sie von PlÃ¤nen ihrer Tochter Vera erfÃ¤hrt. Diese mÃ¶chte einen Film Ã¼ber ihre Familie drehen. Marianne fÃ¼rchtet, dass nun auch die AbgrÃ¼nde der Familie ans Tageslicht kommen kÃ¶nnten, und mit ihnen ein lange\nzurÃ¼ckliegendes Vergehen. Es reicht zurÃ¼ck ins Jahr 1927, als ihre Mutter KÃ¤the in einem geliehenen Kleid am Theater vorsprach. Der Beginn einer beispiellosen Karriere â€“ und einer verhÃ¤ngnisvollen Bekanntschaft mit Hans Bleck, der zum mÃ¤chtigen Produzenten der Ufa aufsteigen sollte â€¦\nEine Familiengeschichte Ã¼ber vier Generationen, von Ur-GroÃŸmutter zur Enkelin, verwoben mit tiefen Geheimnissen, beginnend in Wien, als 1927 das MÃ¤dchen KÃ¤the den Mut aufbrachte, sich ihren Traum zu erfÃ¼llen.\nEs versprach eine spannende Familiengeschichte zu werden. Vier Frauen, die sich vom Schicksal, das der 2. Weltkrieg Ã¼ber sie gebracht hat, nicht von ihrem Weg haben abbringen lassen und letztendlich eine Schauspieler-Dynastie begrÃ¼ndeten, wie es in Ã–sterreich vorher keine gegeben hat. Dabei kommt einiges ans Licht, das lange Zeit verborgen geblieben war.\nDer Rahmen des Romans ist sehr gelungen. Leider schafft es Beate Maxian aber nicht, ihre Geschichte sprachlich so umzusetzten, das man von ihr durchweg gefesselt ist. Der ErzÃ¤hl- und Schreibstil ist sehr unrund. Oftmals wunderte ich mich Ã¼ber holprige und flache Dialoge. Inhaltlich enthÃ¼llten sie ein groÃŸes Geheimnis, doch Beate Maxians Charaktere nahmen dies einfach an ohne eine gewichtige EmotionalitÃ¤t, dich ich von den Figuren zur jeweiligen EnthÃ¼llung erwartet hÃ¤tte. Somit wuchs zunehmend meine Distanz zu den Protagonistinnen. Ich konnte nicht mit ihnen fÃ¼hlen, "sah" ihnen lediglich kopfschÃ¼ttelnd zu.\nDas Beziehungs-Hin-und-Her von Sophie, der letzten in der Reihe der "Altmann-Frauen", das groÃŸe Herzschmerzdrama und eine andauernde Sturheit ohne Einsicht, zerrte mehr und mehr an meinen Nerven. Die stÃ¤ndigen Wiederholungen zu Marianne, wie "Diva" und "betagte Dame", Ã¼ber die ich vermehrt stolperte, stÃ¶rten meinen Lesefluss. Ich hangelte mich von Kapitel zu Kapitel und freute mich immer auf ein Kapitel zur Vergangenheit, das Ã¼ber KÃ¤the, die Ur-GroÃŸmutter, berichtete. Diese RÃ¼ckblicke in die Vergangenheit waren es, die die Spannung aufrecht hielten und mich bis zum Ende haben durchhalten lassen.\nNach Beendigung der LektÃ¼re denke ich, hÃ¤tte sich die Autorin ausschlieÃŸlich auf die historische Geschichte eingelassen, wÃ¤re ihr wahrscheinlich ein sehr guter Roman gelungen. Denn dieser ErzÃ¤hlstrang war gut recherchiert, mit einer wundervollen und fÃ¼r sich einnehmenden Protagonistin ausgearbeitet und einer Liebesgeschichte, die viel Potential gehabt hÃ¤tte. So wÃ¤re auch der Konflikt mit und von Jakob, der Jude war, noch besser zur Geltung gekommen und es wÃ¤ren die Emotionen und Erwartungen des Lesers, die das wunderschÃ¶ne Cover geweckt hatte, erfÃ¼llt worden.\nEin thematisch sehr interessantes Buch, mit einem tollen Handlungsumfeld, spannenden Geheimnissen und vielversprechenden Charakteren, das leider an der Umsetzung scheiterte.\nIch danke dem Heyne Verlag, der mir freundlicherweise dieses Buch als Rezensionsexemplar zur VerfÃ¼gung gestellt hat.\nBeate Maxian Familiensaga Flop Heyne Verlag Ã–sterreich Rezension Rezensionsexemplar Wien\nPrevious Post Buchvorstellung â€“ Das Fundament der Ewigkeit â€“ KEN FOLLETT\nNext Post [Buchvorstellung] Das Geheimnis des Kalligraphen â€“ RAFIK SCHAMI\nIch schau ja bei solchen BÃ¼chern nach den Kritiken, um zu erfahren, ob es was fÃ¼r meine Mutter wÃ¤re. Die liest nÃ¤mlich eher diese Richtung, aber das hier kann ich wohl streichen ðŸ˜‰\n16. Dezember 2017 um 13:33 Uhr\nHey,Wenn du dich so bei den Rezis zu dem Buch umhÃ¶rst, wirst du sehen, dass meine eher schlechte Meinung nicht so durchschnittlich ist. Die meisten waren von dem Buch sehr begeistert. Ich kenne deine Mutte jetzt nicht, ich hoffe, damit entgeht ihr nicht eine Geschichte, die ihr gefallen hÃ¤tte. ðŸ˜‰ :-PGlG, monerl\n21. Dezember 2017 um 9:57 Uhr\nAlso wenn ich deine Kritikpunkte so sehe, dann bleib ich bei meiner Entscheidung ðŸ˜› In der Hinsicht weiÃŸ ich dann doch, was sie mag bzw wir sind uns da recht Ã¤hnlich.\n8. Dezember 2017 um 21:41 Uhr\nHallo liebe Andrea,ja, ich hatte mir viel von diesem Buch versprochen! Wenn deine Mama solche Geschichten liebt, dann empfehle ich dir die von TERESA SIMON oder auch BEATE RÃ–SLER z.B., siehe meine Rezis zu den BÃ¼cher der Autorinnen! Die sind klasse!GlG, monerl\nHallo liebes Monerl,der Klappentext hÃ¶rt sich ja sehr interessant an und lÃ¤sst viel erhoffen, aber da Du nicht wirklich von dem Buch Ã¼berzeugt bist, werde ich das als Geschenk ausschlieÃŸen. Meine Mutter mag gerne solche BÃ¼cher und wÃ¤re natÃ¼rlich fÃ¼r Weihnachten perfekt gewesen. Dann werde ich mich noch ein wenig umsehen. Herzlichen Dank fÃ¼r die Rezi. Liebe GrÃ¼ÃŸeAndrae\nLiebe monerl,"Hitorische Geschichte" â€“ kommt es mir nur so vor oder gibt es derzeit vermehrt derartige Geschichten, die in dieser Zeit spielen? Manchmal habe ich das GefÃ¼hl, es ist besser, eine Biografie aus dieser Zeit zu lesen. Danke fÃ¼r die ehrliche EinschÃ¤tzung.Liebe GrÃ¼ÃŸe, Anne\nLiebe Anne,ja, da hast du gar nicht Unrecht. Manch Biografie kann einem historisch die Zeit viel nÃ¤her bringen. Es gibt sehr gute Romane aus der Zeit. Ich kann jetzt gar nicht sagen, dass mir aufgefallen wÃ¤re, dass es zurzeit vermehrt Geschichten aus dieser Zeit gibt. Ich lese ja breit gefÃ¤chert und bin nicht immer im Bilde. Aber zu viele gleiche Geschichten stehen sich gegenseitig im Weg.GlG vom monerl'}
Dataset({
    features: ['text'],
    num_rows: 500000
})
{'text': '[Buchvorstellung] Die Frau im hellblauen Kleid - BEATE MAXIAN - MonerlS-bunte-Welt\n[Buchvorstellung] Die Frau im hellblauen Kleid â€“ BEATE MAXIAN\n8. Dezember 2017 Monerl\n#166 Rezension\nWien. Marianne Altmann, einst ein gefeierter Filmstar, ist schockiert, als sie von PlÃ¤nen ihrer Tochter Vera erfÃ¤hrt. Diese mÃ¶chte einen Film Ã¼ber ihre Familie drehen. Marianne fÃ¼rchtet, dass nun auch die AbgrÃ¼nde der Familie ans Tageslicht kommen kÃ¶nnten, und mit ihnen ein lange\nzurÃ¼ckliegendes Vergehen. Es reicht zurÃ¼ck ins Jahr 1927, als ihre Mutter KÃ¤the in einem geliehenen Kleid am Theater vorsprach. Der Beginn einer beispiellosen Karriere â€“ und einer verhÃ¤ngnisvollen Bekanntschaft mit Hans Bleck, der zum mÃ¤chtigen Produzenten der Ufa aufsteigen sollte â€¦\nEine Familiengeschichte Ã¼ber vier Generationen, von Ur-GroÃŸmutter zur Enkelin, verwoben mit tiefen Geheimnissen, beginnend in Wien, als 1927 das MÃ¤dchen KÃ¤the den Mut aufbrachte, sich ihren Traum zu erfÃ¼llen.\nEs versprach eine spannende Familiengeschichte zu werden. Vier Frauen, die sich vom Schicksal, das der 2. Weltkrieg Ã¼ber sie gebracht hat, nicht von ihrem Weg haben abbringen lassen und letztendlich eine Schauspieler-Dynastie begrÃ¼ndeten, wie es in Ã–sterreich vorher keine gegeben hat. Dabei kommt einiges ans Licht, das lange Zeit verborgen geblieben war.\nDer Rahmen des Romans ist sehr gelungen. Leider schafft es Beate Maxian aber nicht, ihre Geschichte sprachlich so umzusetzten, das man von ihr durchweg gefesselt ist. Der ErzÃ¤hl- und Schreibstil ist sehr unrund. Oftmals wunderte ich mich Ã¼ber holprige und flache Dialoge. Inhaltlich enthÃ¼llten sie ein groÃŸes Geheimnis, doch Beate Maxians Charaktere nahmen dies einfach an ohne eine gewichtige EmotionalitÃ¤t, dich ich von den Figuren zur jeweiligen EnthÃ¼llung erwartet hÃ¤tte. Somit wuchs zunehmend meine Distanz zu den Protagonistinnen. Ich konnte nicht mit ihnen fÃ¼hlen, "sah" ihnen lediglich kopfschÃ¼ttelnd zu.\nDas Beziehungs-Hin-und-Her von Sophie, der letzten in der Reihe der "Altmann-Frauen", das groÃŸe Herzschmerzdrama und eine andauernde Sturheit ohne Einsicht, zerrte mehr und mehr an meinen Nerven. Die stÃ¤ndigen Wiederholungen zu Marianne, wie "Diva" und "betagte Dame", Ã¼ber die ich vermehrt stolperte, stÃ¶rten meinen Lesefluss. Ich hangelte mich von Kapitel zu Kapitel und freute mich immer auf ein Kapitel zur Vergangenheit, das Ã¼ber KÃ¤the, die Ur-GroÃŸmutter, berichtete. Diese RÃ¼ckblicke in die Vergangenheit waren es, die die Spannung aufrecht hielten und mich bis zum Ende haben durchhalten lassen.\nNach Beendigung der LektÃ¼re denke ich, hÃ¤tte sich die Autorin ausschlieÃŸlich auf die historische Geschichte eingelassen, wÃ¤re ihr wahrscheinlich ein sehr guter Roman gelungen. Denn dieser ErzÃ¤hlstrang war gut recherchiert, mit einer wundervollen und fÃ¼r sich einnehmenden Protagonistin ausgearbeitet und einer Liebesgeschichte, die viel Potential gehabt hÃ¤tte. So wÃ¤re auch der Konflikt mit und von Jakob, der Jude war, noch besser zur Geltung gekommen und es wÃ¤ren die Emotionen und Erwartungen des Lesers, die das wunderschÃ¶ne Cover geweckt hatte, erfÃ¼llt worden.\nEin thematisch sehr interessantes Buch, mit einem tollen Handlungsumfeld, spannenden Geheimnissen und vielversprechenden Charakteren, das leider an der Umsetzung scheiterte.\nIch danke dem Heyne Verlag, der mir freundlicherweise dieses Buch als Rezensionsexemplar zur VerfÃ¼gung gestellt hat.\nBeate Maxian Familiensaga Flop Heyne Verlag Ã–sterreich Rezension Rezensionsexemplar Wien\nPrevious Post Buchvorstellung â€“ Das Fundament der Ewigkeit â€“ KEN FOLLETT\nNext Post [Buchvorstellung] Das Geheimnis des Kalligraphen â€“ RAFIK SCHAMI\nIch schau ja bei solchen BÃ¼chern nach den Kritiken, um zu erfahren, ob es was fÃ¼r meine Mutter wÃ¤re. Die liest nÃ¤mlich eher diese Richtung, aber das hier kann ich wohl streichen ðŸ˜‰\n16. Dezember 2017 um 13:33 Uhr\nHey,Wenn du dich so bei den Rezis zu dem Buch umhÃ¶rst, wirst du sehen, dass meine eher schlechte Meinung nicht so durchschnittlich ist. Die meisten waren von dem Buch sehr begeistert. Ich kenne deine Mutte jetzt nicht, ich hoffe, damit entgeht ihr nicht eine Geschichte, die ihr gefallen hÃ¤tte. ðŸ˜‰ :-PGlG, monerl\n21. Dezember 2017 um 9:57 Uhr\nAlso wenn ich deine Kritikpunkte so sehe, dann bleib ich bei meiner Entscheidung ðŸ˜› In der Hinsicht weiÃŸ ich dann doch, was sie mag bzw wir sind uns da recht Ã¤hnlich.\n8. Dezember 2017 um 21:41 Uhr\nHallo liebe Andrea,ja, ich hatte mir viel von diesem Buch versprochen! Wenn deine Mama solche Geschichten liebt, dann empfehle ich dir die von TERESA SIMON oder auch BEATE RÃ–SLER z.B., siehe meine Rezis zu den BÃ¼cher der Autorinnen! Die sind klasse!GlG, monerl\nHallo liebes Monerl,der Klappentext hÃ¶rt sich ja sehr interessant an und lÃ¤sst viel erhoffen, aber da Du nicht wirklich von dem Buch Ã¼berzeugt bist, werde ich das als Geschenk ausschlieÃŸen. Meine Mutter mag gerne solche BÃ¼cher und wÃ¤re natÃ¼rlich fÃ¼r Weihnachten perfekt gewesen. Dann werde ich mich noch ein wenig umsehen. Herzlichen Dank fÃ¼r die Rezi. Liebe GrÃ¼ÃŸeAndrae\nLiebe monerl,"Hitorische Geschichte" â€“ kommt es mir nur so vor oder gibt es derzeit vermehrt derartige Geschichten, die in dieser Zeit spielen? Manchmal habe ich das GefÃ¼hl, es ist besser, eine Biografie aus dieser Zeit zu lesen. Danke fÃ¼r die ehrliche EinschÃ¤tzung.Liebe GrÃ¼ÃŸe, Anne\nLiebe Anne,ja, da hast du gar nicht Unrecht. Manch Biografie kann einem historisch die Zeit viel nÃ¤her bringen. Es gibt sehr gute Romane aus der Zeit. Ich kann jetzt gar nicht sagen, dass mir aufgefallen wÃ¤re, dass es zurzeit vermehrt Geschichten aus dieser Zeit gibt. Ich lese ja breit gefÃ¤chert und bin nicht immer im Bilde. Aber zu viele gleiche Geschichten stehen sich gegenseitig im Weg.GlG vom monerl'}
[WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:54:39,591 >> Token indices sequence length is longer than the specified maximum sequence length for this model (36986 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00000_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   0%|          | 1000/2000000 [00:11<6:21:09, 87.41 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00001_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   0%|          | 2000/2000000 [00:13<3:22:25, 164.51 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:54:45,695 >> Token indices sequence length is longer than the specified maximum sequence length for this model (46621 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00002_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   0%|          | 3000/2000000 [00:17<2:47:29, 198.71 examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 4000/2000000 [00:18<1:52:23, 295.97 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00003_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   0%|          | 5000/2000000 [00:19<1:30:07, 368.92 examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 6000/2000000 [00:20<1:06:39, 498.62 examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 7000/2000000 [00:23<1:19:10, 419.52 examples/s]Running tokenizer on dataset (num_proc=16):   0%|          | 8000/2000000 [00:24<56:58, 582.64 examples/s]  Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00004_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   0%|          | 9000/2000000 [00:24<48:05, 690.01 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:54:54,834 >> Token indices sequence length is longer than the specified maximum sequence length for this model (45476 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=16):   0%|          | 10000/2000000 [00:26<50:56, 651.17 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:54:55,339 >> Token indices sequence length is longer than the specified maximum sequence length for this model (37350 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=16):   1%|          | 11000/2000000 [00:27<40:57, 809.38 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00005_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   1%|          | 12000/2000000 [00:27<31:17, 1058.71 examples/s]Running tokenizer on dataset (num_proc=16):   1%|          | 13000/2000000 [00:29<45:35, 726.49 examples/s] Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00006_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   1%|          | 14000/2000000 [00:30<35:27, 933.52 examples/s]04/18/2024 15:54:58 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ar_2b.jsonl.
04/18/2024 15:54:58 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ar_2b.jsonl.
04/18/2024 15:54:59 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ar_2b.jsonl.
Dataset({
    features: ['text'],
    num_rows: 500000
})
{'text': 'ØºØµÙ† Ø§Ù„Ø²ÙŠØªÙˆÙ† ÙˆØ§Ù„Ø¨Ù†Ø¯Ù‚ÙŠØ© // ANONYMOUS â€” Ø¬ÙØª Ø§Ù„Ø£Ù‚Ù„Ø§Ù…\nØºØµÙ† Ø§Ù„Ø²ÙŠØªÙˆÙ† ÙˆØ§Ù„Ø¨Ù†Ø¯Ù‚ÙŠØ© // ANONYMOUS\nAugust 08, 2014 in INTERVIEW, TEXT\nØ¥Ø³ØªÙŠÙ‚Ø¸ Ø±Ø¤ÙˆÙ Ù…Ù† Ø³Ø¨Ø§ØªÙ‡ Ø¹Ù„Ù‰ ØµÙˆØª ØµÙØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø±. ÙˆÙ„ÙƒÙ† Ù…Ù† Ø£ÙŠÙ† Ø£ØªØªØŸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØµÙØ§Ø±Ø§Øª Ø¥Ù†Ø°Ø§Ø± ÙÙŠ Ø§Ù„Ø£Ø­ÙŠØ§Ø¡ Ø§Ù„ÙÙ‚ÙŠØ±Ø© Ø§Ù„ØªÙŠ ØªÙ‚Ø¹ Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø§Ø¦Ø· Ø§Ù„Ø¹Ø§Ø²Ù„.\nØ¥ØªØ¶Ø­ Ù„Ø±Ø¤ÙˆÙØŒ ÙˆÙ‡Ùˆ ÙÙŠ Ø­Ø§Ù„Ø© Ø¨ÙŠÙ† Ø§Ù„Ù†ÙˆÙ… Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆØ§Ù„ÙŠÙ‚Ø¸Ø© Ø§Ù„Ø´Ø¯ÙŠØ¯Ø©ØŒ Ø£Ù† ØµÙØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø± Ù‡ÙŠ ØµÙˆØª Ø£Ù…Ù‡ ÙˆÙ‡ÙŠ ØªÙ†Ø§Ø¯ÙŠ:\n"Ø±Ø¤ÙˆÙ!\nÙŠØ§ Ø±Ø¤ÙˆÙ!\nÙ‚ØµÙ! Ù‚ØµÙ! Ù‚Øµ-\nÙ‚Ø¨Ù„ Ø£Ù† ØªØ³ØªØ·ÙŠØ¹ Ø£Ù† ØªÙƒÙ…Ù„ Ø£Ù… Ø±Ø¤ÙˆÙ ÙƒÙ„Ø§Ù…Ù‡Ø§ ØŒ Ø³Ø§Ø¯ Ø§Ù„ØµÙ…Øª Ø¨Ø¹Ø¯ Ø£Ù† ÙˆÙ‚Ø¹ Ø¥Ù†ÙØ¬Ø§Ø± Ø¶Ø®Ù…ØŒ Ù…Ù† Ø³Ù…Ø¹Ù‡ Ù‚Ø¯ ÙŠØ¹ØªÙ‚Ø¯ Ø£Ù† Ø§Ù„Ù‡Ø²Ù‘Ø© Ø§Ù„ØªÙŠ Ø®Ù„ÙÙ‡Ø§ ÙˆØµÙ„Øª- Ø¨ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù‚Ù„- Ø±Ø§Ø¨Ø¹ Ø§Ù„Ø³Ù…Ø§ÙˆØ§Øª Ø§Ù„Ø³Ø¨Ø¹.\nÙƒØ§Ù† Ø±Ø¤ÙˆÙ ÙˆØ­ÙŠØ¯ Ø£Ù…Ù‡ ÙˆØ£Ø¨ÙŠÙ‡ØŒ ÙŠØ³ÙƒÙ† Ù…Ø¹Ù‡Ù…Ø§ ÙÙŠ Ø¨ÙŠØª Ø´Ø¯ÙŠØ¯ Ø§Ù„ØªÙˆØ§Ø¶Ø¹ ÙŠÙ‚Ø¹ Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø§Ø¦Ø· Ø§Ù„Ø¹Ø§Ø²Ù„. ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ù„Ùƒ Ø´Ø¬Ø±Ø© Ø²ÙŠØªÙˆÙ† ØªÙ‚Ø¹ ØªÙ…Ø§Ù…Ø§Ù‹ Ø£Ù…Ø§Ù… Ù†Ø§ÙØ°Ø© Ø¯ÙŠØ§Ø± Ø±Ø¤ÙˆÙØŒ Ù‚Ø¯ Ø²Ø±Ø¹Ù‡Ø§ Ø£Ø¨Ø§Ù‡ ÙŠÙˆÙ… Ø£Ø®Ø° Ø±Ø¤ÙˆÙ Ø£ÙˆÙ„ Ø¥Ø³ØªÙ†Ø´Ø§Ù‚Ø© Ù„Ù‡ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ù†ÙŠØ§ØŒ ÙŠÙˆÙ… ÙŠÙ‚Ø¹ ÙÙŠ Ø£ÙƒØ«Ø± Ø£ÙŠØ§Ù… Ø§Ù„Ø±Ø¨ÙŠØ¹ Ø±Ø¨ÙŠØ¹Ø§Ù‹.\nÙƒØ§Ù†Øª Ø§Ù„Ø±ÙŠØ§Ø­ØŒ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙŠÙˆÙ…ØŒ Ù„Ø·ÙŠÙØ© Ø¨Ø´Ø¯Ø©. Ø¨Ø±ÙˆØ¯ØªÙ‡Ø§ ØªÙ‚Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø±Ø¡ ÙƒØ§Ù„Ø¨Ø´Ø±Ù‰ Ø§Ù„Ø³Ø§Ø±Ø©ØŒ Ù„Ø§ ØªÙ‚Ø³Ùˆ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¸Ø§Ù… ÙˆÙ„Ø§ ÙŠÙ‚Ø´Ø¹Ø± Ù„Ù‡Ø§ Ø§Ù„Ø¨Ø¯Ù†.\nØ¥Ø³ØªÙŠÙ‚Ø¸ Ø±Ø¤ÙˆÙ Ù…Ù† Ø³Ø¨Ø§ØªÙ‡ØŒ ÙˆÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø© ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¨Ø§Øª Ù†ØªÙŠØ¬Ø© Ø¥Ù†Ù‡ÙŠØ§Ø± Ø¯ÙŠØ§Ø±Ù‡ Ø¹Ù„Ù‰ Ø±Ø£Ø³Ù‡. ØªÙÙ‚Ø¯ Ø£Ø¹Ø¶Ø§Ø¡ Ø¬Ø³Ù…Ù‡ ÙˆØ§ÙƒØªØ´Ù Ø£Ù†Ù‡Ø§ Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù…ØŒ Ù…Ù† Ø§Ù„Ù†Ø¸Ø±Ø© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„. Ù„Ù… ØªØ¨ØªØ± Ù„Ù‡ Ø³Ø§Ù‚ Ø£Ùˆ Ø°Ø±Ø§Ø¹ØŒ ÙˆÙ„Ø§ Ø²Ø§Ù„Øª Ø£ØµØ§Ø¨Ø¹Ù‡ ÙƒÙ„Ù‡Ø§ Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ø­ØªÙ‰ Ø§Ù„ØªÙŠ Ø¹Ù„Ù‰ Ø£Ù‚Ø¯Ø§Ù…Ù‡ Ø§Ù„Ø­Ø§ÙÙŠØ©. ÙƒØ§Ù† Ø§Ù„Ø®Ø¯Ø± Ù…Ù†ØªØ´Ø± ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø¬Ø³Ù…Ù‡ØŒ ÙŠØ®Ø·Ùˆ Ø®Ø·Ùˆ Ø§Ù„Ù†Ù…Ù„Ø© Ù…Ù† Ù‚Ù…Ø© Ø±Ø£Ø³Ù‡ Ø¥Ù„Ù‰ Ù†Ù‡Ø§ÙŠØ© Ø£Ø·Ø±Ø§Ù Ø£ØµØ§Ø¨Ø¹ Ù‚Ø¯Ù…ÙŠÙ‡. Ù„Ø­Ø¸Ø© Ø£Ù† Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ­Ø±Ù‘ÙƒØŒ Ø²Ø§Ù„ Ø§Ù„Ø®Ø¯Ø± ÙƒØ§Ù„Ù‚Ù…Ø§Ø´ Ø§Ù„Ø®ÙÙŠÙ Ø§Ù„Ø°ÙŠ ÙŠØ²Ø§Ù„ Ù…Ù† Ø¹Ù„Ù‰ ÙÙˆÙ‚ Ø§Ù„Ø·Ø§ÙˆÙ„Ø©ØŒ ÙˆØ¨Ø¹Ø« Ø¯Ù…Ø§ØºÙ‡ Ù„Ø¬Ø³Ù…Ù‡ ØµÙØ§Ø±Ø© Ø¥Ù†Ø°Ø§Ø± Ù…Ù† Ù†ÙˆØ¹ Ø¢Ø®Ø±ØŒ ÙƒØ§Ù†Øª Ù†ÙˆØ¹Ø§Ù‹ Ù…Ø§ ÙƒØµØ¹Ù‚Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¡ Ø§Ù„ØªÙŠ Ø¬Ø¹Ù„ØªÙ‡ ÙŠØªÙŠÙ‚Ù† Ø£Ù† Ø¨Ø¯Ù†Ù‡ Ù„ÙŠØ³ Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù….\nØ£Ø²Ø§Ø­ Ø§Ù„Ø£Ù†Ù‚Ø§Ø¶ Ù…Ù† ÙÙˆÙ‚Ù‡ ÙˆØ£Ø¯Ø§Ø± Ø¨Ù†Ø¸Ø±Ù‡ ÙŠÙ…ÙŠÙ†Ø§ Ø«Ù… Ø´Ù…Ø§Ù„ ØªØ¬Ø§Ù‡ Ø²ÙˆØ§ÙŠØ§ Ø§Ù„Ø¨ÙŠØª Ø§Ù„ØµØºÙŠØ±ØŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù…Ø§ ØªØ¨Ù‚Ù‰ Ù…Ù† Ø§Ù„Ø¨ÙŠØª Ø§Ù„ØµØºÙŠØ±ØŒ ÙˆÙ„Ù… ÙŠØ±Ù‰ ØºÙŠØ± Ø§Ù„Ø¸Ù„Ø§Ù…. ØªØ­ÙˆÙ„ Ø§Ù„Ø¨ÙŠØª Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ ÙˆØ¸Ù„ Ø­Ø§Ø¦Ø· ÙˆØ§Ø­Ø¯ Ù‡Ùˆ Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ø°ÙŠ Ù„Ø§ ÙŠØ²Ø§Ù„ ÙˆØ§Ù‚Ù Ø¹Ù„Ù‰ Ù‚Ø¯Ù…ÙŠÙ‡. Ø­Ø§ÙˆÙ„ Ø£Ù† ÙŠØ·Ù„Ù‚ Ù…Ù† Ø­Ù†Ø¬Ø±ØªÙ‡ ØµÙˆØªØ§Ù‹ ÙŠÙ†Ø§Ø¯ÙŠ Ø¨Ù‡ Ø£Ù…Ù‡ ÙˆØ£Ø¨Ø§Ù‡ØŒ ÙˆØ¹Ù†Ø¯Ù…Ø§ ØªØ­Ø±ÙƒØª Ø´ÙØªØ§Ù‡ØŒ Ø­Ø³Ù‘ Ø±Ø¤ÙˆÙ ÙÙ‚Ø· Ø¨Ø°Ø¨Ø°Ø¨Ø© ØµØ§Ù…ØªØ© Ø®ÙÙŠÙØ© ØªÙ†Ø¨Ø¹Ø« Ù…Ù† Ø­Ù†Ø¬Ø±ØªÙ‡ØŒ ÙˆØ¹Ù†Ø¯Ù‡Ø§ Ù„Ø§Ø­Ø¸ ÙƒÙŠÙ ÙƒØ§Ù† Ø§Ù„Ø³ÙƒÙˆØª ÙŠØ®Ù„Ø¯ Ø¨Ø«Ù‚Ù„ Ø´Ø¯ÙŠØ¯ ÙÙˆÙ‚ Ø³Ù…Ø¹Ù‡.\nØ¹Ø¨Ø± ÙÙˆÙ‚ Ø£Ù†Ù‚Ø§Ø¶ Ø³Ù‚Ù Ø¨ÙŠØªÙ‡ Ø§Ù„Ø°ÙŠ Ø¨Ø§Øª Ø§Ù„Ø¢Ù† ÙŠØªÙˆØ³Ù‘Ø¯ Ø§Ù„Ø£Ø±Ø¶ ØªØ­Øª Ù‚Ø¯Ù…ÙŠÙ‡ØŒ ÙˆØ¹Ù†Ø¯Ù‡Ø§ Ø®Ø·ÙØª Ø¹ÙŠÙ†Ù‡ Ù„Ù…Ø­Ø© Ø°Ø±Ø§Ø¹ Ù…Ø®Ù‘ØªÙ…Ø© Ø¨Ø®Ø§ØªÙ… Ù†Ø­Ø§Ø³ÙŠ Ù…Ø·Ù„ÙŠ Ø¨Ø§Ù„Ø°Ù‡Ø¨ØŒ Ù…Ù†Ø¨Ø¹Ø«Ø© Ù…Ù† Ø¨ÙŠÙ† Ø£Ù†Ù‚Ø§Ø¶Ù Ù…ØµÙÙˆÙØ© ÙÙˆÙ‚ Ø£Ù†Ù‚Ø§Ø¶. Ø­Ø³Ù‘ Ø±Ø¤ÙˆÙ Ø¨ÙˆØ®Ø²Ø© ÙÙŠ Ø­Ù†Ø¬Ø±ØªÙ‡ØŒ Ø£Ø®Ø°Øª Ø·Ø±ÙŠÙ‚Ù‡Ø§ Ù„Ù…Ù†ØªØµÙ ØµØ¯Ø±Ù‡ Ù…Ø¹ Ø¥Ø¨ØªÙ„Ø§Ø¹ Ø§Ù„Ø±ÙŠÙ‚. ØªØ­ÙˆÙ„Øª Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ®Ø²Ø© Ø¥Ù„Ù‰ Ø­Ø±Ø§Ø±Ø© Ø´Ø¯ÙŠØ¯Ø© ØªÙƒØ§Ø¯ Ø£Ù† ØªØ°ÙŠØ¨ Ø¬Ù„Ø¯Ù‡ ÙˆØªÙ†Ø¨Ø¹Ø« Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø¬Ø³Ù…Ù‡ Ø§Ù„Ù…ØºØ·Ù‰ Ø¨Ø§Ù„Ø¯Ù… ÙˆØ§Ù„ØºØ¨Ø§Ø± ÙˆØ§Ù„Ù…Ù„Ø§Ø¨Ø³ Ø§Ù„Ù…Ù…Ø²Ù‚Ø©.\nØ¥Ù„ØªÙØª Ø±Ø¤ÙˆÙ ÙˆØ±Ø£Ù‰ Ù…Ø³Ø¨Ø§Ø­ Ù…Ù„Ù‚Ù‰ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¶ØŒ ØºØ§Ø±Ù‚ ÙÙŠ Ø¨Ù‚Ø¹Ø© Ù…Ù† Ø§Ù„Ø¯Ù…ØŒ ÙˆØ­ÙŠÙ†Ù‡Ø§ Ø£Ø¯Ø±Ùƒ Ø£Ù† Ø£Ù…Ù‡ ÙˆØ£Ø¨Ø§Ù‡ Ù‚Ø¯ ÙØ§Ø±Ù‚Ø§Ù‡ ÙˆØ¥Ø±ØªØ­Ù„Ø§ Ø¥Ù„Ù‰ Ù…ÙƒØ§Ù† Ø¢Ø®Ø±ØŒ Ù…ÙƒØ§Ù† Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙÙŠÙ‡ ØµÙØ§Ø±Ø§Øª Ø¥Ù†Ø°Ø§Ø±ØŒ ÙˆÙ„Ø§ Ø­Ø§Ø¦Ø· Ø¹Ø§Ø²Ù„. ÙˆÙ‚Ù Ø£Ù…Ø§Ù… Ø§Ù„Ù†Ø¬Ù…ØªÙŠÙ† Ø§Ù„Ù‡Ø§ÙˆÙŠØªØ§Ù† Ø§Ù„Ù„ØªØ§Ù† ÙŠØºØ·ÙŠÙ‡Ù…Ø§ Ø§Ù„Ø³Ù‚Ù Ø§Ù„Ù…Ù†Ù‚Ø¶ØŒ Ø¨ØµÙ…Øª.\nÙˆØ¬Ø¯ Ø±Ø¤ÙˆÙ Ø±ÙØ´ ÙˆØ§Ù„Ø¯Ù‡ ÙÙŠ Ù…ÙƒØ§Ù† Ù…Ø§ ØªØ­Øª Ø§Ù„Ø£Ù†Ù‚Ø§Ø¶ØŒ ÙˆØ¨Ø¹Ø¯Ù…Ø§ Ø£ÙƒÙ…Ù„ Ø¯ÙÙ† ÙˆØ§Ù„Ø¯ÙŠÙ‡ØŒ Ø£Ø®Ø° ÙŠØ­ÙØ± Ø§Ù„Ø¨Ù‚Ø¹Ø© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© Ù„Ø´Ø¬Ø±Ø© Ø§Ù„Ø²ÙŠØªÙˆÙ†ØŒ Ø§Ù„ØªÙŠ Ù„Ù… ÙŠØªØ¨Ù‚Ù‰ Ù…Ù†Ù‡Ø§ Ø¥Ù„Ø§ ØºØµÙ† ÙˆØ§Ø­Ø¯. Ø¹Ù†Ø¯Ù…Ø§ Ø³Ù…Ø¹ ØµÙˆØª Ø§Ù„Ø±ÙØ´ ÙŠØµØ·Ø¯Ù… Ø¨Ø´ÙŠØ¡ Ù…Ø§ ØªØ­Øª Ø§Ù„ØªØ±Ø§Ø¨ØŒ Ø¨Ø¹Ø« ÙŠØ¯Ù‡ ÙÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­ÙØ±Ø© ÙˆØ¥Ø¬ØªØ« Ø§Ù„Ø¨Ù†Ø¯Ù‚ÙŠØ©. Ø£Ù…Ø³Ùƒ Ø¨ØºØµÙ† Ø§Ù„Ø²ÙŠØªÙˆÙ† ÙˆØ±Ù…Ø§Ù‡ ÙÙŠ Ø§Ù„Ù†ÙŠØ±Ø§Ù† Ø§Ù„ØªÙŠ Ø¥Ø´ØªØ¹Ù„Øª Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¶ÙˆØ¡ Ø§Ù„Ø°ÙŠ Ù‡ÙˆÙ‰ ÙÙˆÙ‚ Ø³Ù‚Ù Ø¯ÙŠØ§Ø±Ù‡ ÙˆØ£Ø³Ø±Ù‰ Ø¨Ø£Ù…Ù‡ ÙˆØ£Ø¨Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ø°ÙŠ ÙŠØ®Ù„Ùˆ Ù…Ù† ØµÙØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø±.'}
Dataset({
    features: ['text'],
    num_rows: 500000
})
{'text': 'ØºØµÙ† Ø§Ù„Ø²ÙŠØªÙˆÙ† ÙˆØ§Ù„Ø¨Ù†Ø¯Ù‚ÙŠØ© // ANONYMOUS â€” Ø¬ÙØª Ø§Ù„Ø£Ù‚Ù„Ø§Ù…\nØºØµÙ† Ø§Ù„Ø²ÙŠØªÙˆÙ† ÙˆØ§Ù„Ø¨Ù†Ø¯Ù‚ÙŠØ© // ANONYMOUS\nAugust 08, 2014 in INTERVIEW, TEXT\nØ¥Ø³ØªÙŠÙ‚Ø¸ Ø±Ø¤ÙˆÙ Ù…Ù† Ø³Ø¨Ø§ØªÙ‡ Ø¹Ù„Ù‰ ØµÙˆØª ØµÙØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø±. ÙˆÙ„ÙƒÙ† Ù…Ù† Ø£ÙŠÙ† Ø£ØªØªØŸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØµÙØ§Ø±Ø§Øª Ø¥Ù†Ø°Ø§Ø± ÙÙŠ Ø§Ù„Ø£Ø­ÙŠØ§Ø¡ Ø§Ù„ÙÙ‚ÙŠØ±Ø© Ø§Ù„ØªÙŠ ØªÙ‚Ø¹ Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø§Ø¦Ø· Ø§Ù„Ø¹Ø§Ø²Ù„.\nØ¥ØªØ¶Ø­ Ù„Ø±Ø¤ÙˆÙØŒ ÙˆÙ‡Ùˆ ÙÙŠ Ø­Ø§Ù„Ø© Ø¨ÙŠÙ† Ø§Ù„Ù†ÙˆÙ… Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆØ§Ù„ÙŠÙ‚Ø¸Ø© Ø§Ù„Ø´Ø¯ÙŠØ¯Ø©ØŒ Ø£Ù† ØµÙØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø± Ù‡ÙŠ ØµÙˆØª Ø£Ù…Ù‡ ÙˆÙ‡ÙŠ ØªÙ†Ø§Ø¯ÙŠ:\n"Ø±Ø¤ÙˆÙ!\nÙŠØ§ Ø±Ø¤ÙˆÙ!\nÙ‚ØµÙ! Ù‚ØµÙ! Ù‚Øµ-\nÙ‚Ø¨Ù„ Ø£Ù† ØªØ³ØªØ·ÙŠØ¹ Ø£Ù† ØªÙƒÙ…Ù„ Ø£Ù… Ø±Ø¤ÙˆÙ ÙƒÙ„Ø§Ù…Ù‡Ø§ ØŒ Ø³Ø§Ø¯ Ø§Ù„ØµÙ…Øª Ø¨Ø¹Ø¯ Ø£Ù† ÙˆÙ‚Ø¹ Ø¥Ù†ÙØ¬Ø§Ø± Ø¶Ø®Ù…ØŒ Ù…Ù† Ø³Ù…Ø¹Ù‡ Ù‚Ø¯ ÙŠØ¹ØªÙ‚Ø¯ Ø£Ù† Ø§Ù„Ù‡Ø²Ù‘Ø© Ø§Ù„ØªÙŠ Ø®Ù„ÙÙ‡Ø§ ÙˆØµÙ„Øª- Ø¨ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù‚Ù„- Ø±Ø§Ø¨Ø¹ Ø§Ù„Ø³Ù…Ø§ÙˆØ§Øª Ø§Ù„Ø³Ø¨Ø¹.\nÙƒØ§Ù† Ø±Ø¤ÙˆÙ ÙˆØ­ÙŠØ¯ Ø£Ù…Ù‡ ÙˆØ£Ø¨ÙŠÙ‡ØŒ ÙŠØ³ÙƒÙ† Ù…Ø¹Ù‡Ù…Ø§ ÙÙŠ Ø¨ÙŠØª Ø´Ø¯ÙŠØ¯ Ø§Ù„ØªÙˆØ§Ø¶Ø¹ ÙŠÙ‚Ø¹ Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø§Ø¦Ø· Ø§Ù„Ø¹Ø§Ø²Ù„. ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ù„Ùƒ Ø´Ø¬Ø±Ø© Ø²ÙŠØªÙˆÙ† ØªÙ‚Ø¹ ØªÙ…Ø§Ù…Ø§Ù‹ Ø£Ù…Ø§Ù… Ù†Ø§ÙØ°Ø© Ø¯ÙŠØ§Ø± Ø±Ø¤ÙˆÙØŒ Ù‚Ø¯ Ø²Ø±Ø¹Ù‡Ø§ Ø£Ø¨Ø§Ù‡ ÙŠÙˆÙ… Ø£Ø®Ø° Ø±Ø¤ÙˆÙ Ø£ÙˆÙ„ Ø¥Ø³ØªÙ†Ø´Ø§Ù‚Ø© Ù„Ù‡ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ù†ÙŠØ§ØŒ ÙŠÙˆÙ… ÙŠÙ‚Ø¹ ÙÙŠ Ø£ÙƒØ«Ø± Ø£ÙŠØ§Ù… Ø§Ù„Ø±Ø¨ÙŠØ¹ Ø±Ø¨ÙŠØ¹Ø§Ù‹.\nÙƒØ§Ù†Øª Ø§Ù„Ø±ÙŠØ§Ø­ØŒ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙŠÙˆÙ…ØŒ Ù„Ø·ÙŠÙØ© Ø¨Ø´Ø¯Ø©. Ø¨Ø±ÙˆØ¯ØªÙ‡Ø§ ØªÙ‚Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø±Ø¡ ÙƒØ§Ù„Ø¨Ø´Ø±Ù‰ Ø§Ù„Ø³Ø§Ø±Ø©ØŒ Ù„Ø§ ØªÙ‚Ø³Ùˆ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¸Ø§Ù… ÙˆÙ„Ø§ ÙŠÙ‚Ø´Ø¹Ø± Ù„Ù‡Ø§ Ø§Ù„Ø¨Ø¯Ù†.\nØ¥Ø³ØªÙŠÙ‚Ø¸ Ø±Ø¤ÙˆÙ Ù…Ù† Ø³Ø¨Ø§ØªÙ‡ØŒ ÙˆÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø© ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¨Ø§Øª Ù†ØªÙŠØ¬Ø© Ø¥Ù†Ù‡ÙŠØ§Ø± Ø¯ÙŠØ§Ø±Ù‡ Ø¹Ù„Ù‰ Ø±Ø£Ø³Ù‡. ØªÙÙ‚Ø¯ Ø£Ø¹Ø¶Ø§Ø¡ Ø¬Ø³Ù…Ù‡ ÙˆØ§ÙƒØªØ´Ù Ø£Ù†Ù‡Ø§ Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù…ØŒ Ù…Ù† Ø§Ù„Ù†Ø¸Ø±Ø© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„. Ù„Ù… ØªØ¨ØªØ± Ù„Ù‡ Ø³Ø§Ù‚ Ø£Ùˆ Ø°Ø±Ø§Ø¹ØŒ ÙˆÙ„Ø§ Ø²Ø§Ù„Øª Ø£ØµØ§Ø¨Ø¹Ù‡ ÙƒÙ„Ù‡Ø§ Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ø­ØªÙ‰ Ø§Ù„ØªÙŠ Ø¹Ù„Ù‰ Ø£Ù‚Ø¯Ø§Ù…Ù‡ Ø§Ù„Ø­Ø§ÙÙŠØ©. ÙƒØ§Ù† Ø§Ù„Ø®Ø¯Ø± Ù…Ù†ØªØ´Ø± ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø¬Ø³Ù…Ù‡ØŒ ÙŠØ®Ø·Ùˆ Ø®Ø·Ùˆ Ø§Ù„Ù†Ù…Ù„Ø© Ù…Ù† Ù‚Ù…Ø© Ø±Ø£Ø³Ù‡ Ø¥Ù„Ù‰ Ù†Ù‡Ø§ÙŠØ© Ø£Ø·Ø±Ø§Ù Ø£ØµØ§Ø¨Ø¹ Ù‚Ø¯Ù…ÙŠÙ‡. Ù„Ø­Ø¸Ø© Ø£Ù† Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ­Ø±Ù‘ÙƒØŒ Ø²Ø§Ù„ Ø§Ù„Ø®Ø¯Ø± ÙƒØ§Ù„Ù‚Ù…Ø§Ø´ Ø§Ù„Ø®ÙÙŠÙ Ø§Ù„Ø°ÙŠ ÙŠØ²Ø§Ù„ Ù…Ù† Ø¹Ù„Ù‰ ÙÙˆÙ‚ Ø§Ù„Ø·Ø§ÙˆÙ„Ø©ØŒ ÙˆØ¨Ø¹Ø« Ø¯Ù…Ø§ØºÙ‡ Ù„Ø¬Ø³Ù…Ù‡ ØµÙØ§Ø±Ø© Ø¥Ù†Ø°Ø§Ø± Ù…Ù† Ù†ÙˆØ¹ Ø¢Ø®Ø±ØŒ ÙƒØ§Ù†Øª Ù†ÙˆØ¹Ø§Ù‹ Ù…Ø§ ÙƒØµØ¹Ù‚Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¡ Ø§Ù„ØªÙŠ Ø¬Ø¹Ù„ØªÙ‡ ÙŠØªÙŠÙ‚Ù† Ø£Ù† Ø¨Ø¯Ù†Ù‡ Ù„ÙŠØ³ Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù….\nØ£Ø²Ø§Ø­ Ø§Ù„Ø£Ù†Ù‚Ø§Ø¶ Ù…Ù† ÙÙˆÙ‚Ù‡ ÙˆØ£Ø¯Ø§Ø± Ø¨Ù†Ø¸Ø±Ù‡ ÙŠÙ…ÙŠÙ†Ø§ Ø«Ù… Ø´Ù…Ø§Ù„ ØªØ¬Ø§Ù‡ Ø²ÙˆØ§ÙŠØ§ Ø§Ù„Ø¨ÙŠØª Ø§Ù„ØµØºÙŠØ±ØŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù…Ø§ ØªØ¨Ù‚Ù‰ Ù…Ù† Ø§Ù„Ø¨ÙŠØª Ø§Ù„ØµØºÙŠØ±ØŒ ÙˆÙ„Ù… ÙŠØ±Ù‰ ØºÙŠØ± Ø§Ù„Ø¸Ù„Ø§Ù…. ØªØ­ÙˆÙ„ Ø§Ù„Ø¨ÙŠØª Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ ÙˆØ¸Ù„ Ø­Ø§Ø¦Ø· ÙˆØ§Ø­Ø¯ Ù‡Ùˆ Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ø°ÙŠ Ù„Ø§ ÙŠØ²Ø§Ù„ ÙˆØ§Ù‚Ù Ø¹Ù„Ù‰ Ù‚Ø¯Ù…ÙŠÙ‡. Ø­Ø§ÙˆÙ„ Ø£Ù† ÙŠØ·Ù„Ù‚ Ù…Ù† Ø­Ù†Ø¬Ø±ØªÙ‡ ØµÙˆØªØ§Ù‹ ÙŠÙ†Ø§Ø¯ÙŠ Ø¨Ù‡ Ø£Ù…Ù‡ ÙˆØ£Ø¨Ø§Ù‡ØŒ ÙˆØ¹Ù†Ø¯Ù…Ø§ ØªØ­Ø±ÙƒØª Ø´ÙØªØ§Ù‡ØŒ Ø­Ø³Ù‘ Ø±Ø¤ÙˆÙ ÙÙ‚Ø· Ø¨Ø°Ø¨Ø°Ø¨Ø© ØµØ§Ù…ØªØ© Ø®ÙÙŠÙØ© ØªÙ†Ø¨Ø¹Ø« Ù…Ù† Ø­Ù†Ø¬Ø±ØªÙ‡ØŒ ÙˆØ¹Ù†Ø¯Ù‡Ø§ Ù„Ø§Ø­Ø¸ ÙƒÙŠÙ ÙƒØ§Ù† Ø§Ù„Ø³ÙƒÙˆØª ÙŠØ®Ù„Ø¯ Ø¨Ø«Ù‚Ù„ Ø´Ø¯ÙŠØ¯ ÙÙˆÙ‚ Ø³Ù…Ø¹Ù‡.\nØ¹Ø¨Ø± ÙÙˆÙ‚ Ø£Ù†Ù‚Ø§Ø¶ Ø³Ù‚Ù Ø¨ÙŠØªÙ‡ Ø§Ù„Ø°ÙŠ Ø¨Ø§Øª Ø§Ù„Ø¢Ù† ÙŠØªÙˆØ³Ù‘Ø¯ Ø§Ù„Ø£Ø±Ø¶ ØªØ­Øª Ù‚Ø¯Ù…ÙŠÙ‡ØŒ ÙˆØ¹Ù†Ø¯Ù‡Ø§ Ø®Ø·ÙØª Ø¹ÙŠÙ†Ù‡ Ù„Ù…Ø­Ø© Ø°Ø±Ø§Ø¹ Ù…Ø®Ù‘ØªÙ…Ø© Ø¨Ø®Ø§ØªÙ… Ù†Ø­Ø§Ø³ÙŠ Ù…Ø·Ù„ÙŠ Ø¨Ø§Ù„Ø°Ù‡Ø¨ØŒ Ù…Ù†Ø¨Ø¹Ø«Ø© Ù…Ù† Ø¨ÙŠÙ† Ø£Ù†Ù‚Ø§Ø¶Ù Ù…ØµÙÙˆÙØ© ÙÙˆÙ‚ Ø£Ù†Ù‚Ø§Ø¶. Ø­Ø³Ù‘ Ø±Ø¤ÙˆÙ Ø¨ÙˆØ®Ø²Ø© ÙÙŠ Ø­Ù†Ø¬Ø±ØªÙ‡ØŒ Ø£Ø®Ø°Øª Ø·Ø±ÙŠÙ‚Ù‡Ø§ Ù„Ù…Ù†ØªØµÙ ØµØ¯Ø±Ù‡ Ù…Ø¹ Ø¥Ø¨ØªÙ„Ø§Ø¹ Ø§Ù„Ø±ÙŠÙ‚. ØªØ­ÙˆÙ„Øª Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ®Ø²Ø© Ø¥Ù„Ù‰ Ø­Ø±Ø§Ø±Ø© Ø´Ø¯ÙŠØ¯Ø© ØªÙƒØ§Ø¯ Ø£Ù† ØªØ°ÙŠØ¨ Ø¬Ù„Ø¯Ù‡ ÙˆØªÙ†Ø¨Ø¹Ø« Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø¬Ø³Ù…Ù‡ Ø§Ù„Ù…ØºØ·Ù‰ Ø¨Ø§Ù„Ø¯Ù… ÙˆØ§Ù„ØºØ¨Ø§Ø± ÙˆØ§Ù„Ù…Ù„Ø§Ø¨Ø³ Ø§Ù„Ù…Ù…Ø²Ù‚Ø©.\nØ¥Ù„ØªÙØª Ø±Ø¤ÙˆÙ ÙˆØ±Ø£Ù‰ Ù…Ø³Ø¨Ø§Ø­ Ù…Ù„Ù‚Ù‰ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¶ØŒ ØºØ§Ø±Ù‚ ÙÙŠ Ø¨Ù‚Ø¹Ø© Ù…Ù† Ø§Ù„Ø¯Ù…ØŒ ÙˆØ­ÙŠÙ†Ù‡Ø§ Ø£Ø¯Ø±Ùƒ Ø£Ù† Ø£Ù…Ù‡ ÙˆØ£Ø¨Ø§Ù‡ Ù‚Ø¯ ÙØ§Ø±Ù‚Ø§Ù‡ ÙˆØ¥Ø±ØªØ­Ù„Ø§ Ø¥Ù„Ù‰ Ù…ÙƒØ§Ù† Ø¢Ø®Ø±ØŒ Ù…ÙƒØ§Ù† Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙÙŠÙ‡ ØµÙØ§Ø±Ø§Øª Ø¥Ù†Ø°Ø§Ø±ØŒ ÙˆÙ„Ø§ Ø­Ø§Ø¦Ø· Ø¹Ø§Ø²Ù„. ÙˆÙ‚Ù Ø£Ù…Ø§Ù… Ø§Ù„Ù†Ø¬Ù…ØªÙŠÙ† Ø§Ù„Ù‡Ø§ÙˆÙŠØªØ§Ù† Ø§Ù„Ù„ØªØ§Ù† ÙŠØºØ·ÙŠÙ‡Ù…Ø§ Ø§Ù„Ø³Ù‚Ù Ø§Ù„Ù…Ù†Ù‚Ø¶ØŒ Ø¨ØµÙ…Øª.\nÙˆØ¬Ø¯ Ø±Ø¤ÙˆÙ Ø±ÙØ´ ÙˆØ§Ù„Ø¯Ù‡ ÙÙŠ Ù…ÙƒØ§Ù† Ù…Ø§ ØªØ­Øª Ø§Ù„Ø£Ù†Ù‚Ø§Ø¶ØŒ ÙˆØ¨Ø¹Ø¯Ù…Ø§ Ø£ÙƒÙ…Ù„ Ø¯ÙÙ† ÙˆØ§Ù„Ø¯ÙŠÙ‡ØŒ Ø£Ø®Ø° ÙŠØ­ÙØ± Ø§Ù„Ø¨Ù‚Ø¹Ø© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© Ù„Ø´Ø¬Ø±Ø© Ø§Ù„Ø²ÙŠØªÙˆÙ†ØŒ Ø§Ù„ØªÙŠ Ù„Ù… ÙŠØªØ¨Ù‚Ù‰ Ù…Ù†Ù‡Ø§ Ø¥Ù„Ø§ ØºØµÙ† ÙˆØ§Ø­Ø¯. Ø¹Ù†Ø¯Ù…Ø§ Ø³Ù…Ø¹ ØµÙˆØª Ø§Ù„Ø±ÙØ´ ÙŠØµØ·Ø¯Ù… Ø¨Ø´ÙŠØ¡ Ù…Ø§ ØªØ­Øª Ø§Ù„ØªØ±Ø§Ø¨ØŒ Ø¨Ø¹Ø« ÙŠØ¯Ù‡ ÙÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­ÙØ±Ø© ÙˆØ¥Ø¬ØªØ« Ø§Ù„Ø¨Ù†Ø¯Ù‚ÙŠØ©. Ø£Ù…Ø³Ùƒ Ø¨ØºØµÙ† Ø§Ù„Ø²ÙŠØªÙˆÙ† ÙˆØ±Ù…Ø§Ù‡ ÙÙŠ Ø§Ù„Ù†ÙŠØ±Ø§Ù† Ø§Ù„ØªÙŠ Ø¥Ø´ØªØ¹Ù„Øª Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¶ÙˆØ¡ Ø§Ù„Ø°ÙŠ Ù‡ÙˆÙ‰ ÙÙˆÙ‚ Ø³Ù‚Ù Ø¯ÙŠØ§Ø±Ù‡ ÙˆØ£Ø³Ø±Ù‰ Ø¨Ø£Ù…Ù‡ ÙˆØ£Ø¨Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ø°ÙŠ ÙŠØ®Ù„Ùˆ Ù…Ù† ØµÙØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø±.'}
Dataset({
    features: ['text'],
    num_rows: 500000
})
{'text': 'ØºØµÙ† Ø§Ù„Ø²ÙŠØªÙˆÙ† ÙˆØ§Ù„Ø¨Ù†Ø¯Ù‚ÙŠØ© // ANONYMOUS â€” Ø¬ÙØª Ø§Ù„Ø£Ù‚Ù„Ø§Ù…\nØºØµÙ† Ø§Ù„Ø²ÙŠØªÙˆÙ† ÙˆØ§Ù„Ø¨Ù†Ø¯Ù‚ÙŠØ© // ANONYMOUS\nAugust 08, 2014 in INTERVIEW, TEXT\nØ¥Ø³ØªÙŠÙ‚Ø¸ Ø±Ø¤ÙˆÙ Ù…Ù† Ø³Ø¨Ø§ØªÙ‡ Ø¹Ù„Ù‰ ØµÙˆØª ØµÙØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø±. ÙˆÙ„ÙƒÙ† Ù…Ù† Ø£ÙŠÙ† Ø£ØªØªØŸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØµÙØ§Ø±Ø§Øª Ø¥Ù†Ø°Ø§Ø± ÙÙŠ Ø§Ù„Ø£Ø­ÙŠØ§Ø¡ Ø§Ù„ÙÙ‚ÙŠØ±Ø© Ø§Ù„ØªÙŠ ØªÙ‚Ø¹ Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø§Ø¦Ø· Ø§Ù„Ø¹Ø§Ø²Ù„.\nØ¥ØªØ¶Ø­ Ù„Ø±Ø¤ÙˆÙØŒ ÙˆÙ‡Ùˆ ÙÙŠ Ø­Ø§Ù„Ø© Ø¨ÙŠÙ† Ø§Ù„Ù†ÙˆÙ… Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆØ§Ù„ÙŠÙ‚Ø¸Ø© Ø§Ù„Ø´Ø¯ÙŠØ¯Ø©ØŒ Ø£Ù† ØµÙØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø± Ù‡ÙŠ ØµÙˆØª Ø£Ù…Ù‡ ÙˆÙ‡ÙŠ ØªÙ†Ø§Ø¯ÙŠ:\n"Ø±Ø¤ÙˆÙ!\nÙŠØ§ Ø±Ø¤ÙˆÙ!\nÙ‚ØµÙ! Ù‚ØµÙ! Ù‚Øµ-\nÙ‚Ø¨Ù„ Ø£Ù† ØªØ³ØªØ·ÙŠØ¹ Ø£Ù† ØªÙƒÙ…Ù„ Ø£Ù… Ø±Ø¤ÙˆÙ ÙƒÙ„Ø§Ù…Ù‡Ø§ ØŒ Ø³Ø§Ø¯ Ø§Ù„ØµÙ…Øª Ø¨Ø¹Ø¯ Ø£Ù† ÙˆÙ‚Ø¹ Ø¥Ù†ÙØ¬Ø§Ø± Ø¶Ø®Ù…ØŒ Ù…Ù† Ø³Ù…Ø¹Ù‡ Ù‚Ø¯ ÙŠØ¹ØªÙ‚Ø¯ Ø£Ù† Ø§Ù„Ù‡Ø²Ù‘Ø© Ø§Ù„ØªÙŠ Ø®Ù„ÙÙ‡Ø§ ÙˆØµÙ„Øª- Ø¨ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù‚Ù„- Ø±Ø§Ø¨Ø¹ Ø§Ù„Ø³Ù…Ø§ÙˆØ§Øª Ø§Ù„Ø³Ø¨Ø¹.\nÙƒØ§Ù† Ø±Ø¤ÙˆÙ ÙˆØ­ÙŠØ¯ Ø£Ù…Ù‡ ÙˆØ£Ø¨ÙŠÙ‡ØŒ ÙŠØ³ÙƒÙ† Ù…Ø¹Ù‡Ù…Ø§ ÙÙŠ Ø¨ÙŠØª Ø´Ø¯ÙŠØ¯ Ø§Ù„ØªÙˆØ§Ø¶Ø¹ ÙŠÙ‚Ø¹ Ø®Ø§Ø±Ø¬ Ø§Ù„Ø­Ø§Ø¦Ø· Ø§Ù„Ø¹Ø§Ø²Ù„. ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ù„Ùƒ Ø´Ø¬Ø±Ø© Ø²ÙŠØªÙˆÙ† ØªÙ‚Ø¹ ØªÙ…Ø§Ù…Ø§Ù‹ Ø£Ù…Ø§Ù… Ù†Ø§ÙØ°Ø© Ø¯ÙŠØ§Ø± Ø±Ø¤ÙˆÙØŒ Ù‚Ø¯ Ø²Ø±Ø¹Ù‡Ø§ Ø£Ø¨Ø§Ù‡ ÙŠÙˆÙ… Ø£Ø®Ø° Ø±Ø¤ÙˆÙ Ø£ÙˆÙ„ Ø¥Ø³ØªÙ†Ø´Ø§Ù‚Ø© Ù„Ù‡ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ù†ÙŠØ§ØŒ ÙŠÙˆÙ… ÙŠÙ‚Ø¹ ÙÙŠ Ø£ÙƒØ«Ø± Ø£ÙŠØ§Ù… Ø§Ù„Ø±Ø¨ÙŠØ¹ Ø±Ø¨ÙŠØ¹Ø§Ù‹.\nÙƒØ§Ù†Øª Ø§Ù„Ø±ÙŠØ§Ø­ØŒ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙŠÙˆÙ…ØŒ Ù„Ø·ÙŠÙØ© Ø¨Ø´Ø¯Ø©. Ø¨Ø±ÙˆØ¯ØªÙ‡Ø§ ØªÙ‚Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø±Ø¡ ÙƒØ§Ù„Ø¨Ø´Ø±Ù‰ Ø§Ù„Ø³Ø§Ø±Ø©ØŒ Ù„Ø§ ØªÙ‚Ø³Ùˆ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¸Ø§Ù… ÙˆÙ„Ø§ ÙŠÙ‚Ø´Ø¹Ø± Ù„Ù‡Ø§ Ø§Ù„Ø¨Ø¯Ù†.\nØ¥Ø³ØªÙŠÙ‚Ø¸ Ø±Ø¤ÙˆÙ Ù…Ù† Ø³Ø¨Ø§ØªÙ‡ØŒ ÙˆÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø© ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¨Ø§Øª Ù†ØªÙŠØ¬Ø© Ø¥Ù†Ù‡ÙŠØ§Ø± Ø¯ÙŠØ§Ø±Ù‡ Ø¹Ù„Ù‰ Ø±Ø£Ø³Ù‡. ØªÙÙ‚Ø¯ Ø£Ø¹Ø¶Ø§Ø¡ Ø¬Ø³Ù…Ù‡ ÙˆØ§ÙƒØªØ´Ù Ø£Ù†Ù‡Ø§ Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù…ØŒ Ù…Ù† Ø§Ù„Ù†Ø¸Ø±Ø© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„. Ù„Ù… ØªØ¨ØªØ± Ù„Ù‡ Ø³Ø§Ù‚ Ø£Ùˆ Ø°Ø±Ø§Ø¹ØŒ ÙˆÙ„Ø§ Ø²Ø§Ù„Øª Ø£ØµØ§Ø¨Ø¹Ù‡ ÙƒÙ„Ù‡Ø§ Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ø­ØªÙ‰ Ø§Ù„ØªÙŠ Ø¹Ù„Ù‰ Ø£Ù‚Ø¯Ø§Ù…Ù‡ Ø§Ù„Ø­Ø§ÙÙŠØ©. ÙƒØ§Ù† Ø§Ù„Ø®Ø¯Ø± Ù…Ù†ØªØ´Ø± ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø¬Ø³Ù…Ù‡ØŒ ÙŠØ®Ø·Ùˆ Ø®Ø·Ùˆ Ø§Ù„Ù†Ù…Ù„Ø© Ù…Ù† Ù‚Ù…Ø© Ø±Ø£Ø³Ù‡ Ø¥Ù„Ù‰ Ù†Ù‡Ø§ÙŠØ© Ø£Ø·Ø±Ø§Ù Ø£ØµØ§Ø¨Ø¹ Ù‚Ø¯Ù…ÙŠÙ‡. Ù„Ø­Ø¸Ø© Ø£Ù† Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ­Ø±Ù‘ÙƒØŒ Ø²Ø§Ù„ Ø§Ù„Ø®Ø¯Ø± ÙƒØ§Ù„Ù‚Ù…Ø§Ø´ Ø§Ù„Ø®ÙÙŠÙ Ø§Ù„Ø°ÙŠ ÙŠØ²Ø§Ù„ Ù…Ù† Ø¹Ù„Ù‰ ÙÙˆÙ‚ Ø§Ù„Ø·Ø§ÙˆÙ„Ø©ØŒ ÙˆØ¨Ø¹Ø« Ø¯Ù…Ø§ØºÙ‡ Ù„Ø¬Ø³Ù…Ù‡ ØµÙØ§Ø±Ø© Ø¥Ù†Ø°Ø§Ø± Ù…Ù† Ù†ÙˆØ¹ Ø¢Ø®Ø±ØŒ ÙƒØ§Ù†Øª Ù†ÙˆØ¹Ø§Ù‹ Ù…Ø§ ÙƒØµØ¹Ù‚Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¡ Ø§Ù„ØªÙŠ Ø¬Ø¹Ù„ØªÙ‡ ÙŠØªÙŠÙ‚Ù† Ø£Ù† Ø¨Ø¯Ù†Ù‡ Ù„ÙŠØ³ Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù….\nØ£Ø²Ø§Ø­ Ø§Ù„Ø£Ù†Ù‚Ø§Ø¶ Ù…Ù† ÙÙˆÙ‚Ù‡ ÙˆØ£Ø¯Ø§Ø± Ø¨Ù†Ø¸Ø±Ù‡ ÙŠÙ…ÙŠÙ†Ø§ Ø«Ù… Ø´Ù…Ø§Ù„ ØªØ¬Ø§Ù‡ Ø²ÙˆØ§ÙŠØ§ Ø§Ù„Ø¨ÙŠØª Ø§Ù„ØµØºÙŠØ±ØŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù…Ø§ ØªØ¨Ù‚Ù‰ Ù…Ù† Ø§Ù„Ø¨ÙŠØª Ø§Ù„ØµØºÙŠØ±ØŒ ÙˆÙ„Ù… ÙŠØ±Ù‰ ØºÙŠØ± Ø§Ù„Ø¸Ù„Ø§Ù…. ØªØ­ÙˆÙ„ Ø§Ù„Ø¨ÙŠØª Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ ÙˆØ¸Ù„ Ø­Ø§Ø¦Ø· ÙˆØ§Ø­Ø¯ Ù‡Ùˆ Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ø°ÙŠ Ù„Ø§ ÙŠØ²Ø§Ù„ ÙˆØ§Ù‚Ù Ø¹Ù„Ù‰ Ù‚Ø¯Ù…ÙŠÙ‡. Ø­Ø§ÙˆÙ„ Ø£Ù† ÙŠØ·Ù„Ù‚ Ù…Ù† Ø­Ù†Ø¬Ø±ØªÙ‡ ØµÙˆØªØ§Ù‹ ÙŠÙ†Ø§Ø¯ÙŠ Ø¨Ù‡ Ø£Ù…Ù‡ ÙˆØ£Ø¨Ø§Ù‡ØŒ ÙˆØ¹Ù†Ø¯Ù…Ø§ ØªØ­Ø±ÙƒØª Ø´ÙØªØ§Ù‡ØŒ Ø­Ø³Ù‘ Ø±Ø¤ÙˆÙ ÙÙ‚Ø· Ø¨Ø°Ø¨Ø°Ø¨Ø© ØµØ§Ù…ØªØ© Ø®ÙÙŠÙØ© ØªÙ†Ø¨Ø¹Ø« Ù…Ù† Ø­Ù†Ø¬Ø±ØªÙ‡ØŒ ÙˆØ¹Ù†Ø¯Ù‡Ø§ Ù„Ø§Ø­Ø¸ ÙƒÙŠÙ ÙƒØ§Ù† Ø§Ù„Ø³ÙƒÙˆØª ÙŠØ®Ù„Ø¯ Ø¨Ø«Ù‚Ù„ Ø´Ø¯ÙŠØ¯ ÙÙˆÙ‚ Ø³Ù…Ø¹Ù‡.\nØ¹Ø¨Ø± ÙÙˆÙ‚ Ø£Ù†Ù‚Ø§Ø¶ Ø³Ù‚Ù Ø¨ÙŠØªÙ‡ Ø§Ù„Ø°ÙŠ Ø¨Ø§Øª Ø§Ù„Ø¢Ù† ÙŠØªÙˆØ³Ù‘Ø¯ Ø§Ù„Ø£Ø±Ø¶ ØªØ­Øª Ù‚Ø¯Ù…ÙŠÙ‡ØŒ ÙˆØ¹Ù†Ø¯Ù‡Ø§ Ø®Ø·ÙØª Ø¹ÙŠÙ†Ù‡ Ù„Ù…Ø­Ø© Ø°Ø±Ø§Ø¹ Ù…Ø®Ù‘ØªÙ…Ø© Ø¨Ø®Ø§ØªÙ… Ù†Ø­Ø§Ø³ÙŠ Ù…Ø·Ù„ÙŠ Ø¨Ø§Ù„Ø°Ù‡Ø¨ØŒ Ù…Ù†Ø¨Ø¹Ø«Ø© Ù…Ù† Ø¨ÙŠÙ† Ø£Ù†Ù‚Ø§Ø¶Ù Ù…ØµÙÙˆÙØ© ÙÙˆÙ‚ Ø£Ù†Ù‚Ø§Ø¶. Ø­Ø³Ù‘ Ø±Ø¤ÙˆÙ Ø¨ÙˆØ®Ø²Ø© ÙÙŠ Ø­Ù†Ø¬Ø±ØªÙ‡ØŒ Ø£Ø®Ø°Øª Ø·Ø±ÙŠÙ‚Ù‡Ø§ Ù„Ù…Ù†ØªØµÙ ØµØ¯Ø±Ù‡ Ù…Ø¹ Ø¥Ø¨ØªÙ„Ø§Ø¹ Ø§Ù„Ø±ÙŠÙ‚. ØªØ­ÙˆÙ„Øª Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ®Ø²Ø© Ø¥Ù„Ù‰ Ø­Ø±Ø§Ø±Ø© Ø´Ø¯ÙŠØ¯Ø© ØªÙƒØ§Ø¯ Ø£Ù† ØªØ°ÙŠØ¨ Ø¬Ù„Ø¯Ù‡ ÙˆØªÙ†Ø¨Ø¹Ø« Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø¬Ø³Ù…Ù‡ Ø§Ù„Ù…ØºØ·Ù‰ Ø¨Ø§Ù„Ø¯Ù… ÙˆØ§Ù„ØºØ¨Ø§Ø± ÙˆØ§Ù„Ù…Ù„Ø§Ø¨Ø³ Ø§Ù„Ù…Ù…Ø²Ù‚Ø©.\nØ¥Ù„ØªÙØª Ø±Ø¤ÙˆÙ ÙˆØ±Ø£Ù‰ Ù…Ø³Ø¨Ø§Ø­ Ù…Ù„Ù‚Ù‰ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¶ØŒ ØºØ§Ø±Ù‚ ÙÙŠ Ø¨Ù‚Ø¹Ø© Ù…Ù† Ø§Ù„Ø¯Ù…ØŒ ÙˆØ­ÙŠÙ†Ù‡Ø§ Ø£Ø¯Ø±Ùƒ Ø£Ù† Ø£Ù…Ù‡ ÙˆØ£Ø¨Ø§Ù‡ Ù‚Ø¯ ÙØ§Ø±Ù‚Ø§Ù‡ ÙˆØ¥Ø±ØªØ­Ù„Ø§ Ø¥Ù„Ù‰ Ù…ÙƒØ§Ù† Ø¢Ø®Ø±ØŒ Ù…ÙƒØ§Ù† Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙÙŠÙ‡ ØµÙØ§Ø±Ø§Øª Ø¥Ù†Ø°Ø§Ø±ØŒ ÙˆÙ„Ø§ Ø­Ø§Ø¦Ø· Ø¹Ø§Ø²Ù„. ÙˆÙ‚Ù Ø£Ù…Ø§Ù… Ø§Ù„Ù†Ø¬Ù…ØªÙŠÙ† Ø§Ù„Ù‡Ø§ÙˆÙŠØªØ§Ù† Ø§Ù„Ù„ØªØ§Ù† ÙŠØºØ·ÙŠÙ‡Ù…Ø§ Ø§Ù„Ø³Ù‚Ù Ø§Ù„Ù…Ù†Ù‚Ø¶ØŒ Ø¨ØµÙ…Øª.\nÙˆØ¬Ø¯ Ø±Ø¤ÙˆÙ Ø±ÙØ´ ÙˆØ§Ù„Ø¯Ù‡ ÙÙŠ Ù…ÙƒØ§Ù† Ù…Ø§ ØªØ­Øª Ø§Ù„Ø£Ù†Ù‚Ø§Ø¶ØŒ ÙˆØ¨Ø¹Ø¯Ù…Ø§ Ø£ÙƒÙ…Ù„ Ø¯ÙÙ† ÙˆØ§Ù„Ø¯ÙŠÙ‡ØŒ Ø£Ø®Ø° ÙŠØ­ÙØ± Ø§Ù„Ø¨Ù‚Ø¹Ø© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© Ù„Ø´Ø¬Ø±Ø© Ø§Ù„Ø²ÙŠØªÙˆÙ†ØŒ Ø§Ù„ØªÙŠ Ù„Ù… ÙŠØªØ¨Ù‚Ù‰ Ù…Ù†Ù‡Ø§ Ø¥Ù„Ø§ ØºØµÙ† ÙˆØ§Ø­Ø¯. Ø¹Ù†Ø¯Ù…Ø§ Ø³Ù…Ø¹ ØµÙˆØª Ø§Ù„Ø±ÙØ´ ÙŠØµØ·Ø¯Ù… Ø¨Ø´ÙŠØ¡ Ù…Ø§ ØªØ­Øª Ø§Ù„ØªØ±Ø§Ø¨ØŒ Ø¨Ø¹Ø« ÙŠØ¯Ù‡ ÙÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­ÙØ±Ø© ÙˆØ¥Ø¬ØªØ« Ø§Ù„Ø¨Ù†Ø¯Ù‚ÙŠØ©. Ø£Ù…Ø³Ùƒ Ø¨ØºØµÙ† Ø§Ù„Ø²ÙŠØªÙˆÙ† ÙˆØ±Ù…Ø§Ù‡ ÙÙŠ Ø§Ù„Ù†ÙŠØ±Ø§Ù† Ø§Ù„ØªÙŠ Ø¥Ø´ØªØ¹Ù„Øª Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¶ÙˆØ¡ Ø§Ù„Ø°ÙŠ Ù‡ÙˆÙ‰ ÙÙˆÙ‚ Ø³Ù‚Ù Ø¯ÙŠØ§Ø±Ù‡ ÙˆØ£Ø³Ø±Ù‰ Ø¨Ø£Ù…Ù‡ ÙˆØ£Ø¨Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ø°ÙŠ ÙŠØ®Ù„Ùˆ Ù…Ù† ØµÙØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†Ø°Ø§Ø±.'}
Running tokenizer on dataset (num_proc=16):   1%|          | 16000/2000000 [00:32<35:57, 919.68 examples/s]Running tokenizer on dataset (num_proc=16):   1%|          | 17000/2000000 [00:33<33:51, 976.28 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00007_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   1%|          | 18000/2000000 [00:33<30:59, 1065.63 examples/s]Running tokenizer on dataset (num_proc=16):   1%|          | 20000/2000000 [00:34<24:12, 1362.96 examples/s]Running tokenizer on dataset (num_proc=16):   1%|          | 21000/2000000 [00:35<26:45, 1232.74 examples/s]Running tokenizer on dataset (num_proc=16):   1%|          | 23000/2000000 [00:38<32:39, 1008.84 examples/s]Running tokenizer on dataset (num_proc=16):   1%|          | 24000/2000000 [00:39<34:31, 953.80 examples/s] Running tokenizer on dataset (num_proc=16):   1%|â–         | 25000/2000000 [00:40<29:00, 1134.85 examples/s]Running tokenizer on dataset (num_proc=16):   1%|â–         | 26000/2000000 [00:40<25:22, 1296.41 examples/s]Running tokenizer on dataset (num_proc=16):   1%|â–         | 27000/2000000 [00:41<30:24, 1081.33 examples/s]Running tokenizer on dataset (num_proc=16):   1%|â–         | 28000/2000000 [00:41<23:17, 1411.06 examples/s]Running tokenizer on dataset (num_proc=16):   1%|â–         | 29000/2000000 [00:42<18:35, 1766.28 examples/s]Running tokenizer on dataset (num_proc=16):   2%|â–         | 30000/2000000 [00:42<18:43, 1753.51 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00008_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   2%|â–         | 31000/2000000 [00:43<22:04, 1487.00 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:55:13,794 >> Token indices sequence length is longer than the specified maximum sequence length for this model (48933 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00009_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   2%|â–         | 32000/2000000 [00:45<34:41, 945.32 examples/s] Running tokenizer on dataset (num_proc=16):   2%|â–         | 33000/2000000 [00:45<25:35, 1280.98 examples/s]Running tokenizer on dataset (num_proc=16):   2%|â–         | 34000/2000000 [00:46<24:21, 1345.55 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00012_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   2%|â–         | 35000/2000000 [00:46<22:01, 1486.99 examples/s]Running tokenizer on dataset (num_proc=16):   2%|â–         | 36000/2000000 [00:47<16:38, 1967.25 examples/s]Running tokenizer on dataset (num_proc=16):   2%|â–         | 37000/2000000 [00:47<14:23, 2272.69 examples/s]Running tokenizer on dataset (num_proc=16):   2%|â–         | 38000/2000000 [00:48<18:19, 1784.74 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:55:17,513 >> Token indices sequence length is longer than the specified maximum sequence length for this model (35254 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=16):   2%|â–         | 39000/2000000 [00:49<23:45, 1375.46 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:55:17,912 >> Token indices sequence length is longer than the specified maximum sequence length for this model (38807 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00010_of_00016.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:55:18,139 >> Token indices sequence length is longer than the specified maximum sequence length for this model (40721 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=16):   2%|â–         | 41000/2000000 [00:49<16:32, 1973.61 examples/s]Running tokenizer on dataset (num_proc=16):   2%|â–         | 42000/2000000 [00:50<14:55, 2185.83 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:55:19,663 >> Token indices sequence length is longer than the specified maximum sequence length for this model (174817 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00013_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   2%|â–         | 43000/2000000 [00:51<23:23, 1394.76 examples/s]Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00011_of_00016.arrow
04/18/2024 15:55:21 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ru_2b.jsonl.
Running tokenizer on dataset (num_proc=16):   2%|â–         | 44000/2000000 [00:53<31:41, 1028.89 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:55:21,802 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34999 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=16):   2%|â–         | 45000/2000000 [00:53<24:54, 1307.79 examples/s]Running tokenizer on dataset (num_proc=16):   2%|â–         | 46000/2000000 [00:53<18:44, 1737.87 examples/s]Running tokenizer on dataset (num_proc=16):   2%|â–         | 48000/2000000 [00:53<12:10, 2671.87 examples/s]Dataset({
    features: ['text'],
    num_rows: 500000
})
{'text': 'ÐœÐ¾ÑÐºÐ²Ð° Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚ Ð®Ð¶Ð½Ð¾Ð¹ ÐžÑÐµÑ‚Ð¸Ð¸ â€“ Ð£Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÑÐºÐ°Ñ Ð³Ð°Ð·ÐµÑ‚Ð°\nÐœÐ¾ÑÐºÐ²Ð° Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚ Ð®Ð¶Ð½Ð¾Ð¹ ÐžÑÐµÑ‚Ð¸Ð¸\nÐ’Ð»Ð°ÑÑ‚Ð¸ ÐœÐ¾ÑÐºÐ²Ñ‹ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÑÑŽÑ‚ Ð¿Ð¾ÑÑ‚Ñ€Ð°Ð´Ð°Ð²ÑˆÐ¸Ð¼ Ð² Ð²Ð¾Ð¾Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð¾Ð¼ ÐºÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚Ðµ Ð² Ð®Ð¶Ð½Ð¾Ð¹ ÐžÑÐµÑ‚Ð¸Ð¸ Ð³ÑƒÐ¼Ð°Ð½Ð¸Ñ‚Ð°Ñ€Ð½Ñ‹Ðµ Ð³Ñ€ÑƒÐ·Ñ‹: Ð¿ÐµÑ€Ð²Ð°Ñ Ð¿Ð°Ñ€Ñ‚Ð¸Ñ Ð±Ñ‹Ð»Ð° Ð²ÐµÑÐ¾Ð¼ Ð±Ð¾Ð»ÐµÐµ 100 Ñ‚Ð¾Ð½Ð½ Ð½Ð° Ð¾Ð±Ñ‰ÑƒÑŽ ÑÑƒÐ¼Ð¼Ñƒ 2,5 Ð¼Ð¸Ð»Ð»Ð¸Ð°Ñ€Ð´Ð° Ñ€ÑƒÐ±Ð»ÐµÐ¹, Ð²Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð´Ð²Ðµ â€“ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒÑŽ Ð¾ÐºÐ¾Ð»Ð¾ 35 Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½Ð¾Ð² Ñ€ÑƒÐ±Ð»ÐµÐ¹.\nÐ’ Ð³ÑƒÐ¼Ð°Ð½Ð¸Ñ‚Ð°Ñ€Ð½Ñ‹Ðµ Ð³Ñ€ÑƒÐ·Ñ‹ Ð²Ð¾ÑˆÐ»Ð¸ Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¾Ð»ÑŒÑÑ‚Ð²Ð¸Ðµ (Ð¼ÑƒÐºÐ° Ð¸ ÐºÑ€ÑƒÐ¿Ñ‹), ÐºÐ¾Ð¼Ð¼ÑƒÐ½Ð°Ð»ÑŒÐ½Ð°Ñ Ð¸ ÑÑ‚Ñ€Ð¾Ð¹Ñ‚ÐµÑ…Ð½Ð¸ÐºÐ°, ÑƒÐ±Ð¾Ñ€Ð¾Ñ‡Ð½Ñ‹Ðµ Ð¼Ð°ÑˆÐ¸Ð½Ñ‹. Ð¡Ñ‚Ð¾Ð»Ð¸Ñ†Ð° Ð Ð¾ÑÑÐ¸Ð¸ Ð·Ð°ÐºÐ°Ð·Ð°Ð»Ð° Ð´Ð»Ñ Ð¦Ñ…Ð¸Ð½Ð²Ð°Ð»Ð¸ Ð´ÐµÑÑÑ‚ÑŒ Ð¿Ð°ÑÑÐ°Ð¶Ð¸Ñ€ÑÐºÐ¸Ñ… Ð°Ð²Ñ‚Ð¾Ð±ÑƒÑÐ¾Ð², 30 Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¾Ñ‡Ð½Ñ‹Ñ… Ð¿ÑƒÐ½ÐºÑ‚Ð¾Ð². Ð’ÑÐµ ÑÑ‚Ð¾ Ð´Ð¾ÑÑ‚Ð°Ð²ÑÑ‚ Ð² Ð®Ð¶Ð½ÑƒÑŽ ÐžÑÐµÑ‚Ð¸ÑŽ Ð¿Ð¾ Ð¶ÐµÐ»ÐµÐ·Ð½Ð¾Ð¹ Ð´Ð¾Ñ€Ð¾Ð³Ðµ.'}
Running tokenizer on dataset (num_proc=16):   2%|â–         | 49000/2000000 [00:54<11:41, 2780.43 examples/s]04/18/2024 15:55:22 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ru_2b.jsonl.
Running tokenizer on dataset (num_proc=16):   2%|â–Ž         | 50000/2000000 [00:54<13:52, 2341.68 examples/s]04/18/2024 15:55:23 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ru_2b.jsonl.
Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 51000/2000000 [00:55<12:32, 2591.46 examples/s]Dataset({
    features: ['text'],
    num_rows: 500000
})
{'text': 'ÐœÐ¾ÑÐºÐ²Ð° Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚ Ð®Ð¶Ð½Ð¾Ð¹ ÐžÑÐµÑ‚Ð¸Ð¸ â€“ Ð£Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÑÐºÐ°Ñ Ð³Ð°Ð·ÐµÑ‚Ð°\nÐœÐ¾ÑÐºÐ²Ð° Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚ Ð®Ð¶Ð½Ð¾Ð¹ ÐžÑÐµÑ‚Ð¸Ð¸\nÐ’Ð»Ð°ÑÑ‚Ð¸ ÐœÐ¾ÑÐºÐ²Ñ‹ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÑÑŽÑ‚ Ð¿Ð¾ÑÑ‚Ñ€Ð°Ð´Ð°Ð²ÑˆÐ¸Ð¼ Ð² Ð²Ð¾Ð¾Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð¾Ð¼ ÐºÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚Ðµ Ð² Ð®Ð¶Ð½Ð¾Ð¹ ÐžÑÐµÑ‚Ð¸Ð¸ Ð³ÑƒÐ¼Ð°Ð½Ð¸Ñ‚Ð°Ñ€Ð½Ñ‹Ðµ Ð³Ñ€ÑƒÐ·Ñ‹: Ð¿ÐµÑ€Ð²Ð°Ñ Ð¿Ð°Ñ€Ñ‚Ð¸Ñ Ð±Ñ‹Ð»Ð° Ð²ÐµÑÐ¾Ð¼ Ð±Ð¾Ð»ÐµÐµ 100 Ñ‚Ð¾Ð½Ð½ Ð½Ð° Ð¾Ð±Ñ‰ÑƒÑŽ ÑÑƒÐ¼Ð¼Ñƒ 2,5 Ð¼Ð¸Ð»Ð»Ð¸Ð°Ñ€Ð´Ð° Ñ€ÑƒÐ±Ð»ÐµÐ¹, Ð²Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð´Ð²Ðµ â€“ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒÑŽ Ð¾ÐºÐ¾Ð»Ð¾ 35 Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½Ð¾Ð² Ñ€ÑƒÐ±Ð»ÐµÐ¹.\nÐ’ Ð³ÑƒÐ¼Ð°Ð½Ð¸Ñ‚Ð°Ñ€Ð½Ñ‹Ðµ Ð³Ñ€ÑƒÐ·Ñ‹ Ð²Ð¾ÑˆÐ»Ð¸ Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¾Ð»ÑŒÑÑ‚Ð²Ð¸Ðµ (Ð¼ÑƒÐºÐ° Ð¸ ÐºÑ€ÑƒÐ¿Ñ‹), ÐºÐ¾Ð¼Ð¼ÑƒÐ½Ð°Ð»ÑŒÐ½Ð°Ñ Ð¸ ÑÑ‚Ñ€Ð¾Ð¹Ñ‚ÐµÑ…Ð½Ð¸ÐºÐ°, ÑƒÐ±Ð¾Ñ€Ð¾Ñ‡Ð½Ñ‹Ðµ Ð¼Ð°ÑˆÐ¸Ð½Ñ‹. Ð¡Ñ‚Ð¾Ð»Ð¸Ñ†Ð° Ð Ð¾ÑÑÐ¸Ð¸ Ð·Ð°ÐºÐ°Ð·Ð°Ð»Ð° Ð´Ð»Ñ Ð¦Ñ…Ð¸Ð½Ð²Ð°Ð»Ð¸ Ð´ÐµÑÑÑ‚ÑŒ Ð¿Ð°ÑÑÐ°Ð¶Ð¸Ñ€ÑÐºÐ¸Ñ… Ð°Ð²Ñ‚Ð¾Ð±ÑƒÑÐ¾Ð², 30 Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¾Ñ‡Ð½Ñ‹Ñ… Ð¿ÑƒÐ½ÐºÑ‚Ð¾Ð². Ð’ÑÐµ ÑÑ‚Ð¾ Ð´Ð¾ÑÑ‚Ð°Ð²ÑÑ‚ Ð² Ð®Ð¶Ð½ÑƒÑŽ ÐžÑÐµÑ‚Ð¸ÑŽ Ð¿Ð¾ Ð¶ÐµÐ»ÐµÐ·Ð½Ð¾Ð¹ Ð´Ð¾Ñ€Ð¾Ð³Ðµ.'}
Dataset({
    features: ['text'],
    num_rows: 500000
})
{'text': 'ÐœÐ¾ÑÐºÐ²Ð° Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚ Ð®Ð¶Ð½Ð¾Ð¹ ÐžÑÐµÑ‚Ð¸Ð¸ â€“ Ð£Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÑÐºÐ°Ñ Ð³Ð°Ð·ÐµÑ‚Ð°\nÐœÐ¾ÑÐºÐ²Ð° Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚ Ð®Ð¶Ð½Ð¾Ð¹ ÐžÑÐµÑ‚Ð¸Ð¸\nÐ’Ð»Ð°ÑÑ‚Ð¸ ÐœÐ¾ÑÐºÐ²Ñ‹ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÑÑŽÑ‚ Ð¿Ð¾ÑÑ‚Ñ€Ð°Ð´Ð°Ð²ÑˆÐ¸Ð¼ Ð² Ð²Ð¾Ð¾Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð¾Ð¼ ÐºÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚Ðµ Ð² Ð®Ð¶Ð½Ð¾Ð¹ ÐžÑÐµÑ‚Ð¸Ð¸ Ð³ÑƒÐ¼Ð°Ð½Ð¸Ñ‚Ð°Ñ€Ð½Ñ‹Ðµ Ð³Ñ€ÑƒÐ·Ñ‹: Ð¿ÐµÑ€Ð²Ð°Ñ Ð¿Ð°Ñ€Ñ‚Ð¸Ñ Ð±Ñ‹Ð»Ð° Ð²ÐµÑÐ¾Ð¼ Ð±Ð¾Ð»ÐµÐµ 100 Ñ‚Ð¾Ð½Ð½ Ð½Ð° Ð¾Ð±Ñ‰ÑƒÑŽ ÑÑƒÐ¼Ð¼Ñƒ 2,5 Ð¼Ð¸Ð»Ð»Ð¸Ð°Ñ€Ð´Ð° Ñ€ÑƒÐ±Ð»ÐµÐ¹, Ð²Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð´Ð²Ðµ â€“ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒÑŽ Ð¾ÐºÐ¾Ð»Ð¾ 35 Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½Ð¾Ð² Ñ€ÑƒÐ±Ð»ÐµÐ¹.\nÐ’ Ð³ÑƒÐ¼Ð°Ð½Ð¸Ñ‚Ð°Ñ€Ð½Ñ‹Ðµ Ð³Ñ€ÑƒÐ·Ñ‹ Ð²Ð¾ÑˆÐ»Ð¸ Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¾Ð»ÑŒÑÑ‚Ð²Ð¸Ðµ (Ð¼ÑƒÐºÐ° Ð¸ ÐºÑ€ÑƒÐ¿Ñ‹), ÐºÐ¾Ð¼Ð¼ÑƒÐ½Ð°Ð»ÑŒÐ½Ð°Ñ Ð¸ ÑÑ‚Ñ€Ð¾Ð¹Ñ‚ÐµÑ…Ð½Ð¸ÐºÐ°, ÑƒÐ±Ð¾Ñ€Ð¾Ñ‡Ð½Ñ‹Ðµ Ð¼Ð°ÑˆÐ¸Ð½Ñ‹. Ð¡Ñ‚Ð¾Ð»Ð¸Ñ†Ð° Ð Ð¾ÑÑÐ¸Ð¸ Ð·Ð°ÐºÐ°Ð·Ð°Ð»Ð° Ð´Ð»Ñ Ð¦Ñ…Ð¸Ð½Ð²Ð°Ð»Ð¸ Ð´ÐµÑÑÑ‚ÑŒ Ð¿Ð°ÑÑÐ°Ð¶Ð¸Ñ€ÑÐºÐ¸Ñ… Ð°Ð²Ñ‚Ð¾Ð±ÑƒÑÐ¾Ð², 30 Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¾Ñ‡Ð½Ñ‹Ñ… Ð¿ÑƒÐ½ÐºÑ‚Ð¾Ð². Ð’ÑÐµ ÑÑ‚Ð¾ Ð´Ð¾ÑÑ‚Ð°Ð²ÑÑ‚ Ð² Ð®Ð¶Ð½ÑƒÑŽ ÐžÑÐµÑ‚Ð¸ÑŽ Ð¿Ð¾ Ð¶ÐµÐ»ÐµÐ·Ð½Ð¾Ð¹ Ð´Ð¾Ñ€Ð¾Ð³Ðµ.'}
[WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:55:24,741 >> Token indices sequence length is longer than the specified maximum sequence length for this model (143004 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00014_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 52000/2000000 [00:56<21:39, 1499.12 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:55:25,067 >> Token indices sequence length is longer than the specified maximum sequence length for this model (80592 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-42ad9a1cc1017b9e_00015_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 53000/2000000 [00:56<17:45, 1826.54 examples/s]Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 55000/2000000 [00:56<11:06, 2920.34 examples/s]Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 57000/2000000 [00:59<23:35, 1372.74 examples/s]Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 58000/2000000 [00:59<21:27, 1508.86 examples/s]Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 59000/2000000 [01:00<17:57, 1801.58 examples/s]Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 61000/2000000 [01:00<11:23, 2837.56 examples/s]Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 63000/2000000 [01:00<11:07, 2901.07 examples/s]Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 64000/2000000 [01:01<09:42, 3323.95 examples/s]04/18/2024 15:55:30 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/slimpajam_1b.jsonl.
Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 66000/2000000 [01:02<12:08, 2655.99 examples/s]Dataset({
    features: ['text', 'meta', '__index_level_0__'],
    num_rows: 500000
})
{'text': '@interface PodsDummy_XCDLumberjackNSLogger_OSX : NSObject\n@end\n@implementation PodsDummy_XCDLumberjackNSLogger_OSX\n@end\n', 'meta': {'redpajama_set_name': 'RedPajamaGithub'}, '__index_level_0__': 3706}
Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 67000/2000000 [01:02<14:06, 2283.53 examples/s]04/18/2024 15:55:31 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/slimpajam_1b.jsonl.
Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 68000/2000000 [01:03<15:06, 2132.11 examples/s]Running tokenizer on dataset (num_proc=16):   3%|â–Ž         | 69000/2000000 [01:03<13:15, 2426.68 examples/s]04/18/2024 15:55:32 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/slimpajam_1b.jsonl.
Running tokenizer on dataset (num_proc=16):   4%|â–Ž         | 70000/2000000 [01:03<11:40, 2755.88 examples/s]Dataset({
    features: ['text', 'meta', '__index_level_0__'],
    num_rows: 500000
})
{'text': '@interface PodsDummy_XCDLumberjackNSLogger_OSX : NSObject\n@end\n@implementation PodsDummy_XCDLumberjackNSLogger_OSX\n@end\n', 'meta': {'redpajama_set_name': 'RedPajamaGithub'}, '__index_level_0__': 3706}
Dataset({
    features: ['text', 'meta', '__index_level_0__'],
    num_rows: 500000
})
{'text': '@interface PodsDummy_XCDLumberjackNSLogger_OSX : NSObject\n@end\n@implementation PodsDummy_XCDLumberjackNSLogger_OSX\n@end\n', 'meta': {'redpajama_set_name': 'RedPajamaGithub'}, '__index_level_0__': 3706}
Running tokenizer on dataset (num_proc=16):   4%|â–Ž         | 71000/2000000 [01:04<16:07, 1994.24 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–Ž         | 72000/2000000 [01:05<19:00, 1691.18 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–Ž         | 73000/2000000 [01:05<16:43, 1919.56 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–Ž         | 74000/2000000 [01:06<16:21, 1962.11 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–         | 75000/2000000 [01:06<12:32, 2559.32 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–         | 76000/2000000 [01:06<11:15, 2848.19 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:55:35,419 >> Token indices sequence length is longer than the specified maximum sequence length for this model (38249 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=16):   4%|â–         | 77000/2000000 [01:06<10:48, 2965.67 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–         | 78000/2000000 [01:07<10:55, 2934.02 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:55:36,060 >> Token indices sequence length is longer than the specified maximum sequence length for this model (41044 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=16):   4%|â–         | 79000/2000000 [01:07<12:52, 2487.55 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–         | 81000/2000000 [01:09<15:46, 2027.29 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–         | 82000/2000000 [01:09<16:39, 1919.75 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–         | 83000/2000000 [01:09<13:39, 2339.86 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–         | 84000/2000000 [01:09<10:49, 2948.49 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–         | 85000/2000000 [01:11<21:34, 1478.84 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–         | 86000/2000000 [01:11<17:01, 1873.62 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–         | 87000/2000000 [01:11<14:38, 2176.76 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–         | 88000/2000000 [01:12<13:14, 2406.84 examples/s]Running tokenizer on dataset (num_proc=16):   4%|â–         | 90000/2000000 [01:12<09:56, 3200.09 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–         | 91000/2000000 [01:12<10:13, 3109.46 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–         | 92000/2000000 [01:13<09:57, 3195.22 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–         | 93000/2000000 [01:13<10:31, 3020.12 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–         | 94000/2000000 [01:14<13:54, 2283.84 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–         | 95000/2000000 [01:14<12:59, 2444.82 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–         | 96000/2000000 [01:15<18:05, 1754.13 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–         | 97000/2000000 [01:16<17:02, 1860.47 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–         | 98000/2000000 [01:16<14:11, 2232.40 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:55:45,234 >> Token indices sequence length is longer than the specified maximum sequence length for this model (60416 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=16):   5%|â–         | 99000/2000000 [01:16<14:27, 2191.02 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–Œ         | 100000/2000000 [01:17<13:28, 2350.06 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–Œ         | 101000/2000000 [01:17<16:03, 1970.37 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–Œ         | 102000/2000000 [01:18<12:55, 2448.25 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–Œ         | 103000/2000000 [01:18<10:00, 3156.79 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–Œ         | 105000/2000000 [01:18<09:42, 3252.53 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–Œ         | 106000/2000000 [01:18<09:32, 3309.57 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–Œ         | 107000/2000000 [01:20<19:08, 1647.80 examples/s]Running tokenizer on dataset (num_proc=16):   5%|â–Œ         | 108000/2000000 [01:20<15:38, 2015.76 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–Œ         | 110000/2000000 [01:21<13:27, 2341.85 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–Œ         | 112000/2000000 [01:22<16:08, 1950.00 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–Œ         | 114000/2000000 [01:22<11:13, 2800.74 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–Œ         | 115000/2000000 [01:23<10:43, 2930.13 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–Œ         | 116000/2000000 [01:23<14:39, 2141.74 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–Œ         | 118000/2000000 [01:24<10:01, 3128.24 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–Œ         | 119000/2000000 [01:24<09:55, 3157.80 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–Œ         | 120000/2000000 [01:24<10:16, 3049.55 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–Œ         | 121000/2000000 [01:26<19:52, 1576.29 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–Œ         | 122000/2000000 [01:26<16:40, 1877.54 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–Œ         | 123000/2000000 [01:26<13:39, 2290.52 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–Œ         | 124000/2000000 [01:26<11:33, 2706.49 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–‹         | 125000/2000000 [01:27<09:42, 3216.20 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–‹         | 126000/2000000 [01:27<12:11, 2563.35 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–‹         | 127000/2000000 [01:28<17:53, 1745.47 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–‹         | 128000/2000000 [01:29<18:19, 1702.44 examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–‹         | 130000/2000000 [01:29<13:29, 2311.07 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 131000/2000000 [01:30<12:00, 2595.06 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 133000/2000000 [01:30<08:56, 3480.88 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 134000/2000000 [01:31<12:53, 2413.61 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 135000/2000000 [01:31<11:16, 2756.99 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 136000/2000000 [01:32<18:08, 1712.63 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 137000/2000000 [01:32<14:16, 2174.84 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 138000/2000000 [01:33<15:07, 2052.09 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 139000/2000000 [01:33<13:34, 2285.13 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 140000/2000000 [01:34<15:34, 1990.83 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 141000/2000000 [01:34<13:57, 2220.78 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 142000/2000000 [01:34<12:35, 2460.53 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 143000/2000000 [01:35<13:33, 2281.85 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 144000/2000000 [01:35<11:30, 2686.09 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 145000/2000000 [01:35<09:19, 3314.16 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 146000/2000000 [01:35<07:56, 3890.02 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 147000/2000000 [01:36<07:06, 4344.56 examples/s]Running tokenizer on dataset (num_proc=16):   7%|â–‹         | 149000/2000000 [01:36<04:37, 6680.22 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 150000/2000000 [01:37<12:42, 2425.50 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 151000/2000000 [01:38<20:22, 1512.33 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 152000/2000000 [01:39<16:25, 1874.38 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 153000/2000000 [01:39<15:18, 2009.90 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 154000/2000000 [01:40<18:09, 1693.86 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 155000/2000000 [01:40<14:01, 2192.22 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 156000/2000000 [01:40<12:34, 2445.34 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 157000/2000000 [01:40<10:30, 2921.71 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 158000/2000000 [01:41<09:04, 3385.62 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 159000/2000000 [01:41<10:47, 2844.16 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 161000/2000000 [01:42<10:18, 2972.44 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 164000/2000000 [01:43<10:01, 3054.22 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 165000/2000000 [01:44<13:53, 2201.13 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 166000/2000000 [01:44<14:14, 2146.82 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 167000/2000000 [01:44<12:26, 2455.63 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-04-18 15:56:13,551 >> Token indices sequence length is longer than the specified maximum sequence length for this model (41764 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 168000/2000000 [01:45<13:34, 2248.09 examples/s]Running tokenizer on dataset (num_proc=16):   8%|â–Š         | 170000/2000000 [01:45<10:07, 3010.69 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–Š         | 171000/2000000 [01:46<15:22, 1981.74 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–Š         | 172000/2000000 [01:46<12:23, 2459.16 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–Š         | 173000/2000000 [01:47<13:44, 2217.19 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–Š         | 174000/2000000 [01:47<11:02, 2757.63 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–‰         | 176000/2000000 [01:48<10:27, 2909.00 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–‰         | 178000/2000000 [01:48<07:30, 4043.71 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–‰         | 179000/2000000 [01:49<15:30, 1957.83 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–‰         | 181000/2000000 [01:51<16:09, 1875.34 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–‰         | 182000/2000000 [01:51<13:50, 2189.25 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–‰         | 183000/2000000 [01:51<11:50, 2556.65 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–‰         | 184000/2000000 [01:51<11:01, 2746.72 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–‰         | 185000/2000000 [01:52<15:36, 1938.20 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–‰         | 186000/2000000 [01:52<13:46, 2193.79 examples/s]Running tokenizer on dataset (num_proc=16):   9%|â–‰         | 188000/2000000 [01:53<09:15, 3260.34 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–‰         | 190000/2000000 [01:53<06:19, 4775.13 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–‰         | 191000/2000000 [01:53<08:03, 3741.18 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–‰         | 192000/2000000 [01:54<07:57, 3785.31 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–‰         | 194000/2000000 [01:54<07:23, 4074.90 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–‰         | 195000/2000000 [01:55<12:44, 2360.44 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–‰         | 196000/2000000 [01:57<20:57, 1434.13 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–‰         | 197000/2000000 [01:57<20:28, 1467.26 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–‰         | 198000/2000000 [01:57<15:48, 1899.30 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–‰         | 199000/2000000 [01:58<14:22, 2087.70 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–ˆ         | 200000/2000000 [01:58<12:41, 2365.21 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–ˆ         | 201000/2000000 [01:58<10:12, 2937.15 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–ˆ         | 202000/2000000 [01:59<12:33, 2385.45 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–ˆ         | 203000/2000000 [01:59<10:57, 2731.63 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–ˆ         | 204000/2000000 [01:59<09:00, 3320.74 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–ˆ         | 205000/2000000 [01:59<08:06, 3692.27 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–ˆ         | 206000/2000000 [02:00<07:59, 3740.56 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–ˆ         | 207000/2000000 [02:00<07:13, 4136.01 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–ˆ         | 208000/2000000 [02:00<11:32, 2587.23 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–ˆ         | 209000/2000000 [02:01<17:28, 1707.74 examples/s]Running tokenizer on dataset (num_proc=16):  10%|â–ˆ         | 210000/2000000 [02:02<14:12, 2098.78 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆ         | 211000/2000000 [02:02<13:54, 2142.84 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆ         | 212000/2000000 [02:03<15:20, 1942.88 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆ         | 214000/2000000 [02:03<11:59, 2480.70 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆ         | 215000/2000000 [02:04<12:35, 2361.63 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆ         | 217000/2000000 [02:04<09:05, 3269.87 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆ         | 218000/2000000 [02:05<10:03, 2952.74 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆ         | 219000/2000000 [02:05<08:59, 3300.21 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆ         | 220000/2000000 [02:05<10:08, 2926.36 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆ         | 221000/2000000 [02:05<09:20, 3174.92 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆ         | 222000/2000000 [02:06<13:02, 2272.09 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆ         | 223000/2000000 [02:07<14:37, 2023.94 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆ         | 224000/2000000 [02:08<16:57, 1744.85 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆâ–        | 225000/2000000 [02:08<15:50, 1868.15 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆâ–        | 227000/2000000 [02:09<13:25, 2201.44 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆâ–        | 228000/2000000 [02:09<13:47, 2141.76 examples/s]Running tokenizer on dataset (num_proc=16):  11%|â–ˆâ–        | 229000/2000000 [02:09<12:02, 2450.81 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 230000/2000000 [02:10<10:12, 2887.75 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 231000/2000000 [02:10<09:57, 2960.48 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 234000/2000000 [02:10<06:55, 4247.54 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 235000/2000000 [02:11<07:14, 4062.46 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 237000/2000000 [02:11<05:40, 5184.72 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 238000/2000000 [02:13<17:10, 1709.83 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 239000/2000000 [02:13<16:05, 1823.41 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 240000/2000000 [02:14<13:16, 2209.74 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 241000/2000000 [02:15<19:52, 1474.52 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 242000/2000000 [02:15<15:24, 1902.36 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 243000/2000000 [02:15<12:20, 2371.96 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 245000/2000000 [02:16<09:18, 3143.01 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 246000/2000000 [02:16<07:52, 3713.53 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 247000/2000000 [02:16<07:50, 3723.19 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 248000/2000000 [02:16<08:11, 3561.64 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–        | 249000/2000000 [02:16<07:48, 3739.87 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–Ž        | 250000/2000000 [02:17<08:09, 3576.58 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 251000/2000000 [02:18<16:43, 1743.34 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 252000/2000000 [02:18<14:25, 2020.48 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 253000/2000000 [02:19<11:50, 2460.55 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 254000/2000000 [02:19<10:49, 2688.68 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 255000/2000000 [02:19<10:18, 2819.43 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 257000/2000000 [02:21<15:01, 1932.48 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 258000/2000000 [02:21<14:26, 2009.95 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 260000/2000000 [02:21<09:28, 3062.49 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 261000/2000000 [02:22<10:14, 2830.65 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 262000/2000000 [02:22<12:17, 2356.07 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 264000/2000000 [02:23<12:02, 2402.70 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 266000/2000000 [02:23<08:12, 3517.80 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 267000/2000000 [02:24<11:29, 2511.84 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 268000/2000000 [02:24<10:26, 2762.88 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 269000/2000000 [02:24<08:35, 3356.99 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–Ž        | 270000/2000000 [02:25<12:35, 2288.65 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–Ž        | 271000/2000000 [02:26<13:18, 2166.48 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–Ž        | 272000/2000000 [02:26<13:36, 2116.19 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–Ž        | 273000/2000000 [02:27<16:29, 1744.94 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–        | 276000/2000000 [02:27<09:09, 3135.11 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–        | 277000/2000000 [02:28<09:28, 3030.89 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–        | 279000/2000000 [02:28<08:05, 3547.89 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–        | 280000/2000000 [02:28<08:14, 3477.85 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–        | 281000/2000000 [02:30<14:35, 1963.47 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–        | 282000/2000000 [02:30<12:20, 2320.03 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–        | 283000/2000000 [02:31<16:21, 1749.19 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–        | 285000/2000000 [02:31<10:31, 2717.07 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–        | 287000/2000000 [02:31<08:23, 3403.76 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–        | 288000/2000000 [02:32<12:52, 2216.48 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–        | 289000/2000000 [02:33<10:44, 2654.59 examples/s]Running tokenizer on dataset (num_proc=16):  14%|â–ˆâ–        | 290000/2000000 [02:33<09:49, 2902.28 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–        | 292000/2000000 [02:34<10:10, 2796.21 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–        | 293000/2000000 [02:34<11:30, 2473.14 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–        | 294000/2000000 [02:34<09:33, 2976.50 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–        | 295000/2000000 [02:34<08:16, 3431.84 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–        | 296000/2000000 [02:36<15:06, 1880.50 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–        | 298000/2000000 [02:36<10:39, 2663.54 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–        | 299000/2000000 [02:37<11:52, 2388.90 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–Œ        | 300000/2000000 [02:38<16:04, 1763.12 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–Œ        | 301000/2000000 [02:38<15:39, 1809.28 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–Œ        | 303000/2000000 [02:38<10:51, 2606.66 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–Œ        | 306000/2000000 [02:39<06:55, 4074.15 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–Œ        | 308000/2000000 [02:39<05:47, 4864.17 examples/s]Running tokenizer on dataset (num_proc=16):  15%|â–ˆâ–Œ        | 309000/2000000 [02:39<06:40, 4221.36 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–Œ        | 310000/2000000 [02:40<07:32, 3737.83 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–Œ        | 311000/2000000 [02:41<13:55, 2020.65 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–Œ        | 312000/2000000 [02:42<15:08, 1857.21 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–Œ        | 313000/2000000 [02:42<14:25, 1950.05 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–Œ        | 314000/2000000 [02:42<13:05, 2146.66 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–Œ        | 315000/2000000 [02:43<14:40, 1913.40 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–Œ        | 316000/2000000 [02:44<15:09, 1851.03 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–Œ        | 318000/2000000 [02:44<11:08, 2515.80 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–Œ        | 320000/2000000 [02:44<08:01, 3491.22 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–Œ        | 322000/2000000 [02:45<09:04, 3083.46 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–Œ        | 323000/2000000 [02:45<09:11, 3041.31 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–Œ        | 324000/2000000 [02:46<10:42, 2610.00 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–‹        | 325000/2000000 [02:46<10:11, 2739.99 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–‹        | 326000/2000000 [02:47<10:10, 2739.81 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–‹        | 328000/2000000 [02:47<08:11, 3403.05 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–‹        | 329000/2000000 [02:48<14:15, 1952.61 examples/s]Running tokenizer on dataset (num_proc=16):  16%|â–ˆâ–‹        | 330000/2000000 [02:49<15:19, 1815.73 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 331000/2000000 [02:50<18:04, 1538.80 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 334000/2000000 [02:50<09:22, 2959.81 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 335000/2000000 [02:50<08:07, 3415.81 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 336000/2000000 [02:50<06:58, 3976.42 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 337000/2000000 [02:51<07:50, 3533.07 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 340000/2000000 [02:52<08:39, 3195.35 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 341000/2000000 [02:53<15:23, 1797.03 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 342000/2000000 [02:53<12:44, 2168.41 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 343000/2000000 [02:54<11:22, 2427.86 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 344000/2000000 [02:55<15:56, 1731.82 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 347000/2000000 [02:55<08:37, 3194.99 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 348000/2000000 [02:55<08:16, 3328.08 examples/s]Running tokenizer on dataset (num_proc=16):  17%|â–ˆâ–‹        | 349000/2000000 [02:55<07:24, 3716.80 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 350000/2000000 [02:56<08:34, 3205.79 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 352000/2000000 [02:57<09:33, 2875.50 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 354000/2000000 [02:58<12:08, 2259.34 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 355000/2000000 [02:58<11:17, 2426.85 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 356000/2000000 [02:58<09:55, 2758.71 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 357000/2000000 [02:59<11:35, 2361.97 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 359000/2000000 [03:00<10:55, 2502.97 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 360000/2000000 [03:00<12:16, 2227.20 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 362000/2000000 [03:01<10:26, 2613.91 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 363000/2000000 [03:01<10:10, 2680.13 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 365000/2000000 [03:02<09:28, 2877.69 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 367000/2000000 [03:02<07:47, 3491.75 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 368000/2000000 [03:03<09:13, 2947.14 examples/s]Running tokenizer on dataset (num_proc=16):  18%|â–ˆâ–Š        | 369000/2000000 [03:03<12:11, 2230.95 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–Š        | 371000/2000000 [03:04<10:04, 2692.77 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–Š        | 372000/2000000 [03:05<13:05, 2073.13 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–Š        | 373000/2000000 [03:06<16:08, 1679.95 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–Š        | 374000/2000000 [03:06<12:48, 2117.13 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 376000/2000000 [03:06<10:35, 2556.19 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 377000/2000000 [03:07<09:04, 2979.73 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 378000/2000000 [03:07<08:17, 3262.32 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 379000/2000000 [03:07<07:00, 3854.12 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 380000/2000000 [03:07<07:20, 3675.08 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 381000/2000000 [03:07<06:27, 4180.20 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 382000/2000000 [03:08<06:32, 4117.88 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 383000/2000000 [03:09<11:32, 2334.98 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 384000/2000000 [03:09<10:23, 2592.95 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 385000/2000000 [03:09<08:44, 3079.40 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 387000/2000000 [03:10<12:55, 2079.19 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 388000/2000000 [03:11<12:18, 2181.36 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 389000/2000000 [03:11<13:20, 2012.97 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–‰        | 390000/2000000 [03:12<12:27, 2152.61 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–‰        | 391000/2000000 [03:12<11:13, 2390.57 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–‰        | 393000/2000000 [03:13<11:10, 2397.11 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–‰        | 395000/2000000 [03:13<07:57, 3360.80 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–‰        | 396000/2000000 [03:13<08:25, 3174.31 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–‰        | 397000/2000000 [03:14<09:10, 2909.67 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–‰        | 398000/2000000 [03:14<08:41, 3070.52 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–‰        | 399000/2000000 [03:14<07:13, 3692.83 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 400000/2000000 [03:14<06:13, 4286.48 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 401000/2000000 [03:15<08:55, 2986.92 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 402000/2000000 [03:16<12:14, 2176.13 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 403000/2000000 [03:16<11:24, 2333.00 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 405000/2000000 [03:17<12:26, 2137.99 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 406000/2000000 [03:17<11:10, 2377.78 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 408000/2000000 [03:18<09:26, 2811.64 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 409000/2000000 [03:18<08:34, 3090.61 examples/s]Running tokenizer on dataset (num_proc=16):  20%|â–ˆâ–ˆ        | 410000/2000000 [03:19<12:40, 2089.84 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 412000/2000000 [03:20<14:30, 1825.13 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 413000/2000000 [03:21<12:13, 2164.53 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 415000/2000000 [03:21<09:12, 2868.39 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 416000/2000000 [03:21<08:08, 3244.47 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 417000/2000000 [03:21<06:53, 3829.17 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 419000/2000000 [03:23<13:25, 1963.12 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 422000/2000000 [03:23<08:55, 2944.27 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 423000/2000000 [03:24<07:55, 3317.45 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆ        | 424000/2000000 [03:24<07:21, 3566.11 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆâ–       | 426000/2000000 [03:24<05:42, 4595.29 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆâ–       | 427000/2000000 [03:26<13:41, 1915.31 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆâ–       | 428000/2000000 [03:26<13:12, 1982.85 examples/s]Running tokenizer on dataset (num_proc=16):  21%|â–ˆâ–ˆâ–       | 429000/2000000 [03:26<11:11, 2338.93 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 430000/2000000 [03:26<09:24, 2778.84 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 431000/2000000 [03:27<09:02, 2893.53 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 433000/2000000 [03:28<09:33, 2731.44 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 435000/2000000 [03:28<09:43, 2683.95 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 436000/2000000 [03:28<08:37, 3023.58 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 438000/2000000 [03:29<07:48, 3334.26 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 440000/2000000 [03:29<07:14, 3587.45 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 441000/2000000 [03:30<09:53, 2628.23 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 442000/2000000 [03:31<10:31, 2465.96 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 443000/2000000 [03:31<10:28, 2475.56 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 444000/2000000 [03:32<10:33, 2455.71 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 445000/2000000 [03:32<12:56, 2001.85 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 447000/2000000 [03:32<07:56, 3255.95 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 448000/2000000 [03:33<07:27, 3471.71 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–       | 449000/2000000 [03:33<06:54, 3741.78 examples/s]Running tokenizer on dataset (num_proc=16):  22%|â–ˆâ–ˆâ–Ž       | 450000/2000000 [03:34<11:35, 2228.85 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 451000/2000000 [03:34<09:24, 2742.78 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 452000/2000000 [03:35<11:57, 2158.69 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 455000/2000000 [03:35<06:48, 3785.37 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 456000/2000000 [03:36<10:23, 2474.39 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 457000/2000000 [03:37<15:07, 1701.05 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 459000/2000000 [03:38<11:39, 2202.61 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 460000/2000000 [03:38<11:02, 2325.96 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 461000/2000000 [03:38<09:36, 2671.01 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 463000/2000000 [03:38<07:10, 3566.91 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 464000/2000000 [03:39<07:55, 3232.96 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 465000/2000000 [03:39<08:15, 3100.41 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 467000/2000000 [03:39<05:26, 4700.75 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 468000/2000000 [03:40<10:05, 2531.88 examples/s]Running tokenizer on dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 469000/2000000 [03:40<08:36, 2965.30 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–Ž       | 471000/2000000 [03:41<08:22, 3041.79 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–Ž       | 472000/2000000 [03:42<13:30, 1886.30 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–Ž       | 474000/2000000 [03:43<11:00, 2309.67 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 475000/2000000 [03:43<11:59, 2118.86 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 476000/2000000 [03:44<10:16, 2471.02 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 477000/2000000 [03:44<10:29, 2418.81 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 478000/2000000 [03:44<08:40, 2923.00 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 479000/2000000 [03:44<07:42, 3289.43 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 480000/2000000 [03:45<09:14, 2740.57 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 481000/2000000 [03:45<08:51, 2856.63 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 482000/2000000 [03:45<07:02, 3591.75 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 483000/2000000 [03:46<09:55, 2549.43 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 486000/2000000 [03:46<05:26, 4636.41 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 487000/2000000 [03:47<06:43, 3753.19 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 488000/2000000 [03:48<09:34, 2632.18 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 489000/2000000 [03:49<13:55, 1809.10 examples/s]Running tokenizer on dataset (num_proc=16):  24%|â–ˆâ–ˆâ–       | 490000/2000000 [03:49<12:52, 1954.96 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–       | 491000/2000000 [03:49<10:55, 2301.34 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–       | 492000/2000000 [03:50<10:43, 2344.93 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–       | 493000/2000000 [03:50<09:28, 2649.21 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–       | 494000/2000000 [03:51<11:36, 2163.51 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–       | 496000/2000000 [03:51<07:31, 3333.29 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–       | 497000/2000000 [03:51<06:33, 3818.24 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–       | 498000/2000000 [03:51<08:03, 3105.39 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–       | 499000/2000000 [03:52<09:01, 2769.65 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 500000/2000000 [03:52<10:44, 2325.94 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 501000/2000000 [03:53<09:51, 2535.83 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 502000/2000000 [03:53<08:01, 3108.33 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 503000/2000000 [03:54<12:00, 2078.06 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 504000/2000000 [03:54<11:53, 2095.85 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 505000/2000000 [03:54<09:56, 2507.51 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 506000/2000000 [03:55<11:53, 2095.27 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 507000/2000000 [03:56<11:28, 2167.04 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 508000/2000000 [03:56<11:29, 2163.23 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 509000/2000000 [03:56<10:21, 2398.85 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 510000/2000000 [03:56<08:23, 2962.03 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 512000/2000000 [03:57<08:21, 2965.41 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 513000/2000000 [03:57<07:14, 3420.02 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 514000/2000000 [03:57<06:00, 4118.58 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 515000/2000000 [03:58<05:46, 4283.28 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 516000/2000000 [03:58<05:08, 4817.96 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 517000/2000000 [03:58<08:19, 2967.89 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 518000/2000000 [04:00<19:18, 1279.39 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 519000/2000000 [04:00<14:24, 1713.39 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 520000/2000000 [04:01<13:17, 1856.91 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 521000/2000000 [04:01<11:18, 2181.36 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–Œ       | 523000/2000000 [04:01<07:53, 3116.31 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–‹       | 525000/2000000 [04:02<06:04, 4050.15 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–‹       | 526000/2000000 [04:02<07:21, 3335.01 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–‹       | 529000/2000000 [04:03<05:33, 4416.49 examples/s]Running tokenizer on dataset (num_proc=16):  26%|â–ˆâ–ˆâ–‹       | 530000/2000000 [04:03<06:39, 3678.24 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 531000/2000000 [04:03<06:23, 3834.31 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 533000/2000000 [04:03<04:39, 5255.69 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 534000/2000000 [04:06<18:15, 1337.98 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 535000/2000000 [04:06<14:55, 1636.61 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 536000/2000000 [04:07<12:00, 2032.98 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 537000/2000000 [04:07<10:43, 2273.31 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 538000/2000000 [04:07<11:38, 2092.15 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 540000/2000000 [04:08<07:35, 3203.85 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 542000/2000000 [04:08<05:12, 4666.80 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 543000/2000000 [04:08<06:18, 3847.23 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 545000/2000000 [04:08<05:00, 4841.52 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 546000/2000000 [04:09<04:34, 5291.96 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 547000/2000000 [04:09<04:35, 5278.11 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 548000/2000000 [04:09<07:56, 3049.83 examples/s]Running tokenizer on dataset (num_proc=16):  27%|â–ˆâ–ˆâ–‹       | 549000/2000000 [04:10<10:54, 2215.94 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 550000/2000000 [04:12<17:21, 1392.62 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 552000/2000000 [04:12<12:51, 1877.06 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 553000/2000000 [04:13<11:31, 2092.33 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 554000/2000000 [04:13<10:23, 2320.62 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 555000/2000000 [04:13<08:40, 2777.33 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 556000/2000000 [04:13<08:45, 2748.47 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 558000/2000000 [04:14<08:07, 2955.89 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 559000/2000000 [04:14<07:40, 3131.54 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 561000/2000000 [04:15<07:40, 3128.11 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 562000/2000000 [04:15<06:50, 3502.01 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 563000/2000000 [04:16<12:30, 1913.67 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 564000/2000000 [04:16<10:02, 2385.18 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 565000/2000000 [04:17<13:28, 1774.74 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 567000/2000000 [04:18<09:17, 2570.12 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 568000/2000000 [04:18<07:49, 3052.43 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 569000/2000000 [04:18<06:29, 3676.25 examples/s]Running tokenizer on dataset (num_proc=16):  28%|â–ˆâ–ˆâ–Š       | 570000/2000000 [04:18<07:23, 3225.84 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–Š       | 571000/2000000 [04:19<06:25, 3703.48 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–Š       | 572000/2000000 [04:19<07:18, 3258.46 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–Š       | 574000/2000000 [04:20<06:56, 3426.45 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 575000/2000000 [04:20<08:08, 2917.97 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 576000/2000000 [04:21<11:12, 2116.32 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 577000/2000000 [04:22<17:50, 1329.03 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 578000/2000000 [04:23<14:02, 1686.84 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 579000/2000000 [04:23<11:31, 2055.71 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 581000/2000000 [04:23<08:36, 2747.02 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 582000/2000000 [04:24<08:47, 2685.81 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 583000/2000000 [04:24<07:25, 3179.24 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 584000/2000000 [04:24<06:57, 3390.70 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 585000/2000000 [04:24<06:51, 3442.48 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 587000/2000000 [04:25<05:39, 4157.93 examples/s]Running tokenizer on dataset (num_proc=16):  29%|â–ˆâ–ˆâ–‰       | 589000/2000000 [04:25<04:04, 5768.74 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–‰       | 590000/2000000 [04:26<07:58, 2946.68 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–‰       | 591000/2000000 [04:26<07:57, 2950.89 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–‰       | 592000/2000000 [04:27<13:46, 1704.27 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–‰       | 593000/2000000 [04:28<11:33, 2028.99 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–‰       | 594000/2000000 [04:28<11:20, 2065.56 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–‰       | 595000/2000000 [04:28<10:53, 2149.81 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–‰       | 596000/2000000 [04:30<14:58, 1562.23 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–‰       | 599000/2000000 [04:30<07:46, 3000.44 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–ˆ       | 600000/2000000 [04:30<06:42, 3478.20 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–ˆ       | 602000/2000000 [04:30<04:40, 4975.28 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–ˆ       | 603000/2000000 [04:30<05:53, 3947.89 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–ˆ       | 604000/2000000 [04:31<08:07, 2862.97 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–ˆ       | 605000/2000000 [04:31<07:48, 2979.18 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–ˆ       | 606000/2000000 [04:32<08:53, 2613.50 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–ˆ       | 607000/2000000 [04:33<13:40, 1698.38 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–ˆ       | 609000/2000000 [04:34<09:52, 2348.09 examples/s]Running tokenizer on dataset (num_proc=16):  30%|â–ˆâ–ˆâ–ˆ       | 610000/2000000 [04:34<09:39, 2399.43 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 611000/2000000 [04:34<08:20, 2776.87 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 612000/2000000 [04:35<11:50, 1953.18 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 614000/2000000 [04:35<07:50, 2947.48 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 617000/2000000 [04:36<06:15, 3678.54 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 619000/2000000 [04:36<04:57, 4648.28 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 620000/2000000 [04:37<07:46, 2958.41 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 621000/2000000 [04:37<08:05, 2839.61 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 622000/2000000 [04:38<10:37, 2160.41 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 623000/2000000 [04:39<10:05, 2274.68 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆ       | 624000/2000000 [04:40<14:11, 1615.71 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆâ–      | 626000/2000000 [04:40<08:59, 2545.43 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆâ–      | 627000/2000000 [04:40<08:25, 2716.22 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆâ–      | 628000/2000000 [04:40<07:51, 2908.78 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 630000/2000000 [04:41<05:20, 4272.12 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 631000/2000000 [04:41<06:23, 3573.44 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 632000/2000000 [04:41<05:56, 3837.07 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 634000/2000000 [04:41<04:07, 5529.97 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 635000/2000000 [04:43<12:44, 1784.63 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 636000/2000000 [04:43<10:11, 2232.08 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 638000/2000000 [04:44<07:23, 3069.40 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 639000/2000000 [04:44<10:00, 2267.86 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 640000/2000000 [04:45<10:15, 2208.16 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 641000/2000000 [04:45<09:28, 2392.33 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 642000/2000000 [04:46<10:10, 2223.60 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 644000/2000000 [04:46<08:06, 2788.78 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 646000/2000000 [04:46<05:45, 3917.05 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 647000/2000000 [04:47<06:15, 3603.08 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 648000/2000000 [04:47<05:22, 4194.06 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–      | 649000/2000000 [04:47<04:49, 4665.64 examples/s]Running tokenizer on dataset (num_proc=16):  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 650000/2000000 [04:48<08:25, 2671.48 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 651000/2000000 [04:48<09:39, 2329.58 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 652000/2000000 [04:49<10:12, 2199.87 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 654000/2000000 [04:50<09:53, 2266.91 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 655000/2000000 [04:50<10:33, 2124.45 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 656000/2000000 [04:51<09:10, 2443.02 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 657000/2000000 [04:51<07:56, 2816.78 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 658000/2000000 [04:51<07:21, 3040.76 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 659000/2000000 [04:52<08:25, 2654.56 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 660000/2000000 [04:52<07:30, 2973.18 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 662000/2000000 [04:52<05:50, 3817.89 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 663000/2000000 [04:52<05:45, 3864.64 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 664000/2000000 [04:53<05:10, 4302.29 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 665000/2000000 [04:54<10:55, 2037.28 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 666000/2000000 [04:54<10:14, 2171.33 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 667000/2000000 [04:55<09:53, 2247.36 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 668000/2000000 [04:55<08:47, 2525.55 examples/s]Running tokenizer on dataset (num_proc=16):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 669000/2000000 [04:55<08:49, 2515.27 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 670000/2000000 [04:56<10:27, 2120.27 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 671000/2000000 [04:56<09:13, 2401.65 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 672000/2000000 [04:56<07:44, 2861.80 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 673000/2000000 [04:57<07:58, 2772.11 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 674000/2000000 [04:57<06:47, 3252.78 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 675000/2000000 [04:57<07:25, 2971.15 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 676000/2000000 [04:58<08:25, 2619.82 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 678000/2000000 [04:58<05:14, 4206.29 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 679000/2000000 [04:58<06:50, 3220.74 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 680000/2000000 [04:59<05:43, 3838.09 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 681000/2000000 [05:00<12:05, 1818.19 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 683000/2000000 [05:00<09:32, 2300.13 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 684000/2000000 [05:01<08:44, 2509.50 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 685000/2000000 [05:01<07:24, 2957.16 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 686000/2000000 [05:01<08:16, 2648.56 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 687000/2000000 [05:02<08:29, 2576.79 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 688000/2000000 [05:02<07:09, 3052.36 examples/s]Running tokenizer on dataset (num_proc=16):  34%|â–ˆâ–ˆâ–ˆâ–      | 690000/2000000 [05:03<07:36, 2870.71 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–      | 691000/2000000 [05:03<06:23, 3413.47 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–      | 693000/2000000 [05:03<06:24, 3395.03 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–      | 694000/2000000 [05:04<08:53, 2446.35 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–      | 695000/2000000 [05:04<07:57, 2733.33 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–      | 696000/2000000 [05:05<09:07, 2383.54 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–      | 697000/2000000 [05:05<08:45, 2478.54 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–      | 698000/2000000 [05:06<09:07, 2380.18 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–      | 699000/2000000 [05:06<08:22, 2587.88 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 700000/2000000 [05:07<08:00, 2706.06 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 701000/2000000 [05:07<08:22, 2585.35 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 703000/2000000 [05:07<07:08, 3024.29 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 704000/2000000 [05:08<07:12, 2997.46 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 705000/2000000 [05:08<06:48, 3173.45 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 706000/2000000 [05:09<07:49, 2754.89 examples/s]Running tokenizer on dataset (num_proc=16):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 708000/2000000 [05:09<04:53, 4404.29 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 710000/2000000 [05:10<06:47, 3169.44 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 711000/2000000 [05:10<09:16, 2317.22 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 712000/2000000 [05:11<10:37, 2019.33 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 714000/2000000 [05:12<09:05, 2358.21 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 715000/2000000 [05:12<08:04, 2651.87 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 716000/2000000 [05:12<07:06, 3007.50 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 717000/2000000 [05:13<07:13, 2958.11 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 718000/2000000 [05:13<07:30, 2844.30 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 720000/2000000 [05:13<05:43, 3725.13 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 721000/2000000 [05:14<07:24, 2878.26 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 722000/2000000 [05:15<09:05, 2341.68 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 723000/2000000 [05:15<09:48, 2169.28 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 725000/2000000 [05:15<06:41, 3173.78 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 726000/2000000 [05:16<07:31, 2824.30 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 727000/2000000 [05:17<09:54, 2141.35 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 729000/2000000 [05:17<06:19, 3344.84 examples/s]Running tokenizer on dataset (num_proc=16):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 730000/2000000 [05:17<06:12, 3412.44 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 731000/2000000 [05:18<08:08, 2595.85 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 732000/2000000 [05:18<07:14, 2921.46 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 733000/2000000 [05:18<07:10, 2945.73 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 734000/2000000 [05:19<07:35, 2778.21 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 735000/2000000 [05:19<08:16, 2548.54 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 736000/2000000 [05:20<09:26, 2229.30 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 737000/2000000 [05:20<08:26, 2495.42 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 738000/2000000 [05:21<10:33, 1992.54 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 740000/2000000 [05:21<07:03, 2972.16 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 741000/2000000 [05:21<07:16, 2886.80 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 742000/2000000 [05:22<08:01, 2614.22 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 743000/2000000 [05:22<08:28, 2473.55 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 744000/2000000 [05:23<07:43, 2707.75 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 745000/2000000 [05:23<06:09, 3394.04 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 746000/2000000 [05:23<06:27, 3239.41 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 747000/2000000 [05:23<05:23, 3869.82 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 748000/2000000 [05:23<04:43, 4417.45 examples/s]Running tokenizer on dataset (num_proc=16):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 749000/2000000 [05:24<07:09, 2909.42 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 750000/2000000 [05:25<10:38, 1958.90 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 751000/2000000 [05:25<10:45, 1934.21 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 752000/2000000 [05:26<09:11, 2264.56 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 753000/2000000 [05:26<07:23, 2812.65 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 754000/2000000 [05:26<07:43, 2688.57 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 755000/2000000 [05:26<06:52, 3021.20 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 756000/2000000 [05:27<07:32, 2752.08 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 757000/2000000 [05:27<06:02, 3427.46 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 758000/2000000 [05:28<09:03, 2283.56 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 759000/2000000 [05:28<08:55, 2318.62 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 760000/2000000 [05:29<08:50, 2337.88 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 761000/2000000 [05:29<07:02, 2930.84 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 762000/2000000 [05:29<07:44, 2664.64 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 763000/2000000 [05:29<07:00, 2942.63 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 764000/2000000 [05:30<07:53, 2611.18 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 765000/2000000 [05:30<06:20, 3243.59 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 766000/2000000 [05:31<10:16, 2002.51 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 767000/2000000 [05:31<08:53, 2310.30 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 768000/2000000 [05:31<07:00, 2929.79 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 770000/2000000 [05:32<05:17, 3878.76 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 771000/2000000 [05:32<07:28, 2740.84 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 772000/2000000 [05:33<07:44, 2641.77 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 774000/2000000 [05:34<09:04, 2250.49 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 775000/2000000 [05:34<08:11, 2491.30 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 776000/2000000 [05:34<06:40, 3054.87 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 777000/2000000 [05:35<06:04, 3354.49 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 778000/2000000 [05:35<06:43, 3026.47 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 780000/2000000 [05:35<04:25, 4591.91 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 781000/2000000 [05:36<09:09, 2217.61 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 782000/2000000 [05:37<08:17, 2449.71 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 783000/2000000 [05:37<07:59, 2537.72 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 784000/2000000 [05:37<07:27, 2715.84 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 785000/2000000 [05:37<06:16, 3231.34 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 786000/2000000 [05:38<06:50, 2955.02 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 788000/2000000 [05:38<05:54, 3416.03 examples/s]Running tokenizer on dataset (num_proc=16):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 789000/2000000 [05:39<10:17, 1960.35 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 791000/2000000 [05:40<06:55, 2909.41 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 793000/2000000 [05:40<06:16, 3207.26 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 794000/2000000 [05:41<07:31, 2671.61 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 795000/2000000 [05:42<09:29, 2116.71 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 796000/2000000 [05:42<09:23, 2138.23 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 797000/2000000 [05:42<08:23, 2389.23 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 798000/2000000 [05:42<06:45, 2966.60 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 800000/2000000 [05:43<04:22, 4568.58 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 801000/2000000 [05:43<04:49, 4139.39 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 802000/2000000 [05:43<05:49, 3426.55 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 803000/2000000 [05:44<09:53, 2016.09 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 804000/2000000 [05:45<07:47, 2557.66 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 805000/2000000 [05:45<08:40, 2295.04 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 807000/2000000 [05:45<06:00, 3307.30 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 808000/2000000 [05:46<09:33, 2080.17 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 809000/2000000 [05:47<08:38, 2295.55 examples/s]Running tokenizer on dataset (num_proc=16):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 810000/2000000 [05:47<07:06, 2788.41 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 811000/2000000 [05:47<06:24, 3091.70 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 812000/2000000 [05:47<06:12, 3191.41 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 813000/2000000 [05:48<08:30, 2327.42 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 814000/2000000 [05:48<07:12, 2739.86 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 816000/2000000 [05:48<04:43, 4172.20 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 817000/2000000 [05:49<04:37, 4261.40 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 818000/2000000 [05:50<08:25, 2337.87 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 819000/2000000 [05:50<07:30, 2618.82 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 820000/2000000 [05:50<07:52, 2497.81 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 821000/2000000 [05:51<09:53, 1985.53 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 822000/2000000 [05:51<09:04, 2165.20 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 823000/2000000 [05:52<07:05, 2763.32 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 824000/2000000 [05:52<06:07, 3195.95 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 825000/2000000 [05:53<09:38, 2032.48 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 826000/2000000 [05:53<08:13, 2379.23 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 827000/2000000 [05:53<06:58, 2806.10 examples/s]Running tokenizer on dataset (num_proc=16):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 829000/2000000 [05:54<05:14, 3727.15 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 830000/2000000 [05:54<05:53, 3310.95 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 831000/2000000 [05:54<06:03, 3216.53 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 832000/2000000 [05:55<05:57, 3268.52 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 833000/2000000 [05:55<05:53, 3301.22 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 834000/2000000 [05:56<08:45, 2218.71 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 835000/2000000 [05:56<09:09, 2121.49 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 836000/2000000 [05:56<07:41, 2521.61 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 837000/2000000 [05:57<07:31, 2576.58 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 839000/2000000 [05:57<07:12, 2683.23 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 840000/2000000 [05:58<07:40, 2517.80 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 841000/2000000 [05:58<08:03, 2397.68 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 842000/2000000 [05:59<07:45, 2485.10 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 843000/2000000 [05:59<06:34, 2932.58 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 846000/2000000 [06:00<06:36, 2907.51 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 847000/2000000 [06:00<05:48, 3307.64 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 848000/2000000 [06:00<05:35, 3429.28 examples/s]Running tokenizer on dataset (num_proc=16):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 849000/2000000 [06:02<09:53, 1940.01 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 851000/2000000 [06:02<07:57, 2406.37 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 853000/2000000 [06:03<06:57, 2746.41 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 854000/2000000 [06:04<08:48, 2166.44 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 855000/2000000 [06:04<07:14, 2637.35 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 856000/2000000 [06:04<06:53, 2763.81 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 857000/2000000 [06:04<05:45, 3310.56 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 859000/2000000 [06:04<03:51, 4938.10 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 860000/2000000 [06:05<05:34, 3409.81 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 861000/2000000 [06:06<08:58, 2116.30 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 862000/2000000 [06:06<07:46, 2441.10 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 863000/2000000 [06:06<07:05, 2672.99 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 864000/2000000 [06:07<10:06, 1872.37 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 865000/2000000 [06:08<08:45, 2158.65 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 866000/2000000 [06:08<07:11, 2629.26 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 867000/2000000 [06:08<07:26, 2535.68 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 868000/2000000 [06:08<05:55, 3183.94 examples/s]Running tokenizer on dataset (num_proc=16):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 869000/2000000 [06:09<05:31, 3412.64 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 870000/2000000 [06:09<05:59, 3143.27 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 871000/2000000 [06:09<05:12, 3608.76 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 872000/2000000 [06:09<04:28, 4199.64 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 874000/2000000 [06:10<03:50, 4880.53 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 875000/2000000 [06:10<04:13, 4432.17 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 876000/2000000 [06:10<04:37, 4054.24 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 877000/2000000 [06:11<09:00, 2078.45 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 878000/2000000 [06:12<09:55, 1883.49 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 879000/2000000 [06:13<10:47, 1732.07 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 880000/2000000 [06:13<09:07, 2045.71 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 881000/2000000 [06:14<09:54, 1882.95 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 882000/2000000 [06:14<08:23, 2221.65 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 883000/2000000 [06:14<07:42, 2412.91 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 886000/2000000 [06:14<04:08, 4484.01 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 887000/2000000 [06:15<04:18, 4297.84 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 888000/2000000 [06:15<04:18, 4297.97 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 889000/2000000 [06:15<05:16, 3513.65 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 890000/2000000 [06:16<06:45, 2738.87 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 891000/2000000 [06:17<08:56, 2068.74 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 892000/2000000 [06:17<09:52, 1870.86 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 894000/2000000 [06:18<06:12, 2972.44 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 895000/2000000 [06:18<05:47, 3180.94 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 896000/2000000 [06:19<08:47, 2093.56 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 897000/2000000 [06:19<07:33, 2434.61 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 898000/2000000 [06:19<07:03, 2602.67 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 900000/2000000 [06:20<05:58, 3069.12 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 901000/2000000 [06:20<05:43, 3203.92 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 902000/2000000 [06:20<05:05, 3588.95 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 903000/2000000 [06:21<05:19, 3436.76 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 904000/2000000 [06:21<05:42, 3197.05 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 905000/2000000 [06:22<08:52, 2055.12 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 906000/2000000 [06:22<07:56, 2297.46 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 907000/2000000 [06:23<07:49, 2326.20 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 908000/2000000 [06:23<06:46, 2688.15 examples/s]Running tokenizer on dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 909000/2000000 [06:23<07:00, 2593.76 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 910000/2000000 [06:24<06:39, 2729.75 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 911000/2000000 [06:24<05:21, 3388.85 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 912000/2000000 [06:24<04:33, 3980.29 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 914000/2000000 [06:24<03:18, 5457.91 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 915000/2000000 [06:25<05:22, 3360.10 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 916000/2000000 [06:25<04:41, 3846.07 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 917000/2000000 [06:26<07:07, 2534.68 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 918000/2000000 [06:26<06:54, 2612.56 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 919000/2000000 [06:26<07:51, 2291.80 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 920000/2000000 [06:27<08:43, 2061.38 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 922000/2000000 [06:28<08:26, 2127.67 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 923000/2000000 [06:28<07:38, 2347.25 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 924000/2000000 [06:28<06:28, 2769.52 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 925000/2000000 [06:29<06:21, 2817.01 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 928000/2000000 [06:29<03:43, 4802.69 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 929000/2000000 [06:30<06:25, 2774.68 examples/s]Running tokenizer on dataset (num_proc=16):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 930000/2000000 [06:30<06:28, 2755.74 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 932000/2000000 [06:30<04:21, 4079.43 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 933000/2000000 [06:31<04:08, 4289.57 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 934000/2000000 [06:31<04:17, 4134.36 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 935000/2000000 [06:32<07:12, 2462.04 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 936000/2000000 [06:32<08:15, 2148.89 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 937000/2000000 [06:33<10:16, 1723.41 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 939000/2000000 [06:34<07:14, 2441.13 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 940000/2000000 [06:34<06:36, 2675.85 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 942000/2000000 [06:35<06:10, 2855.04 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 944000/2000000 [06:35<06:31, 2694.95 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 946000/2000000 [06:36<05:44, 3061.62 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 948000/2000000 [06:36<04:09, 4210.75 examples/s]Running tokenizer on dataset (num_proc=16):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 949000/2000000 [06:37<07:21, 2381.69 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 950000/2000000 [06:38<07:05, 2468.93 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 951000/2000000 [06:38<06:32, 2673.18 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 952000/2000000 [06:38<05:40, 3074.30 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 953000/2000000 [06:39<09:10, 1902.55 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 955000/2000000 [06:40<06:41, 2601.42 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 956000/2000000 [06:40<05:37, 3095.52 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 958000/2000000 [06:40<03:52, 4474.17 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 959000/2000000 [06:40<04:10, 4156.32 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 960000/2000000 [06:41<04:56, 3505.88 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 961000/2000000 [06:41<07:18, 2369.74 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 963000/2000000 [06:42<05:06, 3378.85 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 964000/2000000 [06:43<07:47, 2215.66 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 965000/2000000 [06:43<06:59, 2467.14 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 966000/2000000 [06:44<08:29, 2031.23 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 967000/2000000 [06:44<08:05, 2125.53 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 968000/2000000 [06:44<07:59, 2153.86 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 969000/2000000 [06:45<07:45, 2215.04 examples/s]Running tokenizer on dataset (num_proc=16):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 970000/2000000 [06:45<07:05, 2420.06 examples/s]Running tokenizer on dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 973000/2000000 [06:45<03:50, 4459.61 examples/s]Running tokenizer on dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 974000/2000000 [06:46<04:06, 4162.32 examples/s]Running tokenizer on dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 975000/2000000 [06:46<04:39, 3662.81 examples/s]Running tokenizer on dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 977000/2000000 [06:47<06:05, 2797.17 examples/s]Running tokenizer on dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 979000/2000000 [06:47<04:18, 3955.51 examples/s]Running tokenizer on dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 980000/2000000 [06:48<07:12, 2360.56 examples/s]Running tokenizer on dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 981000/2000000 [06:49<08:16, 2052.83 examples/s]Running tokenizer on dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 982000/2000000 [06:49<07:30, 2257.77 examples/s]Running tokenizer on dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 983000/2000000 [06:49<06:29, 2613.23 examples/s]Running tokenizer on dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 984000/2000000 [06:50<08:23, 2016.36 examples/s]Running tokenizer on dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 985000/2000000 [06:51<07:23, 2289.48 examples/s]Running tokenizer on dataset (num_proc=16):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 988000/2000000 [06:51<04:06, 4110.29 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 990000/2000000 [06:51<03:01, 5557.04 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 991000/2000000 [06:52<05:10, 3245.51 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 992000/2000000 [06:52<05:43, 2935.23 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 994000/2000000 [06:52<04:29, 3738.19 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 995000/2000000 [06:53<05:25, 3084.49 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 996000/2000000 [06:54<07:14, 2311.52 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 997000/2000000 [06:54<06:59, 2391.44 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 998000/2000000 [06:55<06:45, 2471.55 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 999000/2000000 [06:55<08:51, 1883.50 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1000000/2000000 [06:56<07:54, 2105.56 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1001000/2000000 [06:56<06:32, 2544.92 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1003000/2000000 [06:56<04:06, 4037.71 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1005000/2000000 [06:56<03:47, 4368.99 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1006000/2000000 [06:57<04:31, 3659.78 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1007000/2000000 [06:57<04:57, 3332.82 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1008000/2000000 [06:58<06:16, 2634.19 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1009000/2000000 [06:58<05:11, 3176.85 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1010000/2000000 [06:59<08:13, 2005.88 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1011000/2000000 [06:59<07:42, 2140.34 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1012000/2000000 [07:00<07:54, 2080.60 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1013000/2000000 [07:00<06:07, 2687.46 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1015000/2000000 [07:01<05:19, 3085.53 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1016000/2000000 [07:01<05:26, 3010.06 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1017000/2000000 [07:01<04:34, 3575.64 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1019000/2000000 [07:01<03:28, 4693.78 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1020000/2000000 [07:01<03:08, 5199.73 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1021000/2000000 [07:02<03:31, 4636.20 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1022000/2000000 [07:03<07:49, 2082.87 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1023000/2000000 [07:03<08:07, 2005.68 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1024000/2000000 [07:04<06:18, 2580.44 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1025000/2000000 [07:04<08:13, 1974.42 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1026000/2000000 [07:05<06:50, 2370.11 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1027000/2000000 [07:05<05:48, 2792.70 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1028000/2000000 [07:05<07:08, 2267.04 examples/s]Running tokenizer on dataset (num_proc=16):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1029000/2000000 [07:06<07:43, 2093.17 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1030000/2000000 [07:06<06:09, 2623.05 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1032000/2000000 [07:07<04:45, 3387.67 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1033000/2000000 [07:07<04:37, 3484.57 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1034000/2000000 [07:07<04:17, 3752.33 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1035000/2000000 [07:07<04:02, 3985.81 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1036000/2000000 [07:07<04:00, 4014.49 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1037000/2000000 [07:08<07:30, 2138.14 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1038000/2000000 [07:09<09:11, 1744.47 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1039000/2000000 [07:10<07:34, 2116.07 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1041000/2000000 [07:10<05:48, 2751.04 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1042000/2000000 [07:10<05:48, 2746.29 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1043000/2000000 [07:11<06:13, 2564.37 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1045000/2000000 [07:11<04:30, 3536.28 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1046000/2000000 [07:11<04:37, 3435.08 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1047000/2000000 [07:12<03:54, 4065.50 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1048000/2000000 [07:12<05:56, 2672.95 examples/s]Running tokenizer on dataset (num_proc=16):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1049000/2000000 [07:13<08:39, 1831.40 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1051000/2000000 [07:14<06:09, 2566.86 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1052000/2000000 [07:14<07:12, 2191.71 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1054000/2000000 [07:14<04:46, 3307.12 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1055000/2000000 [07:15<05:34, 2820.92 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1056000/2000000 [07:15<05:12, 3024.98 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1057000/2000000 [07:16<07:07, 2206.53 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1058000/2000000 [07:16<05:40, 2767.99 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1060000/2000000 [07:17<04:16, 3662.29 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1061000/2000000 [07:17<04:24, 3544.26 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1062000/2000000 [07:18<07:16, 2149.48 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1064000/2000000 [07:19<08:23, 1858.44 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1065000/2000000 [07:19<06:53, 2261.91 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1066000/2000000 [07:20<06:41, 2328.42 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1067000/2000000 [07:20<05:27, 2850.12 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1068000/2000000 [07:20<04:53, 3173.62 examples/s]Running tokenizer on dataset (num_proc=16):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1069000/2000000 [07:20<04:35, 3382.62 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1070000/2000000 [07:20<03:43, 4161.49 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1071000/2000000 [07:21<03:35, 4304.56 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1072000/2000000 [07:21<03:56, 3922.37 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1073000/2000000 [07:21<05:05, 3036.70 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1074000/2000000 [07:21<04:05, 3777.57 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1075000/2000000 [07:22<04:45, 3234.86 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1077000/2000000 [07:22<03:12, 4795.99 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1078000/2000000 [07:24<10:27, 1470.02 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1079000/2000000 [07:25<09:03, 1695.00 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1080000/2000000 [07:25<07:14, 2114.97 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1081000/2000000 [07:25<05:41, 2693.58 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1083000/2000000 [07:25<04:55, 3107.15 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1084000/2000000 [07:26<04:36, 3317.10 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1085000/2000000 [07:26<03:58, 3843.83 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1086000/2000000 [07:26<03:55, 3877.21 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1087000/2000000 [07:26<04:24, 3448.90 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1088000/2000000 [07:26<04:00, 3792.29 examples/s]Running tokenizer on dataset (num_proc=16):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1089000/2000000 [07:27<03:31, 4313.34 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1091000/2000000 [07:27<03:06, 4872.54 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1092000/2000000 [07:27<03:29, 4331.11 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1093000/2000000 [07:28<05:57, 2537.26 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1094000/2000000 [07:29<08:56, 1687.20 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1095000/2000000 [07:30<08:28, 1780.12 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1096000/2000000 [07:30<07:14, 2080.59 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1097000/2000000 [07:30<05:38, 2665.00 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1098000/2000000 [07:31<06:58, 2157.44 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1099000/2000000 [07:31<05:39, 2656.60 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1101000/2000000 [07:31<04:23, 3406.21 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1102000/2000000 [07:32<04:32, 3300.69 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1104000/2000000 [07:32<02:58, 5022.07 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1105000/2000000 [07:32<03:14, 4602.83 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1107000/2000000 [07:32<02:42, 5505.44 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1108000/2000000 [07:33<03:30, 4246.65 examples/s]Running tokenizer on dataset (num_proc=16):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1109000/2000000 [07:35<09:45, 1522.83 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1110000/2000000 [07:35<08:08, 1823.07 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1111000/2000000 [07:35<07:35, 1951.32 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1114000/2000000 [07:36<05:42, 2584.97 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1116000/2000000 [07:36<04:17, 3429.93 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1118000/2000000 [07:37<04:12, 3495.82 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1119000/2000000 [07:37<04:01, 3647.06 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1120000/2000000 [07:38<04:54, 2983.30 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1121000/2000000 [07:38<05:07, 2857.94 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1122000/2000000 [07:38<04:18, 3400.49 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1123000/2000000 [07:39<03:53, 3755.90 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1125000/2000000 [07:40<07:41, 1894.03 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1126000/2000000 [07:40<06:31, 2231.74 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1127000/2000000 [07:41<05:53, 2470.50 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1129000/2000000 [07:41<04:54, 2954.98 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1130000/2000000 [07:41<04:16, 3394.74 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1132000/2000000 [07:42<03:38, 3974.75 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1133000/2000000 [07:42<03:36, 4008.51 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1134000/2000000 [07:42<04:06, 3512.40 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1135000/2000000 [07:43<04:28, 3227.48 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1136000/2000000 [07:43<05:06, 2819.46 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1137000/2000000 [07:43<04:29, 3200.55 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1138000/2000000 [07:44<06:33, 2188.84 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1139000/2000000 [07:45<06:22, 2252.39 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1140000/2000000 [07:45<07:06, 2017.95 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1141000/2000000 [07:46<06:28, 2209.96 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1142000/2000000 [07:46<08:04, 1771.72 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1144000/2000000 [07:47<04:48, 2962.85 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1146000/2000000 [07:47<03:29, 4074.34 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1148000/2000000 [07:47<03:38, 3905.79 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1150000/2000000 [07:48<03:11, 4447.95 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1151000/2000000 [07:48<03:47, 3732.92 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1152000/2000000 [07:49<04:11, 3368.60 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1153000/2000000 [07:49<04:49, 2923.13 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1154000/2000000 [07:50<08:30, 1657.94 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1155000/2000000 [07:51<09:37, 1462.64 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1156000/2000000 [07:52<08:39, 1625.56 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1157000/2000000 [07:52<07:08, 1966.85 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1159000/2000000 [07:52<04:32, 3083.33 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1162000/2000000 [07:53<03:11, 4366.61 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1163000/2000000 [07:53<03:15, 4275.22 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1164000/2000000 [07:53<03:30, 3968.78 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1165000/2000000 [07:54<04:25, 3142.72 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1169000/2000000 [07:54<03:04, 4496.88 examples/s]Running tokenizer on dataset (num_proc=16):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1170000/2000000 [07:57<07:47, 1776.54 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1171000/2000000 [07:57<07:37, 1811.56 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1172000/2000000 [07:58<07:28, 1847.57 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1175000/2000000 [07:58<04:14, 3239.79 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1176000/2000000 [07:58<03:54, 3520.18 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1178000/2000000 [07:58<03:16, 4193.80 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1179000/2000000 [07:58<03:03, 4474.77 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1180000/2000000 [07:59<03:22, 4051.95 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1181000/2000000 [07:59<03:09, 4322.80 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1182000/2000000 [07:59<03:35, 3799.08 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1183000/2000000 [08:00<04:19, 3149.06 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1184000/2000000 [08:00<04:41, 2900.45 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1185000/2000000 [08:01<05:59, 2265.99 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1186000/2000000 [08:02<08:10, 1659.01 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1187000/2000000 [08:02<06:45, 2006.35 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1188000/2000000 [08:02<06:16, 2154.25 examples/s]Running tokenizer on dataset (num_proc=16):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1189000/2000000 [08:03<07:09, 1888.20 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1191000/2000000 [08:03<04:33, 2956.54 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1193000/2000000 [08:04<03:56, 3413.16 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1195000/2000000 [08:04<03:02, 4410.37 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1196000/2000000 [08:05<03:47, 3532.51 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1197000/2000000 [08:05<04:00, 3332.08 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1198000/2000000 [08:05<03:30, 3816.67 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1199000/2000000 [08:05<03:55, 3405.21 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1200000/2000000 [08:07<07:04, 1885.87 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1201000/2000000 [08:07<06:08, 2167.92 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1202000/2000000 [08:07<06:32, 2032.25 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1203000/2000000 [08:08<05:11, 2555.57 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1205000/2000000 [08:09<05:51, 2259.85 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1207000/2000000 [08:09<04:55, 2681.94 examples/s]Running tokenizer on dataset (num_proc=16):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1209000/2000000 [08:09<03:49, 3452.03 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1211000/2000000 [08:10<04:00, 3275.66 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1212000/2000000 [08:10<03:41, 3559.45 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1213000/2000000 [08:10<03:38, 3598.86 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1214000/2000000 [08:11<03:08, 4179.13 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1215000/2000000 [08:12<05:20, 2451.08 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1216000/2000000 [08:12<06:47, 1923.91 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1217000/2000000 [08:12<05:25, 2408.11 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1218000/2000000 [08:13<06:46, 1924.23 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1220000/2000000 [08:14<04:31, 2872.08 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1221000/2000000 [08:14<04:09, 3124.13 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1222000/2000000 [08:14<04:36, 2818.74 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1223000/2000000 [08:14<03:45, 3445.93 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1224000/2000000 [08:15<03:55, 3288.33 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1225000/2000000 [08:15<03:44, 3458.02 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1226000/2000000 [08:15<04:11, 3073.72 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1228000/2000000 [08:16<03:51, 3331.24 examples/s]Running tokenizer on dataset (num_proc=16):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1229000/2000000 [08:16<04:28, 2866.42 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1230000/2000000 [08:17<04:30, 2841.44 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1231000/2000000 [08:17<05:16, 2433.39 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1232000/2000000 [08:18<06:13, 2057.22 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1233000/2000000 [08:18<05:37, 2273.47 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1234000/2000000 [08:18<04:34, 2789.52 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1235000/2000000 [08:19<03:49, 3337.04 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1236000/2000000 [08:19<04:39, 2737.46 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1237000/2000000 [08:19<04:26, 2860.92 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1238000/2000000 [08:20<04:49, 2629.30 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1239000/2000000 [08:20<04:03, 3130.65 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1240000/2000000 [08:21<04:21, 2905.79 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1241000/2000000 [08:21<03:36, 3502.41 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1242000/2000000 [08:21<03:05, 4081.48 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1243000/2000000 [08:21<04:39, 2706.69 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1244000/2000000 [08:22<04:31, 2785.96 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1245000/2000000 [08:23<06:03, 2074.72 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1246000/2000000 [08:23<06:48, 1846.66 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1248000/2000000 [08:24<04:25, 2834.06 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1250000/2000000 [08:24<03:16, 3814.46 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1251000/2000000 [08:25<04:37, 2700.08 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1253000/2000000 [08:25<03:04, 4042.51 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1254000/2000000 [08:25<03:40, 3382.08 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1255000/2000000 [08:26<04:08, 2997.81 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1257000/2000000 [08:26<03:37, 3412.60 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1258000/2000000 [08:27<04:19, 2859.59 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1259000/2000000 [08:27<04:32, 2718.89 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1260000/2000000 [08:28<05:11, 2376.06 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1261000/2000000 [08:28<06:38, 1854.17 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1262000/2000000 [08:29<05:46, 2129.32 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1263000/2000000 [08:29<04:31, 2715.58 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1264000/2000000 [08:29<04:44, 2590.94 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1265000/2000000 [08:29<03:51, 3175.08 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1266000/2000000 [08:30<03:15, 3759.35 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1267000/2000000 [08:30<05:13, 2340.23 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1268000/2000000 [08:31<05:27, 2234.26 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1270000/2000000 [08:31<03:21, 3615.01 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1271000/2000000 [08:31<03:26, 3528.57 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1274000/2000000 [08:32<03:04, 3943.32 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1275000/2000000 [08:33<05:39, 2134.89 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1277000/2000000 [08:34<04:18, 2792.99 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1279000/2000000 [08:34<03:41, 3256.09 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1280000/2000000 [08:34<03:41, 3255.95 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1281000/2000000 [08:35<03:13, 3707.57 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1282000/2000000 [08:35<04:19, 2764.81 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1283000/2000000 [08:36<05:33, 2148.06 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1284000/2000000 [08:36<04:43, 2521.30 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1286000/2000000 [08:37<04:05, 2911.01 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1288000/2000000 [08:37<03:20, 3547.27 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1289000/2000000 [08:38<03:52, 3053.52 examples/s]Running tokenizer on dataset (num_proc=16):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1290000/2000000 [08:38<05:12, 2270.27 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1291000/2000000 [08:39<04:58, 2378.84 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1293000/2000000 [08:39<03:52, 3035.92 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1294000/2000000 [08:40<04:17, 2746.45 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1296000/2000000 [08:40<04:29, 2610.82 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1298000/2000000 [08:41<03:38, 3218.07 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1299000/2000000 [08:41<03:08, 3709.84 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1300000/2000000 [08:42<04:09, 2804.36 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1301000/2000000 [08:42<05:35, 2086.09 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1303000/2000000 [08:43<03:31, 3298.66 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1305000/2000000 [08:43<03:49, 3028.00 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1306000/2000000 [08:44<04:19, 2677.59 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1308000/2000000 [08:44<03:24, 3380.21 examples/s]Running tokenizer on dataset (num_proc=16):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1309000/2000000 [08:45<04:36, 2498.89 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1310000/2000000 [08:45<03:50, 2992.63 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1311000/2000000 [08:46<05:53, 1950.92 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1312000/2000000 [08:46<04:44, 2420.18 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1314000/2000000 [08:47<03:41, 3099.10 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1315000/2000000 [08:47<03:35, 3175.31 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1316000/2000000 [08:47<03:56, 2893.62 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1317000/2000000 [08:48<03:51, 2945.90 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1318000/2000000 [08:48<03:17, 3445.73 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1319000/2000000 [08:48<02:46, 4101.03 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1321000/2000000 [08:49<04:22, 2590.73 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1322000/2000000 [08:49<03:38, 3109.85 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1323000/2000000 [08:50<05:27, 2066.05 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1325000/2000000 [08:50<03:45, 2995.05 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1327000/2000000 [08:51<03:37, 3090.46 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1328000/2000000 [08:51<03:35, 3118.16 examples/s]Running tokenizer on dataset (num_proc=16):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1329000/2000000 [08:52<05:19, 2097.21 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1331000/2000000 [08:52<03:29, 3187.93 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1332000/2000000 [08:53<04:26, 2503.93 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1334000/2000000 [08:53<03:01, 3669.38 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1335000/2000000 [08:54<03:41, 3002.77 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1336000/2000000 [08:54<03:39, 3031.03 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1337000/2000000 [08:55<04:11, 2638.49 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1338000/2000000 [08:55<03:53, 2838.88 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1339000/2000000 [08:55<03:20, 3292.17 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1340000/2000000 [08:55<03:03, 3591.51 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1341000/2000000 [08:56<05:31, 1985.57 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1342000/2000000 [08:57<04:31, 2425.29 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1343000/2000000 [08:57<03:44, 2929.84 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1344000/2000000 [08:57<03:46, 2901.44 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1345000/2000000 [08:58<05:56, 1836.91 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1347000/2000000 [08:58<03:36, 3018.09 examples/s]Running tokenizer on dataset (num_proc=16):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1349000/2000000 [08:59<03:16, 3307.64 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1351000/2000000 [08:59<03:09, 3427.17 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1352000/2000000 [09:00<03:49, 2828.99 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1353000/2000000 [09:00<03:51, 2791.62 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1354000/2000000 [09:01<03:42, 2907.84 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1355000/2000000 [09:01<04:13, 2539.71 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1356000/2000000 [09:01<03:28, 3081.64 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1358000/2000000 [09:02<03:05, 3465.48 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1359000/2000000 [09:02<04:03, 2632.42 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1360000/2000000 [09:03<04:37, 2308.57 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1362000/2000000 [09:03<03:28, 3064.51 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1364000/2000000 [09:04<03:10, 3342.96 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1366000/2000000 [09:05<03:54, 2708.16 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1367000/2000000 [09:05<03:35, 2937.58 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1368000/2000000 [09:05<03:09, 3330.99 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1369000/2000000 [09:06<03:54, 2690.40 examples/s]Running tokenizer on dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1370000/2000000 [09:06<03:22, 3104.28 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1371000/2000000 [09:07<04:21, 2406.15 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1372000/2000000 [09:07<04:02, 2585.84 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1373000/2000000 [09:07<03:27, 3028.81 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1374000/2000000 [09:08<04:07, 2527.35 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1375000/2000000 [09:09<05:26, 1912.91 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1377000/2000000 [09:09<03:20, 3106.71 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1378000/2000000 [09:09<03:10, 3267.20 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1379000/2000000 [09:09<03:11, 3242.85 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1380000/2000000 [09:10<03:01, 3422.82 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1381000/2000000 [09:10<02:56, 3515.39 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1382000/2000000 [09:10<02:25, 4251.91 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1383000/2000000 [09:11<03:47, 2708.78 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1384000/2000000 [09:11<03:25, 2990.66 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1385000/2000000 [09:11<03:44, 2733.84 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1386000/2000000 [09:12<03:58, 2574.91 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1387000/2000000 [09:12<03:22, 3020.43 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1388000/2000000 [09:12<03:19, 3071.74 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1389000/2000000 [09:13<04:02, 2521.69 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1390000/2000000 [09:14<04:51, 2094.63 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1391000/2000000 [09:14<04:44, 2138.81 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1392000/2000000 [09:14<03:41, 2744.30 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1393000/2000000 [09:15<04:49, 2098.98 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1394000/2000000 [09:15<03:46, 2670.51 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1397000/2000000 [09:16<03:29, 2883.11 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1398000/2000000 [09:16<03:15, 3073.31 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1401000/2000000 [09:17<02:07, 4681.30 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1402000/2000000 [09:17<02:52, 3461.16 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1403000/2000000 [09:18<03:07, 3185.34 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1404000/2000000 [09:19<04:32, 2188.83 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1405000/2000000 [09:19<04:22, 2269.34 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1406000/2000000 [09:19<03:47, 2609.59 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1407000/2000000 [09:20<04:07, 2394.96 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1408000/2000000 [09:20<04:31, 2183.66 examples/s]Running tokenizer on dataset (num_proc=16):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1410000/2000000 [09:20<02:44, 3584.30 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1412000/2000000 [09:21<02:43, 3591.06 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1413000/2000000 [09:21<02:26, 4015.07 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1414000/2000000 [09:21<02:37, 3714.44 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1415000/2000000 [09:22<02:58, 3285.33 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1416000/2000000 [09:22<02:59, 3249.60 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1418000/2000000 [09:23<03:33, 2722.20 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1419000/2000000 [09:23<03:37, 2670.41 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1420000/2000000 [09:24<04:05, 2358.14 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1421000/2000000 [09:25<05:58, 1616.50 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1422000/2000000 [09:25<04:42, 2048.52 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1423000/2000000 [09:25<03:57, 2433.77 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1425000/2000000 [09:26<02:25, 3940.71 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1426000/2000000 [09:26<02:08, 4481.90 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1427000/2000000 [09:26<03:23, 2822.00 examples/s]Running tokenizer on dataset (num_proc=16):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1429000/2000000 [09:27<02:08, 4428.89 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1431000/2000000 [09:27<02:58, 3184.24 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1432000/2000000 [09:28<02:57, 3201.90 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1433000/2000000 [09:28<03:33, 2661.08 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1434000/2000000 [09:29<04:55, 1917.29 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1435000/2000000 [09:30<04:18, 2185.91 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1436000/2000000 [09:30<03:34, 2631.91 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1437000/2000000 [09:30<04:34, 2052.74 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1439000/2000000 [09:31<03:15, 2870.87 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1441000/2000000 [09:31<02:54, 3199.30 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1442000/2000000 [09:32<02:43, 3410.19 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1443000/2000000 [09:32<02:36, 3565.02 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1444000/2000000 [09:32<02:20, 3947.04 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1445000/2000000 [09:32<02:45, 3359.58 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1446000/2000000 [09:33<02:26, 3776.80 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1447000/2000000 [09:33<03:03, 3008.73 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1448000/2000000 [09:34<04:17, 2142.13 examples/s]Running tokenizer on dataset (num_proc=16):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1449000/2000000 [09:35<04:43, 1946.53 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1451000/2000000 [09:36<05:24, 1692.47 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1452000/2000000 [09:36<04:30, 2029.30 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1454000/2000000 [09:36<02:55, 3113.05 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1456000/2000000 [09:37<02:36, 3474.23 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1458000/2000000 [09:37<02:01, 4468.27 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1459000/2000000 [09:37<02:14, 4008.21 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1460000/2000000 [09:37<02:02, 4420.15 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1461000/2000000 [09:39<04:16, 2098.95 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1462000/2000000 [09:39<03:33, 2516.53 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1463000/2000000 [09:39<02:51, 3129.95 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1464000/2000000 [09:39<02:21, 3796.37 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1465000/2000000 [09:40<03:46, 2360.11 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1466000/2000000 [09:41<06:17, 1413.76 examples/s]Running tokenizer on dataset (num_proc=16):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1469000/2000000 [09:42<03:11, 2766.65 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1470000/2000000 [09:42<03:24, 2585.52 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1472000/2000000 [09:42<02:42, 3255.87 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1474000/2000000 [09:43<02:12, 3966.46 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1475000/2000000 [09:43<02:33, 3430.95 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1476000/2000000 [09:43<02:20, 3736.78 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1477000/2000000 [09:44<03:42, 2352.30 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1478000/2000000 [09:45<03:37, 2402.71 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1480000/2000000 [09:45<02:37, 3307.88 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1481000/2000000 [09:45<02:59, 2894.76 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1482000/2000000 [09:46<04:24, 1959.64 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1483000/2000000 [09:47<04:38, 1853.90 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1486000/2000000 [09:48<03:05, 2776.07 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1487000/2000000 [09:48<02:56, 2904.54 examples/s]Running tokenizer on dataset (num_proc=16):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1490000/2000000 [09:48<02:19, 3644.31 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1491000/2000000 [09:49<03:14, 2618.95 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1492000/2000000 [09:50<02:54, 2918.23 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1493000/2000000 [09:50<02:40, 3157.36 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1495000/2000000 [09:50<02:10, 3862.62 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1497000/2000000 [09:52<03:34, 2346.18 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1499000/2000000 [09:52<03:07, 2672.72 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1500000/2000000 [09:52<03:01, 2755.07 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1502000/2000000 [09:53<02:06, 3937.12 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1503000/2000000 [09:53<02:43, 3035.74 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1504000/2000000 [09:54<02:44, 3015.26 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1505000/2000000 [09:54<02:34, 3209.98 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1506000/2000000 [09:54<03:11, 2573.23 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1507000/2000000 [09:55<03:30, 2345.67 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1508000/2000000 [09:55<03:46, 2169.05 examples/s]Running tokenizer on dataset (num_proc=16):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1509000/2000000 [09:56<02:57, 2770.49 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1511000/2000000 [09:56<02:16, 3575.69 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1512000/2000000 [09:57<03:03, 2652.81 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1513000/2000000 [09:57<02:59, 2716.27 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1514000/2000000 [09:57<02:32, 3187.54 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1515000/2000000 [09:57<02:07, 3800.58 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1517000/2000000 [09:58<01:50, 4360.02 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1518000/2000000 [09:58<01:59, 4017.33 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1519000/2000000 [09:59<03:36, 2219.93 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1521000/2000000 [09:59<02:42, 2948.15 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1522000/2000000 [10:00<03:48, 2096.47 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1523000/2000000 [10:01<03:19, 2396.17 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1524000/2000000 [10:01<02:59, 2654.10 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1525000/2000000 [10:01<02:47, 2841.60 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1526000/2000000 [10:01<02:40, 2961.35 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1527000/2000000 [10:02<02:53, 2718.65 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1528000/2000000 [10:02<02:59, 2629.02 examples/s]Running tokenizer on dataset (num_proc=16):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1530000/2000000 [10:02<01:54, 4089.03 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1531000/2000000 [10:03<01:51, 4198.39 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1532000/2000000 [10:03<02:49, 2762.47 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1533000/2000000 [10:04<02:37, 2956.18 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1534000/2000000 [10:04<03:07, 2491.82 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1535000/2000000 [10:04<02:48, 2759.72 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1536000/2000000 [10:05<02:46, 2791.20 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1537000/2000000 [10:05<03:07, 2467.10 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1538000/2000000 [10:06<03:39, 2108.72 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1539000/2000000 [10:06<03:03, 2509.85 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1541000/2000000 [10:06<02:10, 3509.23 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1542000/2000000 [10:07<02:43, 2796.22 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1544000/2000000 [10:07<02:04, 3652.79 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1545000/2000000 [10:08<02:10, 3478.32 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1546000/2000000 [10:08<02:09, 3507.12 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1547000/2000000 [10:08<02:42, 2791.02 examples/s]Running tokenizer on dataset (num_proc=16):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1549000/2000000 [10:10<04:01, 1866.66 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1550000/2000000 [10:10<03:23, 2214.33 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1552000/2000000 [10:10<02:10, 3433.46 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1553000/2000000 [10:10<01:58, 3785.26 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1554000/2000000 [10:11<02:18, 3217.39 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1555000/2000000 [10:11<02:39, 2798.40 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1557000/2000000 [10:12<02:16, 3249.64 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1558000/2000000 [10:12<02:26, 3014.18 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1559000/2000000 [10:13<02:09, 3406.87 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1560000/2000000 [10:13<02:55, 2506.73 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1562000/2000000 [10:13<02:03, 3536.41 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1563000/2000000 [10:15<03:41, 1969.66 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1564000/2000000 [10:15<03:39, 1982.56 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1566000/2000000 [10:16<03:53, 1854.77 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1567000/2000000 [10:16<03:09, 2281.15 examples/s]Running tokenizer on dataset (num_proc=16):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1570000/2000000 [10:17<01:42, 4177.89 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1572000/2000000 [10:17<01:17, 5539.00 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1574000/2000000 [10:18<01:54, 3709.11 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1576000/2000000 [10:18<01:56, 3644.26 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1577000/2000000 [10:19<02:01, 3485.86 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1578000/2000000 [10:19<02:56, 2387.15 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1579000/2000000 [10:20<02:51, 2459.94 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1580000/2000000 [10:20<03:09, 2220.38 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1581000/2000000 [10:21<04:15, 1641.06 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1582000/2000000 [10:22<03:23, 2050.77 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1583000/2000000 [10:22<02:52, 2419.35 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1587000/2000000 [10:22<01:25, 4829.71 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1588000/2000000 [10:22<01:27, 4708.76 examples/s]Running tokenizer on dataset (num_proc=16):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1589000/2000000 [10:23<01:32, 4454.79 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1591000/2000000 [10:23<01:23, 4900.27 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1592000/2000000 [10:23<01:23, 4873.31 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1593000/2000000 [10:24<01:53, 3579.80 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1594000/2000000 [10:25<03:28, 1944.72 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1595000/2000000 [10:25<03:11, 2112.23 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1596000/2000000 [10:26<04:00, 1678.03 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1597000/2000000 [10:26<03:07, 2144.12 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1599000/2000000 [10:27<01:59, 3350.35 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1600000/2000000 [10:27<02:13, 2999.72 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1602000/2000000 [10:27<01:46, 3732.07 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1603000/2000000 [10:28<02:24, 2755.41 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1604000/2000000 [10:29<02:39, 2476.71 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1605000/2000000 [10:29<02:15, 2917.89 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1608000/2000000 [10:29<01:32, 4233.22 examples/s]Running tokenizer on dataset (num_proc=16):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1610000/2000000 [10:30<02:06, 3092.18 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1611000/2000000 [10:30<01:53, 3437.96 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1612000/2000000 [10:31<03:00, 2147.10 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1613000/2000000 [10:32<02:34, 2503.51 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1614000/2000000 [10:32<02:24, 2662.19 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1615000/2000000 [10:32<02:11, 2927.14 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1616000/2000000 [10:33<02:24, 2654.09 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1618000/2000000 [10:33<02:01, 3154.66 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1619000/2000000 [10:33<01:46, 3561.14 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1620000/2000000 [10:34<02:20, 2702.74 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1621000/2000000 [10:34<02:22, 2662.17 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1623000/2000000 [10:35<01:39, 3784.47 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1624000/2000000 [10:35<02:28, 2527.27 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1626000/2000000 [10:36<01:39, 3773.98 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1627000/2000000 [10:36<01:53, 3285.99 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1628000/2000000 [10:37<02:28, 2509.81 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1629000/2000000 [10:37<02:41, 2299.79 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1630000/2000000 [10:37<02:23, 2572.57 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1631000/2000000 [10:38<01:55, 3191.73 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1632000/2000000 [10:38<01:58, 3118.04 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1633000/2000000 [10:38<01:41, 3598.73 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1634000/2000000 [10:38<01:51, 3282.90 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1635000/2000000 [10:39<02:50, 2142.64 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1636000/2000000 [10:40<02:26, 2481.44 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1637000/2000000 [10:40<02:01, 2987.74 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1639000/2000000 [10:41<02:23, 2520.29 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1641000/2000000 [10:41<01:46, 3385.46 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1642000/2000000 [10:41<01:50, 3236.45 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1643000/2000000 [10:42<02:03, 2883.97 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1644000/2000000 [10:42<01:54, 3111.59 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1645000/2000000 [10:42<02:01, 2926.49 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1646000/2000000 [10:43<01:45, 3345.94 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1647000/2000000 [10:43<01:36, 3639.36 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1648000/2000000 [10:43<01:40, 3508.05 examples/s]Running tokenizer on dataset (num_proc=16):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1650000/2000000 [10:44<01:31, 3824.38 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1651000/2000000 [10:44<02:25, 2403.53 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1652000/2000000 [10:45<02:26, 2376.03 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1653000/2000000 [10:46<02:53, 1995.71 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1655000/2000000 [10:46<01:51, 3086.57 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1656000/2000000 [10:47<02:32, 2256.13 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1657000/2000000 [10:47<02:56, 1945.47 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1659000/2000000 [10:48<01:56, 2916.31 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1661000/2000000 [10:48<01:51, 3052.16 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1663000/2000000 [10:49<01:38, 3420.75 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1664000/2000000 [10:49<01:44, 3208.80 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1665000/2000000 [10:49<01:28, 3775.50 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1666000/2000000 [10:49<01:16, 4383.45 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1667000/2000000 [10:50<01:20, 4158.84 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1668000/2000000 [10:50<02:10, 2540.06 examples/s]Running tokenizer on dataset (num_proc=16):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1669000/2000000 [10:51<02:39, 2076.84 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1670000/2000000 [10:51<02:18, 2374.75 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1671000/2000000 [10:52<02:11, 2494.41 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1672000/2000000 [10:52<02:46, 1966.21 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1673000/2000000 [10:53<02:08, 2544.95 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1674000/2000000 [10:53<01:51, 2924.52 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1675000/2000000 [10:53<01:33, 3461.45 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1676000/2000000 [10:53<01:56, 2784.49 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1677000/2000000 [10:54<01:42, 3143.70 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1679000/2000000 [10:54<01:37, 3280.32 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1680000/2000000 [10:55<02:07, 2503.66 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1683000/2000000 [10:56<01:50, 2880.90 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1685000/2000000 [10:56<01:38, 3199.52 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1686000/2000000 [10:57<01:31, 3417.26 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1687000/2000000 [10:57<01:55, 2717.87 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1688000/2000000 [10:58<02:12, 2347.90 examples/s]Running tokenizer on dataset (num_proc=16):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1689000/2000000 [10:58<02:19, 2236.23 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1691000/2000000 [10:59<01:50, 2795.84 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1692000/2000000 [10:59<02:03, 2503.75 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1693000/2000000 [11:00<02:18, 2216.10 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1694000/2000000 [11:00<01:52, 2731.85 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1697000/2000000 [11:00<01:03, 4756.42 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1698000/2000000 [11:01<01:59, 2534.20 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1700000/2000000 [11:02<01:34, 3177.32 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1702000/2000000 [11:02<01:11, 4167.72 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1703000/2000000 [11:02<01:27, 3398.76 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1704000/2000000 [11:03<02:05, 2351.74 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1705000/2000000 [11:03<01:47, 2755.35 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1707000/2000000 [11:05<02:12, 2212.23 examples/s]Running tokenizer on dataset (num_proc=16):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1708000/2000000 [11:05<01:53, 2572.65 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1710000/2000000 [11:06<01:50, 2622.15 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1711000/2000000 [11:06<01:46, 2717.15 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1712000/2000000 [11:06<01:34, 3062.05 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1713000/2000000 [11:06<01:35, 3019.33 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1714000/2000000 [11:07<01:49, 2615.01 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1715000/2000000 [11:07<01:53, 2513.08 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1717000/2000000 [11:08<01:37, 2892.62 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1718000/2000000 [11:08<01:22, 3432.71 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1720000/2000000 [11:09<01:14, 3760.40 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1721000/2000000 [11:09<01:06, 4205.66 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1722000/2000000 [11:10<01:49, 2548.16 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1723000/2000000 [11:10<02:02, 2254.48 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1724000/2000000 [11:11<02:41, 1704.46 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1727000/2000000 [11:11<01:32, 2962.57 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1728000/2000000 [11:12<01:31, 2971.84 examples/s]Running tokenizer on dataset (num_proc=16):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1730000/2000000 [11:12<01:23, 3231.33 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1731000/2000000 [11:13<01:33, 2866.98 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1732000/2000000 [11:13<01:20, 3311.47 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1733000/2000000 [11:13<01:14, 3601.97 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1734000/2000000 [11:13<01:03, 4206.04 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1735000/2000000 [11:14<01:07, 3904.42 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1736000/2000000 [11:14<01:01, 4274.96 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1737000/2000000 [11:15<01:48, 2415.68 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1739000/2000000 [11:15<01:36, 2694.99 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1740000/2000000 [11:17<02:50, 1520.54 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1741000/2000000 [11:17<02:16, 1904.09 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1742000/2000000 [11:17<02:09, 1996.50 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1743000/2000000 [11:18<01:55, 2217.03 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1744000/2000000 [11:18<01:30, 2839.37 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1745000/2000000 [11:18<01:11, 3544.22 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1748000/2000000 [11:19<00:58, 4278.48 examples/s]Running tokenizer on dataset (num_proc=16):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1749000/2000000 [11:19<00:53, 4732.71 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1750000/2000000 [11:19<01:14, 3341.79 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1753000/2000000 [11:20<01:09, 3542.58 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1754000/2000000 [11:20<01:09, 3530.75 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1755000/2000000 [11:21<01:43, 2358.49 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1756000/2000000 [11:22<02:20, 1739.07 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1757000/2000000 [11:23<02:08, 1894.19 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1758000/2000000 [11:23<01:45, 2298.04 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1760000/2000000 [11:23<01:09, 3475.26 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1761000/2000000 [11:23<01:00, 3923.51 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1762000/2000000 [11:24<01:12, 3290.60 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1764000/2000000 [11:24<01:12, 3238.49 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1766000/2000000 [11:25<00:59, 3954.94 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1767000/2000000 [11:25<01:19, 2934.40 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1768000/2000000 [11:26<01:18, 2946.85 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1769000/2000000 [11:26<01:39, 2329.42 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1770000/2000000 [11:27<02:07, 1807.20 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1771000/2000000 [11:28<01:59, 1909.63 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1772000/2000000 [11:28<01:34, 2405.95 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1774000/2000000 [11:28<01:09, 3242.08 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1776000/2000000 [11:29<01:05, 3402.24 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1777000/2000000 [11:29<01:00, 3689.11 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1778000/2000000 [11:29<01:13, 3039.90 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1779000/2000000 [11:30<01:19, 2772.97 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1780000/2000000 [11:30<01:24, 2604.25 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1781000/2000000 [11:31<01:21, 2691.76 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1782000/2000000 [11:31<01:21, 2661.89 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1783000/2000000 [11:33<02:29, 1447.83 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1784000/2000000 [11:33<01:55, 1862.28 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1786000/2000000 [11:33<01:41, 2101.62 examples/s]Running tokenizer on dataset (num_proc=16):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1789000/2000000 [11:34<00:56, 3713.78 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1790000/2000000 [11:34<00:59, 3511.95 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1791000/2000000 [11:35<01:46, 1955.97 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1792000/2000000 [11:36<02:00, 1726.85 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1794000/2000000 [11:36<01:16, 2688.25 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1795000/2000000 [11:37<01:46, 1917.91 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1796000/2000000 [11:38<01:40, 2031.59 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1797000/2000000 [11:38<01:44, 1940.50 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1798000/2000000 [11:38<01:25, 2349.29 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1799000/2000000 [11:39<01:19, 2517.80 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1800000/2000000 [11:39<01:17, 2593.36 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1801000/2000000 [11:39<01:06, 2993.16 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1802000/2000000 [11:40<01:12, 2723.85 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1803000/2000000 [11:40<01:03, 3106.12 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1804000/2000000 [11:41<01:52, 1748.97 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1805000/2000000 [11:42<02:06, 1547.27 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1807000/2000000 [11:42<01:12, 2669.21 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1808000/2000000 [11:42<01:09, 2773.67 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1809000/2000000 [11:43<01:09, 2741.15 examples/s]Running tokenizer on dataset (num_proc=16):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1810000/2000000 [11:44<01:27, 2160.59 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1811000/2000000 [11:44<01:37, 1937.06 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1813000/2000000 [11:45<01:12, 2566.28 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1814000/2000000 [11:45<01:10, 2624.37 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1815000/2000000 [11:46<01:38, 1887.13 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1817000/2000000 [11:47<01:52, 1631.55 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1818000/2000000 [11:48<01:35, 1902.48 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1820000/2000000 [11:48<01:10, 2570.07 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1821000/2000000 [11:48<01:02, 2871.07 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1822000/2000000 [11:49<01:17, 2297.47 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1823000/2000000 [11:49<01:14, 2369.70 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1824000/2000000 [11:50<01:03, 2782.61 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1826000/2000000 [11:51<01:22, 2106.37 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1828000/2000000 [11:52<01:40, 1705.98 examples/s]Running tokenizer on dataset (num_proc=16):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1829000/2000000 [11:53<01:32, 1850.84 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1831000/2000000 [11:53<01:22, 2047.84 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1832000/2000000 [11:54<01:11, 2347.46 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1833000/2000000 [11:54<01:18, 2124.81 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1835000/2000000 [11:55<00:56, 2944.24 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1836000/2000000 [11:55<00:51, 3167.97 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1837000/2000000 [11:55<01:02, 2620.74 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1838000/2000000 [11:56<01:28, 1835.68 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1840000/2000000 [11:57<01:20, 1987.80 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1841000/2000000 [11:58<01:24, 1873.67 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1842000/2000000 [11:58<01:18, 2007.49 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1843000/2000000 [11:59<01:05, 2413.58 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1844000/2000000 [11:59<00:51, 3009.13 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1845000/2000000 [11:59<01:05, 2381.61 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1846000/2000000 [12:00<00:55, 2761.20 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1847000/2000000 [12:00<01:20, 1906.15 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1849000/2000000 [12:01<00:48, 3128.84 examples/s]Running tokenizer on dataset (num_proc=16):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1850000/2000000 [12:01<00:59, 2526.80 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1851000/2000000 [12:02<01:28, 1679.49 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1852000/2000000 [12:03<01:20, 1832.52 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1853000/2000000 [12:03<01:19, 1844.42 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1854000/2000000 [12:04<01:09, 2088.32 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1856000/2000000 [12:04<00:42, 3389.78 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1857000/2000000 [12:05<01:28, 1622.62 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1858000/2000000 [12:06<01:25, 1658.34 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1859000/2000000 [12:06<01:07, 2100.98 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1860000/2000000 [12:07<01:15, 1848.08 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1861000/2000000 [12:07<01:11, 1948.68 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1862000/2000000 [12:08<01:28, 1565.07 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1863000/2000000 [12:08<01:12, 1889.56 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1865000/2000000 [12:09<00:46, 2892.51 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1866000/2000000 [12:09<00:47, 2826.28 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1867000/2000000 [12:10<01:06, 1991.20 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1868000/2000000 [12:10<01:04, 2047.92 examples/s]Running tokenizer on dataset (num_proc=16):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1869000/2000000 [12:12<01:26, 1515.51 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1870000/2000000 [12:13<01:47, 1214.71 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1872000/2000000 [12:14<01:24, 1520.10 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1874000/2000000 [12:14<00:58, 2167.40 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1875000/2000000 [12:14<00:50, 2483.53 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1876000/2000000 [12:15<00:58, 2102.33 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1877000/2000000 [12:15<00:48, 2514.56 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1878000/2000000 [12:16<00:52, 2345.66 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1879000/2000000 [12:18<01:46, 1140.98 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1880000/2000000 [12:18<01:20, 1497.69 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1881000/2000000 [12:19<01:36, 1239.23 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1882000/2000000 [12:19<01:12, 1622.77 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1883000/2000000 [12:19<01:03, 1842.61 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1884000/2000000 [12:20<01:19, 1458.84 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1885000/2000000 [12:21<01:01, 1867.87 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1886000/2000000 [12:21<01:07, 1688.55 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1887000/2000000 [12:22<01:07, 1669.08 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1888000/2000000 [12:23<01:04, 1741.05 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1889000/2000000 [12:23<01:06, 1668.71 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1890000/2000000 [12:24<01:28, 1248.56 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1891000/2000000 [12:25<01:22, 1319.20 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1892000/2000000 [12:26<01:40, 1079.68 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1893000/2000000 [12:27<01:19, 1337.90 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1894000/2000000 [12:27<01:09, 1518.48 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1895000/2000000 [12:29<01:38, 1069.64 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1896000/2000000 [12:30<01:36, 1072.38 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1897000/2000000 [12:30<01:18, 1309.30 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1898000/2000000 [12:32<01:54, 888.61 examples/s] Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1899000/2000000 [12:32<01:24, 1199.77 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1900000/2000000 [12:35<02:12, 752.84 examples/s] Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1901000/2000000 [12:36<02:24, 685.54 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1902000/2000000 [12:37<01:56, 840.80 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1903000/2000000 [12:38<01:42, 944.87 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1904000/2000000 [12:41<02:45, 579.19 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1905000/2000000 [12:42<02:28, 640.26 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1906000/2000000 [12:43<02:02, 768.45 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1907000/2000000 [12:43<01:34, 984.64 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1908000/2000000 [12:47<03:01, 507.84 examples/s]Running tokenizer on dataset (num_proc=16):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1909000/2000000 [12:48<02:27, 617.86 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1910000/2000000 [12:48<01:45, 850.07 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1911000/2000000 [12:49<01:20, 1107.98 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1912000/2000000 [12:53<03:00, 488.62 examples/s] Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1913000/2000000 [12:54<02:15, 640.87 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1914000/2000000 [12:54<01:41, 846.35 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1915000/2000000 [12:55<01:22, 1032.85 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1916000/2000000 [12:59<02:56, 475.43 examples/s] Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1917000/2000000 [12:59<02:05, 660.00 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1918000/2000000 [13:00<01:30, 909.19 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1919000/2000000 [13:01<01:26, 941.09 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1920000/2000000 [13:05<02:38, 504.19 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1921000/2000000 [13:05<01:54, 690.53 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1922000/2000000 [13:05<01:25, 912.71 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1923000/2000000 [13:07<01:39, 777.14 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1924000/2000000 [13:10<02:18, 548.15 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1925000/2000000 [13:10<01:44, 718.35 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1926000/2000000 [13:11<01:16, 962.46 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1927000/2000000 [13:12<01:33, 782.17 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1928000/2000000 [13:15<02:09, 556.79 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1929000/2000000 [13:16<01:47, 658.32 examples/s]Running tokenizer on dataset (num_proc=16):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1930000/2000000 [13:17<01:25, 818.24 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1931000/2000000 [13:18<01:21, 847.14 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1932000/2000000 [13:21<01:55, 586.60 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1933000/2000000 [13:22<01:40, 666.01 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1934000/2000000 [13:22<01:11, 925.02 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1935000/2000000 [13:23<01:17, 837.41 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1936000/2000000 [13:27<01:57, 542.43 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1937000/2000000 [13:27<01:34, 668.99 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1938000/2000000 [13:28<01:11, 862.67 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1939000/2000000 [13:30<01:20, 754.02 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1940000/2000000 [13:32<01:38, 607.43 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1941000/2000000 [13:33<01:27, 677.69 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1942000/2000000 [13:34<01:19, 731.53 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1943000/2000000 [13:36<01:24, 676.59 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1944000/2000000 [13:37<01:24, 664.18 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1945000/2000000 [13:38<01:13, 749.19 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1946000/2000000 [13:39<01:06, 816.08 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1947000/2000000 [13:41<01:16, 691.17 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1948000/2000000 [13:43<01:18, 663.65 examples/s]Running tokenizer on dataset (num_proc=16):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1949000/2000000 [13:44<01:09, 735.90 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1950000/2000000 [13:46<01:15, 658.85 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1951000/2000000 [13:48<01:18, 625.14 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1952000/2000000 [13:49<01:08, 705.79 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1953000/2000000 [13:50<01:07, 691.53 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1954000/2000000 [13:51<01:03, 722.65 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1955000/2000000 [13:53<01:07, 669.34 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1956000/2000000 [13:54<01:03, 692.58 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1957000/2000000 [13:56<01:01, 702.11 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1958000/2000000 [13:57<00:50, 836.14 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1959000/2000000 [13:59<01:03, 648.23 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1960000/2000000 [14:00<00:57, 701.10 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1961000/2000000 [14:01<00:50, 779.92 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1962000/2000000 [14:03<00:53, 705.31 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1963000/2000000 [14:05<00:58, 629.82 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1964000/2000000 [14:05<00:47, 757.62 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1965000/2000000 [14:06<00:42, 828.47 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1966000/2000000 [14:09<00:50, 668.12 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1967000/2000000 [14:10<00:54, 610.96 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1968000/2000000 [14:11<00:39, 804.00 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1969000/2000000 [14:12<00:37, 823.46 examples/s]Running tokenizer on dataset (num_proc=16):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1970000/2000000 [14:14<00:46, 644.37 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1971000/2000000 [14:16<00:49, 583.75 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1972000/2000000 [14:17<00:34, 806.50 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1973000/2000000 [14:17<00:31, 866.73 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1974000/2000000 [14:20<00:43, 595.38 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1975000/2000000 [14:22<00:41, 606.97 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1976000/2000000 [14:22<00:29, 805.67 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1977000/2000000 [14:23<00:24, 941.75 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1978000/2000000 [14:26<00:36, 594.86 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1979000/2000000 [14:27<00:28, 729.51 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1980000/2000000 [14:28<00:28, 702.13 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1981000/2000000 [14:28<00:20, 935.49 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1982000/2000000 [14:32<00:31, 575.73 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1983000/2000000 [14:33<00:24, 692.16 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1984000/2000000 [14:34<00:23, 690.75 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1985000/2000000 [14:34<00:15, 938.23 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1986000/2000000 [14:37<00:22, 628.96 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1987000/2000000 [14:38<00:18, 695.48 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1988000/2000000 [14:39<00:17, 700.57 examples/s]Running tokenizer on dataset (num_proc=16):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1989000/2000000 [14:40<00:12, 916.13 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1990000/2000000 [14:42<00:15, 636.57 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1991000/2000000 [14:44<00:15, 599.41 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1993000/2000000 [14:46<00:08, 829.21 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1994000/2000000 [14:49<00:10, 592.70 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1995000/2000000 [14:50<00:07, 651.12 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1996000/2000000 [14:50<00:04, 813.22 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1997000/2000000 [14:51<00:03, 835.34 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1998000/2000000 [14:54<00:03, 600.54 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1999000/2000000 [14:55<00:01, 707.03 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000000/2000000 [14:57<00:00, 594.83 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000000/2000000 [14:58<00:00, 2225.96 examples/s]
Concatenating 16 shards
input_ids:
[32622, 1387, 36115, 54377, 60, 8408, 51743, 732, 14780, 2024, 45258, 26349, 307, 481, 7206, 2336, 8334, 22002, 481, 3128, 261, 75, 50, 1455, 10830, 13002, 3818, 198, 32622, 1387, 36115, 54377, 60, 8408, 51743, 732, 14780, 2024, 45258, 26349, 307, 1365, 7206, 2336, 8334, 22002, 198, 23, 13, 74882, 1377, 220, 17, 15, 16, 22, 3128, 261, 75, 198, 2, 16, 21, 21, 1032, 89, 2645, 198, 54, 3591, 13, 2876, 63352, 1674, 13730, 1020, 11, 4368, 267, 4368, 27684, 68, 1268, 465, 16631, 11870, 11, 5999, 77040, 377, 17029, 11, 10712, 9911, 6538, 1818, 2305, 12495, 54649, 2014, 66685, 67100, 36408, 21519, 3342, 13, 54068, 66316, 15462, 16631, 13785, 34749, 88537, 294, 11063, 268, 13, 2876, 63352, 7180, 13920, 295, 11, 14948, 28095, 10928, 2746, 3680, 137609, 2694, 88537, 8099, 350, 1134, 37633, 58065, 41762, 42469, 11, 2030, 5451, 74021, 4368, 52287, 198, 89, 324, 19358, 11567, 57064, 288, 6250, 709, 12032, 13, 9236, 312, 4865, 49503, 1640, 37419, 220, 16, 24, 17, 22, 11, 10712, 34749, 386, 6207, 730, 2305, 1782, 304, 17443, 17837, 645, 12032, 268, 26349, 307, 1079, 37471, 348, 1087, 649, 610, 13, 12741, 18597, 77, 17058, 387, 68057, 2301, 268, 13225, 84467, 1365, 2030, 17058, 2739, 71, 25423, 25151, 85, 32289, 70219, 276, 65677, 20542, 5451, 24807, 38185, 377, 11, 2694, 16034, 296, 135573, 6433, 12042, 37137, 268, 2694, 547, 3632, 7219, 5342, 6433, 50926, 4593, 198, 87876, 33601, 3921, 826, 59378, 37347, 13785, 57093, 23470, 268, 11, 6538, 16809, 12010, 299, 7997, 76, 6207, 17312, 2925, 17659, 258, 11, 31100, 674, 268, 5451, 259, 4738, 268, 4229, 20572, 77, 36964, 11, 3161, 77, 408, 304, 98886, 11, 10712, 220, 16, 24, 17, 22, 6616, 78596, 730, 2305, 1782, 3371, 31228, 7219, 1323, 84642, 11, 9089, 52716, 17298, 372, 6395, 2714, 30166, 79788, 624, 17360, 5436, 649, 610, 9820, 9390, 77, 10938, 33601, 3921, 826, 59378, 37347, 6395, 12643, 13, 647, 1268, 47610, 11, 2746, 9089, 21982, 5016, 5788, 278, 11, 6616, 2694, 220, 17, 13, 44966, 74, 82491, 13785, 9911, 3893, 85426, 8896, 11, 8793, 6538, 71017, 58534, 17630, 668, 1323, 27918, 47008, 2030, 1077, 11687, 408, 6772, 9820, 5016, 11855, 2493, 7865, 9420, 1872, 559, 645, 87541, 34271, 33748, 11, 13368, 1531, 304, 140108, 13906, 1923, 31357, 3893, 42316, 8896, 13, 96943, 51528, 4368, 51663, 8099, 88937, 11, 6616, 52287, 28831, 18607, 39563, 3893, 2024, 645, 7964, 4116, 624, 22171, 89507, 939, 48717, 5999, 25494, 17837, 11595, 13, 1967, 1776, 5699, 2649, 83, 1531, 2823, 349, 7487, 1103, 19104, 8793, 11, 34749, 77930, 8151, 610, 6772, 773, 4443, 89, 18187, 89, 1960, 11, 6616, 883, 6538, 24440, 19767, 28129, 27684, 433, 3818, 5999, 13, 12741, 9740, 134128, 12, 2030, 5016, 38013, 267, 321, 5999, 25494, 40380, 1241, 13, 506, 723, 76, 1127, 289, 1241, 13820, 10638, 23273, 13785, 23523, 649, 7256, 2030, 1320, 1777, 13393, 68, 13, 758, 39416, 6772, 64208, 2391, 654, 1960, 9911, 4368, 66723, 288, 4229, 20572, 25151, 11, 40157, 2823, 349, 7487, 5380, 4864, 51767, 68, 68917, 5676, 8725, 35323, 458, 28883, 9820, 22539, 4865, 7256, 94200, 36614, 11, 28853, 10638, 6538, 3371, 19037, 77, 17312, 16868, 58791, 6433, 2925, 339, 2391, 654, 2185, 2714, 35608, 295, 95035, 13, 17564, 275, 289, 53152, 98175, 2636, 76, 408, 44390, 422, 8944, 89, 6395, 3371, 1298, 4578, 263, 380, 34711, 13, 25861, 64015, 8793, 5451, 74021, 50232, 2892, 11, 330, 82, 1466, 1, 74021, 6069, 343, 6772, 81804, 3848, 331, 2391, 5566, 301, 303, 6395, 624, 32617, 2823, 13536, 71, 28122, 11278, 258, 12, 1241, 11278, 261, 6538, 59310, 11, 2694, 66968, 304, 2694, 83141, 383, 2694, 330, 2101, 13730, 1020, 7276, 956, 10316, 497, 6616, 56381, 52639, 21062, 1174, 48655, 30373, 2030, 9820, 323, 27097, 42341, 794, 324, 22385, 28883, 60352, 4865, 11, 1147, 615, 665, 18520, 2030, 18520, 458, 81212, 451, 648, 268, 13, 8408, 357, 21545, 6433, 467, 22181, 8452, 11595, 6395, 2876, 63352, 11, 13368, 330, 35, 9924, 1, 2030, 330, 28551, 351, 665, 40698, 497, 13785, 2746, 10638, 95898, 2636, 3342, 357, 337, 79, 13820, 11, 357, 9416, 1960, 81212, 11615, 823, 75, 1854, 13, 25861, 14678, 301, 665, 23273, 6538, 31665, 56643, 6395, 31665, 56643, 2030, 3457, 1070, 23273, 25531, 7219, 4368, 31665, 56643, 17312, 51309, 59141, 22385, 11, 6616, 13785, 730, 2305, 1782, 11, 2746, 16809, 12010, 299, 7997, 76, 6207, 11, 10207, 4865, 7714, 13, 54068, 75074, 65, 415, 440, 304, 2746, 51309, 59141, 22385, 43303, 1531, 11, 2746, 2746, 11903, 46621, 7219, 47631, 305, 13029, 1960, 2030, 23273, 14840, 16034, 51292, 17630, 19767, 35505, 47008, 624, 75919, 2823, 408, 42603, 2694, 444, 17149, 2391, 265, 3371, 440, 10638, 11, 95035, 9089, 2746, 56872, 258, 24131, 331, 83090, 7219, 2746, 6990, 10559, 77930, 48376, 301, 27277, 11, 68573, 24440, 85227, 94213, 6772, 4368, 25494, 17859, 261, 12751, 17837, 11595, 13, 71161, 31008, 9740, 134128, 495, 524, 4116, 17859, 87717, 14604, 529, 11, 5451, 17058, 289, 1241, 648, 32289, 2030, 7180, 9089, 4368, 25402, 76, 19875, 1298, 4578, 263, 380, 258, 9421, 54727, 19985, 295, 2030, 17058, 21491, 9433, 45061, 37347, 11, 2746, 36077, 53957, 29695, 370, 83, 95035, 13, 2055, 68573, 10928, 2694, 23388, 69, 742, 5840, 5451, 2030, 6538, 34834, 674, 11, 2694, 61634, 4116, 11, 17790, 70336, 17312, 479, 3818, 2185, 48323, 46646, 2030, 1531, 289, 96049, 2746, 5748, 5956, 268, 2030, 9740, 35608, 11595, 939, 11615, 388, 11, 2746, 6616, 289, 31009, 331, 133406, 17757, 22539, 68, 68412, 42668, 11, 2714, 30166, 654, 83, 30179, 624, 53750, 1105, 81591, 25494, 39353, 15477, 33278, 11, 5451, 17443, 25851, 268, 8536, 37949, 1242, 30102, 11, 9390, 77, 19875, 4229, 20572, 77, 36964, 2030, 36077, 3004, 61231, 19875, 4864, 51767, 268, 11, 6616, 88028, 458, 2694, 23334, 746, 38132, 70251, 275, 13820, 624, 40369, 9101, 440, 2429, 27553, 811, 6250, 13363, 11, 2694, 8652, 77634, 50095, 41210, 46668, 33278, 10712, 1032, 89, 2645, 11553, 25892, 277, 17312, 90769, 12743, 32863, 8896, 624, 3430, 349, 7487, 1103, 33601, 3921, 724, 12466, 19580, 79, 27553, 811, 6250, 13363, 140108, 1032, 89, 2645, 1032, 89, 2645, 11553, 25892, 277, 98886, 198, 21291, 3877, 33278, 36115, 54377, 1365, 19000, 13190, 2838, 2694, 468, 36922, 26612, 1365, 730, 953, 434]
inputs:
[Buchvorstellung] Die Frau im hellblauen Kleid - BEATE MAXIAN - MonerlS-bunte-Welt
[Buchvorstellung] Die Frau im hellblauen Kleid â€“ BEATE MAXIAN
8. Dezember 2017 Monerl
#166 Rezension
Wien. Marianne Altmann, einst ein gefeierter Filmstar, ist schockiert, als sie von PlÃ¤nen ihrer Tochter Vera erfÃ¤hrt. Diese mÃ¶chte einen Film Ã¼ber ihre Familie drehen. Marianne fÃ¼rchtet, dass nun auch die AbgrÃ¼nde der Familie ans Tageslicht kommen kÃ¶nnten, und mit ihnen ein lange
zurÃ¼ckliegendes Vergehen. Es reicht zurÃ¼ck ins Jahr 1927, als ihre Mutter KÃ¤the in einem geliehenen Kleid am Theater vorsprach. Der Beginn einer beispiellosen Karriere â€“ und einer verhÃ¤ngnisvollen Bekanntschaft mit Hans Bleck, der zum mÃ¤chtigen Produzenten der Ufa aufsteigen sollte â€¦
Eine Familiengeschichte Ã¼ber vier Generationen, von Ur-GroÃŸmutter zur Enkelin, verwoben mit tiefen Geheimnissen, beginnend in Wien, als 1927 das MÃ¤dchen KÃ¤the den Mut aufbrachte, sich ihren Traum zu erfÃ¼llen.
Es versprach eine spannende Familiengeschichte zu werden. Vier Frauen, die sich vom Schicksal, das der 2. Weltkrieg Ã¼ber sie gebracht hat, nicht von ihrem Weg haben abbringen lassen und letztendlich eine Schauspieler-Dynastie begrÃ¼ndeten, wie es in Ã–sterreich vorher keine gegeben hat. Dabei kommt einiges ans Licht, das lange Zeit verborgen geblieben war.
Der Rahmen des Romans ist sehr gelungen. Leider schafft es Beate Maxian aber nicht, ihre Geschichte sprachlich so umzusetzten, das man von ihr durchweg gefesselt ist. Der ErzÃ¤hl- und Schreibstil ist sehr unrund. Oftmals wunderte ich mich Ã¼ber holprige und flache Dialoge. Inhaltlich enthÃ¼llten sie ein groÃŸes Geheimnis, doch Beate Maxians Charaktere nahmen dies einfach an ohne eine gewichtige EmotionalitÃ¤t, dich ich von den Figuren zur jeweiligen EnthÃ¼llung erwartet hÃ¤tte. Somit wuchs zunehmend meine Distanz zu den Protagonistinnen. Ich konnte nicht mit ihnen fÃ¼hlen, "sah" ihnen lediglich kopfschÃ¼ttelnd zu.
Das Beziehungs-Hin-und-Her von Sophie, der letzten in der Reihe der "Altmann-Frauen", das groÃŸe Herzschmerzdrama und eine andauernde Sturheit ohne Einsicht, zerrte mehr und mehr an meinen Nerven. Die stÃ¤ndigen Wiederholungen zu Marianne, wie "Diva" und "betagte Dame", Ã¼ber die ich vermehrt stolperte, stÃ¶rten meinen Lesefluss. Ich hangelte mich von Kapitel zu Kapitel und freute mich immer auf ein Kapitel zur Vergangenheit, das Ã¼ber KÃ¤the, die Ur-GroÃŸmutter, berichtete. Diese RÃ¼ckblicke in die Vergangenheit waren es, die die Spannung aufrecht hielten und mich bis zum Ende haben durchhalten lassen.
Nach Beendigung der LektÃ¼re denke ich, hÃ¤tte sich die Autorin ausschlieÃŸlich auf die historische Geschichte eingelassen, wÃ¤re ihr wahrscheinlich ein sehr guter Roman gelungen. Denn dieser ErzÃ¤hlstrang war gut recherchiert, mit einer wundervollen und fÃ¼r sich einnehmenden Protagonistin ausgearbeitet und einer Liebesgeschichte, die viel Potential gehabt hÃ¤tte. So wÃ¤re auch der Konflikt mit und von Jakob, der Jude war, noch besser zur Geltung gekommen und es wÃ¤ren die Emotionen und Erwartungen des Lesers, die das wunderschÃ¶ne Cover geweckt hatte, erfÃ¼llt worden.
Ein thematisch sehr interessantes Buch, mit einem tollen Handlungsumfeld, spannenden Geheimnissen und vielversprechenden Charakteren, das leider an der Umsetzung scheiterte.
Ich danke dem Heyne Verlag, der mir freundlicherweise dieses Buch als Rezensionsexemplar zur VerfÃ¼gung gestellt hat.
Beate Maxian Familiensaga Flop Heyne Verlag Ã–sterreich Rezension Rezensionsexemplar Wien
Previous Post Buchvorstellung â€“ Das Fundament der Ewigkeit â€“ KEN F
Caching indices mapping at /home/zhouh/.cache/huggingface/datasets/json/default-22ad102cdc2aaff8/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c63c677df0cf8976.arrow
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 2181961
})
PeftModelForCausalLM(
  (base_model): MoeModel(
    (model): Qwen2ForCausalLM(
      (model): Qwen2Model(
        (embed_tokens): Embedding(151936, 2048)
        (layers): ModuleList(
          (0): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (1): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (2): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (3): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (4): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (5): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (6): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (7): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (8): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (9): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (10): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (11): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (12): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (13): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (14): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (15): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (16): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (17): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (18): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (19): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (20): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (21): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (22): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
          (23): Qwen2DecoderLayer(
            (self_attn): Qwen2FlashAttention2(
              (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
              (rotary_emb): Qwen2RotaryEmbedding()
            )
            (mlp): moe.MLP(
              (base_layer): Qwen2MLP(
                (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                (act_fn): SiLU()
              )
              (moe_router_embedding): ModuleDict(
                (default): Linear(in_features=2048, out_features=2, bias=False)
              )
              (moe_experts): ModuleDict(
                (default): ModuleList(
                  (0): Qwen2MLP(
                    (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (up_proj): Linear(in_features=2048, out_features=5504, bias=False)
                    (down_proj): Linear(in_features=5504, out_features=2048, bias=False)
                    (act_fn): SiLU()
                  )
                )
              )
            )
            (input_layernorm): Qwen2RMSNorm()
            (post_attention_layernorm): Qwen2RMSNorm()
          )
        )
        (norm): Qwen2RMSNorm()
      )
      (lm_head): Linear(in_features=2048, out_features=151936, bias=False)
    )
  )
)
[INFO|trainer.py:586] 2024-04-18 16:09:28,312 >> Using auto half precision backend
[2024-04-18 16:09:28,690] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.3, git-hash=unknown, git-branch=unknown
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 2181961
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 2181961
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 2181961
})
[2024-04-18 16:09:34,951] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-04-18 16:09:34,954] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-04-18 16:09:34,954] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-04-18 16:09:34,957] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2024-04-18 16:09:34,957] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2024-04-18 16:09:34,957] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-04-18 16:09:34,957] [INFO] [stage_1_and_2.py:147:__init__] Reduce bucket size 500000000
[2024-04-18 16:09:34,957] [INFO] [stage_1_and_2.py:148:__init__] Allgather bucket size 500000000
[2024-04-18 16:09:34,957] [INFO] [stage_1_and_2.py:149:__init__] CPU Offload: False
[2024-04-18 16:09:34,957] [INFO] [stage_1_and_2.py:150:__init__] Round robin gradient partitioning: False
[2024-04-18 16:09:35,845] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states
[2024-04-18 16:09:35,845] [INFO] [utils.py:803:see_memory_usage] MA 5.38 GB         Max_MA 5.38 GB         CA 5.66 GB         Max_CA 6 GB 
[2024-04-18 16:09:35,846] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 41.62 GB, percent = 11.1%
[2024-04-18 16:09:36,058] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states
[2024-04-18 16:09:36,059] [INFO] [utils.py:803:see_memory_usage] MA 5.38 GB         Max_MA 5.38 GB         CA 5.66 GB         Max_CA 6 GB 
[2024-04-18 16:09:36,059] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 41.62 GB, percent = 11.1%
[2024-04-18 16:09:36,059] [INFO] [stage_1_and_2.py:514:__init__] optimizer state initialized
[2024-04-18 16:09:36,272] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer
[2024-04-18 16:09:36,273] [INFO] [utils.py:803:see_memory_usage] MA 5.38 GB         Max_MA 5.38 GB         CA 5.66 GB         Max_CA 6 GB 
[2024-04-18 16:09:36,273] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 41.62 GB, percent = 11.1%
[2024-04-18 16:09:36,273] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2024-04-18 16:09:36,273] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-04-18 16:09:36,274] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-04-18 16:09:36,274] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[2e-05], mom=[(0.9, 0.999)]
[2024-04-18 16:09:36,275] [INFO] [config.py:974:print] DeepSpeedEngine configuration:
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   amp_enabled .................. False
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   amp_params ................... False
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   bfloat16_enabled ............. True
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   checkpoint_parallel_write_pipeline  False
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   checkpoint_tag_validation_enabled  True
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   checkpoint_tag_validation_fail  False
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f93b07796f0>
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   communication_data_type ...... None
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   curriculum_enabled_legacy .... False
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   curriculum_params_legacy ..... False
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   data_efficiency_enabled ...... False
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   dataloader_drop_last ......... False
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   disable_allgather ............ False
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   dump_state ................... False
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   dynamic_loss_scale_args ...... None
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   eigenvalue_enabled ........... False
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   eigenvalue_gas_boundary_resolution  1
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   eigenvalue_layer_num ......... 0
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   eigenvalue_max_iter .......... 100
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   eigenvalue_stability ......... 1e-06
[2024-04-18 16:09:36,276] [INFO] [config.py:978:print]   eigenvalue_tol ............... 0.01
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   eigenvalue_verbose ........... False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   elasticity_enabled ........... False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   fp16_auto_cast ............... None
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   fp16_enabled ................. False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   fp16_master_weights_and_gradients  False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   global_rank .................. 0
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   grad_accum_dtype ............. None
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   gradient_accumulation_steps .. 8
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   gradient_clipping ............ 1.0
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   gradient_predivide_factor .... 1.0
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   initial_dynamic_scale ........ 1
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   load_universal_checkpoint .... False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   loss_scale ................... 1.0
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   memory_breakdown ............. False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   mics_hierarchial_params_gather  False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   mics_shard_size .............. -1
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   optimizer_legacy_fusion ...... False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   optimizer_name ............... None
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   optimizer_params ............. None
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   pld_enabled .................. False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   pld_params ................... False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   prescale_gradients ........... False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   scheduler_name ............... None
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   scheduler_params ............. None
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   seq_parallel_communication_data_type  torch.float32
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   sparse_attention ............. None
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   sparse_gradients_enabled ..... False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   steps_per_print .............. inf
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   train_batch_size ............. 512
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   train_micro_batch_size_per_gpu  16
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   use_node_local_storage ....... False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   wall_clock_breakdown ......... False
[2024-04-18 16:09:36,277] [INFO] [config.py:978:print]   weight_quantization_config ... None
[2024-04-18 16:09:36,278] [INFO] [config.py:978:print]   world_size ................... 4
[2024-04-18 16:09:36,278] [INFO] [config.py:978:print]   zero_allow_untested_optimizer  True
[2024-04-18 16:09:36,278] [INFO] [config.py:978:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-04-18 16:09:36,278] [INFO] [config.py:978:print]   zero_enabled ................. True
[2024-04-18 16:09:36,278] [INFO] [config.py:978:print]   zero_force_ds_cpu_optimizer .. True
[2024-04-18 16:09:36,278] [INFO] [config.py:978:print]   zero_optimization_stage ...... 2
[2024-04-18 16:09:36,278] [INFO] [config.py:964:print_user_config]   json = {
    "train_batch_size": 512, 
    "train_micro_batch_size_per_gpu": 16, 
    "gradient_accumulation_steps": 8, 
    "gradient_clipping": 1.0, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "initial_scale_power": 16, 
        "loss_scale_window": 1000, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 5.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 5.000000e+08, 
        "contiguous_gradients": true
    }, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }
}
[INFO|trainer.py:1747] 2024-04-18 16:09:36,278 >> ***** Running training *****
[INFO|trainer.py:1748] 2024-04-18 16:09:36,278 >>   Num examples = 2,181,961
[INFO|trainer.py:1749] 2024-04-18 16:09:36,278 >>   Num Epochs = 1
[INFO|trainer.py:1750] 2024-04-18 16:09:36,278 >>   Instantaneous batch size per device = 16
[INFO|trainer.py:1753] 2024-04-18 16:09:36,278 >>   Total train batch size (w. parallel, distributed & accumulation) = 512
[INFO|trainer.py:1754] 2024-04-18 16:09:36,278 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:1755] 2024-04-18 16:09:36,278 >>   Total optimization steps = 4,261
[INFO|trainer.py:1756] 2024-04-18 16:09:36,280 >>   Number of trainable parameters = 98,304
  0%|          | 0/4261 [00:00<?, ?it/s]  0%|          | 1/4261 [00:21<25:57:37, 21.94s/it]  0%|          | 2/4261 [00:42<25:08:42, 21.25s/it]  0%|          | 3/4261 [01:03<24:57:19, 21.10s/it]  0%|          | 4/4261 [01:24<24:54:18, 21.06s/it]  0%|          | 5/4261 [01:45<24:55:09, 21.08s/it]  0%|          | 6/4261 [02:06<24:56:57, 21.11s/it]  0%|          | 7/4261 [02:28<24:59:57, 21.16s/it]  0%|          | 8/4261 [02:49<25:01:46, 21.19s/it]  0%|          | 9/4261 [03:10<25:03:53, 21.22s/it]  0%|          | 10/4261 [03:32<25:06:36, 21.26s/it]                                                    {'loss': 2.338, 'learning_rate': 1.9999728202965487e-05, 'epoch': 0.0}
  0%|          | 10/4261 [03:32<25:06:36, 21.26s/it]  0%|          | 11/4261 [03:53<25:08:13, 21.29s/it]  0%|          | 12/4261 [04:14<25:10:46, 21.33s/it]  0%|          | 13/4261 [04:36<25:13:24, 21.38s/it]  0%|          | 14/4261 [04:57<25:13:40, 21.38s/it]  0%|          | 15/4261 [05:19<25:14:34, 21.40s/it]  0%|          | 16/4261 [05:40<25:14:09, 21.40s/it]  0%|          | 17/4261 [06:02<25:14:43, 21.41s/it]  0%|          | 18/4261 [06:23<25:14:17, 21.41s/it]  0%|          | 19/4261 [06:44<25:14:00, 21.41s/it]  0%|          | 20/4261 [07:06<25:13:29, 21.41s/it]                                                    {'loss': 2.3407, 'learning_rate': 1.999891282663667e-05, 'epoch': 0.0}
  0%|          | 20/4261 [07:06<25:13:29, 21.41s/it]  0%|          | 21/4261 [07:27<25:12:30, 21.40s/it]  1%|          | 22/4261 [07:49<25:12:30, 21.41s/it]  1%|          | 23/4261 [08:10<25:11:28, 21.40s/it]  1%|          | 24/4261 [08:31<25:10:45, 21.39s/it]  1%|          | 25/4261 [08:53<25:09:41, 21.38s/it]  1%|          | 26/4261 [09:14<25:08:44, 21.38s/it]  1%|          | 27/4261 [09:35<25:07:18, 21.36s/it]  1%|          | 28/4261 [09:57<25:07:22, 21.37s/it]  1%|          | 29/4261 [10:18<25:05:55, 21.35s/it]  1%|          | 30/4261 [10:39<25:05:02, 21.34s/it]                                                    {'loss': 2.3261, 'learning_rate': 1.9997553915336926e-05, 'epoch': 0.01}
  1%|          | 30/4261 [10:39<25:05:02, 21.34s/it]  1%|          | 31/4261 [11:01<25:04:29, 21.34s/it]  1%|          | 32/4261 [11:22<25:03:59, 21.34s/it]  1%|          | 33/4261 [11:43<25:03:42, 21.34s/it]  1%|          | 34/4261 [12:05<25:03:14, 21.34s/it]  1%|          | 35/4261 [12:26<25:02:33, 21.33s/it]  1%|          | 36/4261 [12:47<25:01:38, 21.33s/it]  1%|          | 37/4261 [13:09<25:00:46, 21.32s/it]  1%|          | 38/4261 [13:30<25:00:05, 21.31s/it]  1%|          | 39/4261 [13:51<24:59:47, 21.31s/it]  1%|          | 40/4261 [14:13<24:59:56, 21.32s/it]                                                    {'loss': 2.3298, 'learning_rate': 1.999565154293587e-05, 'epoch': 0.01}
  1%|          | 40/4261 [14:13<24:59:56, 21.32s/it]  1%|          | 41/4261 [14:34<24:59:11, 21.32s/it]  1%|          | 42/4261 [14:55<24:59:23, 21.32s/it]  1%|          | 43/4261 [15:17<25:00:16, 21.34s/it]  1%|          | 44/4261 [15:38<24:58:52, 21.33s/it]  1%|          | 45/4261 [15:59<24:58:56, 21.33s/it]  1%|          | 46/4261 [16:21<24:58:25, 21.33s/it]  1%|          | 47/4261 [16:42<25:03:43, 21.41s/it]  1%|          | 48/4261 [17:04<25:01:30, 21.38s/it]  1%|          | 49/4261 [17:25<24:59:17, 21.36s/it]  1%|          | 50/4261 [17:46<24:59:09, 21.36s/it]                                                    {'loss': 2.3335, 'learning_rate': 1.9993205812845326e-05, 'epoch': 0.01}
  1%|          | 50/4261 [17:46<24:59:09, 21.36s/it]  1%|          | 51/4261 [18:08<24:58:03, 21.35s/it]  1%|          | 52/4261 [18:29<24:56:51, 21.34s/it]  1%|          | 53/4261 [18:50<25:02:22, 21.42s/it]  1%|â–         | 54/4261 [19:12<25:00:00, 21.39s/it]  1%|â–         | 55/4261 [19:33<24:57:33, 21.36s/it]  1%|â–         | 56/4261 [19:54<24:56:30, 21.35s/it]  1%|â–         | 57/4261 [20:16<24:54:45, 21.33s/it]  1%|â–         | 58/4261 [20:37<24:54:39, 21.34s/it]  1%|â–         | 59/4261 [20:58<24:54:26, 21.34s/it]  1%|â–         | 60/4261 [21:20<24:52:48, 21.32s/it]                                                    {'loss': 2.3399, 'learning_rate': 1.999021685801374e-05, 'epoch': 0.01}
  1%|â–         | 60/4261 [21:20<24:52:48, 21.32s/it]  1%|â–         | 61/4261 [21:41<24:52:17, 21.32s/it]  1%|â–         | 62/4261 [22:02<24:52:05, 21.32s/it]  1%|â–         | 63/4261 [22:24<24:51:01, 21.31s/it]  2%|â–         | 64/4261 [22:45<24:51:18, 21.32s/it]  2%|â–         | 65/4261 [23:06<24:50:54, 21.32s/it]  2%|â–         | 66/4261 [23:28<24:50:28, 21.32s/it]  2%|â–         | 67/4261 [23:49<24:50:26, 21.32s/it]  2%|â–         | 68/4261 [24:10<24:49:44, 21.32s/it]  2%|â–         | 69/4261 [24:32<24:49:45, 21.32s/it]  2%|â–         | 70/4261 [24:53<24:49:26, 21.32s/it]                                                    {'loss': 2.3338, 'learning_rate': 1.9986684840918927e-05, 'epoch': 0.02}
  2%|â–         | 70/4261 [24:53<24:49:26, 21.32s/it]  2%|â–         | 71/4261 [25:14<24:48:34, 21.32s/it]  2%|â–         | 72/4261 [25:35<24:47:38, 21.31s/it]  2%|â–         | 73/4261 [25:57<24:47:20, 21.31s/it]  2%|â–         | 74/4261 [26:18<24:47:15, 21.31s/it]  2%|â–         | 75/4261 [26:39<24:46:22, 21.30s/it]  2%|â–         | 76/4261 [27:01<24:51:25, 21.38s/it]  2%|â–         | 77/4261 [27:22<24:49:05, 21.35s/it]  2%|â–         | 78/4261 [27:44<24:48:26, 21.35s/it]  2%|â–         | 79/4261 [28:05<24:47:21, 21.34s/it]  2%|â–         | 80/4261 [28:26<24:46:33, 21.33s/it]                                                    {'loss': 2.3309, 'learning_rate': 1.9982609953559235e-05, 'epoch': 0.02}
  2%|â–         | 80/4261 [28:26<24:46:33, 21.33s/it]  2%|â–         | 81/4261 [28:47<24:45:49, 21.33s/it]  2%|â–         | 82/4261 [29:09<24:49:49, 21.39s/it]  2%|â–         | 83/4261 [29:30<24:47:26, 21.36s/it]  2%|â–         | 84/4261 [29:52<24:45:33, 21.34s/it]  2%|â–         | 85/4261 [30:13<24:44:04, 21.32s/it]  2%|â–         | 86/4261 [30:34<24:43:12, 21.32s/it]  2%|â–         | 87/4261 [30:56<24:43:11, 21.32s/it]  2%|â–         | 88/4261 [31:17<24:42:21, 21.31s/it]  2%|â–         | 89/4261 [31:38<24:42:00, 21.31s/it]  2%|â–         | 90/4261 [31:59<24:41:15, 21.31s/it]                                                    {'loss': 2.3263, 'learning_rate': 1.9977992417443124e-05, 'epoch': 0.02}
  2%|â–         | 90/4261 [31:59<24:41:15, 21.31s/it]  2%|â–         | 91/4261 [32:21<24:41:01, 21.31s/it]  2%|â–         | 92/4261 [32:42<24:40:11, 21.30s/it]  2%|â–         | 93/4261 [33:03<24:39:57, 21.30s/it]  2%|â–         | 94/4261 [33:25<24:38:59, 21.30s/it]  2%|â–         | 95/4261 [33:46<24:38:05, 21.29s/it]  2%|â–         | 96/4261 [34:07<24:43:17, 21.37s/it]  2%|â–         | 97/4261 [34:29<24:40:41, 21.34s/it]  2%|â–         | 98/4261 [34:50<24:38:57, 21.32s/it]  2%|â–         | 99/4261 [35:11<24:38:28, 21.31s/it]  2%|â–         | 100/4261 [35:33<24:37:50, 21.31s/it]                                                     {'loss': 2.3458, 'learning_rate': 1.9972832483577117e-05, 'epoch': 0.02}
  2%|â–         | 100/4261 [35:33<24:37:50, 21.31s/it]  2%|â–         | 101/4261 [35:54<24:37:55, 21.32s/it]  2%|â–         | 102/4261 [36:15<24:42:24, 21.39s/it]  2%|â–         | 103/4261 [36:37<24:40:18, 21.36s/it]  2%|â–         | 104/4261 [36:58<24:38:05, 21.33s/it]  2%|â–         | 105/4261 [37:19<24:36:43, 21.32s/it]  2%|â–         | 106/4261 [37:41<24:35:23, 21.31s/it]  3%|â–Ž         | 107/4261 [38:02<24:35:02, 21.31s/it]  3%|â–Ž         | 108/4261 [38:23<24:34:15, 21.30s/it]  3%|â–Ž         | 109/4261 [38:44<24:34:08, 21.30s/it]  3%|â–Ž         | 110/4261 [39:06<24:33:44, 21.30s/it]                                                     {'loss': 2.3296, 'learning_rate': 1.996713043245217e-05, 'epoch': 0.03}
  3%|â–Ž         | 110/4261 [39:06<24:33:44, 21.30s/it]  3%|â–Ž         | 111/4261 [39:27<24:33:10, 21.30s/it]  3%|â–Ž         | 112/4261 [39:49<24:38:06, 21.38s/it]  3%|â–Ž         | 113/4261 [40:10<24:35:50, 21.35s/it]  3%|â–Ž         | 114/4261 [40:31<24:33:58, 21.33s/it]  3%|â–Ž         | 115/4261 [40:52<24:32:11, 21.31s/it]  3%|â–Ž         | 116/4261 [41:14<24:31:04, 21.29s/it]  3%|â–Ž         | 117/4261 [41:35<24:31:25, 21.30s/it]  3%|â–Ž         | 118/4261 [41:57<24:36:22, 21.38s/it]  3%|â–Ž         | 119/4261 [42:18<24:33:56, 21.35s/it]  3%|â–Ž         | 120/4261 [42:39<24:32:38, 21.34s/it]                                                     {'loss': 2.3246, 'learning_rate': 1.996088657402839e-05, 'epoch': 0.03}
  3%|â–Ž         | 120/4261 [42:39<24:32:38, 21.34s/it]  3%|â–Ž         | 121/4261 [43:00<24:31:15, 21.32s/it]  3%|â–Ž         | 122/4261 [43:22<24:30:03, 21.31s/it]  3%|â–Ž         | 123/4261 [43:43<24:29:38, 21.31s/it]  3%|â–Ž         | 124/4261 [44:04<24:28:35, 21.30s/it]  3%|â–Ž         | 125/4261 [44:26<24:27:49, 21.29s/it]  3%|â–Ž         | 126/4261 [44:47<24:27:36, 21.30s/it]  3%|â–Ž         | 127/4261 [45:08<24:26:54, 21.29s/it]  3%|â–Ž         | 128/4261 [45:29<24:26:42, 21.29s/it]  3%|â–Ž         | 129/4261 [45:51<24:26:18, 21.29s/it]  3%|â–Ž         | 130/4261 [46:12<24:26:08, 21.29s/it]                                                     {'loss': 2.3293, 'learning_rate': 1.9954101247718216e-05, 'epoch': 0.03}
  3%|â–Ž         | 130/4261 [46:12<24:26:08, 21.29s/it]  3%|â–Ž         | 131/4261 [46:33<24:25:44, 21.29s/it]  3%|â–Ž         | 132/4261 [46:55<24:25:31, 21.30s/it]  3%|â–Ž         | 133/4261 [47:16<24:25:10, 21.30s/it]  3%|â–Ž         | 134/4261 [47:37<24:25:01, 21.30s/it]  3%|â–Ž         | 135/4261 [47:59<24:24:15, 21.29s/it]  3%|â–Ž         | 136/4261 [48:20<24:23:27, 21.29s/it]  3%|â–Ž         | 137/4261 [48:41<24:22:56, 21.28s/it]  3%|â–Ž         | 138/4261 [49:02<24:22:34, 21.28s/it]  3%|â–Ž         | 139/4261 [49:24<24:22:34, 21.29s/it]  3%|â–Ž         | 140/4261 [49:45<24:22:25, 21.29s/it]                                                     {'loss': 2.3317, 'learning_rate': 1.994677482236797e-05, 'epoch': 0.03}
  3%|â–Ž         | 140/4261 [49:45<24:22:25, 21.29s/it]  3%|â–Ž         | 141/4261 [50:06<24:21:54, 21.29s/it]  3%|â–Ž         | 142/4261 [50:28<24:21:33, 21.29s/it]  3%|â–Ž         | 143/4261 [50:49<24:21:13, 21.29s/it]  3%|â–Ž         | 144/4261 [51:10<24:20:56, 21.29s/it]  3%|â–Ž         | 145/4261 [51:31<24:20:31, 21.29s/it]  3%|â–Ž         | 146/4261 [51:53<24:20:15, 21.29s/it]  3%|â–Ž         | 147/4261 [52:14<24:20:08, 21.30s/it]  3%|â–Ž         | 148/4261 [52:35<24:19:28, 21.29s/it]  3%|â–Ž         | 149/4261 [52:57<24:19:02, 21.29s/it]  4%|â–Ž         | 150/4261 [53:18<24:19:05, 21.30s/it]                                                     {'loss': 2.3264, 'learning_rate': 1.9938907696237785e-05, 'epoch': 0.04}
  4%|â–Ž         | 150/4261 [53:18<24:19:05, 21.30s/it]  4%|â–Ž         | 151/4261 [53:39<24:18:37, 21.29s/it]  4%|â–Ž         | 152/4261 [54:01<24:18:49, 21.30s/it]  4%|â–Ž         | 153/4261 [54:22<24:18:49, 21.31s/it]  4%|â–Ž         | 154/4261 [54:43<24:18:04, 21.30s/it]  4%|â–Ž         | 155/4261 [55:04<24:18:05, 21.31s/it]  4%|â–Ž         | 156/4261 [55:26<24:17:30, 21.30s/it]  4%|â–Ž         | 157/4261 [55:47<24:17:32, 21.31s/it]  4%|â–Ž         | 158/4261 [56:08<24:16:59, 21.31s/it]  4%|â–Ž         | 159/4261 [56:30<24:16:37, 21.31s/it]  4%|â–         | 160/4261 [56:51<24:15:43, 21.30s/it]                                                     {'loss': 2.3296, 'learning_rate': 1.9930500296979968e-05, 'epoch': 0.04}
  4%|â–         | 160/4261 [56:51<24:15:43, 21.30s/it]  4%|â–         | 161/4261 [57:12<24:15:31, 21.30s/it]  4%|â–         | 162/4261 [57:34<24:15:29, 21.31s/it]  4%|â–         | 163/4261 [57:55<24:15:04, 21.30s/it]  4%|â–         | 164/4261 [58:16<24:15:13, 21.31s/it]  4%|â–         | 165/4261 [58:38<24:24:59, 21.46s/it]  4%|â–         | 166/4261 [58:59<24:21:40, 21.42s/it]  4%|â–         | 167/4261 [59:21<24:19:09, 21.38s/it]  4%|â–         | 168/4261 [59:42<24:17:12, 21.36s/it]  4%|â–         | 169/4261 [1:00:03<24:15:30, 21.34s/it]  4%|â–         | 170/4261 [1:00:25<24:14:37, 21.33s/it]                                                       {'loss': 2.3284, 'learning_rate': 1.9921553081615762e-05, 'epoch': 0.04}
  4%|â–         | 170/4261 [1:00:25<24:14:37, 21.33s/it]  4%|â–         | 171/4261 [1:00:46<24:19:01, 21.40s/it]  4%|â–         | 172/4261 [1:01:07<24:17:28, 21.39s/it]  4%|â–         | 173/4261 [1:01:29<24:15:31, 21.36s/it]  4%|â–         | 174/4261 [1:01:50<24:14:27, 21.35s/it]  4%|â–         | 175/4261 [1:02:11<24:13:27, 21.34s/it]  4%|â–         | 176/4261 [1:02:33<24:12:52, 21.34s/it]  4%|â–         | 177/4261 [1:02:54<24:11:49, 21.33s/it]  4%|â–         | 178/4261 [1:03:15<24:11:41, 21.33s/it]  4%|â–         | 179/4261 [1:03:37<24:11:05, 21.33s/it]  4%|â–         | 180/4261 [1:03:58<24:10:22, 21.32s/it]                                                       {'loss': 2.3404, 'learning_rate': 1.9912066536510485e-05, 'epoch': 0.04}
  4%|â–         | 180/4261 [1:03:58<24:10:22, 21.32s/it]  4%|â–         | 181/4261 [1:04:19<24:10:32, 21.33s/it]  4%|â–         | 182/4261 [1:04:41<24:10:31, 21.34s/it]  4%|â–         | 183/4261 [1:05:02<24:09:58, 21.33s/it]  4%|â–         | 184/4261 [1:05:23<24:09:43, 21.34s/it]  4%|â–         | 185/4261 [1:05:45<24:09:04, 21.33s/it]  4%|â–         | 186/4261 [1:06:06<24:08:27, 21.33s/it]  4%|â–         | 187/4261 [1:06:27<24:08:14, 21.33s/it]  4%|â–         | 188/4261 [1:06:49<24:07:36, 21.33s/it]  4%|â–         | 189/4261 [1:07:10<24:07:05, 21.32s/it]  4%|â–         | 190/4261 [1:07:31<24:06:42, 21.32s/it]                                                       {'loss': 2.3331, 'learning_rate': 1.99020411773471e-05, 'epoch': 0.04}
  4%|â–         | 190/4261 [1:07:31<24:06:42, 21.32s/it]  4%|â–         | 191/4261 [1:07:53<24:06:07, 21.32s/it]  5%|â–         | 192/4261 [1:08:14<24:05:53, 21.32s/it]  5%|â–         | 193/4261 [1:08:35<24:06:06, 21.33s/it]  5%|â–         | 194/4261 [1:08:57<24:15:39, 21.48s/it]  5%|â–         | 195/4261 [1:09:18<24:12:19, 21.43s/it]  5%|â–         | 196/4261 [1:09:40<24:09:37, 21.40s/it]  5%|â–         | 197/4261 [1:10:01<24:07:52, 21.38s/it]  5%|â–         | 198/4261 [1:10:22<24:06:36, 21.36s/it]  5%|â–         | 199/4261 [1:10:44<24:05:09, 21.35s/it]  5%|â–         | 200/4261 [1:11:05<24:09:14, 21.41s/it]                                                       {'loss': 2.3345, 'learning_rate': 1.9891477549098193e-05, 'epoch': 0.05}
  5%|â–         | 200/4261 [1:11:05<24:09:14, 21.41s/it]  5%|â–         | 201/4261 [1:11:27<24:07:15, 21.39s/it]  5%|â–         | 202/4261 [1:11:48<24:06:19, 21.38s/it]  5%|â–         | 203/4261 [1:12:09<24:05:22, 21.37s/it]  5%|â–         | 204/4261 [1:12:31<24:04:51, 21.37s/it]  5%|â–         | 205/4261 [1:12:52<24:04:12, 21.36s/it]  5%|â–         | 206/4261 [1:13:13<24:03:05, 21.35s/it]  5%|â–         | 207/4261 [1:13:35<24:01:23, 21.33s/it]  5%|â–         | 208/4261 [1:13:56<24:01:14, 21.34s/it]  5%|â–         | 209/4261 [1:14:17<24:00:27, 21.33s/it]  5%|â–         | 210/4261 [1:14:39<24:00:27, 21.33s/it]                                                       {'loss': 2.3383, 'learning_rate': 1.988037622599632e-05, 'epoch': 0.05}
  5%|â–         | 210/4261 [1:14:39<24:00:27, 21.33s/it]  5%|â–         | 211/4261 [1:15:00<24:00:30, 21.34s/it]  5%|â–         | 212/4261 [1:15:21<24:00:02, 21.34s/it]  5%|â–         | 213/4261 [1:15:43<23:59:43, 21.34s/it]  5%|â–Œ         | 214/4261 [1:16:05<24:08:54, 21.48s/it]  5%|â–Œ         | 215/4261 [1:16:26<24:04:05, 21.42s/it]  5%|â–Œ         | 216/4261 [1:16:47<24:01:09, 21.38s/it]  5%|â–Œ         | 217/4261 [1:17:08<23:59:20, 21.36s/it]  5%|â–Œ         | 218/4261 [1:17:30<23:57:44, 21.34s/it]  5%|â–Œ         | 219/4261 [1:17:51<23:56:13, 21.32s/it]  5%|â–Œ         | 220/4261 [1:18:12<23:54:59, 21.31s/it]                                                       {'loss': 2.3389, 'learning_rate': 1.986873781150283e-05, 'epoch': 0.05}
  5%|â–Œ         | 220/4261 [1:18:12<23:54:59, 21.31s/it]  5%|â–Œ         | 221/4261 [1:18:34<23:58:51, 21.37s/it]  5%|â–Œ         | 222/4261 [1:18:55<23:56:40, 21.34s/it]  5%|â–Œ         | 223/4261 [1:19:16<23:55:08, 21.32s/it]  5%|â–Œ         | 224/4261 [1:19:38<23:54:21, 21.32s/it]  5%|â–Œ         | 225/4261 [1:19:59<23:53:39, 21.31s/it]  5%|â–Œ         | 226/4261 [1:20:20<23:53:11, 21.31s/it]  5%|â–Œ         | 227/4261 [1:20:42<23:52:48, 21.31s/it]  5%|â–Œ         | 228/4261 [1:21:03<23:52:19, 21.31s/it]  5%|â–Œ         | 229/4261 [1:21:24<23:51:38, 21.30s/it]  5%|â–Œ         | 230/4261 [1:21:46<24:01:07, 21.45s/it]                                                       {'loss': 2.3487, 'learning_rate': 1.9856562938275023e-05, 'epoch': 0.05}
  5%|â–Œ         | 230/4261 [1:21:46<24:01:07, 21.45s/it]  5%|â–Œ         | 231/4261 [1:22:07<23:58:02, 21.41s/it]  5%|â–Œ         | 232/4261 [1:22:29<23:55:37, 21.38s/it]  5%|â–Œ         | 233/4261 [1:22:50<23:53:04, 21.35s/it]  5%|â–Œ         | 234/4261 [1:23:11<23:52:05, 21.34s/it]  6%|â–Œ         | 235/4261 [1:23:32<23:50:57, 21.33s/it]  6%|â–Œ         | 236/4261 [1:23:54<23:50:42, 21.33s/it]  6%|â–Œ         | 237/4261 [1:24:15<23:54:42, 21.39s/it]  6%|â–Œ         | 238/4261 [1:24:37<23:51:55, 21.36s/it]  6%|â–Œ         | 239/4261 [1:24:58<23:50:27, 21.34s/it]  6%|â–Œ         | 240/4261 [1:25:19<23:48:59, 21.32s/it]                                                       {'loss': 2.3141, 'learning_rate': 1.9843852268131797e-05, 'epoch': 0.06}
  6%|â–Œ         | 240/4261 [1:25:19<23:48:59, 21.32s/it]  6%|â–Œ         | 241/4261 [1:25:40<23:47:57, 21.31s/it]  6%|â–Œ         | 242/4261 [1:26:02<23:47:28, 21.31s/it]  6%|â–Œ         | 243/4261 [1:26:23<23:46:31, 21.30s/it]  6%|â–Œ         | 244/4261 [1:26:44<23:46:16, 21.30s/it]  6%|â–Œ         | 245/4261 [1:27:06<23:45:29, 21.30s/it]  6%|â–Œ         | 246/4261 [1:27:27<23:44:56, 21.29s/it]  6%|â–Œ         | 247/4261 [1:27:48<23:44:26, 21.29s/it]  6%|â–Œ         | 248/4261 [1:28:10<23:44:15, 21.29s/it]  6%|â–Œ         | 249/4261 [1:28:31<23:44:03, 21.30s/it]  6%|â–Œ         | 250/4261 [1:28:52<23:43:16, 21.29s/it]                                                       {'loss': 2.3391, 'learning_rate': 1.9830606492017633e-05, 'epoch': 0.06}
  6%|â–Œ         | 250/4261 [1:28:52<23:43:16, 21.29s/it]  6%|â–Œ         | 251/4261 [1:29:13<23:44:09, 21.31s/it]  6%|â–Œ         | 252/4261 [1:29:35<23:48:07, 21.37s/it]  6%|â–Œ         | 253/4261 [1:29:56<23:45:50, 21.35s/it]  6%|â–Œ         | 254/4261 [1:30:18<23:44:12, 21.33s/it]  6%|â–Œ         | 255/4261 [1:30:39<23:43:20, 21.32s/it]  6%|â–Œ         | 256/4261 [1:31:00<23:41:45, 21.30s/it]  6%|â–Œ         | 257/4261 [1:31:21<23:41:09, 21.30s/it]  6%|â–Œ         | 258/4261 [1:31:43<23:40:06, 21.29s/it]  6%|â–Œ         | 259/4261 [1:32:04<23:39:06, 21.28s/it]  6%|â–Œ         | 260/4261 [1:32:25<23:38:30, 21.27s/it]                                                       {'loss': 2.3417, 'learning_rate': 1.9816826329965067e-05, 'epoch': 0.06}
  6%|â–Œ         | 260/4261 [1:32:25<23:38:30, 21.27s/it]  6%|â–Œ         | 261/4261 [1:32:46<23:38:43, 21.28s/it]  6%|â–Œ         | 262/4261 [1:33:08<23:38:11, 21.28s/it]  6%|â–Œ         | 263/4261 [1:33:29<23:38:04, 21.28s/it]  6%|â–Œ         | 264/4261 [1:33:50<23:37:25, 21.28s/it]  6%|â–Œ         | 265/4261 [1:34:12<23:37:08, 21.28s/it]  6%|â–Œ         | 266/4261 [1:34:33<23:37:19, 21.29s/it]  6%|â–‹         | 267/4261 [1:34:54<23:36:25, 21.28s/it]  6%|â–‹         | 268/4261 [1:35:15<23:36:30, 21.28s/it]  6%|â–‹         | 269/4261 [1:35:37<23:35:32, 21.28s/it]  6%|â–‹         | 270/4261 [1:35:58<23:35:40, 21.28s/it]                                                       {'loss': 2.3316, 'learning_rate': 1.980251253105554e-05, 'epoch': 0.06}
  6%|â–‹         | 270/4261 [1:35:58<23:35:40, 21.28s/it]  6%|â–‹         | 271/4261 [1:36:19<23:35:02, 21.28s/it]  6%|â–‹         | 272/4261 [1:36:41<23:34:54, 21.28s/it]  6%|â–‹         | 273/4261 [1:37:02<23:35:16, 21.29s/it]  6%|â–‹         | 274/4261 [1:37:23<23:35:19, 21.30s/it]  6%|â–‹         | 275/4261 [1:37:44<23:35:27, 21.31s/it]  6%|â–‹         | 276/4261 [1:38:06<23:35:06, 21.31s/it]  7%|â–‹         | 277/4261 [1:38:27<23:35:16, 21.31s/it]  7%|â–‹         | 278/4261 [1:38:48<23:34:36, 21.31s/it]  7%|â–‹         | 279/4261 [1:39:10<23:34:27, 21.31s/it]  7%|â–‹         | 280/4261 [1:39:31<23:34:24, 21.32s/it]                                                       {'loss': 2.3215, 'learning_rate': 1.9787665873378668e-05, 'epoch': 0.07}
  7%|â–‹         | 280/4261 [1:39:31<23:34:24, 21.32s/it]  7%|â–‹         | 281/4261 [1:39:52<23:34:09, 21.32s/it]  7%|â–‹         | 282/4261 [1:40:14<23:38:38, 21.39s/it]  7%|â–‹         | 283/4261 [1:40:35<23:41:17, 21.44s/it]  7%|â–‹         | 284/4261 [1:40:57<23:38:32, 21.40s/it]  7%|â–‹         | 285/4261 [1:41:18<23:36:24, 21.37s/it]  7%|â–‹         | 286/4261 [1:41:39<23:34:30, 21.35s/it]  7%|â–‹         | 287/4261 [1:42:01<23:32:07, 21.32s/it]  7%|â–‹         | 288/4261 [1:42:22<23:31:24, 21.32s/it]  7%|â–‹         | 289/4261 [1:42:43<23:30:43, 21.31s/it]  7%|â–‹         | 290/4261 [1:43:05<23:30:19, 21.31s/it]                                                       {'loss': 2.3273, 'learning_rate': 1.9772287163989958e-05, 'epoch': 0.07}
  7%|â–‹         | 290/4261 [1:43:05<23:30:19, 21.31s/it]  7%|â–‹         | 291/4261 [1:43:26<23:30:04, 21.31s/it]  7%|â–‹         | 292/4261 [1:43:47<23:29:50, 21.31s/it]  7%|â–‹         | 293/4261 [1:44:08<23:28:52, 21.30s/it]  7%|â–‹         | 294/4261 [1:44:30<23:27:58, 21.30s/it]  7%|â–‹         | 295/4261 [1:44:51<23:28:09, 21.30s/it]  7%|â–‹         | 296/4261 [1:45:12<23:27:42, 21.30s/it]  7%|â–‹         | 297/4261 [1:45:34<23:27:35, 21.31s/it]  7%|â–‹         | 298/4261 [1:45:55<23:27:36, 21.31s/it]  7%|â–‹         | 299/4261 [1:46:16<23:27:30, 21.32s/it]  7%|â–‹         | 300/4261 [1:46:38<23:27:23, 21.32s/it]                                                       {'loss': 2.3274, 'learning_rate': 1.9756377238866923e-05, 'epoch': 0.07}
  7%|â–‹         | 300/4261 [1:46:38<23:27:23, 21.32s/it]  7%|â–‹         | 301/4261 [1:46:59<23:27:45, 21.33s/it]  7%|â–‹         | 302/4261 [1:47:20<23:26:43, 21.32s/it]  7%|â–‹         | 303/4261 [1:47:42<23:26:06, 21.32s/it]  7%|â–‹         | 304/4261 [1:48:03<23:26:01, 21.32s/it]  7%|â–‹         | 305/4261 [1:48:25<23:30:47, 21.40s/it]  7%|â–‹         | 306/4261 [1:48:46<23:28:50, 21.37s/it]  7%|â–‹         | 307/4261 [1:49:07<23:28:11, 21.37s/it]  7%|â–‹         | 308/4261 [1:49:29<23:27:20, 21.36s/it]  7%|â–‹         | 309/4261 [1:49:50<23:26:17, 21.35s/it]  7%|â–‹         | 310/4261 [1:50:11<23:25:46, 21.35s/it]                                                       {'loss': 2.3198, 'learning_rate': 1.9739936962863672e-05, 'epoch': 0.07}
  7%|â–‹         | 310/4261 [1:50:11<23:25:46, 21.35s/it]  7%|â–‹         | 311/4261 [1:50:33<23:24:33, 21.34s/it]  7%|â–‹         | 312/4261 [1:50:54<23:33:50, 21.48s/it]  7%|â–‹         | 313/4261 [1:51:16<23:29:50, 21.43s/it]  7%|â–‹         | 314/4261 [1:51:37<23:27:12, 21.39s/it]  7%|â–‹         | 315/4261 [1:51:58<23:25:28, 21.37s/it]  7%|â–‹         | 316/4261 [1:52:20<23:23:53, 21.35s/it]  7%|â–‹         | 317/4261 [1:52:41<23:23:04, 21.35s/it]  7%|â–‹         | 318/4261 [1:53:02<23:22:35, 21.34s/it]  7%|â–‹         | 319/4261 [1:53:24<23:22:32, 21.35s/it]  8%|â–Š         | 320/4261 [1:53:45<23:22:24, 21.35s/it]                                                       {'loss': 2.3265, 'learning_rate': 1.9722967229663843e-05, 'epoch': 0.08}
  8%|â–Š         | 320/4261 [1:53:45<23:22:24, 21.35s/it]  8%|â–Š         | 321/4261 [1:54:06<23:21:35, 21.34s/it]  8%|â–Š         | 322/4261 [1:54:28<23:20:46, 21.34s/it]  8%|â–Š         | 323/4261 [1:54:49<23:20:26, 21.34s/it]  8%|â–Š         | 324/4261 [1:55:10<23:20:44, 21.35s/it]  8%|â–Š         | 325/4261 [1:55:32<23:20:28, 21.35s/it]  8%|â–Š         | 326/4261 [1:55:53<23:19:46, 21.34s/it]  8%|â–Š         | 327/4261 [1:56:14<23:19:08, 21.34s/it]  8%|â–Š         | 328/4261 [1:56:36<23:18:30, 21.33s/it]  8%|â–Š         | 329/4261 [1:56:57<23:19:05, 21.35s/it]  8%|â–Š         | 330/4261 [1:57:18<23:18:52, 21.35s/it]                                                       {'loss': 2.335, 'learning_rate': 1.970546896173208e-05, 'epoch': 0.08}
  8%|â–Š         | 330/4261 [1:57:18<23:18:52, 21.35s/it]  8%|â–Š         | 331/4261 [1:57:40<23:17:49, 21.34s/it]  8%|â–Š         | 332/4261 [1:58:01<23:21:21, 21.40s/it]  8%|â–Š         | 333/4261 [1:58:23<23:24:33, 21.45s/it]  8%|â–Š         | 334/4261 [1:58:44<23:27:09, 21.50s/it]  8%|â–Š         | 335/4261 [1:59:06<23:22:59, 21.44s/it]  8%|â–Š         | 336/4261 [1:59:27<23:20:45, 21.41s/it]  8%|â–Š         | 337/4261 [1:59:48<23:19:56, 21.41s/it]  8%|â–Š         | 338/4261 [2:00:10<23:18:07, 21.38s/it]  8%|â–Š         | 339/4261 [2:00:31<23:16:21, 21.36s/it]  8%|â–Š         | 340/4261 [2:00:52<23:15:39, 21.36s/it]                                                       {'loss': 2.3282, 'learning_rate': 1.968744311026384e-05, 'epoch': 0.08}
  8%|â–Š         | 340/4261 [2:00:52<23:15:39, 21.36s/it]  8%|â–Š         | 341/4261 [2:01:14<23:15:28, 21.36s/it]  8%|â–Š         | 342/4261 [2:01:35<23:14:25, 21.35s/it]  8%|â–Š         | 343/4261 [2:01:57<23:13:44, 21.34s/it]  8%|â–Š         | 344/4261 [2:02:18<23:13:44, 21.35s/it]  8%|â–Š         | 345/4261 [2:02:39<23:12:26, 21.33s/it]  8%|â–Š         | 346/4261 [2:03:01<23:11:58, 21.33s/it]  8%|â–Š         | 347/4261 [2:03:22<23:11:52, 21.34s/it]  8%|â–Š         | 348/4261 [2:03:43<23:15:28, 21.40s/it]  8%|â–Š         | 349/4261 [2:04:05<23:18:01, 21.44s/it]  8%|â–Š         | 350/4261 [2:04:26<23:14:43, 21.40s/it]                                                       {'loss': 2.329, 'learning_rate': 1.9668890655133723e-05, 'epoch': 0.08}
  8%|â–Š         | 350/4261 [2:04:26<23:14:43, 21.40s/it]  8%|â–Š         | 351/4261 [2:04:48<23:12:59, 21.38s/it]  8%|â–Š         | 352/4261 [2:05:09<23:11:08, 21.35s/it]  8%|â–Š         | 353/4261 [2:05:30<23:09:52, 21.34s/it]  8%|â–Š         | 354/4261 [2:05:51<23:09:07, 21.33s/it]  8%|â–Š         | 355/4261 [2:06:13<23:13:57, 21.41s/it]  8%|â–Š         | 356/4261 [2:06:34<23:11:46, 21.38s/it]  8%|â–Š         | 357/4261 [2:06:56<23:10:26, 21.37s/it]  8%|â–Š         | 358/4261 [2:07:17<23:09:23, 21.36s/it]  8%|â–Š         | 359/4261 [2:07:38<23:08:04, 21.34s/it]  8%|â–Š         | 360/4261 [2:08:00<23:07:28, 21.34s/it]                                                       {'loss': 2.3169, 'learning_rate': 1.9649812604842188e-05, 'epoch': 0.08}
  8%|â–Š         | 360/4261 [2:08:00<23:07:28, 21.34s/it]  8%|â–Š         | 361/4261 [2:08:21<23:07:36, 21.35s/it]  8%|â–Š         | 362/4261 [2:08:42<23:07:29, 21.35s/it]  9%|â–Š         | 363/4261 [2:09:04<23:06:17, 21.34s/it]  9%|â–Š         | 364/4261 [2:09:25<23:09:33, 21.39s/it]  9%|â–Š         | 365/4261 [2:09:47<23:07:25, 21.37s/it]  9%|â–Š         | 366/4261 [2:10:08<23:05:27, 21.34s/it]  9%|â–Š         | 367/4261 [2:10:29<23:04:34, 21.33s/it]  9%|â–Š         | 368/4261 [2:10:50<23:03:15, 21.32s/it]  9%|â–Š         | 369/4261 [2:11:12<23:03:48, 21.33s/it]  9%|â–Š         | 370/4261 [2:11:33<23:03:45, 21.34s/it]                                                       {'loss': 2.3184, 'learning_rate': 1.9630209996460725e-05, 'epoch': 0.09}
  9%|â–Š         | 370/4261 [2:11:33<23:03:45, 21.34s/it]  9%|â–Š         | 371/4261 [2:11:55<23:08:25, 21.42s/it]  9%|â–Š         | 372/4261 [2:12:16<23:06:02, 21.38s/it]  9%|â–‰         | 373/4261 [2:12:37<23:04:24, 21.36s/it]  9%|â–‰         | 374/4261 [2:12:59<23:03:06, 21.35s/it]  9%|â–‰         | 375/4261 [2:13:20<23:01:34, 21.33s/it]  9%|â–‰         | 376/4261 [2:13:41<23:01:01, 21.33s/it]  9%|â–‰         | 377/4261 [2:14:03<23:00:48, 21.33s/it]  9%|â–‰         | 378/4261 [2:14:24<23:00:28, 21.33s/it]  9%|â–‰         | 379/4261 [2:14:45<22:59:59, 21.33s/it]  9%|â–‰         | 380/4261 [2:15:07<23:00:24, 21.34s/it]                                                       {'loss': 2.3264, 'learning_rate': 1.9610083895575508e-05, 'epoch': 0.09}
  9%|â–‰         | 380/4261 [2:15:07<23:00:24, 21.34s/it]  9%|â–‰         | 381/4261 [2:15:28<22:58:50, 21.32s/it]  9%|â–‰         | 382/4261 [2:15:49<22:58:37, 21.32s/it]  9%|â–‰         | 383/4261 [2:16:11<22:57:58, 21.32s/it]  9%|â–‰         | 384/4261 [2:16:32<22:57:46, 21.32s/it]  9%|â–‰         | 385/4261 [2:16:53<22:57:32, 21.32s/it]  9%|â–‰         | 386/4261 [2:17:15<23:02:59, 21.41s/it]  9%|â–‰         | 387/4261 [2:17:36<23:00:06, 21.37s/it]  9%|â–‰         | 388/4261 [2:17:57<22:58:17, 21.35s/it]  9%|â–‰         | 389/4261 [2:18:19<22:57:31, 21.35s/it]  9%|â–‰         | 390/4261 [2:18:40<22:56:08, 21.33s/it]                                                       {'loss': 2.3311, 'learning_rate': 1.9589435396229444e-05, 'epoch': 0.09}
  9%|â–‰         | 390/4261 [2:18:40<22:56:08, 21.33s/it]  9%|â–‰         | 391/4261 [2:19:01<22:55:50, 21.33s/it]  9%|â–‰         | 392/4261 [2:19:23<22:57:54, 21.37s/it]  9%|â–‰         | 393/4261 [2:19:44<22:58:38, 21.39s/it]  9%|â–‰         | 394/4261 [2:20:06<22:59:33, 21.41s/it]  9%|â–‰         | 395/4261 [2:20:27<22:59:39, 21.41s/it]  9%|â–‰         | 396/4261 [2:20:49<22:58:39, 21.40s/it]  9%|â–‰         | 397/4261 [2:21:10<22:57:58, 21.40s/it]  9%|â–‰         | 398/4261 [2:21:31<22:58:12, 21.41s/it]  9%|â–‰         | 399/4261 [2:21:53<22:58:23, 21.41s/it]  9%|â–‰         | 400/4261 [2:22:15<23:04:43, 21.52s/it]                                                       {'loss': 2.3408, 'learning_rate': 1.956826562086271e-05, 'epoch': 0.09}
  9%|â–‰         | 400/4261 [2:22:15<23:04:43, 21.52s/it]  9%|â–‰         | 401/4261 [2:22:36<23:03:25, 21.50s/it]  9%|â–‰         | 402/4261 [2:22:58<23:02:32, 21.50s/it]  9%|â–‰         | 403/4261 [2:23:19<23:01:18, 21.48s/it]  9%|â–‰         | 404/4261 [2:23:40<22:59:32, 21.46s/it] 10%|â–‰         | 405/4261 [2:24:02<22:59:04, 21.46s/it] 10%|â–‰         | 406/4261 [2:24:23<22:59:15, 21.47s/it] 10%|â–‰         | 407/4261 [2:24:45<22:58:58, 21.47s/it] 10%|â–‰         | 408/4261 [2:25:06<22:56:42, 21.44s/it] 10%|â–‰         | 409/4261 [2:25:27<22:54:32, 21.41s/it] 10%|â–‰         | 410/4261 [2:25:49<22:53:16, 21.40s/it]                                                       {'loss': 2.3137, 'learning_rate': 1.9546575720251734e-05, 'epoch': 0.1}
 10%|â–‰         | 410/4261 [2:25:49<22:53:16, 21.40s/it] 10%|â–‰         | 411/4261 [2:26:10<22:51:57, 21.38s/it] 10%|â–‰         | 412/4261 [2:26:32<22:51:25, 21.38s/it] 10%|â–‰         | 413/4261 [2:26:53<22:52:40, 21.40s/it] 10%|â–‰         | 414/4261 [2:27:15<22:54:12, 21.43s/it] 10%|â–‰         | 415/4261 [2:27:36<22:54:28, 21.44s/it] 10%|â–‰         | 416/4261 [2:27:57<22:53:10, 21.43s/it] 10%|â–‰         | 417/4261 [2:28:19<22:56:08, 21.48s/it] 10%|â–‰         | 418/4261 [2:28:40<22:52:08, 21.42s/it] 10%|â–‰         | 419/4261 [2:29:02<22:49:42, 21.39s/it] 10%|â–‰         | 420/4261 [2:29:23<22:48:22, 21.38s/it]                                                       {'loss': 2.3294, 'learning_rate': 1.9524366873446653e-05, 'epoch': 0.1}
 10%|â–‰         | 420/4261 [2:29:23<22:48:22, 21.38s/it] 10%|â–‰         | 421/4261 [2:29:44<22:48:55, 21.39s/it] 10%|â–‰         | 422/4261 [2:30:06<22:49:55, 21.41s/it] 10%|â–‰         | 423/4261 [2:30:27<22:50:14, 21.42s/it] 10%|â–‰         | 424/4261 [2:30:49<22:50:23, 21.43s/it] 10%|â–‰         | 425/4261 [2:31:10<22:50:38, 21.44s/it] 10%|â–‰         | 426/4261 [2:31:32<22:49:17, 21.42s/it] 10%|â–ˆ         | 427/4261 [2:31:53<22:48:09, 21.41s/it] 10%|â–ˆ         | 428/4261 [2:32:14<22:49:06, 21.43s/it] 10%|â–ˆ         | 429/4261 [2:32:36<22:49:43, 21.45s/it] 10%|â–ˆ         | 430/4261 [2:32:58<22:54:06, 21.52s/it]                                                       {'loss': 2.32, 'learning_rate': 1.9501640287707208e-05, 'epoch': 0.1}
 10%|â–ˆ         | 430/4261 [2:32:58<22:54:06, 21.52s/it] 10%|â–ˆ         | 431/4261 [2:33:19<22:52:16, 21.50s/it] 10%|â–ˆ         | 432/4261 [2:33:40<22:49:33, 21.46s/it] 10%|â–ˆ         | 433/4261 [2:34:02<22:46:56, 21.43s/it] 10%|â–ˆ         | 434/4261 [2:34:23<22:44:36, 21.39s/it] 10%|â–ˆ         | 435/4261 [2:34:44<22:42:56, 21.37s/it] 10%|â–ˆ         | 436/4261 [2:35:06<22:41:05, 21.35s/it] 10%|â–ˆ         | 437/4261 [2:35:27<22:39:40, 21.33s/it] 10%|â–ˆ         | 438/4261 [2:35:48<22:39:45, 21.34s/it] 10%|â–ˆ         | 439/4261 [2:36:10<22:43:40, 21.41s/it] 10%|â–ˆ         | 440/4261 [2:36:31<22:41:36, 21.38s/it]                                                       {'loss': 2.3268, 'learning_rate': 1.947839719843712e-05, 'epoch': 0.1}
 10%|â–ˆ         | 440/4261 [2:36:31<22:41:36, 21.38s/it] 10%|â–ˆ         | 441/4261 [2:36:53<22:39:54, 21.36s/it] 10%|â–ˆ         | 442/4261 [2:37:14<22:38:50, 21.35s/it] 10%|â–ˆ         | 443/4261 [2:37:35<22:38:29, 21.35s/it] 10%|â–ˆ         | 444/4261 [2:37:57<22:37:33, 21.34s/it] 10%|â–ˆ         | 445/4261 [2:38:18<22:36:36, 21.33s/it] 10%|â–ˆ         | 446/4261 [2:38:39<22:40:18, 21.39s/it] 10%|â–ˆ         | 447/4261 [2:39:01<22:38:10, 21.37s/it] 11%|â–ˆ         | 448/4261 [2:39:22<22:36:02, 21.34s/it] 11%|â–ˆ         | 449/4261 [2:39:43<22:35:07, 21.33s/it] 11%|â–ˆ         | 450/4261 [2:40:05<22:38:57, 21.40s/it]                                                       {'loss': 2.3236, 'learning_rate': 1.945463886911694e-05, 'epoch': 0.11}
 11%|â–ˆ         | 450/4261 [2:40:05<22:38:57, 21.40s/it] 11%|â–ˆ         | 451/4261 [2:40:26<22:36:57, 21.37s/it] 11%|â–ˆ         | 452/4261 [2:40:47<22:35:54, 21.36s/it] 11%|â–ˆ         | 453/4261 [2:41:09<22:36:07, 21.37s/it] 11%|â–ˆ         | 454/4261 [2:41:30<22:36:49, 21.38s/it] 11%|â–ˆ         | 455/4261 [2:41:52<22:37:47, 21.41s/it] 11%|â–ˆ         | 456/4261 [2:42:13<22:39:18, 21.43s/it] 11%|â–ˆ         | 457/4261 [2:42:35<22:39:17, 21.44s/it] 11%|â–ˆ         | 458/4261 [2:42:56<22:36:18, 21.40s/it] 11%|â–ˆ         | 459/4261 [2:43:17<22:33:07, 21.35s/it] 11%|â–ˆ         | 460/4261 [2:43:39<22:31:28, 21.33s/it]                                                       {'loss': 2.3291, 'learning_rate': 1.9430366591235346e-05, 'epoch': 0.11}
 11%|â–ˆ         | 460/4261 [2:43:39<22:31:28, 21.33s/it] 11%|â–ˆ         | 461/4261 [2:44:00<22:30:31, 21.32s/it] 11%|â–ˆ         | 462/4261 [2:44:21<22:29:06, 21.31s/it] 11%|â–ˆ         | 463/4261 [2:44:42<22:28:47, 21.31s/it] 11%|â–ˆ         | 464/4261 [2:45:04<22:29:02, 21.32s/it] 11%|â–ˆ         | 465/4261 [2:45:25<22:28:35, 21.32s/it] 11%|â–ˆ         | 466/4261 [2:45:47<22:32:45, 21.39s/it] 11%|â–ˆ         | 467/4261 [2:46:08<22:35:20, 21.43s/it] 11%|â–ˆ         | 468/4261 [2:46:30<22:38:00, 21.48s/it] 11%|â–ˆ         | 469/4261 [2:46:51<22:34:07, 21.43s/it] 11%|â–ˆ         | 470/4261 [2:47:12<22:31:21, 21.39s/it]                                                       {'loss': 2.3313, 'learning_rate': 1.9405581684218985e-05, 'epoch': 0.11}
 11%|â–ˆ         | 470/4261 [2:47:12<22:31:21, 21.39s/it] 11%|â–ˆ         | 471/4261 [2:47:34<22:29:34, 21.37s/it] 11%|â–ˆ         | 472/4261 [2:47:55<22:28:17, 21.35s/it] 11%|â–ˆ         | 473/4261 [2:48:16<22:26:51, 21.33s/it] 11%|â–ˆ         | 474/4261 [2:48:38<22:26:18, 21.33s/it] 11%|â–ˆ         | 475/4261 [2:48:59<22:25:28, 21.32s/it] 11%|â–ˆ         | 476/4261 [2:49:20<22:24:43, 21.32s/it] 11%|â–ˆ         | 477/4261 [2:49:42<22:24:39, 21.32s/it] 11%|â–ˆ         | 478/4261 [2:50:03<22:24:12, 21.32s/it] 11%|â–ˆ         | 479/4261 [2:50:24<22:22:50, 21.30s/it] 11%|â–ˆâ–        | 480/4261 [2:50:45<22:22:42, 21.31s/it]                                                       {'loss': 2.3384, 'learning_rate': 1.938028549536069e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 480/4261 [2:50:45<22:22:42, 21.31s/it] 11%|â–ˆâ–        | 481/4261 [2:51:07<22:22:32, 21.31s/it] 11%|â–ˆâ–        | 482/4261 [2:51:28<22:23:02, 21.32s/it] 11%|â–ˆâ–        | 483/4261 [2:51:50<22:26:47, 21.39s/it] 11%|â–ˆâ–        | 484/4261 [2:52:11<22:25:09, 21.37s/it] 11%|â–ˆâ–        | 485/4261 [2:52:32<22:24:00, 21.36s/it] 11%|â–ˆâ–        | 486/4261 [2:52:54<22:23:16, 21.35s/it] 11%|â–ˆâ–        | 487/4261 [2:53:15<22:22:43, 21.35s/it] 11%|â–ˆâ–        | 488/4261 [2:53:36<22:21:54, 21.34s/it] 11%|â–ˆâ–        | 489/4261 [2:53:58<22:25:49, 21.41s/it] 11%|â–ˆâ–        | 490/4261 [2:54:19<22:24:06, 21.39s/it]                                                       {'loss': 2.3342, 'learning_rate': 1.9354479399746288e-05, 'epoch': 0.11}
 11%|â–ˆâ–        | 490/4261 [2:54:19<22:24:06, 21.39s/it] 12%|â–ˆâ–        | 491/4261 [2:54:41<22:22:52, 21.37s/it] 12%|â–ˆâ–        | 492/4261 [2:55:02<22:21:31, 21.36s/it] 12%|â–ˆâ–        | 493/4261 [2:55:23<22:20:47, 21.35s/it] 12%|â–ˆâ–        | 494/4261 [2:55:44<22:19:47, 21.34s/it] 12%|â–ˆâ–        | 495/4261 [2:56:06<22:19:18, 21.34s/it] 12%|â–ˆâ–        | 496/4261 [2:56:27<22:18:38, 21.33s/it] 12%|â–ˆâ–        | 497/4261 [2:56:48<22:17:53, 21.33s/it] 12%|â–ˆâ–        | 498/4261 [2:57:10<22:21:37, 21.39s/it] 12%|â–ˆâ–        | 499/4261 [2:57:31<22:19:12, 21.36s/it] 12%|â–ˆâ–        | 500/4261 [2:57:53<22:17:46, 21.34s/it]                                                       {'loss': 2.3317, 'learning_rate': 1.9328164800179835e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 500/4261 [2:57:53<22:17:46, 21.34s/it] 12%|â–ˆâ–        | 501/4261 [2:58:14<22:16:08, 21.32s/it] 12%|â–ˆâ–        | 502/4261 [2:58:35<22:15:12, 21.31s/it] 12%|â–ˆâ–        | 503/4261 [2:58:56<22:15:21, 21.32s/it] 12%|â–ˆâ–        | 504/4261 [2:59:18<22:15:17, 21.32s/it] 12%|â–ˆâ–        | 505/4261 [2:59:39<22:20:05, 21.41s/it] 12%|â–ˆâ–        | 506/4261 [3:00:01<22:17:33, 21.37s/it] 12%|â–ˆâ–        | 507/4261 [3:00:22<22:15:39, 21.35s/it] 12%|â–ˆâ–        | 508/4261 [3:00:43<22:14:45, 21.34s/it] 12%|â–ˆâ–        | 509/4261 [3:01:05<22:14:05, 21.33s/it] 12%|â–ˆâ–        | 510/4261 [3:01:26<22:13:48, 21.34s/it]                                                       {'loss': 2.3293, 'learning_rate': 1.9301343127107352e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 510/4261 [3:01:26<22:13:48, 21.34s/it] 12%|â–ˆâ–        | 511/4261 [3:01:47<22:13:11, 21.33s/it] 12%|â–ˆâ–        | 512/4261 [3:02:09<22:12:12, 21.32s/it] 12%|â–ˆâ–        | 513/4261 [3:02:30<22:11:49, 21.32s/it] 12%|â–ˆâ–        | 514/4261 [3:02:51<22:12:20, 21.33s/it] 12%|â–ˆâ–        | 515/4261 [3:03:13<22:11:35, 21.33s/it] 12%|â–ˆâ–        | 516/4261 [3:03:34<22:11:13, 21.33s/it] 12%|â–ˆâ–        | 517/4261 [3:03:55<22:10:46, 21.33s/it] 12%|â–ˆâ–        | 518/4261 [3:04:17<22:14:55, 21.40s/it] 12%|â–ˆâ–        | 519/4261 [3:04:38<22:12:08, 21.36s/it] 12%|â–ˆâ–        | 520/4261 [3:05:00<22:15:06, 21.41s/it]                                                       {'loss': 2.3269, 'learning_rate': 1.927401583853908e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 520/4261 [3:05:00<22:15:06, 21.41s/it] 12%|â–ˆâ–        | 521/4261 [3:05:21<22:12:17, 21.37s/it] 12%|â–ˆâ–        | 522/4261 [3:05:42<22:10:30, 21.35s/it] 12%|â–ˆâ–        | 523/4261 [3:06:04<22:09:32, 21.34s/it] 12%|â–ˆâ–        | 524/4261 [3:06:25<22:08:42, 21.33s/it] 12%|â–ˆâ–        | 525/4261 [3:06:46<22:07:33, 21.32s/it] 12%|â–ˆâ–        | 526/4261 [3:07:07<22:07:17, 21.32s/it] 12%|â–ˆâ–        | 527/4261 [3:07:29<22:06:16, 21.31s/it] 12%|â–ˆâ–        | 528/4261 [3:07:50<22:05:34, 21.31s/it] 12%|â–ˆâ–        | 529/4261 [3:08:11<22:05:01, 21.30s/it] 12%|â–ˆâ–        | 530/4261 [3:08:33<22:04:46, 21.30s/it]                                                       {'loss': 2.3235, 'learning_rate': 1.9246184419970216e-05, 'epoch': 0.12}
 12%|â–ˆâ–        | 530/4261 [3:08:33<22:04:46, 21.30s/it] 12%|â–ˆâ–        | 531/4261 [3:08:54<22:04:40, 21.31s/it] 12%|â–ˆâ–        | 532/4261 [3:09:15<22:04:30, 21.31s/it] 13%|â–ˆâ–Ž        | 533/4261 [3:09:37<22:05:11, 21.33s/it] 13%|â–ˆâ–Ž        | 534/4261 [3:09:58<22:04:13, 21.32s/it] 13%|â–ˆâ–Ž        | 535/4261 [3:10:19<22:03:34, 21.31s/it] 13%|â–ˆâ–Ž        | 536/4261 [3:10:41<22:03:57, 21.33s/it] 13%|â–ˆâ–Ž        | 537/4261 [3:11:02<22:03:45, 21.33s/it] 13%|â–ˆâ–Ž        | 538/4261 [3:11:23<22:03:38, 21.33s/it] 13%|â–ˆâ–Ž        | 539/4261 [3:11:45<22:02:56, 21.33s/it] 13%|â–ˆâ–Ž        | 540/4261 [3:12:06<22:02:35, 21.33s/it]                                                       {'loss': 2.3365, 'learning_rate': 1.9217850384300174e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 540/4261 [3:12:06<22:02:35, 21.33s/it] 13%|â–ˆâ–Ž        | 541/4261 [3:12:27<22:02:28, 21.33s/it] 13%|â–ˆâ–Ž        | 542/4261 [3:12:49<22:01:57, 21.33s/it] 13%|â–ˆâ–Ž        | 543/4261 [3:13:10<22:00:56, 21.32s/it] 13%|â–ˆâ–Ž        | 544/4261 [3:13:31<22:00:16, 21.31s/it] 13%|â–ˆâ–Ž        | 545/4261 [3:13:52<22:00:07, 21.32s/it] 13%|â–ˆâ–Ž        | 546/4261 [3:14:14<21:59:10, 21.31s/it] 13%|â–ˆâ–Ž        | 547/4261 [3:14:35<22:02:55, 21.37s/it] 13%|â–ˆâ–Ž        | 548/4261 [3:14:57<22:01:05, 21.35s/it] 13%|â–ˆâ–Ž        | 549/4261 [3:15:18<21:59:08, 21.32s/it] 13%|â–ˆâ–Ž        | 550/4261 [3:15:39<21:58:21, 21.32s/it]                                                       {'loss': 2.3267, 'learning_rate': 1.9189015271750317e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 550/4261 [3:15:39<21:58:21, 21.32s/it] 13%|â–ˆâ–Ž        | 551/4261 [3:16:01<22:01:33, 21.37s/it] 13%|â–ˆâ–Ž        | 552/4261 [3:16:22<21:59:13, 21.34s/it] 13%|â–ˆâ–Ž        | 553/4261 [3:16:43<21:58:07, 21.33s/it] 13%|â–ˆâ–Ž        | 554/4261 [3:17:05<21:57:48, 21.33s/it] 13%|â–ˆâ–Ž        | 555/4261 [3:17:26<21:57:11, 21.33s/it] 13%|â–ˆâ–Ž        | 556/4261 [3:17:47<21:56:10, 21.31s/it] 13%|â–ˆâ–Ž        | 557/4261 [3:18:08<21:55:50, 21.31s/it] 13%|â–ˆâ–Ž        | 558/4261 [3:18:30<21:55:44, 21.32s/it] 13%|â–ˆâ–Ž        | 559/4261 [3:18:51<21:55:23, 21.32s/it] 13%|â–ˆâ–Ž        | 560/4261 [3:19:12<21:54:48, 21.32s/it]                                                       {'loss': 2.3238, 'learning_rate': 1.9159680649780272e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 560/4261 [3:19:12<21:54:48, 21.32s/it] 13%|â–ˆâ–Ž        | 561/4261 [3:19:34<21:54:39, 21.32s/it] 13%|â–ˆâ–Ž        | 562/4261 [3:19:55<21:54:13, 21.32s/it] 13%|â–ˆâ–Ž        | 563/4261 [3:20:16<21:54:15, 21.32s/it] 13%|â–ˆâ–Ž        | 564/4261 [3:20:38<21:53:45, 21.32s/it] 13%|â–ˆâ–Ž        | 565/4261 [3:20:59<21:53:21, 21.32s/it] 13%|â–ˆâ–Ž        | 566/4261 [3:21:20<21:52:29, 21.31s/it] 13%|â–ˆâ–Ž        | 567/4261 [3:21:42<21:51:53, 21.31s/it] 13%|â–ˆâ–Ž        | 568/4261 [3:22:03<21:55:52, 21.38s/it] 13%|â–ˆâ–Ž        | 569/4261 [3:22:24<21:53:38, 21.35s/it] 13%|â–ˆâ–Ž        | 570/4261 [3:22:46<21:52:30, 21.34s/it]                                                       {'loss': 2.3312, 'learning_rate': 1.9129848113002685e-05, 'epoch': 0.13}
 13%|â–ˆâ–Ž        | 570/4261 [3:22:46<21:52:30, 21.34s/it] 13%|â–ˆâ–Ž        | 571/4261 [3:23:07<21:51:41, 21.33s/it] 13%|â–ˆâ–Ž        | 572/4261 [3:23:28<21:50:52, 21.32s/it] 13%|â–ˆâ–Ž        | 573/4261 [3:23:50<21:53:58, 21.38s/it] 13%|â–ˆâ–Ž        | 574/4261 [3:24:11<21:52:36, 21.36s/it] 13%|â–ˆâ–Ž        | 575/4261 [3:24:33<21:50:49, 21.34s/it] 14%|â–ˆâ–Ž        | 576/4261 [3:24:54<21:49:37, 21.32s/it] 14%|â–ˆâ–Ž        | 577/4261 [3:25:15<21:48:39, 21.31s/it] 14%|â–ˆâ–Ž        | 578/4261 [3:25:36<21:47:54, 21.31s/it] 14%|â–ˆâ–Ž        | 579/4261 [3:25:58<21:47:23, 21.30s/it] 14%|â–ˆâ–Ž        | 580/4261 [3:26:19<21:51:48, 21.38s/it]                                                       {'loss': 2.3302, 'learning_rate': 1.9099519283096562e-05, 'epoch': 0.14}
 14%|â–ˆâ–Ž        | 580/4261 [3:26:19<21:51:48, 21.38s/it] 14%|â–ˆâ–Ž        | 581/4261 [3:26:40<21:48:56, 21.34s/it] 14%|â–ˆâ–Ž        | 582/4261 [3:27:02<21:47:08, 21.32s/it] 14%|â–ˆâ–Ž        | 583/4261 [3:27:23<21:46:07, 21.31s/it] 14%|â–ˆâ–Ž        | 584/4261 [3:27:45<21:50:16, 21.38s/it] 14%|â–ˆâ–Ž        | 585/4261 [3:28:06<21:47:57, 21.35s/it] 14%|â–ˆâ–        | 586/4261 [3:28:27<21:46:42, 21.33s/it] 14%|â–ˆâ–        | 587/4261 [3:28:49<21:46:41, 21.34s/it] 14%|â–ˆâ–        | 588/4261 [3:29:10<21:45:23, 21.32s/it] 14%|â–ˆâ–        | 589/4261 [3:29:31<21:44:40, 21.32s/it] 14%|â–ˆâ–        | 590/4261 [3:29:52<21:43:34, 21.31s/it]                                                       {'loss': 2.3253, 'learning_rate': 1.906869580871911e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 590/4261 [3:29:52<21:43:34, 21.31s/it] 14%|â–ˆâ–        | 591/4261 [3:30:14<21:43:41, 21.31s/it] 14%|â–ˆâ–        | 592/4261 [3:30:35<21:43:25, 21.32s/it] 14%|â–ˆâ–        | 593/4261 [3:30:56<21:42:57, 21.31s/it] 14%|â–ˆâ–        | 594/4261 [3:31:18<21:44:39, 21.35s/it] 14%|â–ˆâ–        | 595/4261 [3:31:39<21:45:19, 21.36s/it] 14%|â–ˆâ–        | 596/4261 [3:32:01<21:46:53, 21.40s/it] 14%|â–ˆâ–        | 597/4261 [3:32:22<21:46:57, 21.40s/it] 14%|â–ˆâ–        | 598/4261 [3:32:43<21:45:32, 21.38s/it] 14%|â–ˆâ–        | 599/4261 [3:33:05<21:48:21, 21.44s/it] 14%|â–ˆâ–        | 600/4261 [3:33:26<21:45:26, 21.39s/it]                                                       {'loss': 2.3188, 'learning_rate': 1.9037379365416116e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 600/4261 [3:33:26<21:45:26, 21.39s/it] 14%|â–ˆâ–        | 601/4261 [3:33:48<21:47:45, 21.44s/it] 14%|â–ˆâ–        | 602/4261 [3:34:09<21:49:27, 21.47s/it] 14%|â–ˆâ–        | 603/4261 [3:34:31<21:45:51, 21.42s/it] 14%|â–ˆâ–        | 604/4261 [3:34:52<21:43:28, 21.39s/it] 14%|â–ˆâ–        | 605/4261 [3:35:13<21:41:29, 21.36s/it] 14%|â–ˆâ–        | 606/4261 [3:35:35<21:40:13, 21.34s/it] 14%|â–ˆâ–        | 607/4261 [3:35:56<21:39:08, 21.33s/it] 14%|â–ˆâ–        | 608/4261 [3:36:17<21:38:20, 21.33s/it] 14%|â–ˆâ–        | 609/4261 [3:36:38<21:37:13, 21.31s/it] 14%|â–ˆâ–        | 610/4261 [3:37:00<21:36:27, 21.31s/it]                                                       {'loss': 2.3112, 'learning_rate': 1.900557165553086e-05, 'epoch': 0.14}
 14%|â–ˆâ–        | 610/4261 [3:37:00<21:36:27, 21.31s/it] 14%|â–ˆâ–        | 611/4261 [3:37:21<21:35:56, 21.30s/it] 14%|â–ˆâ–        | 612/4261 [3:37:42<21:35:19, 21.30s/it] 14%|â–ˆâ–        | 613/4261 [3:38:04<21:35:26, 21.31s/it] 14%|â–ˆâ–        | 614/4261 [3:38:25<21:34:34, 21.30s/it] 14%|â–ˆâ–        | 615/4261 [3:38:46<21:35:10, 21.31s/it] 14%|â–ˆâ–        | 616/4261 [3:39:08<21:34:33, 21.31s/it] 14%|â–ˆâ–        | 617/4261 [3:39:29<21:38:25, 21.38s/it] 15%|â–ˆâ–        | 618/4261 [3:39:50<21:36:22, 21.35s/it] 15%|â–ˆâ–        | 619/4261 [3:40:12<21:35:02, 21.34s/it] 15%|â–ˆâ–        | 620/4261 [3:40:33<21:33:03, 21.31s/it]                                                       {'loss': 2.3122, 'learning_rate': 1.897327440811159e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 620/4261 [3:40:33<21:33:03, 21.31s/it] 15%|â–ˆâ–        | 621/4261 [3:40:54<21:32:18, 21.30s/it] 15%|â–ˆâ–        | 622/4261 [3:41:16<21:32:06, 21.30s/it] 15%|â–ˆâ–        | 623/4261 [3:41:37<21:35:52, 21.37s/it] 15%|â–ˆâ–        | 624/4261 [3:41:58<21:33:51, 21.35s/it] 15%|â–ˆâ–        | 625/4261 [3:42:20<21:32:01, 21.32s/it] 15%|â–ˆâ–        | 626/4261 [3:42:41<21:31:32, 21.32s/it] 15%|â–ˆâ–        | 627/4261 [3:43:02<21:30:50, 21.31s/it] 15%|â–ˆâ–        | 628/4261 [3:43:24<21:29:46, 21.30s/it] 15%|â–ˆâ–        | 629/4261 [3:43:45<21:28:58, 21.29s/it] 15%|â–ˆâ–        | 630/4261 [3:44:06<21:28:55, 21.30s/it]                                                       {'loss': 2.3315, 'learning_rate': 1.894048937881752e-05, 'epoch': 0.15}
 15%|â–ˆâ–        | 630/4261 [3:44:06<21:28:55, 21.30s/it] 15%|â–ˆâ–        | 631/4261 [3:44:27<21:28:16, 21.29s/it] 15%|â–ˆâ–        | 632/4261 [3:44:49<21:32:14, 21.37s/it] 15%|â–ˆâ–        | 633/4261 [3:45:10<21:30:53, 21.35s/it] 15%|â–ˆâ–        | 634/4261 [3:45:32<21:29:36, 21.33s/it] 15%|â–ˆâ–        | 635/4261 [3:45:53<21:29:11, 21.33s/it] 15%|â–ˆâ–        | 636/4261 [3:46:14<21:27:45, 21.31s/it] 15%|â–ˆâ–        | 637/4261 [3:46:35<21:27:01, 21.31s/it] 15%|â–ˆâ–        | 638/4261 [3:46:57<21:26:26, 21.30s/it] 15%|â–ˆâ–        | 639/4261 [3:47:18<21:30:16, 21.37s/it] 15%|â–ˆâ–Œ        | 640/4261 [3:47:40<21:28:17, 21.35s/it]                                                       {'loss': 2.32, 'learning_rate': 1.8907218349823394e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 640/4261 [3:47:40<21:28:17, 21.35s/it] 15%|â–ˆâ–Œ        | 641/4261 [3:48:01<21:27:03, 21.33s/it] 15%|â–ˆâ–Œ        | 642/4261 [3:48:22<21:25:44, 21.32s/it] 15%|â–ˆâ–Œ        | 643/4261 [3:48:43<21:24:45, 21.31s/it] 15%|â–ˆâ–Œ        | 644/4261 [3:49:05<21:24:13, 21.30s/it] 15%|â–ˆâ–Œ        | 645/4261 [3:49:26<21:23:10, 21.29s/it] 15%|â–ˆâ–Œ        | 646/4261 [3:49:47<21:22:34, 21.29s/it] 15%|â–ˆâ–Œ        | 647/4261 [3:50:09<21:22:02, 21.28s/it] 15%|â–ˆâ–Œ        | 648/4261 [3:50:30<21:21:45, 21.29s/it] 15%|â–ˆâ–Œ        | 649/4261 [3:50:51<21:21:25, 21.29s/it] 15%|â–ˆâ–Œ        | 650/4261 [3:51:12<21:20:24, 21.28s/it]                                                       {'loss': 2.3387, 'learning_rate': 1.8873463129722625e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 650/4261 [3:51:12<21:20:24, 21.28s/it] 15%|â–ˆâ–Œ        | 651/4261 [3:51:34<21:20:24, 21.28s/it] 15%|â–ˆâ–Œ        | 652/4261 [3:51:55<21:24:37, 21.36s/it] 15%|â–ˆâ–Œ        | 653/4261 [3:52:16<21:22:49, 21.33s/it] 15%|â–ˆâ–Œ        | 654/4261 [3:52:38<21:26:13, 21.40s/it] 15%|â–ˆâ–Œ        | 655/4261 [3:52:59<21:23:18, 21.35s/it] 15%|â–ˆâ–Œ        | 656/4261 [3:53:21<21:21:33, 21.33s/it] 15%|â–ˆâ–Œ        | 657/4261 [3:53:42<21:20:07, 21.31s/it] 15%|â–ˆâ–Œ        | 658/4261 [3:54:03<21:19:40, 21.31s/it] 15%|â–ˆâ–Œ        | 659/4261 [3:54:24<21:19:42, 21.32s/it] 15%|â–ˆâ–Œ        | 660/4261 [3:54:46<21:19:46, 21.32s/it]                                                       {'loss': 2.3202, 'learning_rate': 1.8839225553428945e-05, 'epoch': 0.15}
 15%|â–ˆâ–Œ        | 660/4261 [3:54:46<21:19:46, 21.32s/it] 16%|â–ˆâ–Œ        | 661/4261 [3:55:07<21:18:40, 21.31s/it] 16%|â–ˆâ–Œ        | 662/4261 [3:55:28<21:18:07, 21.31s/it] 16%|â–ˆâ–Œ        | 663/4261 [3:55:50<21:17:35, 21.31s/it] 16%|â–ˆâ–Œ        | 664/4261 [3:56:11<21:17:01, 21.30s/it] 16%|â–ˆâ–Œ        | 665/4261 [3:56:32<21:15:56, 21.29s/it] 16%|â–ˆâ–Œ        | 666/4261 [3:56:54<21:16:01, 21.30s/it] 16%|â–ˆâ–Œ        | 667/4261 [3:57:15<21:16:13, 21.31s/it] 16%|â–ˆâ–Œ        | 668/4261 [3:57:36<21:15:47, 21.30s/it] 16%|â–ˆâ–Œ        | 669/4261 [3:57:57<21:15:53, 21.31s/it] 16%|â–ˆâ–Œ        | 670/4261 [3:58:19<21:15:44, 21.32s/it]                                                       {'loss': 2.3375, 'learning_rate': 1.8804507482076705e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 670/4261 [3:58:19<21:15:44, 21.32s/it] 16%|â–ˆâ–Œ        | 671/4261 [3:58:40<21:15:12, 21.31s/it] 16%|â–ˆâ–Œ        | 672/4261 [3:59:01<21:14:44, 21.31s/it] 16%|â–ˆâ–Œ        | 673/4261 [3:59:23<21:13:53, 21.30s/it] 16%|â–ˆâ–Œ        | 674/4261 [3:59:44<21:13:16, 21.30s/it] 16%|â–ˆâ–Œ        | 675/4261 [4:00:05<21:12:38, 21.29s/it] 16%|â–ˆâ–Œ        | 676/4261 [4:00:27<21:12:25, 21.30s/it] 16%|â–ˆâ–Œ        | 677/4261 [4:00:48<21:12:55, 21.31s/it] 16%|â–ˆâ–Œ        | 678/4261 [4:01:09<21:12:07, 21.30s/it] 16%|â–ˆâ–Œ        | 679/4261 [4:01:30<21:11:41, 21.30s/it] 16%|â–ˆâ–Œ        | 680/4261 [4:01:52<21:11:02, 21.30s/it]                                                       {'loss': 2.3343, 'learning_rate': 1.8769310802919665e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 680/4261 [4:01:52<21:11:02, 21.30s/it] 16%|â–ˆâ–Œ        | 681/4261 [4:02:13<21:14:33, 21.36s/it] 16%|â–ˆâ–Œ        | 682/4261 [4:02:35<21:12:46, 21.34s/it] 16%|â–ˆâ–Œ        | 683/4261 [4:02:56<21:12:14, 21.33s/it] 16%|â–ˆâ–Œ        | 684/4261 [4:03:17<21:11:36, 21.33s/it] 16%|â–ˆâ–Œ        | 685/4261 [4:03:39<21:15:09, 21.40s/it] 16%|â–ˆâ–Œ        | 686/4261 [4:04:00<21:13:25, 21.37s/it] 16%|â–ˆâ–Œ        | 687/4261 [4:04:21<21:11:52, 21.35s/it] 16%|â–ˆâ–Œ        | 688/4261 [4:04:43<21:11:02, 21.34s/it] 16%|â–ˆâ–Œ        | 689/4261 [4:05:04<21:10:34, 21.34s/it] 16%|â–ˆâ–Œ        | 690/4261 [4:05:25<21:09:53, 21.34s/it]                                                       {'loss': 2.338, 'learning_rate': 1.8733637429228434e-05, 'epoch': 0.16}
 16%|â–ˆâ–Œ        | 690/4261 [4:05:25<21:09:53, 21.34s/it] 16%|â–ˆâ–Œ        | 691/4261 [4:05:47<21:09:07, 21.33s/it] 16%|â–ˆâ–Œ        | 692/4261 [4:06:08<21:08:56, 21.33s/it] 16%|â–ˆâ–‹        | 693/4261 [4:06:29<21:08:08, 21.33s/it] 16%|â–ˆâ–‹        | 694/4261 [4:06:51<21:07:27, 21.32s/it] 16%|â–ˆâ–‹        | 695/4261 [4:07:12<21:06:39, 21.31s/it] 16%|â–ˆâ–‹        | 696/4261 [4:07:33<21:06:03, 21.31s/it] 16%|â–ˆâ–‹        | 697/4261 [4:07:55<21:05:53, 21.31s/it] 16%|â–ˆâ–‹        | 698/4261 [4:08:16<21:05:16, 21.31s/it] 16%|â–ˆâ–‹        | 699/4261 [4:08:37<21:05:23, 21.31s/it] 16%|â–ˆâ–‹        | 700/4261 [4:08:58<21:05:09, 21.32s/it]                                                       {'loss': 2.3226, 'learning_rate': 1.8697489300186445e-05, 'epoch': 0.16}
 16%|â–ˆâ–‹        | 700/4261 [4:08:59<21:05:09, 21.32s/it] 16%|â–ˆâ–‹        | 701/4261 [4:09:20<21:09:32, 21.40s/it] 16%|â–ˆâ–‹        | 702/4261 [4:09:41<21:07:03, 21.36s/it] 16%|â–ˆâ–‹        | 703/4261 [4:10:03<21:05:37, 21.34s/it] 17%|â–ˆâ–‹        | 704/4261 [4:10:24<21:05:10, 21.34s/it] 17%|â–ˆâ–‹        | 705/4261 [4:10:45<21:04:34, 21.34s/it] 17%|â–ˆâ–‹        | 706/4261 [4:11:07<21:04:07, 21.34s/it] 17%|â–ˆâ–‹        | 707/4261 [4:11:28<21:08:00, 21.41s/it] 17%|â–ˆâ–‹        | 708/4261 [4:11:50<21:05:52, 21.38s/it] 17%|â–ˆâ–‹        | 709/4261 [4:12:11<21:04:39, 21.36s/it] 17%|â–ˆâ–‹        | 710/4261 [4:12:32<21:03:22, 21.35s/it]                                                       {'loss': 2.3299, 'learning_rate': 1.8660868380784555e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 710/4261 [4:12:32<21:03:22, 21.35s/it] 17%|â–ˆâ–‹        | 711/4261 [4:12:53<21:02:07, 21.33s/it] 17%|â–ˆâ–‹        | 712/4261 [4:13:15<21:01:25, 21.33s/it] 17%|â–ˆâ–‹        | 713/4261 [4:13:36<21:00:56, 21.32s/it] 17%|â–ˆâ–‹        | 714/4261 [4:13:58<21:05:31, 21.41s/it] 17%|â–ˆâ–‹        | 715/4261 [4:14:19<21:03:26, 21.38s/it] 17%|â–ˆâ–‹        | 716/4261 [4:14:40<21:01:34, 21.35s/it] 17%|â–ˆâ–‹        | 717/4261 [4:15:02<21:05:08, 21.42s/it] 17%|â–ˆâ–‹        | 718/4261 [4:15:23<21:03:03, 21.39s/it] 17%|â–ˆâ–‹        | 719/4261 [4:15:45<21:01:05, 21.36s/it] 17%|â–ˆâ–‹        | 720/4261 [4:16:06<21:00:12, 21.35s/it]                                                       {'loss': 2.3363, 'learning_rate': 1.862377666171422e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 720/4261 [4:16:06<21:00:12, 21.35s/it] 17%|â–ˆâ–‹        | 721/4261 [4:16:27<20:59:11, 21.34s/it] 17%|â–ˆâ–‹        | 722/4261 [4:16:48<20:58:25, 21.34s/it] 17%|â–ˆâ–‹        | 723/4261 [4:17:10<20:58:58, 21.35s/it] 17%|â–ˆâ–‹        | 724/4261 [4:17:31<20:58:37, 21.35s/it] 17%|â–ˆâ–‹        | 725/4261 [4:17:53<20:57:51, 21.34s/it] 17%|â–ˆâ–‹        | 726/4261 [4:18:14<20:57:03, 21.34s/it] 17%|â–ˆâ–‹        | 727/4261 [4:18:35<20:56:34, 21.33s/it] 17%|â–ˆâ–‹        | 728/4261 [4:18:57<20:56:07, 21.33s/it] 17%|â–ˆâ–‹        | 729/4261 [4:19:18<20:55:57, 21.34s/it] 17%|â–ˆâ–‹        | 730/4261 [4:19:39<20:55:01, 21.33s/it]                                                       {'loss': 2.3377, 'learning_rate': 1.85862161592593e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 730/4261 [4:19:39<20:55:01, 21.33s/it] 17%|â–ˆâ–‹        | 731/4261 [4:20:00<20:54:16, 21.32s/it] 17%|â–ˆâ–‹        | 732/4261 [4:20:22<20:53:38, 21.31s/it] 17%|â–ˆâ–‹        | 733/4261 [4:20:43<20:53:40, 21.32s/it] 17%|â–ˆâ–‹        | 734/4261 [4:21:04<20:52:59, 21.32s/it] 17%|â–ˆâ–‹        | 735/4261 [4:21:26<20:56:38, 21.38s/it] 17%|â–ˆâ–‹        | 736/4261 [4:21:48<20:59:51, 21.44s/it] 17%|â–ˆâ–‹        | 737/4261 [4:22:09<20:56:58, 21.40s/it] 17%|â–ˆâ–‹        | 738/4261 [4:22:30<20:55:14, 21.38s/it] 17%|â–ˆâ–‹        | 739/4261 [4:22:51<20:53:57, 21.36s/it] 17%|â–ˆâ–‹        | 740/4261 [4:23:13<20:52:57, 21.35s/it]                                                       {'loss': 2.3345, 'learning_rate': 1.8548188915186414e-05, 'epoch': 0.17}
 17%|â–ˆâ–‹        | 740/4261 [4:23:13<20:52:57, 21.35s/it] 17%|â–ˆâ–‹        | 741/4261 [4:23:34<20:51:39, 21.34s/it] 17%|â–ˆâ–‹        | 742/4261 [4:23:55<20:50:30, 21.32s/it] 17%|â–ˆâ–‹        | 743/4261 [4:24:17<20:49:39, 21.31s/it] 17%|â–ˆâ–‹        | 744/4261 [4:24:38<20:49:07, 21.31s/it] 17%|â–ˆâ–‹        | 745/4261 [4:24:59<20:49:00, 21.31s/it] 18%|â–ˆâ–Š        | 746/4261 [4:25:21<20:48:40, 21.31s/it] 18%|â–ˆâ–Š        | 747/4261 [4:25:42<20:48:27, 21.32s/it] 18%|â–ˆâ–Š        | 748/4261 [4:26:03<20:48:06, 21.32s/it] 18%|â–ˆâ–Š        | 749/4261 [4:26:25<20:48:13, 21.32s/it] 18%|â–ˆâ–Š        | 750/4261 [4:26:46<20:48:19, 21.33s/it]                                                       {'loss': 2.329, 'learning_rate': 1.850969699663401e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 750/4261 [4:26:46<20:48:19, 21.33s/it] 18%|â–ˆâ–Š        | 751/4261 [4:27:08<20:51:52, 21.40s/it] 18%|â–ˆâ–Š        | 752/4261 [4:27:29<20:49:49, 21.37s/it] 18%|â–ˆâ–Š        | 753/4261 [4:27:50<20:48:08, 21.35s/it] 18%|â–ˆâ–Š        | 754/4261 [4:28:11<20:47:02, 21.34s/it] 18%|â–ˆâ–Š        | 755/4261 [4:28:33<20:45:49, 21.32s/it] 18%|â–ˆâ–Š        | 756/4261 [4:28:54<20:45:27, 21.32s/it] 18%|â–ˆâ–Š        | 757/4261 [4:29:16<20:49:16, 21.39s/it] 18%|â–ˆâ–Š        | 758/4261 [4:29:37<20:47:51, 21.37s/it] 18%|â–ˆâ–Š        | 759/4261 [4:29:58<20:46:18, 21.35s/it] 18%|â–ˆâ–Š        | 760/4261 [4:30:20<20:45:18, 21.34s/it]                                                       {'loss': 2.321, 'learning_rate': 1.847074249599995e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 760/4261 [4:30:20<20:45:18, 21.34s/it] 18%|â–ˆâ–Š        | 761/4261 [4:30:41<20:44:51, 21.34s/it] 18%|â–ˆâ–Š        | 762/4261 [4:31:02<20:43:35, 21.32s/it] 18%|â–ˆâ–Š        | 763/4261 [4:31:23<20:43:24, 21.33s/it] 18%|â–ˆâ–Š        | 764/4261 [4:31:45<20:43:00, 21.33s/it] 18%|â–ˆâ–Š        | 765/4261 [4:32:06<20:42:31, 21.32s/it] 18%|â–ˆâ–Š        | 766/4261 [4:32:28<20:45:31, 21.38s/it] 18%|â–ˆâ–Š        | 767/4261 [4:32:49<20:44:24, 21.37s/it] 18%|â–ˆâ–Š        | 768/4261 [4:33:10<20:44:06, 21.37s/it] 18%|â–ˆâ–Š        | 769/4261 [4:33:32<20:43:24, 21.36s/it] 18%|â–ˆâ–Š        | 770/4261 [4:33:53<20:46:17, 21.42s/it]                                                       {'loss': 2.3308, 'learning_rate': 1.8431327530827777e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 770/4261 [4:33:53<20:46:17, 21.42s/it] 18%|â–ˆâ–Š        | 771/4261 [4:34:15<20:43:48, 21.38s/it] 18%|â–ˆâ–Š        | 772/4261 [4:34:36<20:42:36, 21.37s/it] 18%|â–ˆâ–Š        | 773/4261 [4:34:57<20:45:22, 21.42s/it] 18%|â–ˆâ–Š        | 774/4261 [4:35:19<20:43:25, 21.40s/it] 18%|â–ˆâ–Š        | 775/4261 [4:35:40<20:41:27, 21.37s/it] 18%|â–ˆâ–Š        | 776/4261 [4:36:01<20:40:20, 21.35s/it] 18%|â–ˆâ–Š        | 777/4261 [4:36:23<20:38:55, 21.34s/it] 18%|â–ˆâ–Š        | 778/4261 [4:36:44<20:38:14, 21.33s/it] 18%|â–ˆâ–Š        | 779/4261 [4:37:05<20:37:37, 21.33s/it] 18%|â–ˆâ–Š        | 780/4261 [4:37:27<20:37:12, 21.32s/it]                                                       {'loss': 2.3461, 'learning_rate': 1.839145424369163e-05, 'epoch': 0.18}
 18%|â–ˆâ–Š        | 780/4261 [4:37:27<20:37:12, 21.32s/it] 18%|â–ˆâ–Š        | 781/4261 [4:37:48<20:36:19, 21.32s/it] 18%|â–ˆâ–Š        | 782/4261 [4:38:09<20:35:22, 21.31s/it] 18%|â–ˆâ–Š        | 783/4261 [4:38:31<20:34:18, 21.29s/it] 18%|â–ˆâ–Š        | 784/4261 [4:38:52<20:34:22, 21.30s/it] 18%|â–ˆâ–Š        | 785/4261 [4:39:13<20:34:05, 21.30s/it] 18%|â–ˆâ–Š        | 786/4261 [4:39:34<20:33:31, 21.30s/it] 18%|â–ˆâ–Š        | 787/4261 [4:39:56<20:32:38, 21.29s/it] 18%|â–ˆâ–Š        | 788/4261 [4:40:17<20:38:56, 21.40s/it] 19%|â–ˆâ–Š        | 789/4261 [4:40:39<20:38:46, 21.41s/it] 19%|â–ˆâ–Š        | 790/4261 [4:41:00<20:39:06, 21.42s/it]                                                       {'loss': 2.3245, 'learning_rate': 1.835112480207974e-05, 'epoch': 0.19}
 19%|â–ˆâ–Š        | 790/4261 [4:41:00<20:39:06, 21.42s/it] 19%|â–ˆâ–Š        | 791/4261 [4:41:22<20:39:05, 21.43s/it] 19%|â–ˆâ–Š        | 792/4261 [4:41:43<20:39:10, 21.43s/it] 19%|â–ˆâ–Š        | 793/4261 [4:42:05<20:39:44, 21.45s/it] 19%|â–ˆâ–Š        | 794/4261 [4:42:26<20:38:25, 21.43s/it] 19%|â–ˆâ–Š        | 795/4261 [4:42:47<20:36:40, 21.41s/it] 19%|â–ˆâ–Š        | 796/4261 [4:43:09<20:34:36, 21.38s/it] 19%|â–ˆâ–Š        | 797/4261 [4:43:30<20:33:29, 21.37s/it] 19%|â–ˆâ–Š        | 798/4261 [4:43:51<20:32:35, 21.36s/it] 19%|â–ˆâ–‰        | 799/4261 [4:44:13<20:35:38, 21.42s/it] 19%|â–ˆâ–‰        | 800/4261 [4:44:34<20:33:45, 21.39s/it]                                                       {'loss': 2.3229, 'learning_rate': 1.8310341398276642e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 800/4261 [4:44:34<20:33:45, 21.39s/it] 19%|â–ˆâ–‰        | 801/4261 [4:44:56<20:32:17, 21.37s/it] 19%|â–ˆâ–‰        | 802/4261 [4:45:17<20:31:03, 21.35s/it] 19%|â–ˆâ–‰        | 803/4261 [4:45:38<20:30:03, 21.34s/it] 19%|â–ˆâ–‰        | 804/4261 [4:45:59<20:29:10, 21.33s/it] 19%|â–ˆâ–‰        | 805/4261 [4:46:21<20:28:08, 21.32s/it] 19%|â–ˆâ–‰        | 806/4261 [4:46:42<20:28:16, 21.33s/it] 19%|â–ˆâ–‰        | 807/4261 [4:47:03<20:27:32, 21.32s/it] 19%|â–ˆâ–‰        | 808/4261 [4:47:25<20:27:04, 21.32s/it] 19%|â–ˆâ–‰        | 809/4261 [4:47:46<20:27:13, 21.33s/it] 19%|â–ˆâ–‰        | 810/4261 [4:48:07<20:27:03, 21.33s/it]                                                       {'loss': 2.3301, 'learning_rate': 1.8269106249243972e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 810/4261 [4:48:07<20:27:03, 21.33s/it] 19%|â–ˆâ–‰        | 811/4261 [4:48:29<20:26:34, 21.33s/it] 19%|â–ˆâ–‰        | 812/4261 [4:48:50<20:25:46, 21.32s/it] 19%|â–ˆâ–‰        | 813/4261 [4:49:11<20:25:27, 21.32s/it] 19%|â–ˆâ–‰        | 814/4261 [4:49:33<20:24:08, 21.31s/it] 19%|â–ˆâ–‰        | 815/4261 [4:49:54<20:23:20, 21.30s/it] 19%|â–ˆâ–‰        | 816/4261 [4:50:15<20:23:09, 21.30s/it] 19%|â–ˆâ–‰        | 817/4261 [4:50:37<20:22:18, 21.29s/it] 19%|â–ˆâ–‰        | 818/4261 [4:50:58<20:21:56, 21.29s/it] 19%|â–ˆâ–‰        | 819/4261 [4:51:19<20:25:52, 21.37s/it] 19%|â–ˆâ–‰        | 820/4261 [4:51:41<20:23:58, 21.34s/it]                                                       {'loss': 2.3267, 'learning_rate': 1.8227421596499977e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 820/4261 [4:51:41<20:23:58, 21.34s/it] 19%|â–ˆâ–‰        | 821/4261 [4:52:02<20:23:33, 21.34s/it] 19%|â–ˆâ–‰        | 822/4261 [4:52:23<20:24:43, 21.37s/it] 19%|â–ˆâ–‰        | 823/4261 [4:52:45<20:25:32, 21.39s/it] 19%|â–ˆâ–‰        | 824/4261 [4:53:06<20:26:25, 21.41s/it] 19%|â–ˆâ–‰        | 825/4261 [4:53:28<20:26:35, 21.42s/it] 19%|â–ˆâ–‰        | 826/4261 [4:53:49<20:26:02, 21.42s/it] 19%|â–ˆâ–‰        | 827/4261 [4:54:11<20:25:19, 21.41s/it] 19%|â–ˆâ–‰        | 828/4261 [4:54:32<20:23:30, 21.38s/it] 19%|â–ˆâ–‰        | 829/4261 [4:54:53<20:22:58, 21.38s/it] 19%|â–ˆâ–‰        | 830/4261 [4:55:15<20:23:36, 21.40s/it]                                                       {'loss': 2.3199, 'learning_rate': 1.8185289705997655e-05, 'epoch': 0.19}
 19%|â–ˆâ–‰        | 830/4261 [4:55:15<20:23:36, 21.40s/it] 20%|â–ˆâ–‰        | 831/4261 [4:55:36<20:23:37, 21.40s/it] 20%|â–ˆâ–‰        | 832/4261 [4:55:58<20:23:59, 21.42s/it] 20%|â–ˆâ–‰        | 833/4261 [4:56:19<20:24:11, 21.43s/it] 20%|â–ˆâ–‰        | 834/4261 [4:56:40<20:22:09, 21.40s/it] 20%|â–ˆâ–‰        | 835/4261 [4:57:02<20:24:05, 21.44s/it] 20%|â–ˆâ–‰        | 836/4261 [4:57:23<20:21:51, 21.40s/it] 20%|â–ˆâ–‰        | 837/4261 [4:57:44<20:19:26, 21.37s/it] 20%|â–ˆâ–‰        | 838/4261 [4:58:06<20:18:28, 21.36s/it] 20%|â–ˆâ–‰        | 839/4261 [4:58:27<20:17:35, 21.35s/it] 20%|â–ˆâ–‰        | 840/4261 [4:58:48<20:16:13, 21.33s/it]                                                       {'loss': 2.318, 'learning_rate': 1.814271286800159e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 840/4261 [4:58:48<20:16:13, 21.33s/it] 20%|â–ˆâ–‰        | 841/4261 [4:59:10<20:19:57, 21.40s/it] 20%|â–ˆâ–‰        | 842/4261 [4:59:31<20:17:48, 21.37s/it] 20%|â–ˆâ–‰        | 843/4261 [4:59:53<20:15:41, 21.34s/it] 20%|â–ˆâ–‰        | 844/4261 [5:00:14<20:14:32, 21.33s/it] 20%|â–ˆâ–‰        | 845/4261 [5:00:35<20:13:25, 21.31s/it] 20%|â–ˆâ–‰        | 846/4261 [5:00:56<20:12:44, 21.31s/it] 20%|â–ˆâ–‰        | 847/4261 [5:01:18<20:12:07, 21.30s/it] 20%|â–ˆâ–‰        | 848/4261 [5:01:39<20:15:54, 21.38s/it] 20%|â–ˆâ–‰        | 849/4261 [5:02:01<20:13:58, 21.35s/it] 20%|â–ˆâ–‰        | 850/4261 [5:02:22<20:12:49, 21.33s/it]                                                       {'loss': 2.3232, 'learning_rate': 1.8099693396963444e-05, 'epoch': 0.2}
 20%|â–ˆâ–‰        | 850/4261 [5:02:22<20:12:49, 21.33s/it] 20%|â–ˆâ–‰        | 851/4261 [5:02:43<20:12:17, 21.33s/it] 20%|â–ˆâ–‰        | 852/4261 [5:03:04<20:10:36, 21.31s/it] 20%|â–ˆâ–ˆ        | 853/4261 [5:03:26<20:09:47, 21.30s/it] 20%|â–ˆâ–ˆ        | 854/4261 [5:03:47<20:09:09, 21.29s/it] 20%|â–ˆâ–ˆ        | 855/4261 [5:04:08<20:09:02, 21.30s/it] 20%|â–ˆâ–ˆ        | 856/4261 [5:04:30<20:08:25, 21.29s/it] 20%|â–ˆâ–ˆ        | 857/4261 [5:04:51<20:08:32, 21.30s/it] 20%|â–ˆâ–ˆ        | 858/4261 [5:05:12<20:08:07, 21.30s/it] 20%|â–ˆâ–ˆ        | 859/4261 [5:05:34<20:07:46, 21.30s/it] 20%|â–ˆâ–ˆ        | 860/4261 [5:05:55<20:07:46, 21.31s/it]                                                       {'loss': 2.3203, 'learning_rate': 1.805623363139614e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 860/4261 [5:05:55<20:07:46, 21.31s/it] 20%|â–ˆâ–ˆ        | 861/4261 [5:06:16<20:06:58, 21.30s/it] 20%|â–ˆâ–ˆ        | 862/4261 [5:06:37<20:06:28, 21.30s/it] 20%|â–ˆâ–ˆ        | 863/4261 [5:06:59<20:06:03, 21.30s/it] 20%|â–ˆâ–ˆ        | 864/4261 [5:07:20<20:06:02, 21.30s/it] 20%|â–ˆâ–ˆ        | 865/4261 [5:07:41<20:05:29, 21.30s/it] 20%|â–ˆâ–ˆ        | 866/4261 [5:08:03<20:05:11, 21.30s/it] 20%|â–ˆâ–ˆ        | 867/4261 [5:08:24<20:05:08, 21.30s/it] 20%|â–ˆâ–ˆ        | 868/4261 [5:08:45<20:04:13, 21.29s/it] 20%|â–ˆâ–ˆ        | 869/4261 [5:09:07<20:08:07, 21.37s/it] 20%|â–ˆâ–ˆ        | 870/4261 [5:09:28<20:10:09, 21.41s/it]                                                       {'loss': 2.3153, 'learning_rate': 1.8012335933746766e-05, 'epoch': 0.2}
 20%|â–ˆâ–ˆ        | 870/4261 [5:09:28<20:10:09, 21.41s/it] 20%|â–ˆâ–ˆ        | 871/4261 [5:09:50<20:08:10, 21.38s/it] 20%|â–ˆâ–ˆ        | 872/4261 [5:10:11<20:06:04, 21.35s/it] 20%|â–ˆâ–ˆ        | 873/4261 [5:10:32<20:04:52, 21.34s/it] 21%|â–ˆâ–ˆ        | 874/4261 [5:10:53<20:03:43, 21.32s/it] 21%|â–ˆâ–ˆ        | 875/4261 [5:11:15<20:03:23, 21.32s/it] 21%|â–ˆâ–ˆ        | 876/4261 [5:11:36<20:03:23, 21.33s/it] 21%|â–ˆâ–ˆ        | 877/4261 [5:11:57<20:02:24, 21.32s/it] 21%|â–ˆâ–ˆ        | 878/4261 [5:12:19<20:01:42, 21.31s/it] 21%|â–ˆâ–ˆ        | 879/4261 [5:12:40<20:01:04, 21.31s/it] 21%|â–ˆâ–ˆ        | 880/4261 [5:13:01<20:00:24, 21.30s/it]                                                       {'loss': 2.3303, 'learning_rate': 1.7968002690268125e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 880/4261 [5:13:01<20:00:24, 21.30s/it] 21%|â–ˆâ–ˆ        | 881/4261 [5:13:23<20:00:28, 21.31s/it] 21%|â–ˆâ–ˆ        | 882/4261 [5:13:44<20:00:14, 21.31s/it] 21%|â–ˆâ–ˆ        | 883/4261 [5:14:05<20:00:13, 21.32s/it] 21%|â–ˆâ–ˆ        | 884/4261 [5:14:27<20:00:12, 21.32s/it] 21%|â–ˆâ–ˆ        | 885/4261 [5:14:48<20:04:04, 21.40s/it] 21%|â–ˆâ–ˆ        | 886/4261 [5:15:10<20:02:27, 21.38s/it] 21%|â–ˆâ–ˆ        | 887/4261 [5:15:31<20:01:51, 21.37s/it] 21%|â–ˆâ–ˆ        | 888/4261 [5:15:52<20:04:40, 21.43s/it] 21%|â–ˆâ–ˆ        | 889/4261 [5:16:14<20:02:10, 21.39s/it] 21%|â–ˆâ–ˆ        | 890/4261 [5:16:35<20:00:58, 21.38s/it]                                                       {'loss': 2.331, 'learning_rate': 1.7923236310889044e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 890/4261 [5:16:35<20:00:58, 21.38s/it] 21%|â–ˆâ–ˆ        | 891/4261 [5:16:57<20:03:14, 21.42s/it] 21%|â–ˆâ–ˆ        | 892/4261 [5:17:18<20:01:24, 21.40s/it] 21%|â–ˆâ–ˆ        | 893/4261 [5:17:39<20:00:41, 21.39s/it] 21%|â–ˆâ–ˆ        | 894/4261 [5:18:01<19:59:40, 21.38s/it] 21%|â–ˆâ–ˆ        | 895/4261 [5:18:22<19:58:46, 21.37s/it] 21%|â–ˆâ–ˆ        | 896/4261 [5:18:43<19:57:27, 21.35s/it] 21%|â–ˆâ–ˆ        | 897/4261 [5:19:05<19:56:39, 21.34s/it] 21%|â–ˆâ–ˆ        | 898/4261 [5:19:26<19:56:14, 21.34s/it] 21%|â–ˆâ–ˆ        | 899/4261 [5:19:47<19:56:19, 21.35s/it] 21%|â–ˆâ–ˆ        | 900/4261 [5:20:09<20:00:14, 21.43s/it]                                                       {'loss': 2.3277, 'learning_rate': 1.787803922908335e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆ        | 900/4261 [5:20:09<20:00:14, 21.43s/it] 21%|â–ˆâ–ˆ        | 901/4261 [5:20:30<19:58:16, 21.40s/it] 21%|â–ˆâ–ˆ        | 902/4261 [5:20:52<19:57:14, 21.39s/it] 21%|â–ˆâ–ˆ        | 903/4261 [5:21:13<19:56:28, 21.38s/it] 21%|â–ˆâ–ˆ        | 904/4261 [5:21:34<19:55:40, 21.37s/it] 21%|â–ˆâ–ˆ        | 905/4261 [5:21:56<19:54:15, 21.35s/it] 21%|â–ˆâ–ˆâ–       | 906/4261 [5:22:17<19:53:37, 21.35s/it] 21%|â–ˆâ–ˆâ–       | 907/4261 [5:22:39<19:56:48, 21.41s/it] 21%|â–ˆâ–ˆâ–       | 908/4261 [5:23:00<19:55:01, 21.38s/it] 21%|â–ˆâ–ˆâ–       | 909/4261 [5:23:21<19:53:14, 21.36s/it] 21%|â–ˆâ–ˆâ–       | 910/4261 [5:23:43<19:52:19, 21.35s/it]                                                       {'loss': 2.3315, 'learning_rate': 1.783241390173761e-05, 'epoch': 0.21}
 21%|â–ˆâ–ˆâ–       | 910/4261 [5:23:43<19:52:19, 21.35s/it] 21%|â–ˆâ–ˆâ–       | 911/4261 [5:24:04<19:51:35, 21.34s/it] 21%|â–ˆâ–ˆâ–       | 912/4261 [5:24:25<19:50:53, 21.34s/it] 21%|â–ˆâ–ˆâ–       | 913/4261 [5:24:47<19:50:53, 21.34s/it] 21%|â–ˆâ–ˆâ–       | 914/4261 [5:25:08<19:50:45, 21.35s/it] 21%|â–ˆâ–ˆâ–       | 915/4261 [5:25:29<19:50:46, 21.35s/it] 21%|â–ˆâ–ˆâ–       | 916/4261 [5:25:51<19:50:48, 21.36s/it] 22%|â–ˆâ–ˆâ–       | 917/4261 [5:26:12<19:54:00, 21.42s/it] 22%|â–ˆâ–ˆâ–       | 918/4261 [5:26:34<19:52:07, 21.40s/it] 22%|â–ˆâ–ˆâ–       | 919/4261 [5:26:55<19:50:11, 21.37s/it] 22%|â–ˆâ–ˆâ–       | 920/4261 [5:27:16<19:49:38, 21.36s/it]                                                       {'loss': 2.3355, 'learning_rate': 1.7786362809017552e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 920/4261 [5:27:16<19:49:38, 21.36s/it] 22%|â–ˆâ–ˆâ–       | 921/4261 [5:27:38<19:49:05, 21.36s/it] 22%|â–ˆâ–ˆâ–       | 922/4261 [5:27:59<19:52:04, 21.42s/it] 22%|â–ˆâ–ˆâ–       | 923/4261 [5:28:20<19:49:40, 21.38s/it] 22%|â–ˆâ–ˆâ–       | 924/4261 [5:28:42<19:48:17, 21.37s/it] 22%|â–ˆâ–ˆâ–       | 925/4261 [5:29:03<19:47:14, 21.35s/it] 22%|â–ˆâ–ˆâ–       | 926/4261 [5:29:24<19:46:20, 21.34s/it] 22%|â–ˆâ–ˆâ–       | 927/4261 [5:29:46<19:46:06, 21.35s/it] 22%|â–ˆâ–ˆâ–       | 928/4261 [5:30:07<19:46:10, 21.35s/it] 22%|â–ˆâ–ˆâ–       | 929/4261 [5:30:28<19:45:43, 21.35s/it] 22%|â–ˆâ–ˆâ–       | 930/4261 [5:30:50<19:44:22, 21.33s/it]                                                       {'loss': 2.3239, 'learning_rate': 1.7739888454233266e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 930/4261 [5:30:50<19:44:22, 21.33s/it] 22%|â–ˆâ–ˆâ–       | 931/4261 [5:31:11<19:44:06, 21.34s/it] 22%|â–ˆâ–ˆâ–       | 932/4261 [5:31:32<19:43:29, 21.33s/it] 22%|â–ˆâ–ˆâ–       | 933/4261 [5:31:54<19:43:32, 21.34s/it] 22%|â–ˆâ–ˆâ–       | 934/4261 [5:32:15<19:43:36, 21.35s/it] 22%|â–ˆâ–ˆâ–       | 935/4261 [5:32:36<19:43:38, 21.35s/it] 22%|â–ˆâ–ˆâ–       | 936/4261 [5:32:58<19:43:27, 21.36s/it] 22%|â–ˆâ–ˆâ–       | 937/4261 [5:33:19<19:46:47, 21.42s/it] 22%|â–ˆâ–ˆâ–       | 938/4261 [5:33:41<19:44:57, 21.40s/it] 22%|â–ˆâ–ˆâ–       | 939/4261 [5:34:02<19:43:57, 21.38s/it] 22%|â–ˆâ–ˆâ–       | 940/4261 [5:34:23<19:43:15, 21.38s/it]                                                       {'loss': 2.3298, 'learning_rate': 1.7692993363703116e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 940/4261 [5:34:23<19:43:15, 21.38s/it] 22%|â–ˆâ–ˆâ–       | 941/4261 [5:34:45<19:43:20, 21.39s/it] 22%|â–ˆâ–ˆâ–       | 942/4261 [5:35:06<19:42:00, 21.37s/it] 22%|â–ˆâ–ˆâ–       | 943/4261 [5:35:28<19:41:20, 21.36s/it] 22%|â–ˆâ–ˆâ–       | 944/4261 [5:35:49<19:40:47, 21.36s/it] 22%|â–ˆâ–ˆâ–       | 945/4261 [5:36:10<19:40:27, 21.36s/it] 22%|â–ˆâ–ˆâ–       | 946/4261 [5:36:32<19:39:32, 21.35s/it] 22%|â–ˆâ–ˆâ–       | 947/4261 [5:36:53<19:38:59, 21.35s/it] 22%|â–ˆâ–ˆâ–       | 948/4261 [5:37:14<19:38:29, 21.34s/it] 22%|â–ˆâ–ˆâ–       | 949/4261 [5:37:36<19:37:57, 21.34s/it] 22%|â–ˆâ–ˆâ–       | 950/4261 [5:37:57<19:37:57, 21.35s/it]                                                       {'loss': 2.32, 'learning_rate': 1.7645680086616408e-05, 'epoch': 0.22}
 22%|â–ˆâ–ˆâ–       | 950/4261 [5:37:57<19:37:57, 21.35s/it] 22%|â–ˆâ–ˆâ–       | 951/4261 [5:38:18<19:37:42, 21.35s/it] 22%|â–ˆâ–ˆâ–       | 952/4261 [5:38:40<19:38:06, 21.36s/it] 22%|â–ˆâ–ˆâ–       | 953/4261 [5:39:02<19:45:39, 21.51s/it] 22%|â–ˆâ–ˆâ–       | 954/4261 [5:39:23<19:41:44, 21.44s/it] 22%|â–ˆâ–ˆâ–       | 955/4261 [5:39:44<19:39:49, 21.41s/it] 22%|â–ˆâ–ˆâ–       | 956/4261 [5:40:05<19:38:12, 21.39s/it] 22%|â–ˆâ–ˆâ–       | 957/4261 [5:40:27<19:36:10, 21.36s/it] 22%|â–ˆâ–ˆâ–       | 958/4261 [5:40:48<19:35:55, 21.36s/it] 23%|â–ˆâ–ˆâ–Ž       | 959/4261 [5:41:10<19:35:24, 21.36s/it] 23%|â–ˆâ–ˆâ–Ž       | 960/4261 [5:41:31<19:34:57, 21.36s/it]                                                       {'loss': 2.3184, 'learning_rate': 1.7597951194894823e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 960/4261 [5:41:31<19:34:57, 21.36s/it] 23%|â–ˆâ–ˆâ–Ž       | 961/4261 [5:41:52<19:35:02, 21.36s/it] 23%|â–ˆâ–ˆâ–Ž       | 962/4261 [5:42:14<19:34:16, 21.36s/it] 23%|â–ˆâ–ˆâ–Ž       | 963/4261 [5:42:35<19:33:40, 21.35s/it] 23%|â–ˆâ–ˆâ–Ž       | 964/4261 [5:42:56<19:34:01, 21.37s/it] 23%|â–ˆâ–ˆâ–Ž       | 965/4261 [5:43:18<19:33:51, 21.37s/it] 23%|â–ˆâ–ˆâ–Ž       | 966/4261 [5:43:39<19:33:46, 21.37s/it] 23%|â–ˆâ–ˆâ–Ž       | 967/4261 [5:44:00<19:33:11, 21.37s/it] 23%|â–ˆâ–ˆâ–Ž       | 968/4261 [5:44:22<19:32:51, 21.37s/it] 23%|â–ˆâ–ˆâ–Ž       | 969/4261 [5:44:43<19:32:50, 21.38s/it] 23%|â–ˆâ–ˆâ–Ž       | 970/4261 [5:45:05<19:31:44, 21.36s/it]                                                       {'loss': 2.3357, 'learning_rate': 1.7549809283052604e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 970/4261 [5:45:05<19:31:44, 21.36s/it] 23%|â–ˆâ–ˆâ–Ž       | 971/4261 [5:45:26<19:31:48, 21.37s/it] 23%|â–ˆâ–ˆâ–Ž       | 972/4261 [5:45:47<19:31:11, 21.37s/it] 23%|â–ˆâ–ˆâ–Ž       | 973/4261 [5:46:09<19:30:22, 21.36s/it] 23%|â–ˆâ–ˆâ–Ž       | 974/4261 [5:46:30<19:29:24, 21.35s/it] 23%|â–ˆâ–ˆâ–Ž       | 975/4261 [5:46:52<19:32:56, 21.42s/it] 23%|â–ˆâ–ˆâ–Ž       | 976/4261 [5:47:13<19:31:25, 21.40s/it] 23%|â–ˆâ–ˆâ–Ž       | 977/4261 [5:47:34<19:29:50, 21.37s/it] 23%|â–ˆâ–ˆâ–Ž       | 978/4261 [5:47:56<19:29:37, 21.38s/it] 23%|â–ˆâ–ˆâ–Ž       | 979/4261 [5:48:17<19:28:44, 21.37s/it] 23%|â–ˆâ–ˆâ–Ž       | 980/4261 [5:48:38<19:27:28, 21.35s/it]                                                       {'loss': 2.3376, 'learning_rate': 1.7501256968055535e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 980/4261 [5:48:38<19:27:28, 21.35s/it] 23%|â–ˆâ–ˆâ–Ž       | 981/4261 [5:49:00<19:26:45, 21.34s/it] 23%|â–ˆâ–ˆâ–Ž       | 982/4261 [5:49:21<19:30:40, 21.42s/it] 23%|â–ˆâ–ˆâ–Ž       | 983/4261 [5:49:42<19:28:41, 21.39s/it] 23%|â–ˆâ–ˆâ–Ž       | 984/4261 [5:50:04<19:26:53, 21.37s/it] 23%|â–ˆâ–ˆâ–Ž       | 985/4261 [5:50:25<19:25:46, 21.35s/it] 23%|â–ˆâ–ˆâ–Ž       | 986/4261 [5:50:46<19:24:13, 21.33s/it] 23%|â–ˆâ–ˆâ–Ž       | 987/4261 [5:51:08<19:23:55, 21.33s/it] 23%|â–ˆâ–ˆâ–Ž       | 988/4261 [5:51:29<19:23:39, 21.33s/it] 23%|â–ˆâ–ˆâ–Ž       | 989/4261 [5:51:50<19:23:46, 21.34s/it] 23%|â–ˆâ–ˆâ–Ž       | 990/4261 [5:52:12<19:23:35, 21.34s/it]                                                       {'loss': 2.3236, 'learning_rate': 1.7452296889178655e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 990/4261 [5:52:12<19:23:35, 21.34s/it] 23%|â–ˆâ–ˆâ–Ž       | 991/4261 [5:52:33<19:22:24, 21.33s/it] 23%|â–ˆâ–ˆâ–Ž       | 992/4261 [5:52:54<19:22:13, 21.33s/it] 23%|â–ˆâ–ˆâ–Ž       | 993/4261 [5:53:16<19:21:33, 21.33s/it] 23%|â–ˆâ–ˆâ–Ž       | 994/4261 [5:53:37<19:21:11, 21.33s/it] 23%|â–ˆâ–ˆâ–Ž       | 995/4261 [5:53:58<19:20:59, 21.33s/it] 23%|â–ˆâ–ˆâ–Ž       | 996/4261 [5:54:20<19:20:40, 21.33s/it] 23%|â–ˆâ–ˆâ–Ž       | 997/4261 [5:54:41<19:20:31, 21.33s/it] 23%|â–ˆâ–ˆâ–Ž       | 998/4261 [5:55:02<19:20:11, 21.33s/it] 23%|â–ˆâ–ˆâ–Ž       | 999/4261 [5:55:24<19:19:33, 21.33s/it] 23%|â–ˆâ–ˆâ–Ž       | 1000/4261 [5:55:45<19:19:16, 21.33s/it]                                                        {'loss': 2.3281, 'learning_rate': 1.7402931707862815e-05, 'epoch': 0.23}
 23%|â–ˆâ–ˆâ–Ž       | 1000/4261 [5:55:45<19:19:16, 21.33s/it][INFO|trainer.py:2979] 2024-04-18 22:05:25,395 >> Saving model checkpoint to /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/tmp-checkpoint-1000
/home/nfs02/wangzj/public_code/hitsz/peft/src/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /home/nfs02/wangzj/models/Qwen1.5-1.8B - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2435] 2024-04-18 22:05:41,529 >> tokenizer config file saved in /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/tmp-checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-04-18 22:05:41,530 >> Special tokens file saved in /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/tmp-checkpoint-1000/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-04-18 22:05:41,530 >> added tokens file saved in /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/tmp-checkpoint-1000/added_tokens.json
 23%|â–ˆâ–ˆâ–Ž       | 1001/4261 [5:56:27<24:49:38, 27.42s/it] 24%|â–ˆâ–ˆâ–Ž       | 1002/4261 [5:56:48<23:07:24, 25.54s/it] 24%|â–ˆâ–ˆâ–Ž       | 1003/4261 [5:57:09<22:04:01, 24.38s/it] 24%|â–ˆâ–ˆâ–Ž       | 1004/4261 [5:57:31<21:16:20, 23.51s/it] 24%|â–ˆâ–ˆâ–Ž       | 1005/4261 [5:57:52<20:43:02, 22.91s/it] 24%|â–ˆâ–ˆâ–Ž       | 1006/4261 [5:58:14<20:24:31, 22.57s/it] 24%|â–ˆâ–ˆâ–Ž       | 1007/4261 [5:58:36<20:07:30, 22.27s/it] 24%|â–ˆâ–ˆâ–Ž       | 1008/4261 [5:58:57<19:55:29, 22.05s/it] 24%|â–ˆâ–ˆâ–Ž       | 1009/4261 [5:59:19<19:46:30, 21.89s/it] 24%|â–ˆâ–ˆâ–Ž       | 1010/4261 [5:59:40<19:39:27, 21.77s/it]                                                        {'loss': 2.3201, 'learning_rate': 1.7353164107569996e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–Ž       | 1010/4261 [5:59:40<19:39:27, 21.77s/it] 24%|â–ˆâ–ˆâ–Ž       | 1011/4261 [6:00:02<19:34:24, 21.68s/it] 24%|â–ˆâ–ˆâ–       | 1012/4261 [6:00:23<19:30:36, 21.62s/it] 24%|â–ˆâ–ˆâ–       | 1013/4261 [6:00:45<19:27:27, 21.57s/it] 24%|â–ˆâ–ˆâ–       | 1014/4261 [6:01:06<19:24:45, 21.52s/it] 24%|â–ˆâ–ˆâ–       | 1015/4261 [6:01:28<19:22:04, 21.48s/it] 24%|â–ˆâ–ˆâ–       | 1016/4261 [6:01:49<19:19:35, 21.44s/it] 24%|â–ˆâ–ˆâ–       | 1017/4261 [6:02:10<19:18:45, 21.43s/it] 24%|â–ˆâ–ˆâ–       | 1018/4261 [6:02:32<19:16:57, 21.41s/it] 24%|â–ˆâ–ˆâ–       | 1019/4261 [6:02:53<19:19:27, 21.46s/it] 24%|â–ˆâ–ˆâ–       | 1020/4261 [6:03:15<19:17:48, 21.43s/it]                                                        {'loss': 2.325, 'learning_rate': 1.7302996793637426e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1020/4261 [6:03:15<19:17:48, 21.43s/it] 24%|â–ˆâ–ˆâ–       | 1021/4261 [6:03:36<19:16:36, 21.42s/it] 24%|â–ˆâ–ˆâ–       | 1022/4261 [6:03:57<19:15:02, 21.40s/it] 24%|â–ˆâ–ˆâ–       | 1023/4261 [6:04:19<19:13:18, 21.37s/it] 24%|â–ˆâ–ˆâ–       | 1024/4261 [6:04:40<19:12:20, 21.36s/it] 24%|â–ˆâ–ˆâ–       | 1025/4261 [6:05:01<19:11:12, 21.35s/it] 24%|â–ˆâ–ˆâ–       | 1026/4261 [6:05:23<19:10:42, 21.34s/it] 24%|â–ˆâ–ˆâ–       | 1027/4261 [6:05:44<19:10:29, 21.34s/it] 24%|â–ˆâ–ˆâ–       | 1028/4261 [6:06:05<19:09:55, 21.34s/it] 24%|â–ˆâ–ˆâ–       | 1029/4261 [6:06:27<19:09:11, 21.33s/it] 24%|â–ˆâ–ˆâ–       | 1030/4261 [6:06:48<19:09:10, 21.34s/it]                                                        {'loss': 2.3175, 'learning_rate': 1.7252432493130546e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1030/4261 [6:06:48<19:09:10, 21.34s/it] 24%|â–ˆâ–ˆâ–       | 1031/4261 [6:07:09<19:08:52, 21.34s/it] 24%|â–ˆâ–ˆâ–       | 1032/4261 [6:07:31<19:08:35, 21.34s/it] 24%|â–ˆâ–ˆâ–       | 1033/4261 [6:07:52<19:08:28, 21.35s/it] 24%|â–ˆâ–ˆâ–       | 1034/4261 [6:08:14<19:11:31, 21.41s/it] 24%|â–ˆâ–ˆâ–       | 1035/4261 [6:08:35<19:10:25, 21.40s/it] 24%|â–ˆâ–ˆâ–       | 1036/4261 [6:08:57<19:12:46, 21.45s/it] 24%|â–ˆâ–ˆâ–       | 1037/4261 [6:09:18<19:10:23, 21.41s/it] 24%|â–ˆâ–ˆâ–       | 1038/4261 [6:09:39<19:09:26, 21.40s/it] 24%|â–ˆâ–ˆâ–       | 1039/4261 [6:10:01<19:08:30, 21.39s/it] 24%|â–ˆâ–ˆâ–       | 1040/4261 [6:10:22<19:07:16, 21.37s/it]                                                        {'loss': 2.3293, 'learning_rate': 1.7201473954694735e-05, 'epoch': 0.24}
 24%|â–ˆâ–ˆâ–       | 1040/4261 [6:10:22<19:07:16, 21.37s/it] 24%|â–ˆâ–ˆâ–       | 1041/4261 [6:10:43<19:06:33, 21.36s/it] 24%|â–ˆâ–ˆâ–       | 1042/4261 [6:11:05<19:05:21, 21.35s/it] 24%|â–ˆâ–ˆâ–       | 1043/4261 [6:11:26<19:04:26, 21.34s/it] 25%|â–ˆâ–ˆâ–       | 1044/4261 [6:11:47<19:04:13, 21.34s/it] 25%|â–ˆâ–ˆâ–       | 1045/4261 [6:12:09<19:03:46, 21.34s/it] 25%|â–ˆâ–ˆâ–       | 1046/4261 [6:12:30<19:03:19, 21.34s/it] 25%|â–ˆâ–ˆâ–       | 1047/4261 [6:12:51<19:02:32, 21.33s/it] 25%|â–ˆâ–ˆâ–       | 1048/4261 [6:13:13<19:02:31, 21.34s/it] 25%|â–ˆâ–ˆâ–       | 1049/4261 [6:13:34<19:02:19, 21.34s/it] 25%|â–ˆâ–ˆâ–       | 1050/4261 [6:13:55<19:01:58, 21.34s/it]                                                        {'loss': 2.3334, 'learning_rate': 1.7150123948405925e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1050/4261 [6:13:55<19:01:58, 21.34s/it] 25%|â–ˆâ–ˆâ–       | 1051/4261 [6:14:17<19:01:47, 21.34s/it] 25%|â–ˆâ–ˆâ–       | 1052/4261 [6:14:38<19:01:15, 21.34s/it] 25%|â–ˆâ–ˆâ–       | 1053/4261 [6:14:59<19:00:40, 21.33s/it] 25%|â–ˆâ–ˆâ–       | 1054/4261 [6:15:21<19:00:13, 21.33s/it] 25%|â–ˆâ–ˆâ–       | 1055/4261 [6:15:42<18:59:45, 21.33s/it] 25%|â–ˆâ–ˆâ–       | 1056/4261 [6:16:04<19:07:27, 21.48s/it] 25%|â–ˆâ–ˆâ–       | 1057/4261 [6:16:25<19:04:19, 21.43s/it] 25%|â–ˆâ–ˆâ–       | 1058/4261 [6:16:46<19:02:10, 21.40s/it] 25%|â–ˆâ–ˆâ–       | 1059/4261 [6:17:08<19:01:07, 21.38s/it] 25%|â–ˆâ–ˆâ–       | 1060/4261 [6:17:29<19:00:24, 21.38s/it]                                                        {'loss': 2.3237, 'learning_rate': 1.7098385265619996e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–       | 1060/4261 [6:17:29<19:00:24, 21.38s/it] 25%|â–ˆâ–ˆâ–       | 1061/4261 [6:17:50<18:59:47, 21.37s/it] 25%|â–ˆâ–ˆâ–       | 1062/4261 [6:18:12<18:58:14, 21.35s/it] 25%|â–ˆâ–ˆâ–       | 1063/4261 [6:18:33<18:57:29, 21.34s/it] 25%|â–ˆâ–ˆâ–       | 1064/4261 [6:18:54<18:57:04, 21.34s/it] 25%|â–ˆâ–ˆâ–       | 1065/4261 [6:19:16<18:56:42, 21.34s/it] 25%|â–ˆâ–ˆâ–Œ       | 1066/4261 [6:19:37<18:56:50, 21.35s/it] 25%|â–ˆâ–ˆâ–Œ       | 1067/4261 [6:19:58<18:55:51, 21.34s/it] 25%|â–ˆâ–ˆâ–Œ       | 1068/4261 [6:20:20<18:55:10, 21.33s/it] 25%|â–ˆâ–ˆâ–Œ       | 1069/4261 [6:20:41<18:54:19, 21.32s/it] 25%|â–ˆâ–ˆâ–Œ       | 1070/4261 [6:21:02<18:53:55, 21.32s/it]                                                        {'loss': 2.3376, 'learning_rate': 1.7046260718821057e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1070/4261 [6:21:02<18:53:55, 21.32s/it] 25%|â–ˆâ–ˆâ–Œ       | 1071/4261 [6:21:24<18:54:04, 21.33s/it] 25%|â–ˆâ–ˆâ–Œ       | 1072/4261 [6:21:45<18:57:50, 21.41s/it] 25%|â–ˆâ–ˆâ–Œ       | 1073/4261 [6:22:07<18:56:36, 21.39s/it] 25%|â–ˆâ–ˆâ–Œ       | 1074/4261 [6:22:28<18:55:29, 21.38s/it] 25%|â–ˆâ–ˆâ–Œ       | 1075/4261 [6:22:49<18:54:34, 21.37s/it] 25%|â–ˆâ–ˆâ–Œ       | 1076/4261 [6:23:11<18:54:22, 21.37s/it] 25%|â–ˆâ–ˆâ–Œ       | 1077/4261 [6:23:32<18:53:32, 21.36s/it] 25%|â–ˆâ–ˆâ–Œ       | 1078/4261 [6:23:53<18:52:18, 21.34s/it] 25%|â–ˆâ–ˆâ–Œ       | 1079/4261 [6:24:15<18:51:03, 21.33s/it] 25%|â–ˆâ–ˆâ–Œ       | 1080/4261 [6:24:36<18:50:45, 21.33s/it]                                                        {'loss': 2.3391, 'learning_rate': 1.6993753141468564e-05, 'epoch': 0.25}
 25%|â–ˆâ–ˆâ–Œ       | 1080/4261 [6:24:36<18:50:45, 21.33s/it] 25%|â–ˆâ–ˆâ–Œ       | 1081/4261 [6:24:57<18:50:15, 21.33s/it] 25%|â–ˆâ–ˆâ–Œ       | 1082/4261 [6:25:19<18:49:25, 21.32s/it] 25%|â–ˆâ–ˆâ–Œ       | 1083/4261 [6:25:40<18:49:32, 21.33s/it] 25%|â–ˆâ–ˆâ–Œ       | 1084/4261 [6:26:01<18:49:10, 21.33s/it] 25%|â–ˆâ–ˆâ–Œ       | 1085/4261 [6:26:23<18:52:59, 21.40s/it] 25%|â–ˆâ–ˆâ–Œ       | 1086/4261 [6:26:44<18:51:36, 21.38s/it] 26%|â–ˆâ–ˆâ–Œ       | 1087/4261 [6:27:06<18:53:50, 21.43s/it] 26%|â–ˆâ–ˆâ–Œ       | 1088/4261 [6:27:27<18:51:42, 21.40s/it] 26%|â–ˆâ–ˆâ–Œ       | 1089/4261 [6:27:48<18:50:30, 21.38s/it] 26%|â–ˆâ–ˆâ–Œ       | 1090/4261 [6:28:10<18:49:04, 21.36s/it]                                                        {'loss': 2.3299, 'learning_rate': 1.6940865387843274e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1090/4261 [6:28:10<18:49:04, 21.36s/it] 26%|â–ˆâ–ˆâ–Œ       | 1091/4261 [6:28:31<18:48:09, 21.35s/it] 26%|â–ˆâ–ˆâ–Œ       | 1092/4261 [6:28:52<18:46:54, 21.34s/it] 26%|â–ˆâ–ˆâ–Œ       | 1093/4261 [6:29:14<18:45:56, 21.32s/it] 26%|â–ˆâ–ˆâ–Œ       | 1094/4261 [6:29:35<18:45:25, 21.32s/it] 26%|â–ˆâ–ˆâ–Œ       | 1095/4261 [6:29:56<18:45:17, 21.33s/it] 26%|â–ˆâ–ˆâ–Œ       | 1096/4261 [6:30:18<18:44:29, 21.32s/it] 26%|â–ˆâ–ˆâ–Œ       | 1097/4261 [6:30:39<18:44:25, 21.32s/it] 26%|â–ˆâ–ˆâ–Œ       | 1098/4261 [6:31:00<18:44:38, 21.33s/it] 26%|â–ˆâ–ˆâ–Œ       | 1099/4261 [6:31:22<18:44:34, 21.34s/it] 26%|â–ˆâ–ˆâ–Œ       | 1100/4261 [6:31:43<18:44:03, 21.34s/it]                                                        {'loss': 2.3312, 'learning_rate': 1.6887600332892114e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1100/4261 [6:31:43<18:44:03, 21.34s/it] 26%|â–ˆâ–ˆâ–Œ       | 1101/4261 [6:32:04<18:43:11, 21.33s/it] 26%|â–ˆâ–ˆâ–Œ       | 1102/4261 [6:32:26<18:42:14, 21.32s/it] 26%|â–ˆâ–ˆâ–Œ       | 1103/4261 [6:32:47<18:41:41, 21.31s/it] 26%|â–ˆâ–ˆâ–Œ       | 1104/4261 [6:33:08<18:41:00, 21.31s/it] 26%|â–ˆâ–ˆâ–Œ       | 1105/4261 [6:33:30<18:44:32, 21.38s/it] 26%|â–ˆâ–ˆâ–Œ       | 1106/4261 [6:33:51<18:43:05, 21.36s/it] 26%|â–ˆâ–ˆâ–Œ       | 1107/4261 [6:34:12<18:42:07, 21.35s/it] 26%|â–ˆâ–ˆâ–Œ       | 1108/4261 [6:34:34<18:41:31, 21.34s/it] 26%|â–ˆâ–ˆâ–Œ       | 1109/4261 [6:34:55<18:40:44, 21.33s/it] 26%|â–ˆâ–ˆâ–Œ       | 1110/4261 [6:35:16<18:40:50, 21.34s/it]                                                        {'loss': 2.3352, 'learning_rate': 1.683396087207187e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–Œ       | 1110/4261 [6:35:16<18:40:50, 21.34s/it] 26%|â–ˆâ–ˆâ–Œ       | 1111/4261 [6:35:38<18:40:17, 21.34s/it] 26%|â–ˆâ–ˆâ–Œ       | 1112/4261 [6:35:59<18:39:13, 21.33s/it] 26%|â–ˆâ–ˆâ–Œ       | 1113/4261 [6:36:20<18:38:54, 21.33s/it] 26%|â–ˆâ–ˆâ–Œ       | 1114/4261 [6:36:42<18:38:12, 21.32s/it] 26%|â–ˆâ–ˆâ–Œ       | 1115/4261 [6:37:03<18:37:30, 21.31s/it] 26%|â–ˆâ–ˆâ–Œ       | 1116/4261 [6:37:24<18:40:30, 21.38s/it] 26%|â–ˆâ–ˆâ–Œ       | 1117/4261 [6:37:46<18:39:01, 21.36s/it] 26%|â–ˆâ–ˆâ–Œ       | 1118/4261 [6:38:07<18:37:43, 21.34s/it] 26%|â–ˆâ–ˆâ–‹       | 1119/4261 [6:38:28<18:37:24, 21.34s/it] 26%|â–ˆâ–ˆâ–‹       | 1120/4261 [6:38:50<18:37:09, 21.34s/it]                                                        {'loss': 2.3304, 'learning_rate': 1.6779949921191826e-05, 'epoch': 0.26}
 26%|â–ˆâ–ˆâ–‹       | 1120/4261 [6:38:50<18:37:09, 21.34s/it] 26%|â–ˆâ–ˆâ–‹       | 1121/4261 [6:39:11<18:39:38, 21.39s/it] 26%|â–ˆâ–ˆâ–‹       | 1122/4261 [6:39:32<18:37:28, 21.36s/it] 26%|â–ˆâ–ˆâ–‹       | 1123/4261 [6:39:54<18:36:12, 21.34s/it] 26%|â–ˆâ–ˆâ–‹       | 1124/4261 [6:40:15<18:35:33, 21.34s/it] 26%|â–ˆâ–ˆâ–‹       | 1125/4261 [6:40:37<18:38:36, 21.40s/it] 26%|â–ˆâ–ˆâ–‹       | 1126/4261 [6:40:58<18:36:41, 21.37s/it] 26%|â–ˆâ–ˆâ–‹       | 1127/4261 [6:41:19<18:35:29, 21.36s/it] 26%|â–ˆâ–ˆâ–‹       | 1128/4261 [6:41:41<18:34:10, 21.34s/it] 26%|â–ˆâ–ˆâ–‹       | 1129/4261 [6:42:02<18:33:19, 21.33s/it] 27%|â–ˆâ–ˆâ–‹       | 1130/4261 [6:42:23<18:33:26, 21.34s/it]                                                        {'loss': 2.327, 'learning_rate': 1.6725570416255235e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1130/4261 [6:42:23<18:33:26, 21.34s/it] 27%|â–ˆâ–ˆâ–‹       | 1131/4261 [6:42:45<18:32:50, 21.33s/it] 27%|â–ˆâ–ˆâ–‹       | 1132/4261 [6:43:06<18:32:59, 21.34s/it] 27%|â–ˆâ–ˆâ–‹       | 1133/4261 [6:43:27<18:33:48, 21.36s/it] 27%|â–ˆâ–ˆâ–‹       | 1134/4261 [6:43:49<18:35:06, 21.40s/it] 27%|â–ˆâ–ˆâ–‹       | 1135/4261 [6:44:10<18:35:05, 21.40s/it] 27%|â–ˆâ–ˆâ–‹       | 1136/4261 [6:44:32<18:39:49, 21.50s/it] 27%|â–ˆâ–ˆâ–‹       | 1137/4261 [6:44:53<18:38:30, 21.48s/it] 27%|â–ˆâ–ˆâ–‹       | 1138/4261 [6:45:15<18:37:49, 21.48s/it] 27%|â–ˆâ–ˆâ–‹       | 1139/4261 [6:45:36<18:36:31, 21.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1140/4261 [6:45:58<18:36:21, 21.46s/it]                                                        {'loss': 2.3222, 'learning_rate': 1.667082531329973e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1140/4261 [6:45:58<18:36:21, 21.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1141/4261 [6:46:19<18:35:22, 21.45s/it] 27%|â–ˆâ–ˆâ–‹       | 1142/4261 [6:46:41<18:34:44, 21.44s/it] 27%|â–ˆâ–ˆâ–‹       | 1143/4261 [6:47:02<18:35:05, 21.46s/it] 27%|â–ˆâ–ˆâ–‹       | 1144/4261 [6:47:23<18:33:06, 21.43s/it] 27%|â–ˆâ–ˆâ–‹       | 1145/4261 [6:47:45<18:30:33, 21.38s/it] 27%|â–ˆâ–ˆâ–‹       | 1146/4261 [6:48:06<18:28:54, 21.36s/it] 27%|â–ˆâ–ˆâ–‹       | 1147/4261 [6:48:27<18:27:55, 21.35s/it] 27%|â–ˆâ–ˆâ–‹       | 1148/4261 [6:48:49<18:26:30, 21.33s/it] 27%|â–ˆâ–ˆâ–‹       | 1149/4261 [6:49:10<18:25:38, 21.32s/it] 27%|â–ˆâ–ˆâ–‹       | 1150/4261 [6:49:31<18:24:40, 21.31s/it]                                                        {'loss': 2.3367, 'learning_rate': 1.6615717588236647e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1150/4261 [6:49:31<18:24:40, 21.31s/it] 27%|â–ˆâ–ˆâ–‹       | 1151/4261 [6:49:52<18:23:56, 21.30s/it] 27%|â–ˆâ–ˆâ–‹       | 1152/4261 [6:50:14<18:27:05, 21.37s/it] 27%|â–ˆâ–ˆâ–‹       | 1153/4261 [6:50:35<18:25:08, 21.33s/it] 27%|â–ˆâ–ˆâ–‹       | 1154/4261 [6:50:57<18:28:13, 21.40s/it] 27%|â–ˆâ–ˆâ–‹       | 1155/4261 [6:51:18<18:26:35, 21.38s/it] 27%|â–ˆâ–ˆâ–‹       | 1156/4261 [6:51:39<18:25:13, 21.36s/it] 27%|â–ˆâ–ˆâ–‹       | 1157/4261 [6:52:01<18:24:17, 21.35s/it] 27%|â–ˆâ–ˆâ–‹       | 1158/4261 [6:52:22<18:23:23, 21.34s/it] 27%|â–ˆâ–ˆâ–‹       | 1159/4261 [6:52:43<18:22:44, 21.33s/it] 27%|â–ˆâ–ˆâ–‹       | 1160/4261 [6:53:05<18:21:58, 21.32s/it]                                                        {'loss': 2.3334, 'learning_rate': 1.656025023668923e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1160/4261 [6:53:05<18:21:58, 21.32s/it] 27%|â–ˆâ–ˆâ–‹       | 1161/4261 [6:53:26<18:21:34, 21.32s/it] 27%|â–ˆâ–ˆâ–‹       | 1162/4261 [6:53:47<18:20:53, 21.31s/it] 27%|â–ˆâ–ˆâ–‹       | 1163/4261 [6:54:09<18:20:48, 21.32s/it] 27%|â–ˆâ–ˆâ–‹       | 1164/4261 [6:54:30<18:19:55, 21.31s/it] 27%|â–ˆâ–ˆâ–‹       | 1165/4261 [6:54:51<18:19:26, 21.31s/it] 27%|â–ˆâ–ˆâ–‹       | 1166/4261 [6:55:13<18:19:11, 21.31s/it] 27%|â–ˆâ–ˆâ–‹       | 1167/4261 [6:55:34<18:18:22, 21.30s/it] 27%|â–ˆâ–ˆâ–‹       | 1168/4261 [6:55:55<18:18:01, 21.30s/it] 27%|â–ˆâ–ˆâ–‹       | 1169/4261 [6:56:16<18:17:00, 21.29s/it] 27%|â–ˆâ–ˆâ–‹       | 1170/4261 [6:56:38<18:17:05, 21.30s/it]                                                        {'loss': 2.3253, 'learning_rate': 1.6504426273829813e-05, 'epoch': 0.27}
 27%|â–ˆâ–ˆâ–‹       | 1170/4261 [6:56:38<18:17:05, 21.30s/it] 27%|â–ˆâ–ˆâ–‹       | 1171/4261 [6:56:59<18:16:50, 21.30s/it] 28%|â–ˆâ–ˆâ–Š       | 1172/4261 [6:57:20<18:16:30, 21.30s/it] 28%|â–ˆâ–ˆâ–Š       | 1173/4261 [6:57:42<18:16:23, 21.30s/it] 28%|â–ˆâ–ˆâ–Š       | 1174/4261 [6:58:03<18:24:09, 21.46s/it] 28%|â–ˆâ–ˆâ–Š       | 1175/4261 [6:58:25<18:21:13, 21.41s/it] 28%|â–ˆâ–ˆâ–Š       | 1176/4261 [6:58:46<18:19:11, 21.38s/it] 28%|â–ˆâ–ˆâ–Š       | 1177/4261 [6:59:07<18:17:35, 21.35s/it] 28%|â–ˆâ–ˆâ–Š       | 1178/4261 [6:59:29<18:16:13, 21.33s/it] 28%|â–ˆâ–ˆâ–Š       | 1179/4261 [6:59:50<18:15:08, 21.32s/it] 28%|â–ˆâ–ˆâ–Š       | 1180/4261 [7:00:11<18:14:08, 21.31s/it]                                                        {'loss': 2.3107, 'learning_rate': 1.6448248734215905e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1180/4261 [7:00:11<18:14:08, 21.31s/it] 28%|â–ˆâ–ˆâ–Š       | 1181/4261 [7:00:32<18:13:04, 21.29s/it] 28%|â–ˆâ–ˆâ–Š       | 1182/4261 [7:00:54<18:12:51, 21.30s/it] 28%|â–ˆâ–ˆâ–Š       | 1183/4261 [7:01:15<18:12:45, 21.30s/it] 28%|â–ˆâ–ˆâ–Š       | 1184/4261 [7:01:36<18:12:22, 21.30s/it] 28%|â–ˆâ–ˆâ–Š       | 1185/4261 [7:01:58<18:11:33, 21.29s/it] 28%|â–ˆâ–ˆâ–Š       | 1186/4261 [7:02:19<18:11:30, 21.30s/it] 28%|â–ˆâ–ˆâ–Š       | 1187/4261 [7:02:40<18:11:25, 21.30s/it] 28%|â–ˆâ–ˆâ–Š       | 1188/4261 [7:03:02<18:10:35, 21.29s/it] 28%|â–ˆâ–ˆâ–Š       | 1189/4261 [7:03:23<18:10:29, 21.30s/it] 28%|â–ˆâ–ˆâ–Š       | 1190/4261 [7:03:44<18:14:18, 21.38s/it]                                                        {'loss': 2.331, 'learning_rate': 1.6391720671625247e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1190/4261 [7:03:44<18:14:18, 21.38s/it] 28%|â–ˆâ–ˆâ–Š       | 1191/4261 [7:04:06<18:13:01, 21.36s/it] 28%|â–ˆâ–ˆâ–Š       | 1192/4261 [7:04:27<18:12:25, 21.36s/it] 28%|â–ˆâ–ˆâ–Š       | 1193/4261 [7:04:48<18:11:24, 21.34s/it] 28%|â–ˆâ–ˆâ–Š       | 1194/4261 [7:05:10<18:10:27, 21.33s/it] 28%|â–ˆâ–ˆâ–Š       | 1195/4261 [7:05:31<18:09:59, 21.33s/it] 28%|â–ˆâ–ˆâ–Š       | 1196/4261 [7:05:52<18:09:04, 21.32s/it] 28%|â–ˆâ–ˆâ–Š       | 1197/4261 [7:06:14<18:08:04, 21.31s/it] 28%|â–ˆâ–ˆâ–Š       | 1198/4261 [7:06:35<18:06:56, 21.29s/it] 28%|â–ˆâ–ˆâ–Š       | 1199/4261 [7:06:56<18:06:53, 21.30s/it] 28%|â–ˆâ–ˆâ–Š       | 1200/4261 [7:07:18<18:07:16, 21.31s/it]                                                        {'loss': 2.3302, 'learning_rate': 1.6334845158889792e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1200/4261 [7:07:18<18:07:16, 21.31s/it] 28%|â–ˆâ–ˆâ–Š       | 1201/4261 [7:07:39<18:06:43, 21.31s/it] 28%|â–ˆâ–ˆâ–Š       | 1202/4261 [7:08:00<18:05:59, 21.30s/it] 28%|â–ˆâ–ˆâ–Š       | 1203/4261 [7:08:22<18:09:31, 21.38s/it] 28%|â–ˆâ–ˆâ–Š       | 1204/4261 [7:08:43<18:07:59, 21.35s/it] 28%|â–ˆâ–ˆâ–Š       | 1205/4261 [7:09:05<18:10:48, 21.42s/it] 28%|â–ˆâ–ˆâ–Š       | 1206/4261 [7:09:26<18:08:57, 21.39s/it] 28%|â–ˆâ–ˆâ–Š       | 1207/4261 [7:09:47<18:07:34, 21.37s/it] 28%|â–ˆâ–ˆâ–Š       | 1208/4261 [7:10:08<18:06:20, 21.35s/it] 28%|â–ˆâ–ˆâ–Š       | 1209/4261 [7:10:30<18:05:26, 21.34s/it] 28%|â–ˆâ–ˆâ–Š       | 1210/4261 [7:10:51<18:04:18, 21.32s/it]                                                        {'loss': 2.3172, 'learning_rate': 1.6277625287728676e-05, 'epoch': 0.28}
 28%|â–ˆâ–ˆâ–Š       | 1210/4261 [7:10:51<18:04:18, 21.32s/it] 28%|â–ˆâ–ˆâ–Š       | 1211/4261 [7:11:12<18:03:31, 21.32s/it] 28%|â–ˆâ–ˆâ–Š       | 1212/4261 [7:11:34<18:03:16, 21.32s/it] 28%|â–ˆâ–ˆâ–Š       | 1213/4261 [7:11:55<18:02:59, 21.32s/it] 28%|â–ˆâ–ˆâ–Š       | 1214/4261 [7:12:16<18:02:31, 21.32s/it] 29%|â–ˆâ–ˆâ–Š       | 1215/4261 [7:12:38<18:02:21, 21.32s/it] 29%|â–ˆâ–ˆâ–Š       | 1216/4261 [7:12:59<18:01:26, 21.31s/it] 29%|â–ˆâ–ˆâ–Š       | 1217/4261 [7:13:20<18:01:19, 21.31s/it] 29%|â–ˆâ–ˆâ–Š       | 1218/4261 [7:13:42<18:00:49, 21.31s/it] 29%|â–ˆâ–ˆâ–Š       | 1219/4261 [7:14:03<18:00:09, 21.30s/it] 29%|â–ˆâ–ˆâ–Š       | 1220/4261 [7:14:24<17:59:15, 21.29s/it]                                                        {'loss': 2.3278, 'learning_rate': 1.6220064168580162e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–Š       | 1220/4261 [7:14:24<17:59:15, 21.29s/it] 29%|â–ˆâ–ˆâ–Š       | 1221/4261 [7:14:45<17:59:25, 21.30s/it] 29%|â–ˆâ–ˆâ–Š       | 1222/4261 [7:15:07<17:59:06, 21.31s/it] 29%|â–ˆâ–ˆâ–Š       | 1223/4261 [7:15:28<18:02:03, 21.37s/it] 29%|â–ˆâ–ˆâ–Š       | 1224/4261 [7:15:50<18:00:27, 21.35s/it] 29%|â–ˆâ–ˆâ–Š       | 1225/4261 [7:16:11<17:59:29, 21.33s/it] 29%|â–ˆâ–ˆâ–‰       | 1226/4261 [7:16:32<17:58:38, 21.32s/it] 29%|â–ˆâ–ˆâ–‰       | 1227/4261 [7:16:53<17:57:41, 21.31s/it] 29%|â–ˆâ–ˆâ–‰       | 1228/4261 [7:17:15<17:57:21, 21.31s/it] 29%|â–ˆâ–ˆâ–‰       | 1229/4261 [7:17:36<17:56:33, 21.30s/it] 29%|â–ˆâ–ˆâ–‰       | 1230/4261 [7:17:57<17:55:34, 21.29s/it]                                                        {'loss': 2.3183, 'learning_rate': 1.616216493043255e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1230/4261 [7:17:57<17:55:34, 21.29s/it] 29%|â–ˆâ–ˆâ–‰       | 1231/4261 [7:18:19<17:55:42, 21.30s/it] 29%|â–ˆâ–ˆâ–‰       | 1232/4261 [7:18:40<17:55:00, 21.29s/it] 29%|â–ˆâ–ˆâ–‰       | 1233/4261 [7:19:01<17:55:12, 21.31s/it] 29%|â–ˆâ–ˆâ–‰       | 1234/4261 [7:19:23<17:58:26, 21.38s/it] 29%|â–ˆâ–ˆâ–‰       | 1235/4261 [7:19:44<17:57:02, 21.36s/it] 29%|â–ˆâ–ˆâ–‰       | 1236/4261 [7:20:05<17:55:21, 21.33s/it] 29%|â–ˆâ–ˆâ–‰       | 1237/4261 [7:20:27<17:54:25, 21.32s/it] 29%|â–ˆâ–ˆâ–‰       | 1238/4261 [7:20:48<17:53:46, 21.31s/it] 29%|â–ˆâ–ˆâ–‰       | 1239/4261 [7:21:10<17:57:02, 21.38s/it] 29%|â–ˆâ–ˆâ–‰       | 1240/4261 [7:21:31<17:55:48, 21.37s/it]                                                        {'loss': 2.3107, 'learning_rate': 1.610393072065408e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1240/4261 [7:21:31<17:55:48, 21.37s/it] 29%|â–ˆâ–ˆâ–‰       | 1241/4261 [7:21:52<17:54:48, 21.35s/it] 29%|â–ˆâ–ˆâ–‰       | 1242/4261 [7:22:14<17:54:20, 21.35s/it] 29%|â–ˆâ–ˆâ–‰       | 1243/4261 [7:22:35<17:57:34, 21.42s/it] 29%|â–ˆâ–ˆâ–‰       | 1244/4261 [7:22:56<17:55:27, 21.39s/it] 29%|â–ˆâ–ˆâ–‰       | 1245/4261 [7:23:18<17:53:46, 21.36s/it] 29%|â–ˆâ–ˆâ–‰       | 1246/4261 [7:23:39<17:52:31, 21.34s/it] 29%|â–ˆâ–ˆâ–‰       | 1247/4261 [7:24:00<17:51:59, 21.34s/it] 29%|â–ˆâ–ˆâ–‰       | 1248/4261 [7:24:22<17:51:37, 21.34s/it] 29%|â–ˆâ–ˆâ–‰       | 1249/4261 [7:24:43<17:51:16, 21.34s/it] 29%|â–ˆâ–ˆâ–‰       | 1250/4261 [7:25:04<17:50:16, 21.33s/it]                                                        {'loss': 2.3289, 'learning_rate': 1.6045364704821857e-05, 'epoch': 0.29}
 29%|â–ˆâ–ˆâ–‰       | 1250/4261 [7:25:04<17:50:16, 21.33s/it] 29%|â–ˆâ–ˆâ–‰       | 1251/4261 [7:25:26<17:49:57, 21.33s/it] 29%|â–ˆâ–ˆâ–‰       | 1252/4261 [7:25:47<17:49:05, 21.32s/it] 29%|â–ˆâ–ˆâ–‰       | 1253/4261 [7:26:08<17:48:55, 21.32s/it] 29%|â–ˆâ–ˆâ–‰       | 1254/4261 [7:26:30<17:52:13, 21.39s/it] 29%|â–ˆâ–ˆâ–‰       | 1255/4261 [7:26:51<17:50:39, 21.37s/it] 29%|â–ˆâ–ˆâ–‰       | 1256/4261 [7:27:12<17:49:26, 21.35s/it] 30%|â–ˆâ–ˆâ–‰       | 1257/4261 [7:27:34<17:48:45, 21.35s/it] 30%|â–ˆâ–ˆâ–‰       | 1258/4261 [7:27:55<17:47:58, 21.34s/it] 30%|â–ˆâ–ˆâ–‰       | 1259/4261 [7:28:16<17:47:41, 21.34s/it] 30%|â–ˆâ–ˆâ–‰       | 1260/4261 [7:28:38<17:46:50, 21.33s/it]                                                        {'loss': 2.3239, 'learning_rate': 1.5986470066549774e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1260/4261 [7:28:38<17:46:50, 21.33s/it] 30%|â–ˆâ–ˆâ–‰       | 1261/4261 [7:28:59<17:46:03, 21.32s/it] 30%|â–ˆâ–ˆâ–‰       | 1262/4261 [7:29:20<17:45:17, 21.31s/it] 30%|â–ˆâ–ˆâ–‰       | 1263/4261 [7:29:42<17:45:05, 21.32s/it] 30%|â–ˆâ–ˆâ–‰       | 1264/4261 [7:30:03<17:44:36, 21.31s/it] 30%|â–ˆâ–ˆâ–‰       | 1265/4261 [7:30:24<17:43:59, 21.31s/it] 30%|â–ˆâ–ˆâ–‰       | 1266/4261 [7:30:46<17:44:02, 21.32s/it] 30%|â–ˆâ–ˆâ–‰       | 1267/4261 [7:31:07<17:44:07, 21.33s/it] 30%|â–ˆâ–ˆâ–‰       | 1268/4261 [7:31:28<17:44:20, 21.34s/it] 30%|â–ˆâ–ˆâ–‰       | 1269/4261 [7:31:50<17:43:46, 21.33s/it] 30%|â–ˆâ–ˆâ–‰       | 1270/4261 [7:32:11<17:47:08, 21.41s/it]                                                        {'loss': 2.3174, 'learning_rate': 1.5927250007315426e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–‰       | 1270/4261 [7:32:11<17:47:08, 21.41s/it] 30%|â–ˆâ–ˆâ–‰       | 1271/4261 [7:32:33<17:46:45, 21.41s/it] 30%|â–ˆâ–ˆâ–‰       | 1272/4261 [7:32:54<17:50:58, 21.50s/it] 30%|â–ˆâ–ˆâ–‰       | 1273/4261 [7:33:16<17:49:00, 21.47s/it] 30%|â–ˆâ–ˆâ–‰       | 1274/4261 [7:33:37<17:48:28, 21.46s/it] 30%|â–ˆâ–ˆâ–‰       | 1275/4261 [7:33:59<17:46:28, 21.43s/it] 30%|â–ˆâ–ˆâ–‰       | 1276/4261 [7:34:20<17:44:08, 21.39s/it] 30%|â–ˆâ–ˆâ–‰       | 1277/4261 [7:34:41<17:41:54, 21.35s/it] 30%|â–ˆâ–ˆâ–‰       | 1278/4261 [7:35:02<17:40:45, 21.34s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1279/4261 [7:35:24<17:39:58, 21.33s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1280/4261 [7:35:45<17:39:03, 21.32s/it]                                                        {'loss': 2.3337, 'learning_rate': 1.586770774628612e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1280/4261 [7:35:45<17:39:03, 21.32s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1281/4261 [7:36:06<17:38:35, 21.31s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1282/4261 [7:36:28<17:37:33, 21.30s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1283/4261 [7:36:49<17:37:26, 21.31s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1284/4261 [7:37:10<17:36:34, 21.29s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1285/4261 [7:37:31<17:36:11, 21.29s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1286/4261 [7:37:53<17:35:44, 21.29s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1287/4261 [7:38:14<17:35:19, 21.29s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1288/4261 [7:38:35<17:34:47, 21.29s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1289/4261 [7:38:57<17:34:33, 21.29s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1290/4261 [7:39:18<17:34:23, 21.29s/it]                                                        {'loss': 2.3154, 'learning_rate': 1.5807846520143848e-05, 'epoch': 0.3}
 30%|â–ˆâ–ˆâ–ˆ       | 1290/4261 [7:39:18<17:34:23, 21.29s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1291/4261 [7:39:39<17:34:40, 21.31s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1292/4261 [7:40:01<17:41:31, 21.45s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1293/4261 [7:40:22<17:39:14, 21.41s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1294/4261 [7:40:44<17:37:38, 21.39s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1295/4261 [7:41:05<17:35:57, 21.36s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1296/4261 [7:41:26<17:34:48, 21.35s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1297/4261 [7:41:48<17:34:09, 21.34s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1298/4261 [7:42:09<17:33:49, 21.34s/it] 30%|â–ˆâ–ˆâ–ˆ       | 1299/4261 [7:42:30<17:32:35, 21.32s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1300/4261 [7:42:52<17:31:58, 21.32s/it]                                                        {'loss': 2.3356, 'learning_rate': 1.574766958290936e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1300/4261 [7:42:52<17:31:58, 21.32s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1301/4261 [7:43:13<17:31:28, 21.31s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1302/4261 [7:43:34<17:31:07, 21.31s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1303/4261 [7:43:56<17:30:52, 21.32s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1304/4261 [7:44:17<17:30:44, 21.32s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1305/4261 [7:44:38<17:29:57, 21.31s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1306/4261 [7:44:59<17:29:03, 21.30s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1307/4261 [7:45:21<17:28:27, 21.30s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1308/4261 [7:45:42<17:32:12, 21.38s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1309/4261 [7:46:04<17:31:18, 21.37s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1310/4261 [7:46:25<17:29:46, 21.34s/it]                                                        {'loss': 2.3257, 'learning_rate': 1.568718020576527e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1310/4261 [7:46:25<17:29:46, 21.34s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1311/4261 [7:46:46<17:29:09, 21.34s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1312/4261 [7:47:08<17:28:05, 21.32s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1313/4261 [7:47:29<17:27:25, 21.32s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1314/4261 [7:47:50<17:26:59, 21.32s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1315/4261 [7:48:11<17:26:23, 21.31s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1316/4261 [7:48:33<17:26:10, 21.31s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1317/4261 [7:48:54<17:25:34, 21.31s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1318/4261 [7:49:15<17:24:49, 21.30s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1319/4261 [7:49:37<17:24:22, 21.30s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1320/4261 [7:49:58<17:24:15, 21.30s/it]                                                        {'loss': 2.3312, 'learning_rate': 1.5626381676878243e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1320/4261 [7:49:58<17:24:15, 21.30s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1321/4261 [7:50:20<17:27:37, 21.38s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1322/4261 [7:50:41<17:26:35, 21.37s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1323/4261 [7:51:02<17:29:28, 21.43s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1324/4261 [7:51:24<17:27:16, 21.39s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1325/4261 [7:51:45<17:25:34, 21.37s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1326/4261 [7:52:06<17:24:25, 21.35s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1327/4261 [7:52:28<17:23:00, 21.33s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1328/4261 [7:52:49<17:22:05, 21.32s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1329/4261 [7:53:10<17:21:34, 21.31s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1330/4261 [7:53:32<17:21:20, 21.32s/it]                                                        {'loss': 2.3278, 'learning_rate': 1.5565277301220256e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆ       | 1330/4261 [7:53:32<17:21:20, 21.32s/it] 31%|â–ˆâ–ˆâ–ˆ       | 1331/4261 [7:53:53<17:21:22, 21.33s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1332/4261 [7:54:14<17:20:31, 21.32s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1333/4261 [7:54:35<17:19:55, 21.31s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1334/4261 [7:54:57<17:19:25, 21.31s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1335/4261 [7:55:18<17:19:12, 21.31s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1336/4261 [7:55:39<17:18:33, 21.30s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1337/4261 [7:56:01<17:17:53, 21.30s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1338/4261 [7:56:22<17:17:32, 21.30s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1339/4261 [7:56:43<17:17:17, 21.30s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1340/4261 [7:57:05<17:17:17, 21.31s/it]                                                        {'loss': 2.3357, 'learning_rate': 1.5503870400388924e-05, 'epoch': 0.31}
 31%|â–ˆâ–ˆâ–ˆâ–      | 1340/4261 [7:57:05<17:17:17, 21.31s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1341/4261 [7:57:26<17:16:53, 21.31s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 1342/4261 [7:57:47<17:19:52, 21.37s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1343/4261 [7:58:09<17:18:11, 21.35s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1344/4261 [7:58:30<17:17:40, 21.34s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1345/4261 [7:58:51<17:16:56, 21.34s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1346/4261 [7:59:13<17:16:14, 21.33s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1347/4261 [7:59:34<17:15:35, 21.32s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1348/4261 [7:59:55<17:15:25, 21.33s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1349/4261 [8:00:17<17:15:31, 21.34s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1350/4261 [8:00:38<17:14:42, 21.33s/it]                                                        {'loss': 2.3446, 'learning_rate': 1.5442164312426958e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1350/4261 [8:00:38<17:14:42, 21.33s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1351/4261 [8:00:59<17:14:42, 21.33s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1352/4261 [8:01:21<17:18:54, 21.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1353/4261 [8:01:42<17:17:50, 21.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1354/4261 [8:02:04<17:17:28, 21.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1355/4261 [8:02:25<17:17:20, 21.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1356/4261 [8:02:47<17:17:34, 21.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1357/4261 [8:03:08<17:19:44, 21.48s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1358/4261 [8:03:30<17:17:01, 21.43s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1359/4261 [8:03:51<17:15:05, 21.40s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1360/4261 [8:04:12<17:13:21, 21.37s/it]                                                        {'loss': 2.3212, 'learning_rate': 1.5380162391640698e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1360/4261 [8:04:12<17:13:21, 21.37s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1361/4261 [8:04:34<17:16:10, 21.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1362/4261 [8:04:55<17:14:00, 21.40s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1363/4261 [8:05:16<17:13:09, 21.39s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1364/4261 [8:05:38<17:11:40, 21.37s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1365/4261 [8:05:59<17:11:49, 21.38s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1366/4261 [8:06:21<17:12:22, 21.40s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1367/4261 [8:06:42<17:13:06, 21.42s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1368/4261 [8:07:04<17:13:58, 21.44s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1369/4261 [8:07:25<17:14:09, 21.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1370/4261 [8:07:47<17:13:49, 21.46s/it]                                                        {'loss': 2.319, 'learning_rate': 1.531786800841779e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1370/4261 [8:07:47<17:13:49, 21.46s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1371/4261 [8:08:08<17:14:19, 21.47s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1372/4261 [8:08:30<17:18:52, 21.58s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1373/4261 [8:08:51<17:16:37, 21.54s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1374/4261 [8:09:13<17:15:04, 21.51s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1375/4261 [8:09:34<17:14:37, 21.51s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1376/4261 [8:09:56<17:13:59, 21.50s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1377/4261 [8:10:17<17:13:47, 21.51s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1378/4261 [8:10:39<17:13:13, 21.50s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1379/4261 [8:11:00<17:12:22, 21.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1380/4261 [8:11:22<17:12:14, 21.50s/it]                                                        {'loss': 2.3378, 'learning_rate': 1.5255284549043957e-05, 'epoch': 0.32}
 32%|â–ˆâ–ˆâ–ˆâ–      | 1380/4261 [8:11:22<17:12:14, 21.50s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1381/4261 [8:11:43<17:11:58, 21.50s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1382/4261 [8:12:05<17:11:53, 21.51s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1383/4261 [8:12:26<17:11:21, 21.50s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 1384/4261 [8:12:48<17:11:01, 21.50s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1385/4261 [8:13:09<17:10:43, 21.50s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1386/4261 [8:13:31<17:10:40, 21.51s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1387/4261 [8:13:52<17:10:40, 21.52s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1388/4261 [8:14:14<17:14:24, 21.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1389/4261 [8:14:36<17:13:04, 21.58s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1390/4261 [8:14:57<17:15:49, 21.65s/it]                                                        {'loss': 2.3309, 'learning_rate': 1.5192415415518932e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1390/4261 [8:14:58<17:15:49, 21.65s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1391/4261 [8:15:19<17:13:46, 21.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1392/4261 [8:15:41<17:12:00, 21.58s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1393/4261 [8:16:02<17:11:11, 21.57s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1394/4261 [8:16:24<17:10:20, 21.56s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1395/4261 [8:16:45<17:09:47, 21.56s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1396/4261 [8:17:07<17:09:06, 21.55s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1397/4261 [8:17:28<17:08:34, 21.55s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1398/4261 [8:17:50<17:07:41, 21.54s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1399/4261 [8:18:11<17:07:24, 21.54s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1400/4261 [8:18:33<17:07:08, 21.54s/it]                                                        {'loss': 2.3324, 'learning_rate': 1.5129264025371528e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1400/4261 [8:18:33<17:07:08, 21.54s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1401/4261 [8:18:54<17:07:28, 21.56s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1402/4261 [8:19:16<17:06:55, 21.55s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1403/4261 [8:19:38<17:06:16, 21.55s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1404/4261 [8:19:59<17:06:09, 21.55s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1405/4261 [8:20:21<17:05:55, 21.55s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1406/4261 [8:20:42<17:05:57, 21.56s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1407/4261 [8:21:04<17:05:34, 21.56s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1408/4261 [8:21:25<17:04:56, 21.55s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1409/4261 [8:21:47<17:04:47, 21.56s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1410/4261 [8:22:09<17:08:53, 21.65s/it]                                                        {'loss': 2.3278, 'learning_rate': 1.5065833811473858e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1410/4261 [8:22:09<17:08:53, 21.65s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1411/4261 [8:22:31<17:10:36, 21.70s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1412/4261 [8:22:52<17:07:57, 21.65s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1413/4261 [8:23:14<17:06:53, 21.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1414/4261 [8:23:35<17:05:33, 21.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1415/4261 [8:23:57<17:04:58, 21.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1416/4261 [8:24:18<17:03:45, 21.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1417/4261 [8:24:40<17:03:29, 21.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1418/4261 [8:25:02<17:02:18, 21.58s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1419/4261 [8:25:23<17:01:57, 21.58s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1420/4261 [8:25:45<17:02:24, 21.59s/it]                                                        {'loss': 2.3202, 'learning_rate': 1.5002128221854725e-05, 'epoch': 0.33}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1420/4261 [8:25:45<17:02:24, 21.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1421/4261 [8:26:06<17:02:01, 21.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1422/4261 [8:26:28<17:01:14, 21.58s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1423/4261 [8:26:50<17:01:57, 21.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1424/4261 [8:27:11<17:01:11, 21.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1425/4261 [8:27:33<17:00:36, 21.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1426/4261 [8:27:54<16:59:12, 21.57s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1427/4261 [8:28:16<17:02:13, 21.64s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1428/4261 [8:28:38<17:00:45, 21.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1429/4261 [8:28:59<16:59:42, 21.60s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1430/4261 [8:29:21<16:57:24, 21.56s/it]                                                        {'loss': 2.3245, 'learning_rate': 1.4938150719512205e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1430/4261 [8:29:21<16:57:24, 21.56s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1431/4261 [8:29:42<16:54:49, 21.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1432/4261 [8:30:03<16:53:07, 21.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1433/4261 [8:30:25<16:51:38, 21.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1434/4261 [8:30:46<16:50:36, 21.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1435/4261 [8:31:08<16:48:47, 21.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1436/4261 [8:31:29<16:47:31, 21.40s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1437/4261 [8:31:50<16:46:56, 21.39s/it] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 1438/4261 [8:32:12<16:46:13, 21.39s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1439/4261 [8:32:33<16:45:54, 21.39s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1440/4261 [8:32:55<16:52:41, 21.54s/it]                                                        {'loss': 2.327, 'learning_rate': 1.4873904782225372e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 1440/4261 [8:32:55<16:52:41, 21.54s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1441/4261 [8:33:16<16:49:25, 21.48s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1442/4261 [8:33:38<16:50:52, 21.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1443/4261 [8:33:59<16:48:11, 21.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1444/4261 [8:34:21<16:46:04, 21.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1445/4261 [8:34:42<16:44:40, 21.41s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1446/4261 [8:35:03<16:43:58, 21.40s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1447/4261 [8:35:25<16:42:55, 21.38s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1448/4261 [8:35:46<16:42:37, 21.39s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1449/4261 [8:36:08<16:42:09, 21.38s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1450/4261 [8:36:29<16:41:38, 21.38s/it]                                                        {'loss': 2.3267, 'learning_rate': 1.4809393902365278e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 1450/4261 [8:36:29<16:41:38, 21.38s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1451/4261 [8:36:50<16:40:59, 21.37s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1452/4261 [8:37:12<16:40:59, 21.38s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1453/4261 [8:37:33<16:40:26, 21.38s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1454/4261 [8:37:54<16:40:01, 21.38s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1455/4261 [8:38:16<16:40:25, 21.39s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1456/4261 [8:38:37<16:41:38, 21.43s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1457/4261 [8:38:59<16:42:08, 21.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1458/4261 [8:39:20<16:41:40, 21.44s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1459/4261 [8:39:42<16:41:48, 21.45s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1460/4261 [8:40:03<16:45:33, 21.54s/it]                                                        {'loss': 2.3194, 'learning_rate': 1.4744621586705091e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 1460/4261 [8:40:03<16:45:33, 21.54s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1461/4261 [8:40:25<16:44:02, 21.52s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1462/4261 [8:40:46<16:43:37, 21.51s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1463/4261 [8:41:08<16:42:57, 21.51s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1464/4261 [8:41:29<16:42:41, 21.51s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1465/4261 [8:41:51<16:42:20, 21.51s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1466/4261 [8:42:12<16:41:28, 21.50s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1467/4261 [8:42:34<16:40:22, 21.48s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1468/4261 [8:42:55<16:40:13, 21.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1469/4261 [8:43:17<16:39:17, 21.47s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 1470/4261 [8:43:39<16:43:08, 21.57s/it]                                                        {'loss': 2.3319, 'learning_rate': 1.4679591356229472e-05, 'epoch': 0.34}
 34%|â–ˆâ–ˆâ–ˆâ–      | 1470/4261 [8:43:39<16:43:08, 21.57s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1471/4261 [8:44:00<16:42:10, 21.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1472/4261 [8:44:22<16:41:13, 21.54s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1473/4261 [8:44:43<16:40:28, 21.53s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1474/4261 [8:45:05<16:39:40, 21.52s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1475/4261 [8:45:26<16:38:57, 21.51s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1476/4261 [8:45:48<16:42:40, 21.60s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1477/4261 [8:46:09<16:40:54, 21.57s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1478/4261 [8:46:31<16:39:13, 21.54s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1479/4261 [8:46:52<16:37:45, 21.52s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1480/4261 [8:47:14<16:37:02, 21.51s/it]                                                        {'loss': 2.3269, 'learning_rate': 1.4614306745943178e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 1480/4261 [8:47:14<16:37:02, 21.51s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1481/4261 [8:47:35<16:36:39, 21.51s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1482/4261 [8:47:57<16:35:17, 21.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1483/4261 [8:48:18<16:34:41, 21.48s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1484/4261 [8:48:40<16:34:17, 21.48s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1485/4261 [8:49:01<16:34:47, 21.50s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1486/4261 [8:49:23<16:33:45, 21.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1487/4261 [8:49:44<16:33:45, 21.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1488/4261 [8:50:06<16:33:24, 21.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1489/4261 [8:50:27<16:32:53, 21.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1490/4261 [8:50:49<16:36:47, 21.58s/it]                                                        {'loss': 2.3081, 'learning_rate': 1.4548771304678911e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–      | 1490/4261 [8:50:49<16:36:47, 21.58s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 1491/4261 [8:51:11<16:35:26, 21.56s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1492/4261 [8:51:32<16:34:27, 21.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1493/4261 [8:51:54<16:33:50, 21.54s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1494/4261 [8:52:15<16:32:59, 21.53s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1495/4261 [8:52:37<16:36:41, 21.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1496/4261 [8:52:59<16:36:24, 21.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1497/4261 [8:53:20<16:34:22, 21.59s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1498/4261 [8:53:42<16:33:49, 21.58s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1499/4261 [8:54:03<16:33:46, 21.59s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1500/4261 [8:54:25<16:32:38, 21.57s/it]                                                        {'loss': 2.3294, 'learning_rate': 1.4482988594904384e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1500/4261 [8:54:25<16:32:38, 21.57s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1501/4261 [8:54:46<16:31:18, 21.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1502/4261 [8:55:08<16:30:15, 21.53s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1503/4261 [8:55:29<16:29:51, 21.53s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1504/4261 [8:55:51<16:29:23, 21.53s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1505/4261 [8:56:12<16:29:13, 21.54s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1506/4261 [8:56:34<16:31:12, 21.59s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1507/4261 [8:56:56<16:30:03, 21.57s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1508/4261 [8:57:17<16:29:31, 21.57s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1509/4261 [8:57:39<16:28:54, 21.56s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1510/4261 [8:58:00<16:27:44, 21.54s/it]                                                        {'loss': 2.3266, 'learning_rate': 1.4416962192528687e-05, 'epoch': 0.35}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1510/4261 [8:58:00<16:27:44, 21.54s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1511/4261 [8:58:22<16:27:52, 21.55s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1512/4261 [8:58:43<16:28:20, 21.57s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1513/4261 [8:59:05<16:27:59, 21.57s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1514/4261 [8:59:27<16:27:27, 21.57s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1515/4261 [8:59:48<16:26:30, 21.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1516/4261 [9:00:10<16:26:46, 21.57s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1517/4261 [9:00:31<16:26:09, 21.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1518/4261 [9:00:53<16:26:05, 21.57s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1519/4261 [9:01:14<16:26:49, 21.59s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1520/4261 [9:01:36<16:25:42, 21.58s/it]                                                        {'loss': 2.3153, 'learning_rate': 1.4350695686707892e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1520/4261 [9:01:36<16:25:42, 21.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1521/4261 [9:01:58<16:26:06, 21.59s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1522/4261 [9:02:19<16:25:26, 21.59s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1523/4261 [9:02:41<16:25:06, 21.59s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1524/4261 [9:03:03<16:27:52, 21.66s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1525/4261 [9:03:24<16:25:18, 21.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1526/4261 [9:03:46<16:23:39, 21.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1527/4261 [9:04:07<16:22:44, 21.57s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1528/4261 [9:04:29<16:22:21, 21.57s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1529/4261 [9:04:50<16:24:57, 21.63s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1530/4261 [9:05:12<16:23:36, 21.61s/it]                                                        {'loss': 2.3298, 'learning_rate': 1.4284192679649951e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1530/4261 [9:05:12<16:23:36, 21.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1531/4261 [9:05:34<16:22:03, 21.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1532/4261 [9:05:55<16:21:36, 21.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1533/4261 [9:06:17<16:20:40, 21.57s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1534/4261 [9:06:38<16:19:53, 21.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1535/4261 [9:07:00<16:19:23, 21.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1536/4261 [9:07:21<16:19:12, 21.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1537/4261 [9:07:43<16:18:52, 21.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1538/4261 [9:08:05<16:19:46, 21.59s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1539/4261 [9:08:26<16:18:50, 21.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1540/4261 [9:08:48<16:18:44, 21.58s/it]                                                        {'loss': 2.3329, 'learning_rate': 1.4217456786418889e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1540/4261 [9:08:48<16:18:44, 21.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1541/4261 [9:09:09<16:18:34, 21.59s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1542/4261 [9:09:31<16:18:08, 21.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1543/4261 [9:09:52<16:16:57, 21.57s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1544/4261 [9:10:14<16:16:21, 21.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1545/4261 [9:10:36<16:19:00, 21.63s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1546/4261 [9:10:57<16:17:11, 21.60s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1547/4261 [9:11:19<16:16:33, 21.59s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1548/4261 [9:11:40<16:16:06, 21.59s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1549/4261 [9:12:02<16:15:13, 21.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1550/4261 [9:12:24<16:14:56, 21.58s/it]                                                        {'loss': 2.3293, 'learning_rate': 1.4150491634738278e-05, 'epoch': 0.36}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1550/4261 [9:12:24<16:14:56, 21.58s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1551/4261 [9:12:45<16:14:10, 21.57s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1552/4261 [9:13:07<16:13:02, 21.55s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1553/4261 [9:13:28<16:13:13, 21.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1554/4261 [9:13:50<16:12:06, 21.55s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1555/4261 [9:14:11<16:12:12, 21.56s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1556/4261 [9:14:33<16:11:43, 21.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1557/4261 [9:14:54<16:11:07, 21.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1558/4261 [9:15:17<16:18:41, 21.72s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1559/4261 [9:15:38<16:15:27, 21.66s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1560/4261 [9:16:00<16:13:16, 21.62s/it]                                                        {'loss': 2.3275, 'learning_rate': 1.408330086479405e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1560/4261 [9:16:00<16:13:16, 21.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1561/4261 [9:16:21<16:14:52, 21.66s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1562/4261 [9:16:43<16:12:59, 21.63s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1563/4261 [9:17:04<16:11:40, 21.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1564/4261 [9:17:26<16:09:51, 21.58s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1565/4261 [9:17:47<16:09:18, 21.57s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1566/4261 [9:18:09<16:08:40, 21.57s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1567/4261 [9:18:31<16:08:25, 21.57s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1568/4261 [9:18:52<16:07:08, 21.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1569/4261 [9:19:14<16:06:42, 21.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1570/4261 [9:19:35<16:06:20, 21.55s/it]                                                        {'loss': 2.3212, 'learning_rate': 1.4015888129036604e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1570/4261 [9:19:35<16:06:20, 21.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1571/4261 [9:19:57<16:06:00, 21.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1572/4261 [9:20:18<16:06:12, 21.56s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1573/4261 [9:20:40<16:05:28, 21.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1574/4261 [9:21:01<16:05:07, 21.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1575/4261 [9:21:23<16:04:07, 21.54s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1576/4261 [9:21:45<16:06:57, 21.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1577/4261 [9:22:06<16:05:32, 21.58s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1578/4261 [9:22:28<16:08:42, 21.66s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1579/4261 [9:22:50<16:07:10, 21.64s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1580/4261 [9:23:11<16:05:50, 21.62s/it]                                                        {'loss': 2.322, 'learning_rate': 1.3948257091982278e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1580/4261 [9:23:11<16:05:50, 21.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1581/4261 [9:23:33<16:03:49, 21.58s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1582/4261 [9:23:54<16:01:59, 21.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1583/4261 [9:24:16<16:01:38, 21.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1584/4261 [9:24:37<16:01:24, 21.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1585/4261 [9:24:59<16:01:15, 21.55s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1586/4261 [9:25:20<16:00:22, 21.54s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1587/4261 [9:25:42<15:59:59, 21.54s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1588/4261 [9:26:04<16:03:31, 21.63s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1589/4261 [9:26:25<16:02:16, 21.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1590/4261 [9:26:47<16:02:10, 21.61s/it]                                                        {'loss': 2.333, 'learning_rate': 1.388041143001413e-05, 'epoch': 0.37}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1590/4261 [9:26:47<16:02:10, 21.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1591/4261 [9:27:08<16:01:28, 21.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1592/4261 [9:27:30<16:00:29, 21.59s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1593/4261 [9:27:52<15:59:43, 21.58s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1594/4261 [9:28:13<16:02:32, 21.65s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1595/4261 [9:28:35<16:00:06, 21.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1596/4261 [9:28:56<15:57:55, 21.57s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1597/4261 [9:29:18<15:57:17, 21.56s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1598/4261 [9:29:39<15:56:14, 21.55s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1599/4261 [9:30:01<15:55:02, 21.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1600/4261 [9:30:22<15:54:20, 21.52s/it]                                                        {'loss': 2.3382, 'learning_rate': 1.3812354831182107e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1600/4261 [9:30:22<15:54:20, 21.52s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1601/4261 [9:30:44<15:53:47, 21.51s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1602/4261 [9:31:06<15:54:05, 21.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1603/4261 [9:31:27<15:53:47, 21.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1604/4261 [9:31:49<15:53:23, 21.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1605/4261 [9:32:10<15:53:08, 21.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1606/4261 [9:32:32<15:52:35, 21.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1607/4261 [9:32:53<15:52:36, 21.54s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1608/4261 [9:33:15<15:55:56, 21.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1609/4261 [9:33:36<15:53:56, 21.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1610/4261 [9:33:58<15:52:42, 21.56s/it]                                                        {'loss': 2.3148, 'learning_rate': 1.374409099500256e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1610/4261 [9:33:58<15:52:42, 21.56s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1611/4261 [9:34:19<15:51:18, 21.54s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1612/4261 [9:34:41<15:50:42, 21.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1613/4261 [9:35:03<15:50:04, 21.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1614/4261 [9:35:24<15:50:14, 21.54s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1615/4261 [9:35:46<15:49:56, 21.54s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1616/4261 [9:36:07<15:49:40, 21.54s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1617/4261 [9:36:29<15:49:28, 21.55s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1618/4261 [9:36:50<15:48:54, 21.54s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1619/4261 [9:37:12<15:47:50, 21.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1620/4261 [9:37:33<15:47:38, 21.53s/it]                                                        {'loss': 2.3141, 'learning_rate': 1.3675623632257133e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1620/4261 [9:37:33<15:47:38, 21.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1621/4261 [9:37:55<15:47:58, 21.55s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1622/4261 [9:38:16<15:47:13, 21.54s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1623/4261 [9:38:38<15:45:46, 21.51s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1624/4261 [9:39:00<15:48:43, 21.59s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1625/4261 [9:39:21<15:48:04, 21.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1626/4261 [9:39:43<15:47:34, 21.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1627/4261 [9:40:04<15:46:30, 21.56s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1628/4261 [9:40:26<15:45:34, 21.55s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1629/4261 [9:40:48<15:48:44, 21.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1630/4261 [9:41:09<15:47:26, 21.61s/it]                                                        {'loss': 2.3426, 'learning_rate': 1.3606956464791061e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1630/4261 [9:41:09<15:47:26, 21.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1631/4261 [9:41:31<15:46:05, 21.58s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1632/4261 [9:41:52<15:44:52, 21.56s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1633/4261 [9:42:14<15:44:02, 21.55s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1634/4261 [9:42:35<15:43:53, 21.56s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1635/4261 [9:42:57<15:43:53, 21.57s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1636/4261 [9:43:18<15:43:01, 21.55s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1637/4261 [9:43:40<15:42:09, 21.54s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1638/4261 [9:44:01<15:41:10, 21.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1639/4261 [9:44:23<15:40:53, 21.53s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1640/4261 [9:44:44<15:39:57, 21.52s/it]                                                        {'loss': 2.3335, 'learning_rate': 1.3538093225310838e-05, 'epoch': 0.38}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1640/4261 [9:44:44<15:39:57, 21.52s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1641/4261 [9:45:06<15:39:56, 21.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1642/4261 [9:45:27<15:39:06, 21.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1643/4261 [9:45:49<15:38:04, 21.50s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1644/4261 [9:46:10<15:38:06, 21.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1645/4261 [9:46:32<15:37:47, 21.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1646/4261 [9:46:54<15:37:36, 21.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1647/4261 [9:47:15<15:40:25, 21.59s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1648/4261 [9:47:37<15:38:08, 21.54s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1649/4261 [9:47:58<15:37:35, 21.54s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1650/4261 [9:48:20<15:36:43, 21.53s/it]                                                        {'loss': 2.3344, 'learning_rate': 1.3469037657181319e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1650/4261 [9:48:20<15:36:43, 21.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 1651/4261 [9:48:41<15:36:24, 21.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1652/4261 [9:49:03<15:36:24, 21.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1653/4261 [9:49:24<15:35:43, 21.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1654/4261 [9:49:46<15:35:18, 21.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1655/4261 [9:50:07<15:34:28, 21.52s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1656/4261 [9:50:29<15:33:45, 21.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1657/4261 [9:50:50<15:33:34, 21.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1658/4261 [9:51:12<15:36:20, 21.58s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1659/4261 [9:51:34<15:34:21, 21.55s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1660/4261 [9:51:55<15:33:43, 21.54s/it]                                                        {'loss': 2.3349, 'learning_rate': 1.3399793514222234e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1660/4261 [9:51:55<15:33:43, 21.54s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1661/4261 [9:52:17<15:32:47, 21.53s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1662/4261 [9:52:38<15:32:15, 21.52s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1663/4261 [9:53:00<15:31:20, 21.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1664/4261 [9:53:21<15:30:38, 21.50s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1665/4261 [9:53:43<15:30:18, 21.50s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1666/4261 [9:54:04<15:29:18, 21.49s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1667/4261 [9:54:25<15:28:19, 21.47s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1668/4261 [9:54:47<15:28:14, 21.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1669/4261 [9:55:08<15:28:06, 21.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1670/4261 [9:55:30<15:27:38, 21.48s/it]                                                        {'loss': 2.3172, 'learning_rate': 1.3330364560504126e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1670/4261 [9:55:30<15:27:38, 21.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1671/4261 [9:55:51<15:27:23, 21.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1672/4261 [9:56:13<15:26:04, 21.46s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1673/4261 [9:56:34<15:25:46, 21.46s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1674/4261 [9:56:56<15:26:04, 21.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1675/4261 [9:57:17<15:25:37, 21.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1676/4261 [9:57:39<15:32:22, 21.64s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1677/4261 [9:58:01<15:29:32, 21.58s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1678/4261 [9:58:22<15:27:51, 21.55s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1679/4261 [9:58:44<15:29:37, 21.60s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1680/4261 [9:59:05<15:27:19, 21.56s/it]                                                        {'loss': 2.3339, 'learning_rate': 1.3260754570143734e-05, 'epoch': 0.39}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1680/4261 [9:59:05<15:27:19, 21.56s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1681/4261 [9:59:27<15:25:21, 21.52s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1682/4261 [9:59:48<15:24:23, 21.51s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1683/4261 [10:00:10<15:24:00, 21.51s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1684/4261 [10:00:31<15:22:54, 21.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1685/4261 [10:00:53<15:22:22, 21.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1686/4261 [10:01:14<15:21:24, 21.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1687/4261 [10:01:36<15:21:10, 21.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1688/4261 [10:01:57<15:21:01, 21.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1689/4261 [10:02:19<15:20:23, 21.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1690/4261 [10:02:40<15:20:16, 21.48s/it]                                                         {'loss': 2.316, 'learning_rate': 1.3190967327098857e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1690/4261 [10:02:40<15:20:16, 21.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1691/4261 [10:03:02<15:19:59, 21.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1692/4261 [10:03:23<15:19:39, 21.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1693/4261 [10:03:44<15:19:02, 21.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1694/4261 [10:04:06<15:18:24, 21.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1695/4261 [10:04:28<15:21:50, 21.56s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1696/4261 [10:04:49<15:24:02, 21.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1697/4261 [10:05:11<15:21:36, 21.57s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1698/4261 [10:05:32<15:20:15, 21.54s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1699/4261 [10:05:54<15:19:26, 21.53s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1700/4261 [10:06:15<15:18:46, 21.53s/it]                                                         {'loss': 2.336, 'learning_rate': 1.3121006624962633e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1700/4261 [10:06:15<15:18:46, 21.53s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1701/4261 [10:06:37<15:17:44, 21.51s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1702/4261 [10:06:58<15:18:01, 21.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1703/4261 [10:07:20<15:17:18, 21.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1704/4261 [10:07:41<15:16:56, 21.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1705/4261 [10:08:03<15:20:13, 21.60s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1706/4261 [10:08:25<15:18:38, 21.57s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1707/4261 [10:08:46<15:17:01, 21.54s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1708/4261 [10:09:08<15:15:48, 21.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1709/4261 [10:09:29<15:14:50, 21.51s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1710/4261 [10:09:51<15:18:15, 21.60s/it]                                                         {'loss': 2.3202, 'learning_rate': 1.3050876266757333e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1710/4261 [10:09:51<15:18:15, 21.60s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1711/4261 [10:10:13<15:17:24, 21.59s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1712/4261 [10:10:34<15:20:04, 21.66s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1713/4261 [10:10:56<15:17:40, 21.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1714/4261 [10:11:17<15:15:26, 21.57s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1715/4261 [10:11:39<15:14:10, 21.54s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1716/4261 [10:12:00<15:13:00, 21.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1717/4261 [10:12:22<15:12:19, 21.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1718/4261 [10:12:43<15:11:53, 21.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1719/4261 [10:13:05<15:11:02, 21.50s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1720/4261 [10:13:26<15:10:41, 21.50s/it]                                                         {'loss': 2.3331, 'learning_rate': 1.2980580064727641e-05, 'epoch': 0.4}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1720/4261 [10:13:26<15:10:41, 21.50s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1721/4261 [10:13:48<15:10:36, 21.51s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1722/4261 [10:14:09<15:10:42, 21.52s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1723/4261 [10:14:31<15:09:20, 21.50s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1724/4261 [10:14:52<15:08:30, 21.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1725/4261 [10:15:14<15:08:00, 21.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1726/4261 [10:15:35<15:10:51, 21.56s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1727/4261 [10:15:57<15:09:43, 21.54s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1728/4261 [10:16:18<15:08:43, 21.53s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1729/4261 [10:16:40<15:08:00, 21.52s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1730/4261 [10:17:01<15:07:26, 21.51s/it]                                                         {'loss': 2.3292, 'learning_rate': 1.2910121840133404e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1730/4261 [10:17:01<15:07:26, 21.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1731/4261 [10:17:23<15:06:48, 21.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1732/4261 [10:17:44<15:06:25, 21.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1733/4261 [10:18:06<15:06:01, 21.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1734/4261 [10:18:27<15:05:38, 21.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1735/4261 [10:18:49<15:05:15, 21.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1736/4261 [10:19:10<15:04:39, 21.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1737/4261 [10:19:32<15:03:59, 21.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1738/4261 [10:19:53<15:04:37, 21.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1739/4261 [10:20:15<15:04:06, 21.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1740/4261 [10:20:37<15:03:45, 21.51s/it]                                                         {'loss': 2.3124, 'learning_rate': 1.2839505423041925e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1740/4261 [10:20:37<15:03:45, 21.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1741/4261 [10:20:58<15:03:46, 21.52s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1742/4261 [10:21:20<15:06:27, 21.59s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1743/4261 [10:21:41<15:04:48, 21.56s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1744/4261 [10:22:03<15:03:51, 21.55s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1745/4261 [10:22:24<15:02:46, 21.53s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1746/4261 [10:22:46<15:01:48, 21.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1747/4261 [10:23:07<15:01:01, 21.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1748/4261 [10:23:29<15:00:09, 21.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1749/4261 [10:23:50<14:59:31, 21.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1750/4261 [10:24:12<14:58:49, 21.48s/it]                                                         {'loss': 2.3138, 'learning_rate': 1.276873465211975e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1750/4261 [10:24:12<14:58:49, 21.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1751/4261 [10:24:33<14:58:41, 21.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1752/4261 [10:24:55<14:58:28, 21.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1753/4261 [10:25:16<14:58:24, 21.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1754/4261 [10:25:38<14:57:57, 21.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1755/4261 [10:25:59<14:57:54, 21.50s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1756/4261 [10:26:21<14:56:46, 21.48s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1757/4261 [10:26:42<15:00:12, 21.57s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1758/4261 [10:27:04<14:58:48, 21.55s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1759/4261 [10:27:25<14:58:04, 21.54s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1760/4261 [10:27:47<14:56:59, 21.52s/it]                                                         {'loss': 2.3248, 'learning_rate': 1.2697813374424012e-05, 'epoch': 0.41}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1760/4261 [10:27:47<14:56:59, 21.52s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1761/4261 [10:28:08<14:56:43, 21.52s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1762/4261 [10:28:30<14:56:02, 21.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1763/4261 [10:28:52<14:59:19, 21.60s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1764/4261 [10:29:13<14:56:54, 21.55s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1765/4261 [10:29:35<14:59:34, 21.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1766/4261 [10:29:56<14:57:48, 21.59s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1767/4261 [10:30:18<14:55:43, 21.55s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1768/4261 [10:30:39<14:54:59, 21.54s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1769/4261 [10:31:01<14:53:46, 21.52s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1770/4261 [10:31:22<14:53:07, 21.51s/it]                                                         {'loss': 2.3305, 'learning_rate': 1.2626745445193307e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1770/4261 [10:31:22<14:53:07, 21.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1771/4261 [10:31:44<14:52:20, 21.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1772/4261 [10:32:05<14:51:46, 21.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1773/4261 [10:32:27<14:51:26, 21.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1774/4261 [10:32:48<14:50:47, 21.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1775/4261 [10:33:10<14:50:26, 21.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1776/4261 [10:33:31<14:49:49, 21.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1777/4261 [10:33:53<14:49:03, 21.47s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1778/4261 [10:34:14<14:48:10, 21.46s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1779/4261 [10:34:36<14:48:22, 21.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1780/4261 [10:34:57<14:48:00, 21.48s/it]                                                         {'loss': 2.3257, 'learning_rate': 1.2555534727638119e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1780/4261 [10:34:57<14:48:00, 21.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1781/4261 [10:35:19<14:47:52, 21.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1782/4261 [10:35:40<14:47:39, 21.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1783/4261 [10:36:02<14:48:15, 21.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1784/4261 [10:36:23<14:47:52, 21.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1785/4261 [10:36:45<14:46:49, 21.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1786/4261 [10:37:06<14:46:27, 21.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1787/4261 [10:37:28<14:46:25, 21.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1788/4261 [10:37:49<14:46:16, 21.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1789/4261 [10:38:11<14:46:10, 21.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1790/4261 [10:38:32<14:45:34, 21.50s/it]                                                         {'loss': 2.3193, 'learning_rate': 1.2484185092730818e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1790/4261 [10:38:32<14:45:34, 21.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1791/4261 [10:38:54<14:45:11, 21.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1792/4261 [10:39:15<14:48:16, 21.59s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1793/4261 [10:39:37<14:46:40, 21.56s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1794/4261 [10:39:59<14:48:37, 21.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1795/4261 [10:40:20<14:46:45, 21.58s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1796/4261 [10:40:42<14:44:46, 21.54s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1797/4261 [10:41:03<14:43:05, 21.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1798/4261 [10:41:24<14:42:01, 21.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1799/4261 [10:41:46<14:41:49, 21.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1800/4261 [10:42:07<14:41:34, 21.49s/it]                                                         {'loss': 2.3143, 'learning_rate': 1.2412700418995236e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1800/4261 [10:42:07<14:41:34, 21.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1801/4261 [10:42:29<14:40:57, 21.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1802/4261 [10:42:50<14:41:19, 21.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1803/4261 [10:43:12<14:41:02, 21.51s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1804/4261 [10:43:33<14:40:29, 21.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1805/4261 [10:43:55<14:40:04, 21.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1806/4261 [10:44:16<14:39:22, 21.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1807/4261 [10:44:38<14:38:56, 21.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1808/4261 [10:44:59<14:38:37, 21.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1809/4261 [10:45:21<14:38:38, 21.50s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1810/4261 [10:45:43<14:42:27, 21.60s/it]                                                         {'loss': 2.3233, 'learning_rate': 1.2341084592295846e-05, 'epoch': 0.42}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1810/4261 [10:45:43<14:42:27, 21.60s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1811/4261 [10:46:04<14:41:07, 21.58s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1812/4261 [10:46:26<14:39:59, 21.56s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1813/4261 [10:46:48<14:41:37, 21.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1814/4261 [10:47:09<14:39:37, 21.57s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1815/4261 [10:47:31<14:40:54, 21.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1816/4261 [10:47:52<14:38:59, 21.57s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1817/4261 [10:48:14<14:37:47, 21.55s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1818/4261 [10:48:35<14:37:16, 21.55s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1819/4261 [10:48:57<14:36:26, 21.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1820/4261 [10:49:18<14:36:06, 21.53s/it]                                                         {'loss': 2.3335, 'learning_rate': 1.226934150562651e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1820/4261 [10:49:18<14:36:06, 21.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1821/4261 [10:49:40<14:35:19, 21.52s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1822/4261 [10:50:01<14:35:15, 21.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1823/4261 [10:50:23<14:34:33, 21.52s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1824/4261 [10:50:44<14:33:26, 21.50s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1825/4261 [10:51:06<14:32:42, 21.50s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1826/4261 [10:51:27<14:32:10, 21.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1827/4261 [10:51:49<14:32:02, 21.50s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1828/4261 [10:52:10<14:31:25, 21.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1829/4261 [10:52:32<14:34:12, 21.57s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1830/4261 [10:52:54<14:36:54, 21.64s/it]                                                         {'loss': 2.3258, 'learning_rate': 1.2197475058898866e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1830/4261 [10:52:54<14:36:54, 21.64s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1831/4261 [10:53:15<14:34:28, 21.59s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1832/4261 [10:53:37<14:32:55, 21.56s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1833/4261 [10:53:58<14:31:33, 21.54s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1834/4261 [10:54:20<14:30:42, 21.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1835/4261 [10:54:41<14:29:41, 21.51s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1836/4261 [10:55:03<14:29:19, 21.51s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1837/4261 [10:55:24<14:28:44, 21.50s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1838/4261 [10:55:46<14:27:39, 21.49s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1839/4261 [10:56:07<14:30:13, 21.56s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1840/4261 [10:56:29<14:28:57, 21.54s/it]                                                         {'loss': 2.3223, 'learning_rate': 1.2125489158730336e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1840/4261 [10:56:29<14:28:57, 21.54s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1841/4261 [10:56:50<14:28:13, 21.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1842/4261 [10:57:12<14:28:07, 21.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1843/4261 [10:57:33<14:27:23, 21.52s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1844/4261 [10:57:55<14:30:11, 21.60s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1845/4261 [10:58:17<14:28:24, 21.57s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1846/4261 [10:58:38<14:27:40, 21.56s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1847/4261 [10:59:00<14:26:42, 21.54s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1848/4261 [10:59:21<14:25:46, 21.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1849/4261 [10:59:43<14:25:17, 21.52s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1850/4261 [11:00:04<14:25:12, 21.53s/it]                                                         {'loss': 2.3265, 'learning_rate': 1.2053387718231762e-05, 'epoch': 0.43}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1850/4261 [11:00:04<14:25:12, 21.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1851/4261 [11:00:26<14:24:38, 21.53s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1852/4261 [11:00:47<14:24:41, 21.54s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1853/4261 [11:01:09<14:24:11, 21.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1854/4261 [11:01:30<14:22:51, 21.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1855/4261 [11:01:52<14:21:48, 21.49s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1856/4261 [11:02:13<14:20:33, 21.47s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1857/4261 [11:02:35<14:20:02, 21.47s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1858/4261 [11:02:56<14:19:47, 21.47s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1859/4261 [11:03:18<14:22:44, 21.55s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1860/4261 [11:03:39<14:21:50, 21.54s/it]                                                         {'loss': 2.3231, 'learning_rate': 1.1981174656794686e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1860/4261 [11:03:39<14:21:50, 21.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1861/4261 [11:04:01<14:21:17, 21.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1862/4261 [11:04:22<14:21:09, 21.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1863/4261 [11:04:44<14:20:33, 21.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1864/4261 [11:05:06<14:19:46, 21.52s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1865/4261 [11:05:27<14:19:18, 21.52s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1866/4261 [11:05:49<14:18:42, 21.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1867/4261 [11:06:10<14:18:21, 21.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1868/4261 [11:06:32<14:17:55, 21.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1869/4261 [11:06:53<14:17:08, 21.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1870/4261 [11:07:15<14:17:09, 21.51s/it]                                                         {'loss': 2.3302, 'learning_rate': 1.1908853899878288e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1870/4261 [11:07:15<14:17:09, 21.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1871/4261 [11:07:36<14:17:04, 21.52s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1872/4261 [11:07:58<14:16:18, 21.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1873/4261 [11:08:19<14:15:48, 21.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1874/4261 [11:08:41<14:15:36, 21.51s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1875/4261 [11:09:02<14:18:42, 21.59s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1876/4261 [11:09:24<14:17:30, 21.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1877/4261 [11:09:45<14:16:42, 21.56s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1878/4261 [11:10:07<14:16:09, 21.56s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1879/4261 [11:10:28<14:14:56, 21.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1880/4261 [11:10:50<14:14:15, 21.53s/it]                                                         {'loss': 2.3192, 'learning_rate': 1.1836429378796034e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1880/4261 [11:10:50<14:14:15, 21.53s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1881/4261 [11:11:12<14:14:41, 21.55s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1882/4261 [11:11:33<14:14:05, 21.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1883/4261 [11:11:55<14:16:33, 21.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1884/4261 [11:12:16<14:14:49, 21.58s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1885/4261 [11:12:38<14:14:06, 21.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1886/4261 [11:12:59<14:13:43, 21.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1887/4261 [11:13:21<14:12:21, 21.54s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1888/4261 [11:13:43<14:12:31, 21.56s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1889/4261 [11:14:04<14:12:04, 21.55s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1890/4261 [11:14:26<14:11:35, 21.55s/it]                                                         {'loss': 2.3249, 'learning_rate': 1.1763905030501927e-05, 'epoch': 0.44}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1890/4261 [11:14:26<14:11:35, 21.55s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1891/4261 [11:14:47<14:11:34, 21.56s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1892/4261 [11:15:09<14:11:27, 21.56s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1893/4261 [11:15:30<14:10:51, 21.56s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1894/4261 [11:15:52<14:10:45, 21.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1895/4261 [11:16:13<14:10:26, 21.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1896/4261 [11:16:35<14:09:45, 21.56s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1897/4261 [11:16:57<14:12:14, 21.63s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1898/4261 [11:17:18<14:10:37, 21.60s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1899/4261 [11:17:40<14:09:34, 21.58s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1900/4261 [11:18:01<14:09:30, 21.59s/it]                                                         {'loss': 2.3352, 'learning_rate': 1.1691284797376534e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1900/4261 [11:18:01<14:09:30, 21.59s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1901/4261 [11:18:23<14:08:49, 21.58s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1902/4261 [11:18:45<14:08:47, 21.59s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1903/4261 [11:19:06<14:07:37, 21.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1904/4261 [11:19:28<14:06:52, 21.56s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1905/4261 [11:19:49<14:06:55, 21.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1906/4261 [11:20:11<14:06:48, 21.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1907/4261 [11:20:32<14:06:27, 21.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1908/4261 [11:20:54<14:05:38, 21.56s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1909/4261 [11:21:16<14:05:26, 21.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1910/4261 [11:21:37<14:05:06, 21.57s/it]                                                         {'loss': 2.3232, 'learning_rate': 1.1618572627012647e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1910/4261 [11:21:37<14:05:06, 21.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1911/4261 [11:21:59<14:04:53, 21.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1912/4261 [11:22:20<14:04:28, 21.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1913/4261 [11:22:42<14:07:26, 21.66s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1914/4261 [11:23:04<14:05:59, 21.63s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1915/4261 [11:23:25<14:05:13, 21.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1916/4261 [11:23:47<14:04:58, 21.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1917/4261 [11:24:09<14:04:05, 21.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1918/4261 [11:24:30<14:03:33, 21.60s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1919/4261 [11:24:52<14:02:49, 21.59s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1920/4261 [11:25:13<14:02:35, 21.60s/it]                                                         {'loss': 2.3146, 'learning_rate': 1.154577247200073e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1920/4261 [11:25:13<14:02:35, 21.60s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1921/4261 [11:25:35<14:01:43, 21.58s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1922/4261 [11:25:56<14:01:28, 21.59s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1923/4261 [11:26:18<14:01:10, 21.59s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1924/4261 [11:26:40<14:01:44, 21.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1925/4261 [11:27:01<14:01:03, 21.60s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1926/4261 [11:27:23<14:04:18, 21.70s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1927/4261 [11:27:45<14:01:38, 21.64s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1928/4261 [11:28:07<14:03:50, 21.70s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1929/4261 [11:28:28<14:02:02, 21.66s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1930/4261 [11:28:50<14:00:20, 21.63s/it]                                                         {'loss': 2.3227, 'learning_rate': 1.1472888289714025e-05, 'epoch': 0.45}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1930/4261 [11:28:50<14:00:20, 21.63s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1931/4261 [11:29:11<13:59:10, 21.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1932/4261 [11:29:33<13:58:30, 21.60s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1933/4261 [11:29:55<14:01:28, 21.69s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1934/4261 [11:30:16<13:59:27, 21.64s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1935/4261 [11:30:38<13:58:16, 21.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1936/4261 [11:30:59<13:57:22, 21.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1937/4261 [11:31:21<13:56:54, 21.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1938/4261 [11:31:43<13:55:47, 21.59s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1939/4261 [11:32:04<13:55:50, 21.60s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1940/4261 [11:32:26<13:55:30, 21.60s/it]                                                         {'loss': 2.3339, 'learning_rate': 1.139992404209346e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1940/4261 [11:32:26<13:55:30, 21.60s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1941/4261 [11:32:47<13:54:56, 21.59s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1942/4261 [11:33:09<13:54:13, 21.58s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1943/4261 [11:33:30<13:53:23, 21.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1944/4261 [11:33:52<13:53:11, 21.58s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1945/4261 [11:34:14<13:53:09, 21.58s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1946/4261 [11:34:35<13:52:24, 21.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1947/4261 [11:34:57<13:54:14, 21.63s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1948/4261 [11:35:18<13:52:57, 21.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1949/4261 [11:35:40<13:55:12, 21.68s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1950/4261 [11:36:02<13:53:04, 21.63s/it]                                                         {'loss': 2.3238, 'learning_rate': 1.1326883695432258e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1950/4261 [11:36:02<13:53:04, 21.63s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1951/4261 [11:36:23<13:51:52, 21.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1952/4261 [11:36:45<13:50:41, 21.59s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1953/4261 [11:37:06<13:49:45, 21.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1954/4261 [11:37:28<13:49:24, 21.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1955/4261 [11:37:50<13:48:41, 21.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1956/4261 [11:38:11<13:48:35, 21.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1957/4261 [11:38:33<13:50:43, 21.63s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1958/4261 [11:38:55<13:49:21, 21.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1959/4261 [11:39:16<13:47:58, 21.58s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1960/4261 [11:39:38<13:46:33, 21.55s/it]                                                         {'loss': 2.3238, 'learning_rate': 1.125377122016034e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1960/4261 [11:39:38<13:46:33, 21.55s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1961/4261 [11:39:59<13:45:21, 21.53s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1962/4261 [11:40:21<13:45:09, 21.54s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1963/4261 [11:40:42<13:47:34, 21.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1964/4261 [11:41:04<13:46:22, 21.59s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1965/4261 [11:41:25<13:45:21, 21.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1966/4261 [11:41:47<13:44:21, 21.55s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1967/4261 [11:42:08<13:44:09, 21.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1968/4261 [11:42:30<13:43:42, 21.55s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1969/4261 [11:42:52<13:43:05, 21.55s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1970/4261 [11:43:13<13:42:39, 21.54s/it]                                                         {'loss': 2.3284, 'learning_rate': 1.1180590590628505e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1970/4261 [11:43:13<13:42:39, 21.54s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1971/4261 [11:43:35<13:43:04, 21.57s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1972/4261 [11:43:56<13:42:29, 21.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1973/4261 [11:44:18<13:41:55, 21.55s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1974/4261 [11:44:39<13:41:16, 21.55s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1975/4261 [11:45:01<13:40:30, 21.54s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1976/4261 [11:45:22<13:40:11, 21.54s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1977/4261 [11:45:44<13:43:04, 21.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1978/4261 [11:46:06<13:44:00, 21.66s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1979/4261 [11:46:27<13:41:47, 21.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1980/4261 [11:46:49<13:40:54, 21.59s/it]                                                         {'loss': 2.3196, 'learning_rate': 1.1107345784892367e-05, 'epoch': 0.46}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1980/4261 [11:46:49<13:40:54, 21.59s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1981/4261 [11:47:11<13:39:57, 21.58s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1982/4261 [11:47:32<13:39:21, 21.57s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1983/4261 [11:47:54<13:39:04, 21.57s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1984/4261 [11:48:15<13:38:33, 21.57s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1985/4261 [11:48:37<13:37:32, 21.55s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1986/4261 [11:48:58<13:37:23, 21.56s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1987/4261 [11:49:20<13:36:58, 21.56s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1988/4261 [11:49:41<13:36:36, 21.56s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1989/4261 [11:50:03<13:35:39, 21.54s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1990/4261 [11:50:24<13:35:41, 21.55s/it]                                                         {'loss': 2.3268, 'learning_rate': 1.103404078449613e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1990/4261 [11:50:24<13:35:41, 21.55s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1991/4261 [11:50:46<13:35:45, 21.56s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1992/4261 [11:51:08<13:35:27, 21.56s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1993/4261 [11:51:29<13:37:54, 21.64s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1994/4261 [11:51:51<13:36:00, 21.60s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1995/4261 [11:52:12<13:34:47, 21.57s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1996/4261 [11:52:34<13:34:09, 21.57s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1997/4261 [11:52:55<13:32:53, 21.54s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1998/4261 [11:53:17<13:32:12, 21.53s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1999/4261 [11:53:39<13:31:48, 21.53s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2000/4261 [11:54:00<13:31:50, 21.54s/it]                                                         {'loss': 2.3265, 'learning_rate': 1.096067957425613e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2000/4261 [11:54:00<13:31:50, 21.54s/it][INFO|trainer.py:2979] 2024-04-19 04:03:41,189 >> Saving model checkpoint to /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/tmp-checkpoint-2000
[INFO|tokenization_utils_base.py:2435] 2024-04-19 04:03:57,306 >> tokenizer config file saved in /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/tmp-checkpoint-2000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-04-19 04:03:57,307 >> Special tokens file saved in /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/tmp-checkpoint-2000/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-04-19 04:03:57,308 >> added tokens file saved in /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/tmp-checkpoint-2000/added_tokens.json
[INFO|trainer.py:3071] 2024-04-19 04:03:58,269 >> Deleting older checkpoint [/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/checkpoint-1000] due to args.save_total_limit
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2001/4261 [11:54:43<17:35:01, 28.01s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2002/4261 [11:55:05<16:19:48, 26.02s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2003/4261 [11:55:26<15:29:55, 24.71s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2004/4261 [11:55:48<14:55:21, 23.80s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2005/4261 [11:56:10<14:31:44, 23.18s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2006/4261 [11:56:31<14:15:02, 22.75s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2007/4261 [11:56:53<14:03:30, 22.45s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2008/4261 [11:57:15<13:55:20, 22.25s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2009/4261 [11:57:37<13:49:34, 22.10s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2010/4261 [11:57:58<13:45:00, 21.99s/it]                                                         {'loss': 2.332, 'learning_rate': 1.088726614204425e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2010/4261 [11:57:58<13:45:00, 21.99s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2011/4261 [11:58:20<13:41:21, 21.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2012/4261 [11:58:42<13:41:04, 21.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2013/4261 [11:59:04<13:37:28, 21.82s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2014/4261 [11:59:25<13:34:51, 21.76s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2015/4261 [11:59:47<13:32:39, 21.71s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2016/4261 [12:00:09<13:31:49, 21.70s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2017/4261 [12:00:30<13:33:32, 21.75s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2018/4261 [12:00:52<13:34:26, 21.79s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2019/4261 [12:01:14<13:31:28, 21.72s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2020/4261 [12:01:35<13:29:17, 21.67s/it]                                                         {'loss': 2.312, 'learning_rate': 1.0813804478571126e-05, 'epoch': 0.47}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2020/4261 [12:01:35<13:29:17, 21.67s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2021/4261 [12:01:57<13:28:02, 21.64s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2022/4261 [12:02:19<13:26:37, 21.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2023/4261 [12:02:40<13:26:12, 21.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2024/4261 [12:03:02<13:25:02, 21.59s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2025/4261 [12:03:23<13:24:48, 21.60s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2026/4261 [12:03:45<13:23:48, 21.58s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2027/4261 [12:04:06<13:23:09, 21.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2028/4261 [12:04:28<13:25:33, 21.65s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2029/4261 [12:04:50<13:23:47, 21.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2030/4261 [12:05:11<13:22:59, 21.60s/it]                                                         {'loss': 2.3182, 'learning_rate': 1.074029857716921e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2030/4261 [12:05:11<13:22:59, 21.60s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2031/4261 [12:05:33<13:22:21, 21.59s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2032/4261 [12:05:54<13:22:07, 21.59s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2033/4261 [12:06:16<13:21:00, 21.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2034/4261 [12:06:38<13:23:10, 21.64s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2035/4261 [12:06:59<13:21:06, 21.59s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2036/4261 [12:07:21<13:20:47, 21.59s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2037/4261 [12:07:42<13:19:43, 21.58s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2038/4261 [12:08:04<13:19:23, 21.58s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2039/4261 [12:08:26<13:19:11, 21.58s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2040/4261 [12:08:47<13:18:24, 21.57s/it]                                                         {'loss': 2.3304, 'learning_rate': 1.066675243357571e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2040/4261 [12:08:47<13:18:24, 21.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2041/4261 [12:09:09<13:17:49, 21.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2042/4261 [12:09:30<13:17:53, 21.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2043/4261 [12:09:52<13:17:24, 21.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2044/4261 [12:10:13<13:17:00, 21.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2045/4261 [12:10:35<13:15:57, 21.55s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2046/4261 [12:10:56<13:15:53, 21.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2047/4261 [12:11:18<13:15:29, 21.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2048/4261 [12:11:40<13:15:07, 21.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2049/4261 [12:12:01<13:14:54, 21.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2050/4261 [12:12:23<13:14:30, 21.56s/it]                                                         {'loss': 2.3198, 'learning_rate': 1.0593170045715368e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2050/4261 [12:12:23<13:14:30, 21.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2051/4261 [12:12:44<13:14:00, 21.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2052/4261 [12:13:06<13:13:28, 21.55s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2053/4261 [12:13:27<13:13:14, 21.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2054/4261 [12:13:49<13:12:42, 21.55s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2055/4261 [12:14:10<13:12:24, 21.55s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2056/4261 [12:14:32<13:11:44, 21.54s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2057/4261 [12:14:54<13:11:44, 21.55s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2058/4261 [12:15:15<13:11:06, 21.55s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2059/4261 [12:15:37<13:10:34, 21.54s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2060/4261 [12:15:58<13:10:07, 21.54s/it]                                                         {'loss': 2.324, 'learning_rate': 1.0519555413483152e-05, 'epoch': 0.48}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2060/4261 [12:15:58<13:10:07, 21.54s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2061/4261 [12:16:20<13:10:46, 21.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2062/4261 [12:16:41<13:10:12, 21.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2063/4261 [12:17:03<13:09:56, 21.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2064/4261 [12:17:25<13:10:30, 21.59s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2065/4261 [12:17:46<13:09:29, 21.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2066/4261 [12:18:08<13:08:51, 21.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2067/4261 [12:18:29<13:08:17, 21.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2068/4261 [12:18:51<13:08:11, 21.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2069/4261 [12:19:12<13:07:45, 21.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2070/4261 [12:19:34<13:10:23, 21.64s/it]                                                         {'loss': 2.3274, 'learning_rate': 1.0445912538526801e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2070/4261 [12:19:34<13:10:23, 21.64s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2071/4261 [12:19:56<13:09:04, 21.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2072/4261 [12:20:17<13:08:10, 21.60s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2073/4261 [12:20:39<13:07:54, 21.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2074/4261 [12:21:00<13:07:19, 21.60s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2075/4261 [12:21:22<13:06:20, 21.58s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2076/4261 [12:21:44<13:05:25, 21.57s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2077/4261 [12:22:05<13:05:07, 21.57s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2078/4261 [12:22:27<13:04:16, 21.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2079/4261 [12:22:48<13:03:35, 21.55s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2080/4261 [12:23:10<13:03:19, 21.55s/it]                                                         {'loss': 2.3232, 'learning_rate': 1.0372245424029329e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2080/4261 [12:23:10<13:03:19, 21.55s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2081/4261 [12:23:32<13:05:38, 21.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2082/4261 [12:23:53<13:03:48, 21.58s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2083/4261 [12:24:15<13:02:55, 21.57s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2084/4261 [12:24:36<13:02:00, 21.55s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2085/4261 [12:24:58<13:02:04, 21.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2086/4261 [12:25:19<13:04:25, 21.64s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2087/4261 [12:25:41<13:02:49, 21.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2088/4261 [12:26:03<13:01:46, 21.59s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2089/4261 [12:26:24<13:01:12, 21.58s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2090/4261 [12:26:46<13:00:21, 21.57s/it]                                                         {'loss': 2.3199, 'learning_rate': 1.0298558074491381e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2090/4261 [12:26:46<13:00:21, 21.57s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2091/4261 [12:27:07<13:00:11, 21.57s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2092/4261 [12:27:29<12:59:13, 21.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2093/4261 [12:27:50<12:58:34, 21.55s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2094/4261 [12:28:12<12:58:08, 21.55s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2095/4261 [12:28:33<12:58:08, 21.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2096/4261 [12:28:55<12:58:17, 21.57s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2097/4261 [12:29:17<12:57:52, 21.57s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2098/4261 [12:29:38<12:57:28, 21.57s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2099/4261 [12:30:00<12:59:01, 21.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2100/4261 [12:30:21<12:57:07, 21.58s/it]                                                         {'loss': 2.32, 'learning_rate': 1.0224854495513581e-05, 'epoch': 0.49}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2100/4261 [12:30:21<12:57:07, 21.58s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2101/4261 [12:30:43<12:56:19, 21.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2102/4261 [12:31:04<12:55:39, 21.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2103/4261 [12:31:26<12:54:29, 21.53s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2104/4261 [12:31:47<12:54:19, 21.54s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2105/4261 [12:32:09<12:53:47, 21.53s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2106/4261 [12:32:31<12:53:51, 21.55s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2107/4261 [12:32:52<12:53:17, 21.54s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2108/4261 [12:33:14<12:53:01, 21.54s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2109/4261 [12:33:35<12:52:24, 21.54s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2110/4261 [12:33:57<12:54:21, 21.60s/it]                                                         {'loss': 2.3373, 'learning_rate': 1.0151138693578764e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2110/4261 [12:33:57<12:54:21, 21.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2111/4261 [12:34:18<12:53:42, 21.59s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2112/4261 [12:34:40<12:52:42, 21.57s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2113/4261 [12:35:01<12:51:33, 21.55s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2114/4261 [12:35:23<12:50:58, 21.55s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2115/4261 [12:35:45<12:51:02, 21.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2116/4261 [12:36:06<12:52:53, 21.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2117/4261 [12:36:28<12:51:50, 21.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2118/4261 [12:36:49<12:50:03, 21.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2119/4261 [12:37:11<12:52:45, 21.65s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2120/4261 [12:37:33<12:50:43, 21.60s/it]                                                         {'loss': 2.3269, 'learning_rate': 1.0077414675834203e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2120/4261 [12:37:33<12:50:43, 21.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2121/4261 [12:37:54<12:49:44, 21.58s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2122/4261 [12:38:16<12:49:05, 21.57s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2123/4261 [12:38:37<12:48:26, 21.57s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2124/4261 [12:38:59<12:47:37, 21.55s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2125/4261 [12:39:20<12:46:40, 21.54s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2126/4261 [12:39:42<12:46:33, 21.54s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2127/4261 [12:40:03<12:46:19, 21.55s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2128/4261 [12:40:25<12:45:33, 21.53s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2129/4261 [12:40:47<12:45:09, 21.53s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2130/4261 [12:41:08<12:44:46, 21.53s/it]                                                         {'loss': 2.3226, 'learning_rate': 1.000368644987378e-05, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2130/4261 [12:41:08<12:44:46, 21.53s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2131/4261 [12:41:30<12:47:21, 21.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2132/4261 [12:41:51<12:46:01, 21.59s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2133/4261 [12:42:13<12:44:43, 21.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2134/4261 [12:42:34<12:44:07, 21.55s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2135/4261 [12:42:56<12:46:17, 21.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2136/4261 [12:43:18<12:47:55, 21.68s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2137/4261 [12:43:40<12:46:28, 21.65s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2138/4261 [12:44:01<12:44:48, 21.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2139/4261 [12:44:23<12:43:06, 21.58s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2140/4261 [12:44:44<12:42:01, 21.56s/it]                                                         {'loss': 2.3222, 'learning_rate': 9.929958023520126e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2140/4261 [12:44:44<12:42:01, 21.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2141/4261 [12:45:06<12:41:37, 21.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2142/4261 [12:45:27<12:41:14, 21.55s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2143/4261 [12:45:49<12:40:54, 21.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2144/4261 [12:46:10<12:40:36, 21.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2145/4261 [12:46:32<12:40:13, 21.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2146/4261 [12:46:54<12:42:45, 21.64s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2147/4261 [12:47:15<12:41:14, 21.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2148/4261 [12:47:37<12:40:29, 21.59s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2149/4261 [12:47:58<12:39:01, 21.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2150/4261 [12:48:20<12:38:53, 21.57s/it]                                                         {'loss': 2.3333, 'learning_rate': 9.856233404606776e-06, 'epoch': 0.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2150/4261 [12:48:20<12:38:53, 21.57s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2151/4261 [12:48:41<12:38:16, 21.56s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2152/4261 [12:49:03<12:40:19, 21.63s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2153/4261 [12:49:25<12:39:01, 21.60s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2154/4261 [12:49:46<12:37:59, 21.59s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2155/4261 [12:50:08<12:37:23, 21.58s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2156/4261 [12:50:29<12:36:46, 21.57s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2157/4261 [12:50:51<12:36:02, 21.56s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2158/4261 [12:51:13<12:35:36, 21.56s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2159/4261 [12:51:34<12:35:14, 21.56s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2160/4261 [12:51:56<12:34:46, 21.55s/it]                                                         {'loss': 2.3321, 'learning_rate': 9.782516600760278e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2160/4261 [12:51:56<12:34:46, 21.55s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2161/4261 [12:52:17<12:34:33, 21.56s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2162/4261 [12:52:39<12:34:15, 21.56s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2163/4261 [12:53:00<12:33:56, 21.56s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2164/4261 [12:53:22<12:32:38, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2165/4261 [12:53:43<12:32:09, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2166/4261 [12:54:05<12:31:42, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2167/4261 [12:54:26<12:30:54, 21.52s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2168/4261 [12:54:48<12:30:53, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2169/4261 [12:55:09<12:30:49, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2170/4261 [12:55:31<12:30:13, 21.53s/it]                                                         {'loss': 2.3211, 'learning_rate': 9.708811619182376e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2170/4261 [12:55:31<12:30:13, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2171/4261 [12:55:53<12:30:06, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2172/4261 [12:56:14<12:29:44, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2173/4261 [12:56:36<12:29:18, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2174/4261 [12:56:57<12:28:43, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2175/4261 [12:57:19<12:28:39, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2176/4261 [12:57:40<12:28:08, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2177/4261 [12:58:02<12:27:27, 21.52s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2178/4261 [12:58:23<12:26:48, 21.51s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2179/4261 [12:58:45<12:26:25, 21.51s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2180/4261 [12:59:06<12:25:54, 21.51s/it]                                                         {'loss': 2.3291, 'learning_rate': 9.635122466432156e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2180/4261 [12:59:06<12:25:54, 21.51s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2181/4261 [12:59:28<12:25:40, 21.51s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2182/4261 [12:59:49<12:24:41, 21.49s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2183/4261 [13:00:11<12:24:35, 21.50s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2184/4261 [13:00:32<12:23:37, 21.48s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2185/4261 [13:00:54<12:23:59, 21.50s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2186/4261 [13:01:15<12:23:28, 21.50s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2187/4261 [13:01:37<12:22:59, 21.49s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2188/4261 [13:01:58<12:26:36, 21.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2189/4261 [13:02:20<12:25:42, 21.59s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2190/4261 [13:02:42<12:24:26, 21.57s/it]                                                         {'loss': 2.3233, 'learning_rate': 9.561453148208248e-06, 'epoch': 0.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2190/4261 [13:02:42<12:24:26, 21.57s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2191/4261 [13:03:03<12:22:52, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2192/4261 [13:03:25<12:22:21, 21.53s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2193/4261 [13:03:46<12:22:31, 21.54s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2194/4261 [13:04:08<12:22:06, 21.54s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2195/4261 [13:04:29<12:21:13, 21.53s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2196/4261 [13:04:51<12:20:42, 21.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2197/4261 [13:05:12<12:20:06, 21.51s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2198/4261 [13:05:34<12:19:39, 21.51s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2199/4261 [13:05:55<12:21:47, 21.58s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2200/4261 [13:06:17<12:20:39, 21.56s/it]                                                         {'loss': 2.33, 'learning_rate': 9.487807669131107e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2200/4261 [13:06:17<12:20:39, 21.56s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2201/4261 [13:06:38<12:19:18, 21.53s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2202/4261 [13:07:00<12:18:05, 21.51s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2203/4261 [13:07:21<12:17:27, 21.50s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2204/4261 [13:07:43<12:19:29, 21.57s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2205/4261 [13:08:04<12:17:42, 21.53s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2206/4261 [13:08:26<12:16:38, 21.51s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2207/4261 [13:08:47<12:16:00, 21.50s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2208/4261 [13:09:09<12:15:36, 21.50s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2209/4261 [13:09:30<12:15:00, 21.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2210/4261 [13:09:52<12:14:11, 21.48s/it]                                                         {'loss': 2.3235, 'learning_rate': 9.414190032525287e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2210/4261 [13:09:52<12:14:11, 21.48s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2211/4261 [13:10:13<12:13:28, 21.47s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2212/4261 [13:10:35<12:13:46, 21.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2213/4261 [13:10:56<12:13:33, 21.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2214/4261 [13:11:18<12:13:07, 21.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2215/4261 [13:11:39<12:12:56, 21.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2216/4261 [13:12:01<12:12:21, 21.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2217/4261 [13:12:23<12:15:16, 21.58s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2218/4261 [13:12:44<12:12:54, 21.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2219/4261 [13:13:05<12:12:03, 21.51s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2220/4261 [13:13:27<12:11:08, 21.49s/it]                                                         {'loss': 2.3219, 'learning_rate': 9.34060424020186e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2220/4261 [13:13:27<12:11:08, 21.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2221/4261 [13:13:48<12:10:34, 21.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2222/4261 [13:14:10<12:09:50, 21.48s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2223/4261 [13:14:31<12:09:45, 21.48s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2224/4261 [13:14:53<12:09:06, 21.48s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2225/4261 [13:15:14<12:08:46, 21.48s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2226/4261 [13:15:36<12:08:58, 21.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2227/4261 [13:15:57<12:08:54, 21.50s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2228/4261 [13:16:19<12:08:54, 21.51s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2229/4261 [13:16:41<12:11:00, 21.58s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2230/4261 [13:17:02<12:09:52, 21.56s/it]                                                         {'loss': 2.3217, 'learning_rate': 9.26705429224085e-06, 'epoch': 0.52}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2230/4261 [13:17:02<12:09:52, 21.56s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2231/4261 [13:17:24<12:08:21, 21.53s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2232/4261 [13:17:45<12:07:10, 21.50s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2233/4261 [13:18:06<12:06:42, 21.50s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2234/4261 [13:18:28<12:09:39, 21.60s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2235/4261 [13:18:50<12:08:14, 21.57s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2236/4261 [13:19:11<12:07:20, 21.55s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2237/4261 [13:19:33<12:09:15, 21.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2238/4261 [13:19:55<12:07:36, 21.58s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2239/4261 [13:20:16<12:06:41, 21.56s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2240/4261 [13:20:38<12:05:49, 21.55s/it]                                                         {'loss': 2.3121, 'learning_rate': 9.193544186773804e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2240/4261 [13:20:38<12:05:49, 21.55s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2241/4261 [13:20:59<12:05:19, 21.54s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2242/4261 [13:21:21<12:04:47, 21.54s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2243/4261 [13:21:42<12:04:03, 21.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2244/4261 [13:22:04<12:02:56, 21.51s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2245/4261 [13:22:25<12:02:25, 21.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2246/4261 [13:22:47<12:01:57, 21.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2247/4261 [13:23:08<12:01:10, 21.48s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2248/4261 [13:23:30<12:00:48, 21.48s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2249/4261 [13:23:51<12:03:13, 21.57s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2250/4261 [13:24:13<12:02:10, 21.55s/it]                                                         {'loss': 2.3248, 'learning_rate': 9.120077919766462e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2250/4261 [13:24:13<12:02:10, 21.55s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2251/4261 [13:24:34<12:01:45, 21.54s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2252/4261 [13:24:56<12:00:32, 21.52s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2253/4261 [13:25:18<12:02:24, 21.59s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2254/4261 [13:25:39<12:03:43, 21.64s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2255/4261 [13:26:01<12:01:58, 21.59s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2256/4261 [13:26:22<12:00:23, 21.56s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2257/4261 [13:26:44<11:59:13, 21.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2258/4261 [13:27:05<11:58:21, 21.52s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2259/4261 [13:27:27<11:57:39, 21.51s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2260/4261 [13:27:48<11:57:08, 21.50s/it]                                                         {'loss': 2.3355, 'learning_rate': 9.046659484801517e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2260/4261 [13:27:48<11:57:08, 21.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2261/4261 [13:28:10<11:56:50, 21.51s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2262/4261 [13:28:31<11:56:46, 21.51s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2263/4261 [13:28:53<11:56:38, 21.52s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2264/4261 [13:29:14<11:56:10, 21.52s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2265/4261 [13:29:36<11:58:07, 21.59s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2266/4261 [13:29:58<11:57:18, 21.57s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2267/4261 [13:30:19<11:55:59, 21.54s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2268/4261 [13:30:41<11:55:13, 21.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2269/4261 [13:31:02<11:54:45, 21.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2270/4261 [13:31:24<11:56:42, 21.60s/it]                                                         {'loss': 2.3197, 'learning_rate': 8.973292872861556e-06, 'epoch': 0.53}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2270/4261 [13:31:24<11:56:42, 21.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2271/4261 [13:31:45<11:55:34, 21.58s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2272/4261 [13:32:07<11:54:56, 21.57s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2273/4261 [13:32:28<11:53:44, 21.54s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2274/4261 [13:32:50<11:53:20, 21.54s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2275/4261 [13:33:11<11:52:38, 21.53s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2276/4261 [13:33:33<11:51:34, 21.51s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2277/4261 [13:33:54<11:50:55, 21.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2278/4261 [13:34:16<11:50:53, 21.51s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2279/4261 [13:34:37<11:50:38, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2280/4261 [13:34:59<11:50:46, 21.53s/it]                                                         {'loss': 2.3309, 'learning_rate': 8.899982072112091e-06, 'epoch': 0.53}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2280/4261 [13:34:59<11:50:46, 21.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2281/4261 [13:35:21<11:50:10, 21.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2282/4261 [13:35:42<11:49:38, 21.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2283/4261 [13:36:04<11:49:21, 21.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2284/4261 [13:36:25<11:49:07, 21.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2285/4261 [13:36:47<11:48:40, 21.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2286/4261 [13:37:08<11:48:00, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2287/4261 [13:37:30<11:47:34, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2288/4261 [13:37:51<11:47:06, 21.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2289/4261 [13:38:13<11:47:16, 21.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2290/4261 [13:38:34<11:46:43, 21.51s/it]                                                         {'loss': 2.3382, 'learning_rate': 8.826731067684766e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2290/4261 [13:38:34<11:46:43, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2291/4261 [13:38:56<11:46:13, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2292/4261 [13:39:17<11:45:37, 21.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2293/4261 [13:39:39<11:45:07, 21.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2294/4261 [13:40:00<11:45:01, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2295/4261 [13:40:22<11:44:34, 21.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2296/4261 [13:40:43<11:44:21, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2297/4261 [13:41:05<11:44:33, 21.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2298/4261 [13:41:26<11:43:45, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2299/4261 [13:41:48<11:43:26, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2300/4261 [13:42:09<11:43:15, 21.52s/it]                                                         {'loss': 2.3141, 'learning_rate': 8.753543841460742e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2300/4261 [13:42:09<11:43:15, 21.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2301/4261 [13:42:31<11:42:59, 21.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2302/4261 [13:42:52<11:42:58, 21.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2303/4261 [13:43:14<11:42:38, 21.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2304/4261 [13:43:35<11:42:33, 21.54s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2305/4261 [13:43:57<11:41:46, 21.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2306/4261 [13:44:19<11:43:36, 21.59s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2307/4261 [13:44:40<11:42:29, 21.57s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2308/4261 [13:45:02<11:41:33, 21.55s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2309/4261 [13:45:23<11:40:30, 21.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2310/4261 [13:45:45<11:39:45, 21.52s/it]                                                         {'loss': 2.3412, 'learning_rate': 8.680424371854225e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2310/4261 [13:45:45<11:39:45, 21.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2311/4261 [13:46:06<11:39:20, 21.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2312/4261 [13:46:28<11:38:50, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2313/4261 [13:46:49<11:38:26, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2314/4261 [13:47:11<11:38:35, 21.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2315/4261 [13:47:32<11:37:39, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2316/4261 [13:47:54<11:37:01, 21.50s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2317/4261 [13:48:15<11:37:06, 21.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2318/4261 [13:48:37<11:39:06, 21.59s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2319/4261 [13:48:58<11:37:42, 21.56s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2320/4261 [13:49:20<11:36:29, 21.53s/it]                                                         {'loss': 2.3267, 'learning_rate': 8.607376633596219e-06, 'epoch': 0.54}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2320/4261 [13:49:20<11:36:29, 21.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2321/4261 [13:49:41<11:35:34, 21.51s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2322/4261 [13:50:03<11:38:22, 21.61s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2323/4261 [13:50:25<11:36:33, 21.57s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2324/4261 [13:50:46<11:35:32, 21.54s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2325/4261 [13:51:08<11:34:35, 21.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2326/4261 [13:51:29<11:34:28, 21.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2327/4261 [13:51:51<11:33:54, 21.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2328/4261 [13:52:12<11:33:23, 21.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2329/4261 [13:52:34<11:33:16, 21.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2330/4261 [13:52:55<11:32:43, 21.52s/it]                                                         {'loss': 2.3276, 'learning_rate': 8.534404597518447e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2330/4261 [13:52:55<11:32:43, 21.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2331/4261 [13:53:17<11:31:54, 21.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2332/4261 [13:53:38<11:31:23, 21.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2333/4261 [13:54:00<11:31:04, 21.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2334/4261 [13:54:21<11:30:56, 21.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2335/4261 [13:54:43<11:33:30, 21.60s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2336/4261 [13:55:05<11:32:00, 21.57s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2337/4261 [13:55:26<11:30:53, 21.55s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2338/4261 [13:55:48<11:30:20, 21.54s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2339/4261 [13:56:09<11:29:33, 21.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2340/4261 [13:56:31<11:29:21, 21.53s/it]                                                         {'loss': 2.3287, 'learning_rate': 8.461512230337511e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2340/4261 [13:56:31<11:29:21, 21.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2341/4261 [13:56:52<11:29:19, 21.54s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2342/4261 [13:57:14<11:29:00, 21.54s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2343/4261 [13:57:35<11:28:30, 21.54s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2344/4261 [13:57:57<11:27:25, 21.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2345/4261 [13:58:18<11:26:33, 21.50s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2346/4261 [13:58:40<11:26:04, 21.50s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2347/4261 [13:59:01<11:27:54, 21.56s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2348/4261 [13:59:23<11:26:50, 21.54s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2349/4261 [13:59:44<11:26:13, 21.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2350/4261 [14:00:06<11:25:32, 21.52s/it]                                                         {'loss': 2.3254, 'learning_rate': 8.388703494439267e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2350/4261 [14:00:06<11:25:32, 21.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2351/4261 [14:00:28<11:27:59, 21.61s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2352/4261 [14:00:49<11:26:39, 21.58s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2353/4261 [14:01:11<11:26:02, 21.57s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2354/4261 [14:01:32<11:25:12, 21.56s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2355/4261 [14:01:54<11:24:05, 21.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2356/4261 [14:02:16<11:26:16, 21.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2357/4261 [14:02:37<11:24:40, 21.58s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2358/4261 [14:02:59<11:23:22, 21.55s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2359/4261 [14:03:20<11:22:27, 21.53s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2360/4261 [14:03:42<11:21:56, 21.52s/it]                                                         {'loss': 2.3179, 'learning_rate': 8.315982347663406e-06, 'epoch': 0.55}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2360/4261 [14:03:42<11:21:56, 21.52s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2361/4261 [14:04:03<11:21:16, 21.51s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2362/4261 [14:04:25<11:20:26, 21.50s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2363/4261 [14:04:46<11:19:54, 21.49s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2364/4261 [14:05:08<11:19:47, 21.50s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2365/4261 [14:05:29<11:19:34, 21.51s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2366/4261 [14:05:51<11:19:24, 21.51s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2367/4261 [14:06:12<11:21:31, 21.59s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2368/4261 [14:06:34<11:20:16, 21.56s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2369/4261 [14:06:55<11:19:12, 21.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2370/4261 [14:07:17<11:18:22, 21.52s/it]                                                         {'loss': 2.3112, 'learning_rate': 8.243352743088342e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2370/4261 [14:07:17<11:18:22, 21.52s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2371/4261 [14:07:39<11:20:49, 21.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2372/4261 [14:08:00<11:22:03, 21.66s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2373/4261 [14:08:22<11:19:49, 21.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2374/4261 [14:08:43<11:18:11, 21.56s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2375/4261 [14:09:05<11:17:18, 21.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2376/4261 [14:09:26<11:16:09, 21.52s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2377/4261 [14:09:48<11:16:00, 21.53s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2378/4261 [14:10:09<11:16:00, 21.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2379/4261 [14:10:31<11:15:28, 21.53s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2380/4261 [14:10:53<11:15:13, 21.54s/it]                                                         {'loss': 2.3283, 'learning_rate': 8.1708186288163e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2380/4261 [14:10:53<11:15:13, 21.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2381/4261 [14:11:14<11:14:20, 21.52s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2382/4261 [14:11:36<11:13:52, 21.52s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2383/4261 [14:11:57<11:15:57, 21.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2384/4261 [14:12:19<11:14:47, 21.57s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2385/4261 [14:12:40<11:14:25, 21.57s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2386/4261 [14:13:02<11:13:35, 21.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2387/4261 [14:13:24<11:13:30, 21.56s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2388/4261 [14:13:45<11:15:19, 21.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2389/4261 [14:14:07<11:13:44, 21.59s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2390/4261 [14:14:28<11:12:45, 21.57s/it]                                                         {'loss': 2.3344, 'learning_rate': 8.098383947758711e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2390/4261 [14:14:28<11:12:45, 21.57s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2391/4261 [14:14:50<11:11:59, 21.56s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2392/4261 [14:15:11<11:11:02, 21.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2393/4261 [14:15:33<11:10:37, 21.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2394/4261 [14:15:54<11:10:22, 21.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2395/4261 [14:16:16<11:10:03, 21.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2396/4261 [14:16:38<11:09:38, 21.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2397/4261 [14:16:59<11:09:29, 21.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2398/4261 [14:17:21<11:09:11, 21.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2399/4261 [14:17:42<11:08:42, 21.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2400/4261 [14:18:04<11:08:30, 21.55s/it]                                                         {'loss': 2.3271, 'learning_rate': 8.026052637421884e-06, 'epoch': 0.56}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2400/4261 [14:18:04<11:08:30, 21.55s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2401/4261 [14:18:25<11:08:30, 21.56s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2402/4261 [14:18:47<11:07:28, 21.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2403/4261 [14:19:09<11:09:47, 21.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2404/4261 [14:19:30<11:08:38, 21.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2405/4261 [14:19:52<11:07:44, 21.59s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2406/4261 [14:20:13<11:07:03, 21.58s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2407/4261 [14:20:35<11:06:03, 21.56s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2408/4261 [14:20:56<11:06:04, 21.57s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2409/4261 [14:21:18<11:05:43, 21.57s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2410/4261 [14:21:40<11:05:07, 21.56s/it]                                                         {'loss': 2.3235, 'learning_rate': 7.953828629692938e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2410/4261 [14:21:40<11:05:07, 21.56s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2411/4261 [14:22:01<11:04:53, 21.56s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2412/4261 [14:22:23<11:04:30, 21.56s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2413/4261 [14:22:44<11:04:50, 21.59s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2414/4261 [14:23:06<11:04:22, 21.58s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2415/4261 [14:23:28<11:04:30, 21.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2416/4261 [14:23:49<11:03:51, 21.59s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2417/4261 [14:24:11<11:03:09, 21.58s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2418/4261 [14:24:32<11:03:00, 21.58s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2419/4261 [14:24:54<11:02:58, 21.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2420/4261 [14:25:15<11:02:55, 21.61s/it]                                                         {'loss': 2.3364, 'learning_rate': 7.881715850626107e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2420/4261 [14:25:16<11:02:55, 21.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2421/4261 [14:25:37<11:02:16, 21.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2422/4261 [14:25:59<11:01:59, 21.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2423/4261 [14:26:20<11:01:51, 21.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2424/4261 [14:26:42<11:04:38, 21.71s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2425/4261 [14:27:04<11:03:25, 21.68s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2426/4261 [14:27:25<11:02:20, 21.66s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2427/4261 [14:27:47<11:01:10, 21.63s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2428/4261 [14:28:09<11:00:31, 21.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2429/4261 [14:28:30<10:59:34, 21.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2430/4261 [14:28:52<10:59:02, 21.60s/it]                                                         {'loss': 2.3179, 'learning_rate': 7.809718220229285e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2430/4261 [14:28:52<10:59:02, 21.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2431/4261 [14:29:13<10:58:58, 21.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2432/4261 [14:29:35<10:59:00, 21.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2433/4261 [14:29:57<10:58:26, 21.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2434/4261 [14:30:18<10:57:37, 21.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2435/4261 [14:30:40<10:57:09, 21.59s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2436/4261 [14:31:02<10:58:48, 21.66s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2437/4261 [14:31:23<10:57:33, 21.63s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2438/4261 [14:31:45<10:57:15, 21.63s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2439/4261 [14:32:06<10:56:46, 21.63s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2440/4261 [14:32:28<10:55:55, 21.61s/it]                                                         {'loss': 2.3173, 'learning_rate': 7.737839652250962e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2440/4261 [14:32:28<10:55:55, 21.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2441/4261 [14:32:50<10:55:54, 21.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2442/4261 [14:33:11<10:55:20, 21.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2443/4261 [14:33:33<10:55:01, 21.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2444/4261 [14:33:55<10:54:55, 21.63s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2445/4261 [14:34:16<10:54:52, 21.64s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2446/4261 [14:34:38<10:54:16, 21.63s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2447/4261 [14:34:59<10:53:49, 21.63s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2448/4261 [14:35:21<10:52:57, 21.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2449/4261 [14:35:43<10:52:29, 21.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2450/4261 [14:36:04<10:52:02, 21.60s/it]                                                         {'loss': 2.316, 'learning_rate': 7.666084053967465e-06, 'epoch': 0.57}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2450/4261 [14:36:04<10:52:02, 21.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2451/4261 [14:36:26<10:51:30, 21.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2452/4261 [14:36:47<10:51:09, 21.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2453/4261 [14:37:09<10:50:43, 21.59s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2454/4261 [14:37:31<10:52:38, 21.67s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2455/4261 [14:37:52<10:51:42, 21.65s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2456/4261 [14:38:14<10:53:18, 21.72s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2457/4261 [14:38:36<10:51:55, 21.68s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2458/4261 [14:38:57<10:50:57, 21.66s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2459/4261 [14:39:19<10:50:29, 21.66s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2460/4261 [14:39:41<10:49:35, 21.64s/it]                                                         {'loss': 2.3303, 'learning_rate': 7.59445532597055e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2460/4261 [14:39:41<10:49:35, 21.64s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2461/4261 [14:40:02<10:48:48, 21.63s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2462/4261 [14:40:24<10:47:49, 21.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2463/4261 [14:40:45<10:47:22, 21.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2464/4261 [14:41:07<10:46:28, 21.58s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2465/4261 [14:41:29<10:47:55, 21.65s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2466/4261 [14:41:50<10:46:51, 21.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2467/4261 [14:42:12<10:46:11, 21.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2468/4261 [14:42:34<10:45:43, 21.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2469/4261 [14:42:55<10:44:58, 21.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2470/4261 [14:43:17<10:44:38, 21.60s/it]                                                         {'loss': 2.3286, 'learning_rate': 7.522957361955399e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2470/4261 [14:43:17<10:44:38, 21.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2471/4261 [14:43:38<10:44:04, 21.59s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2472/4261 [14:44:00<10:43:33, 21.58s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2473/4261 [14:44:21<10:43:08, 21.58s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2474/4261 [14:44:43<10:45:33, 21.68s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2475/4261 [14:45:05<10:44:05, 21.64s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2476/4261 [14:45:26<10:43:04, 21.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2477/4261 [14:45:48<10:41:59, 21.59s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2478/4261 [14:46:10<10:41:33, 21.59s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2479/4261 [14:46:31<10:40:46, 21.57s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2480/4261 [14:46:53<10:40:08, 21.57s/it]                                                         {'loss': 2.3273, 'learning_rate': 7.451594048508919e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2480/4261 [14:46:53<10:40:08, 21.57s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2481/4261 [14:47:14<10:39:20, 21.55s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2482/4261 [14:47:36<10:39:11, 21.56s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2483/4261 [14:47:57<10:38:24, 21.54s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2484/4261 [14:48:19<10:38:38, 21.56s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2485/4261 [14:48:41<10:42:36, 21.71s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2486/4261 [14:49:02<10:40:52, 21.66s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2487/4261 [14:49:24<10:39:15, 21.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2488/4261 [14:49:46<10:38:04, 21.59s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2489/4261 [14:50:07<10:37:17, 21.58s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2490/4261 [14:50:29<10:39:08, 21.65s/it]                                                         {'loss': 2.3314, 'learning_rate': 7.380369264898512e-06, 'epoch': 0.58}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2490/4261 [14:50:29<10:39:08, 21.65s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2491/4261 [14:50:50<10:38:17, 21.64s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2492/4261 [14:51:12<10:37:19, 21.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2493/4261 [14:51:34<10:36:28, 21.60s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2494/4261 [14:51:55<10:35:23, 21.58s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2495/4261 [14:52:17<10:34:53, 21.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2496/4261 [14:52:38<10:34:13, 21.56s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2497/4261 [14:53:00<10:33:33, 21.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2498/4261 [14:53:21<10:33:20, 21.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2499/4261 [14:53:43<10:32:59, 21.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2500/4261 [14:54:04<10:32:43, 21.56s/it]                                                         {'loss': 2.3287, 'learning_rate': 7.309286882861171e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2500/4261 [14:54:04<10:32:43, 21.56s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2501/4261 [14:54:26<10:34:45, 21.64s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2502/4261 [14:54:48<10:33:52, 21.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2503/4261 [14:55:09<10:33:05, 21.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2504/4261 [14:55:31<10:32:55, 21.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2505/4261 [14:55:53<10:34:41, 21.69s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2506/4261 [14:56:14<10:32:55, 21.64s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2507/4261 [14:56:36<10:31:53, 21.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2508/4261 [14:56:58<10:30:27, 21.58s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2509/4261 [14:57:19<10:29:41, 21.56s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2510/4261 [14:57:41<10:28:47, 21.55s/it]                                                         {'loss': 2.3144, 'learning_rate': 7.238350766393022e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2510/4261 [14:57:41<10:28:47, 21.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2511/4261 [14:58:02<10:28:41, 21.56s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2512/4261 [14:58:24<10:28:09, 21.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2513/4261 [14:58:45<10:27:54, 21.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2514/4261 [14:59:07<10:27:20, 21.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2515/4261 [14:59:28<10:27:10, 21.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2516/4261 [14:59:50<10:27:14, 21.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2517/4261 [15:00:12<10:27:06, 21.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2518/4261 [15:00:33<10:26:37, 21.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2519/4261 [15:00:55<10:25:57, 21.56s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2520/4261 [15:01:16<10:25:12, 21.55s/it]                                                         {'loss': 2.3349, 'learning_rate': 7.167564771539286e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2520/4261 [15:01:16<10:25:12, 21.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2521/4261 [15:01:38<10:27:47, 21.65s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2522/4261 [15:02:00<10:26:23, 21.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2523/4261 [15:02:21<10:24:51, 21.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2524/4261 [15:02:43<10:24:25, 21.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2525/4261 [15:03:04<10:24:00, 21.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2526/4261 [15:03:26<10:23:42, 21.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2527/4261 [15:03:47<10:23:01, 21.56s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2528/4261 [15:04:09<10:22:10, 21.54s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2529/4261 [15:04:30<10:22:14, 21.56s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2530/4261 [15:04:52<10:22:07, 21.56s/it]                                                         {'loss': 2.3329, 'learning_rate': 7.096932746184657e-06, 'epoch': 0.59}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2530/4261 [15:04:52<10:22:07, 21.56s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2531/4261 [15:05:13<10:21:22, 21.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2532/4261 [15:05:35<10:20:38, 21.54s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2533/4261 [15:05:57<10:20:31, 21.55s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2534/4261 [15:06:18<10:20:00, 21.54s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2535/4261 [15:06:40<10:19:33, 21.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2536/4261 [15:07:01<10:19:20, 21.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2537/4261 [15:07:23<10:19:12, 21.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2538/4261 [15:07:44<10:19:14, 21.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2539/4261 [15:08:06<10:18:33, 21.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2540/4261 [15:08:27<10:18:23, 21.56s/it]                                                         {'loss': 2.3311, 'learning_rate': 7.026458529844145e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2540/4261 [15:08:27<10:18:23, 21.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2541/4261 [15:08:49<10:17:57, 21.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2542/4261 [15:09:10<10:17:37, 21.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2543/4261 [15:09:32<10:19:39, 21.64s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2544/4261 [15:09:54<10:18:25, 21.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2545/4261 [15:10:15<10:17:21, 21.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2546/4261 [15:10:37<10:16:34, 21.57s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2547/4261 [15:10:58<10:16:01, 21.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2548/4261 [15:11:20<10:15:36, 21.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2549/4261 [15:11:42<10:14:57, 21.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2550/4261 [15:12:03<10:14:10, 21.54s/it]                                                         {'loss': 2.3339, 'learning_rate': 6.956145953454354e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2550/4261 [15:12:03<10:14:10, 21.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2551/4261 [15:12:25<10:13:54, 21.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2552/4261 [15:12:46<10:13:55, 21.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2553/4261 [15:13:08<10:13:45, 21.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2554/4261 [15:13:30<10:15:27, 21.63s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2555/4261 [15:13:51<10:14:35, 21.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2556/4261 [15:14:13<10:14:01, 21.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2557/4261 [15:14:34<10:13:10, 21.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2558/4261 [15:14:56<10:12:33, 21.58s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2559/4261 [15:15:17<10:11:30, 21.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2560/4261 [15:15:39<10:10:54, 21.55s/it]                                                         {'loss': 2.3237, 'learning_rate': 6.88599883916523e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2560/4261 [15:15:39<10:10:54, 21.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2561/4261 [15:16:00<10:10:24, 21.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2562/4261 [15:16:22<10:10:02, 21.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2563/4261 [15:16:44<10:09:42, 21.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2564/4261 [15:17:05<10:09:20, 21.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2565/4261 [15:17:27<10:09:08, 21.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2566/4261 [15:17:48<10:08:46, 21.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2567/4261 [15:18:10<10:08:37, 21.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2568/4261 [15:18:31<10:08:38, 21.57s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2569/4261 [15:18:53<10:08:27, 21.58s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2570/4261 [15:19:15<10:08:31, 21.59s/it]                                                         {'loss': 2.3255, 'learning_rate': 6.816021000132304e-06, 'epoch': 0.6}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2570/4261 [15:19:15<10:08:31, 21.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2571/4261 [15:19:36<10:08:44, 21.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2572/4261 [15:19:58<10:10:33, 21.69s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2573/4261 [15:20:20<10:09:27, 21.66s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2574/4261 [15:20:42<10:10:29, 21.71s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2575/4261 [15:21:03<10:09:00, 21.67s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2576/4261 [15:21:25<10:07:44, 21.64s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2577/4261 [15:21:46<10:06:52, 21.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2578/4261 [15:22:08<10:06:00, 21.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2579/4261 [15:22:29<10:05:27, 21.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2580/4261 [15:22:51<10:05:04, 21.60s/it]                                                         {'loss': 2.3344, 'learning_rate': 6.746216240309402e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2580/4261 [15:22:51<10:05:04, 21.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2581/4261 [15:23:13<10:04:30, 21.59s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2582/4261 [15:23:34<10:03:32, 21.57s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2583/4261 [15:23:56<10:05:10, 21.64s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2584/4261 [15:24:17<10:04:12, 21.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2585/4261 [15:24:39<10:03:29, 21.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2586/4261 [15:25:01<10:02:28, 21.58s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2587/4261 [15:25:22<10:01:45, 21.57s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2588/4261 [15:25:44<10:01:31, 21.57s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2589/4261 [15:26:05<10:01:41, 21.59s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2590/4261 [15:26:27<10:00:45, 21.57s/it]                                                         {'loss': 2.3161, 'learning_rate': 6.676588354241867e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2590/4261 [15:26:27<10:00:45, 21.57s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2591/4261 [15:26:48<9:59:58, 21.56s/it]  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2592/4261 [15:27:10<10:02:11, 21.65s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2593/4261 [15:27:32<10:00:47, 21.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2594/4261 [15:27:53<9:59:40, 21.58s/it]  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2595/4261 [15:28:15<9:59:08, 21.58s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2596/4261 [15:28:36<9:58:24, 21.56s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2597/4261 [15:28:58<9:57:48, 21.56s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2598/4261 [15:29:19<9:57:05, 21.54s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2599/4261 [15:29:41<9:56:28, 21.53s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2600/4261 [15:30:02<9:55:24, 21.51s/it]                                                        {'loss': 2.3303, 'learning_rate': 6.607141126860288e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2600/4261 [15:30:02<9:55:24, 21.51s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2601/4261 [15:30:24<9:55:04, 21.51s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2602/4261 [15:30:45<9:54:55, 21.52s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2603/4261 [15:31:07<9:56:38, 21.59s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2604/4261 [15:31:29<9:57:41, 21.64s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2605/4261 [15:31:50<9:56:27, 21.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2606/4261 [15:32:12<9:55:47, 21.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2607/4261 [15:32:34<9:54:49, 21.58s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2608/4261 [15:32:55<9:56:47, 21.66s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2609/4261 [15:33:17<9:55:09, 21.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2610/4261 [15:33:38<9:53:51, 21.58s/it]                                                        {'loss': 2.32, 'learning_rate': 6.537878333274755e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2610/4261 [15:33:38<9:53:51, 21.58s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2611/4261 [15:34:00<9:52:28, 21.54s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2612/4261 [15:34:21<9:52:20, 21.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2613/4261 [15:34:43<9:51:56, 21.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2614/4261 [15:35:05<9:51:26, 21.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2615/4261 [15:35:26<9:51:10, 21.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2616/4261 [15:35:48<9:50:58, 21.56s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2617/4261 [15:36:09<9:50:17, 21.54s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2618/4261 [15:36:31<9:49:39, 21.53s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2619/4261 [15:36:53<9:51:46, 21.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2620/4261 [15:37:14<9:50:40, 21.60s/it]                                                        {'loss': 2.332, 'learning_rate': 6.4688037385696555e-06, 'epoch': 0.61}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2620/4261 [15:37:14<9:50:40, 21.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2621/4261 [15:37:36<9:49:58, 21.58s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2622/4261 [15:37:57<9:49:27, 21.58s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2623/4261 [15:38:19<9:51:01, 21.65s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2624/4261 [15:38:41<9:49:44, 21.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2625/4261 [15:39:02<9:48:32, 21.58s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2626/4261 [15:39:24<9:47:45, 21.57s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2627/4261 [15:39:45<9:47:19, 21.57s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2628/4261 [15:40:07<9:46:34, 21.55s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2629/4261 [15:40:28<9:45:57, 21.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2630/4261 [15:40:50<9:45:34, 21.54s/it]                                                        {'loss': 2.3269, 'learning_rate': 6.399921097598981e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2630/4261 [15:40:50<9:45:34, 21.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2631/4261 [15:41:11<9:45:22, 21.55s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2632/4261 [15:41:33<9:44:48, 21.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2633/4261 [15:41:54<9:44:28, 21.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2634/4261 [15:42:16<9:44:06, 21.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2635/4261 [15:42:37<9:43:41, 21.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2636/4261 [15:42:59<9:43:16, 21.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2637/4261 [15:43:20<9:42:39, 21.53s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2638/4261 [15:43:42<9:42:19, 21.53s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2639/4261 [15:44:04<9:44:08, 21.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2640/4261 [15:44:25<9:42:48, 21.57s/it]                                                        {'loss': 2.3209, 'learning_rate': 6.331234154782247e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2640/4261 [15:44:25<9:42:48, 21.57s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2641/4261 [15:44:47<9:41:48, 21.55s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2642/4261 [15:45:08<9:41:00, 21.53s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2643/4261 [15:45:30<9:40:17, 21.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2644/4261 [15:45:51<9:39:34, 21.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2645/4261 [15:46:13<9:39:27, 21.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2646/4261 [15:46:34<9:39:01, 21.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2647/4261 [15:46:56<9:38:38, 21.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2648/4261 [15:47:17<9:38:30, 21.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2649/4261 [15:47:39<9:38:02, 21.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2650/4261 [15:48:00<9:37:21, 21.50s/it]                                                        {'loss': 2.3062, 'learning_rate': 6.262746643900923e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2650/4261 [15:48:00<9:37:21, 21.50s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2651/4261 [15:48:22<9:37:06, 21.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2652/4261 [15:48:43<9:36:43, 21.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2653/4261 [15:49:05<9:36:29, 21.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2654/4261 [15:49:26<9:35:39, 21.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2655/4261 [15:49:48<9:35:20, 21.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2656/4261 [15:50:09<9:35:06, 21.50s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2657/4261 [15:50:31<9:35:15, 21.52s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2658/4261 [15:50:52<9:35:07, 21.53s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2659/4261 [15:51:14<9:34:13, 21.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2660/4261 [15:51:35<9:33:19, 21.49s/it]                                                        {'loss': 2.3223, 'learning_rate': 6.194462287895479e-06, 'epoch': 0.62}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2660/4261 [15:51:35<9:33:19, 21.49s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2661/4261 [15:51:57<9:35:11, 21.57s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2662/4261 [15:52:19<9:34:01, 21.54s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2663/4261 [15:52:40<9:33:18, 21.53s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2664/4261 [15:53:02<9:32:52, 21.52s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2665/4261 [15:53:23<9:32:19, 21.52s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2666/4261 [15:53:45<9:31:40, 21.51s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2667/4261 [15:54:06<9:31:05, 21.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2668/4261 [15:54:28<9:30:48, 21.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2669/4261 [15:54:49<9:30:26, 21.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2670/4261 [15:55:10<9:29:48, 21.49s/it]                                                        {'loss': 2.3102, 'learning_rate': 6.126384798663016e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2670/4261 [15:55:10<9:29:48, 21.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2671/4261 [15:55:32<9:29:27, 21.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2672/4261 [15:55:54<9:31:17, 21.57s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2673/4261 [15:56:15<9:29:53, 21.53s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2674/4261 [15:56:37<9:29:01, 21.51s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2675/4261 [15:56:58<9:28:18, 21.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2676/4261 [15:57:20<9:27:35, 21.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2677/4261 [15:57:41<9:27:19, 21.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2678/4261 [15:58:03<9:26:57, 21.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2679/4261 [15:58:24<9:26:12, 21.47s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2680/4261 [15:58:45<9:25:30, 21.46s/it]                                                        {'loss': 2.3337, 'learning_rate': 6.058517876855463e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2680/4261 [15:58:45<9:25:30, 21.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2681/4261 [15:59:07<9:25:15, 21.47s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2682/4261 [15:59:28<9:24:43, 21.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2683/4261 [15:59:50<9:24:24, 21.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2684/4261 [16:00:11<9:23:59, 21.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2685/4261 [16:00:33<9:23:48, 21.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2686/4261 [16:00:54<9:23:09, 21.45s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2687/4261 [16:01:16<9:22:54, 21.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2688/4261 [16:01:37<9:22:24, 21.45s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2689/4261 [16:01:59<9:22:22, 21.46s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2690/4261 [16:02:20<9:24:09, 21.55s/it]                                                        {'loss': 2.3215, 'learning_rate': 5.990865211678445e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2690/4261 [16:02:20<9:24:09, 21.55s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2691/4261 [16:02:42<9:23:14, 21.53s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2692/4261 [16:03:03<9:24:20, 21.58s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2693/4261 [16:03:25<9:22:42, 21.53s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2694/4261 [16:03:46<9:21:48, 21.51s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2695/4261 [16:04:08<9:20:52, 21.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2696/4261 [16:04:29<9:20:11, 21.48s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2697/4261 [16:04:51<9:19:39, 21.47s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2698/4261 [16:05:12<9:19:17, 21.47s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2699/4261 [16:05:34<9:19:43, 21.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2700/4261 [16:05:55<9:19:32, 21.51s/it]                                                        {'loss': 2.3169, 'learning_rate': 5.923430480690712e-06, 'epoch': 0.63}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2700/4261 [16:05:55<9:19:32, 21.51s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2701/4261 [16:06:17<9:19:01, 21.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2702/4261 [16:06:38<9:20:24, 21.57s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2703/4261 [16:07:00<9:19:16, 21.54s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2704/4261 [16:07:21<9:18:17, 21.51s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2705/4261 [16:07:43<9:17:47, 21.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2706/4261 [16:08:04<9:17:47, 21.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2707/4261 [16:08:26<9:17:23, 21.52s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2708/4261 [16:08:47<9:16:16, 21.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2709/4261 [16:09:09<9:15:51, 21.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2710/4261 [16:09:31<9:17:40, 21.57s/it]                                                        {'loss': 2.3286, 'learning_rate': 5.8562173496042454e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2710/4261 [16:09:31<9:17:40, 21.57s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2711/4261 [16:09:52<9:16:26, 21.54s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2712/4261 [16:10:14<9:15:19, 21.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2713/4261 [16:10:35<9:14:37, 21.50s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2714/4261 [16:10:56<9:14:00, 21.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2715/4261 [16:11:18<9:13:39, 21.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2716/4261 [16:11:39<9:13:23, 21.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2717/4261 [16:12:01<9:12:59, 21.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2718/4261 [16:12:22<9:12:36, 21.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2719/4261 [16:12:44<9:12:11, 21.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2720/4261 [16:13:05<9:11:48, 21.49s/it]                                                        {'loss': 2.3179, 'learning_rate': 5.789229472084992e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2720/4261 [16:13:05<9:11:48, 21.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2721/4261 [16:13:27<9:13:12, 21.55s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2722/4261 [16:13:49<9:14:00, 21.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2723/4261 [16:14:10<9:12:51, 21.57s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2724/4261 [16:14:32<9:11:34, 21.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2725/4261 [16:14:53<9:10:43, 21.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2726/4261 [16:15:15<9:12:28, 21.59s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2727/4261 [16:15:36<9:11:09, 21.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2728/4261 [16:15:58<9:09:57, 21.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2729/4261 [16:16:19<9:09:16, 21.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2730/4261 [16:16:41<9:08:56, 21.51s/it]                                                        {'loss': 2.333, 'learning_rate': 5.722470489554236e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2730/4261 [16:16:41<9:08:56, 21.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2731/4261 [16:17:02<9:08:35, 21.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2732/4261 [16:17:24<9:07:38, 21.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2733/4261 [16:17:45<9:07:04, 21.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2734/4261 [16:18:07<9:06:46, 21.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2735/4261 [16:18:28<9:06:26, 21.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2736/4261 [16:18:50<9:06:15, 21.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2737/4261 [16:19:11<9:06:12, 21.50s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2738/4261 [16:19:33<9:07:44, 21.58s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2739/4261 [16:19:55<9:06:57, 21.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2740/4261 [16:20:16<9:06:27, 21.56s/it]                                                        {'loss': 2.3158, 'learning_rate': 5.655944030990678e-06, 'epoch': 0.64}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2740/4261 [16:20:16<9:06:27, 21.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2741/4261 [16:20:38<9:07:52, 21.63s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2742/4261 [16:20:59<9:06:27, 21.58s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2743/4261 [16:21:21<9:05:24, 21.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2744/4261 [16:21:42<9:04:37, 21.54s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2745/4261 [16:22:04<9:04:15, 21.54s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2746/4261 [16:22:26<9:03:37, 21.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2747/4261 [16:22:47<9:03:09, 21.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2748/4261 [16:23:09<9:02:55, 21.53s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2749/4261 [16:23:30<9:02:14, 21.52s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2750/4261 [16:23:52<9:01:38, 21.51s/it]                                                        {'loss': 2.3176, 'learning_rate': 5.5896537127331475e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2750/4261 [16:23:52<9:01:38, 21.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2751/4261 [16:24:13<9:00:43, 21.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2752/4261 [16:24:34<9:00:31, 21.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2753/4261 [16:24:56<9:00:19, 21.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2754/4261 [16:25:17<8:59:46, 21.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2755/4261 [16:25:39<8:59:24, 21.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2756/4261 [16:26:00<8:59:01, 21.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2757/4261 [16:26:22<9:00:57, 21.58s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2758/4261 [16:26:44<8:59:56, 21.55s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2759/4261 [16:27:05<8:59:27, 21.55s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2760/4261 [16:27:27<8:58:31, 21.53s/it]                                                        {'loss': 2.3259, 'learning_rate': 5.523603138284028e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2760/4261 [16:27:27<8:58:31, 21.53s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2761/4261 [16:27:48<8:58:03, 21.52s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2762/4261 [16:28:10<8:57:25, 21.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2763/4261 [16:28:31<8:57:00, 21.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2764/4261 [16:28:53<8:56:29, 21.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2765/4261 [16:29:14<8:56:01, 21.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2766/4261 [16:29:36<8:55:44, 21.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2767/4261 [16:29:57<8:55:38, 21.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2768/4261 [16:30:19<8:54:54, 21.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2769/4261 [16:30:40<8:54:14, 21.48s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2770/4261 [16:31:02<8:54:23, 21.50s/it]                                                        {'loss': 2.3288, 'learning_rate': 5.4577958981133735e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2770/4261 [16:31:02<8:54:23, 21.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2771/4261 [16:31:23<8:53:29, 21.48s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2772/4261 [16:31:45<8:53:47, 21.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2773/4261 [16:32:06<8:53:39, 21.52s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2774/4261 [16:32:28<8:52:57, 21.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2775/4261 [16:32:49<8:52:26, 21.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2776/4261 [16:33:11<8:52:00, 21.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2777/4261 [16:33:32<8:51:36, 21.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2778/4261 [16:33:54<8:51:32, 21.51s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2779/4261 [16:34:16<8:53:05, 21.58s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2780/4261 [16:34:37<8:52:17, 21.57s/it]                                                        {'loss': 2.3257, 'learning_rate': 5.392235569463729e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2780/4261 [16:34:37<8:52:17, 21.57s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2781/4261 [16:34:59<8:51:47, 21.56s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2782/4261 [16:35:20<8:50:52, 21.54s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2783/4261 [16:35:42<8:50:13, 21.52s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2784/4261 [16:36:03<8:49:46, 21.52s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2785/4261 [16:36:25<8:49:27, 21.52s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2786/4261 [16:36:46<8:48:31, 21.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2787/4261 [16:37:08<8:48:14, 21.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2788/4261 [16:37:29<8:47:34, 21.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2789/4261 [16:37:51<8:47:27, 21.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2790/4261 [16:38:12<8:47:20, 21.51s/it]                                                        {'loss': 2.33, 'learning_rate': 5.32692571615568e-06, 'epoch': 0.65}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2790/4261 [16:38:12<8:47:20, 21.51s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2791/4261 [16:38:34<8:49:04, 21.59s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2792/4261 [16:38:55<8:48:03, 21.57s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2793/4261 [16:39:17<8:47:00, 21.54s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2794/4261 [16:39:38<8:46:37, 21.54s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2795/4261 [16:40:00<8:46:05, 21.53s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2796/4261 [16:40:21<8:44:44, 21.49s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2797/4261 [16:40:43<8:44:39, 21.50s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2798/4261 [16:41:04<8:44:48, 21.52s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2799/4261 [16:41:26<8:44:14, 21.51s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2800/4261 [16:41:47<8:43:53, 21.52s/it]                                                        {'loss': 2.3252, 'learning_rate': 5.261869888394108e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2800/4261 [16:41:47<8:43:53, 21.52s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2801/4261 [16:42:09<8:43:23, 21.51s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2802/4261 [16:42:30<8:42:51, 21.50s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2803/4261 [16:42:52<8:42:35, 21.51s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2804/4261 [16:43:13<8:42:09, 21.50s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2805/4261 [16:43:35<8:41:47, 21.50s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2806/4261 [16:43:56<8:41:44, 21.52s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2807/4261 [16:44:18<8:41:22, 21.52s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2808/4261 [16:44:40<8:43:10, 21.60s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2809/4261 [16:45:02<8:44:05, 21.66s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2810/4261 [16:45:23<8:42:35, 21.61s/it]                                                        {'loss': 2.3174, 'learning_rate': 5.197071622575228e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2810/4261 [16:45:23<8:42:35, 21.61s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2811/4261 [16:45:45<8:41:34, 21.58s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2812/4261 [16:46:06<8:40:37, 21.56s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2813/4261 [16:46:28<8:39:33, 21.53s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2814/4261 [16:46:49<8:39:19, 21.53s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2815/4261 [16:47:11<8:39:03, 21.54s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2816/4261 [16:47:32<8:38:19, 21.52s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2817/4261 [16:47:54<8:37:58, 21.52s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2818/4261 [16:48:15<8:37:35, 21.52s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2819/4261 [16:48:37<8:37:32, 21.53s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2820/4261 [16:48:58<8:38:49, 21.60s/it]                                                        {'loss': 2.3282, 'learning_rate': 5.1325344410943505e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2820/4261 [16:48:58<8:38:49, 21.60s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2821/4261 [16:49:20<8:38:28, 21.60s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2822/4261 [16:49:42<8:37:19, 21.57s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2823/4261 [16:50:03<8:36:43, 21.56s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2824/4261 [16:50:25<8:36:18, 21.56s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2825/4261 [16:50:46<8:35:54, 21.56s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2826/4261 [16:51:08<8:35:39, 21.56s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2827/4261 [16:51:29<8:35:28, 21.57s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2828/4261 [16:51:51<8:34:40, 21.55s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2829/4261 [16:52:13<8:36:03, 21.62s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2830/4261 [16:52:34<8:35:14, 21.60s/it]                                                        {'loss': 2.3303, 'learning_rate': 5.068261852154368e-06, 'epoch': 0.66}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2830/4261 [16:52:34<8:35:14, 21.60s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2831/4261 [16:52:56<8:34:19, 21.58s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2832/4261 [16:53:17<8:33:16, 21.55s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2833/4261 [16:53:39<8:32:51, 21.55s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2834/4261 [16:54:00<8:32:19, 21.54s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2835/4261 [16:54:22<8:31:56, 21.54s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2836/4261 [16:54:43<8:31:33, 21.54s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2837/4261 [16:55:05<8:30:50, 21.52s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2838/4261 [16:55:26<8:30:01, 21.51s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2839/4261 [16:55:48<8:31:29, 21.58s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2840/4261 [16:56:10<8:32:00, 21.62s/it]                                                        {'loss': 2.3333, 'learning_rate': 5.004257349575103e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2840/4261 [16:56:10<8:32:00, 21.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2841/4261 [16:56:31<8:30:48, 21.58s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2842/4261 [16:56:53<8:30:05, 21.57s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2843/4261 [16:57:14<8:29:09, 21.54s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2844/4261 [16:57:36<8:30:54, 21.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2845/4261 [16:57:58<8:29:30, 21.59s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2846/4261 [16:58:19<8:28:26, 21.56s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2847/4261 [16:58:41<8:27:48, 21.55s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2848/4261 [16:59:02<8:27:02, 21.53s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2849/4261 [16:59:24<8:26:36, 21.53s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2850/4261 [16:59:45<8:26:08, 21.52s/it]                                                        {'loss': 2.3179, 'learning_rate': 4.9405244126033555e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2850/4261 [16:59:45<8:26:08, 21.52s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2851/4261 [17:00:07<8:25:44, 21.52s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2852/4261 [17:00:28<8:25:24, 21.52s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2853/4261 [17:00:50<8:24:54, 21.52s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2854/4261 [17:01:11<8:24:43, 21.52s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2855/4261 [17:01:33<8:24:15, 21.52s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2856/4261 [17:01:55<8:25:35, 21.59s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2857/4261 [17:02:16<8:24:48, 21.57s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2858/4261 [17:02:38<8:23:57, 21.55s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2859/4261 [17:02:59<8:24:57, 21.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2860/4261 [17:03:21<8:23:58, 21.58s/it]                                                        {'loss': 2.3181, 'learning_rate': 4.8770665057237806e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2860/4261 [17:03:21<8:23:58, 21.58s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2861/4261 [17:03:42<8:23:21, 21.57s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2862/4261 [17:04:04<8:22:33, 21.55s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2863/4261 [17:04:25<8:21:56, 21.54s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2864/4261 [17:04:47<8:21:15, 21.53s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2865/4261 [17:05:08<8:20:58, 21.53s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2866/4261 [17:05:30<8:20:52, 21.54s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2867/4261 [17:05:52<8:20:25, 21.54s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2868/4261 [17:06:13<8:19:59, 21.54s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2869/4261 [17:06:35<8:19:32, 21.53s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2870/4261 [17:06:56<8:19:09, 21.53s/it]                                                        {'loss': 2.3338, 'learning_rate': 4.813887078470553e-06, 'epoch': 0.67}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2870/4261 [17:06:56<8:19:09, 21.53s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2871/4261 [17:07:18<8:18:35, 21.52s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2872/4261 [17:07:39<8:17:59, 21.51s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2873/4261 [17:08:01<8:17:36, 21.51s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2874/4261 [17:08:22<8:17:09, 21.51s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2875/4261 [17:08:44<8:18:51, 21.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2876/4261 [17:09:05<8:17:48, 21.57s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2877/4261 [17:09:27<8:17:13, 21.56s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2878/4261 [17:09:49<8:17:03, 21.56s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2879/4261 [17:10:10<8:16:18, 21.55s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2880/4261 [17:10:32<8:15:42, 21.54s/it]                                                        {'loss': 2.3264, 'learning_rate': 4.7509895652398705e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2880/4261 [17:10:32<8:15:42, 21.54s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2881/4261 [17:10:53<8:15:16, 21.53s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2882/4261 [17:11:15<8:15:08, 21.54s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2883/4261 [17:11:36<8:14:42, 21.54s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2884/4261 [17:11:58<8:14:23, 21.54s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2885/4261 [17:12:19<8:14:21, 21.56s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2886/4261 [17:12:41<8:14:12, 21.57s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2887/4261 [17:13:02<8:13:42, 21.56s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2888/4261 [17:13:24<8:13:36, 21.57s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2889/4261 [17:13:46<8:13:34, 21.58s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2890/4261 [17:14:07<8:12:55, 21.57s/it]                                                        {'loss': 2.3261, 'learning_rate': 4.6883773851032485e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2890/4261 [17:14:07<8:12:55, 21.57s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2891/4261 [17:14:29<8:12:37, 21.57s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2892/4261 [17:14:50<8:12:25, 21.58s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2893/4261 [17:15:12<8:12:18, 21.59s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2894/4261 [17:15:34<8:12:07, 21.60s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2895/4261 [17:15:55<8:11:28, 21.59s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2896/4261 [17:16:17<8:11:23, 21.60s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2897/4261 [17:16:39<8:12:43, 21.67s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2898/4261 [17:17:00<8:11:50, 21.65s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2899/4261 [17:17:22<8:11:23, 21.65s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2900/4261 [17:17:43<8:10:27, 21.62s/it]                                                        {'loss': 2.3283, 'learning_rate': 4.626053941621663e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2900/4261 [17:17:43<8:10:27, 21.62s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2901/4261 [17:18:05<8:10:00, 21.62s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2902/4261 [17:18:27<8:09:04, 21.59s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2903/4261 [17:18:48<8:08:55, 21.60s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2904/4261 [17:19:10<8:08:57, 21.62s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2905/4261 [17:19:31<8:08:39, 21.62s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2906/4261 [17:19:53<8:08:08, 21.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2907/4261 [17:20:15<8:07:40, 21.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2908/4261 [17:20:36<8:07:09, 21.60s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2909/4261 [17:20:58<8:08:05, 21.66s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2910/4261 [17:21:20<8:06:49, 21.62s/it]                                                        {'loss': 2.3192, 'learning_rate': 4.564022622660539e-06, 'epoch': 0.68}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2910/4261 [17:21:20<8:06:49, 21.62s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2911/4261 [17:21:41<8:06:02, 21.60s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2912/4261 [17:22:03<8:05:11, 21.58s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2913/4261 [17:22:24<8:04:49, 21.58s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2914/4261 [17:22:46<8:04:43, 21.59s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2915/4261 [17:23:07<8:04:15, 21.59s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2916/4261 [17:23:29<8:03:57, 21.59s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2917/4261 [17:23:51<8:03:26, 21.58s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2918/4261 [17:24:12<8:02:57, 21.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2919/4261 [17:24:34<8:02:41, 21.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2920/4261 [17:24:55<8:02:25, 21.59s/it]                                                        {'loss': 2.3207, 'learning_rate': 4.502286800205583e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2920/4261 [17:24:55<8:02:25, 21.59s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2921/4261 [17:25:17<8:02:21, 21.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2922/4261 [17:25:39<8:01:40, 21.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2923/4261 [17:26:00<8:01:13, 21.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2924/4261 [17:26:22<8:00:47, 21.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2925/4261 [17:26:43<8:00:30, 21.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2926/4261 [17:27:05<8:00:02, 21.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2927/4261 [17:27:27<8:03:37, 21.75s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2928/4261 [17:27:49<8:01:35, 21.68s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2929/4261 [17:28:10<8:00:55, 21.66s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2930/4261 [17:28:32<8:00:22, 21.65s/it]                                                        {'loss': 2.3339, 'learning_rate': 4.44084983017949e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2930/4261 [17:28:32<8:00:22, 21.65s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2931/4261 [17:28:53<7:59:32, 21.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2932/4261 [17:29:15<7:59:07, 21.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2933/4261 [17:29:37<7:58:10, 21.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2934/4261 [17:29:58<7:58:00, 21.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2935/4261 [17:30:20<7:57:30, 21.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2936/4261 [17:30:41<7:56:52, 21.59s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2937/4261 [17:31:03<7:56:36, 21.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2938/4261 [17:31:25<7:57:43, 21.67s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2939/4261 [17:31:46<7:56:18, 21.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2940/4261 [17:32:08<7:55:30, 21.60s/it]                                                        {'loss': 2.3264, 'learning_rate': 4.379715052259515e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2940/4261 [17:32:08<7:55:30, 21.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2941/4261 [17:32:29<7:54:49, 21.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2942/4261 [17:32:51<7:54:25, 21.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2943/4261 [17:33:12<7:53:40, 21.56s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2944/4261 [17:33:34<7:53:30, 21.57s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2945/4261 [17:33:56<7:53:00, 21.57s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2946/4261 [17:34:17<7:52:50, 21.57s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2947/4261 [17:34:39<7:54:09, 21.65s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2948/4261 [17:35:01<7:53:12, 21.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2949/4261 [17:35:22<7:52:19, 21.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2950/4261 [17:35:44<7:51:38, 21.59s/it]                                                        {'loss': 2.3191, 'learning_rate': 4.318885789695922e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2950/4261 [17:35:44<7:51:38, 21.59s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2951/4261 [17:36:05<7:51:02, 21.57s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2952/4261 [17:36:27<7:50:39, 21.57s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2953/4261 [17:36:48<7:50:09, 21.57s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2954/4261 [17:37:10<7:50:07, 21.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2955/4261 [17:37:32<7:49:54, 21.59s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2956/4261 [17:37:53<7:49:35, 21.59s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2957/4261 [17:38:15<7:50:53, 21.67s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2958/4261 [17:38:37<7:51:42, 21.72s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2959/4261 [17:38:58<7:50:03, 21.66s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2960/4261 [17:39:20<7:49:07, 21.63s/it]                                                        {'loss': 2.3243, 'learning_rate': 4.258365349131346e-06, 'epoch': 0.69}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2960/4261 [17:39:20<7:49:07, 21.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2961/4261 [17:39:42<7:48:14, 21.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2962/4261 [17:40:03<7:47:28, 21.59s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2963/4261 [17:40:25<7:49:07, 21.69s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2964/4261 [17:40:46<7:47:43, 21.64s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2965/4261 [17:41:08<7:46:43, 21.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2966/4261 [17:41:30<7:46:13, 21.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2967/4261 [17:41:51<7:45:54, 21.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2968/4261 [17:42:13<7:45:06, 21.58s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2969/4261 [17:42:34<7:44:22, 21.57s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2970/4261 [17:42:56<7:43:49, 21.56s/it]                                                        {'loss': 2.3207, 'learning_rate': 4.198157020421043e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2970/4261 [17:42:56<7:43:49, 21.56s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2971/4261 [17:43:17<7:43:24, 21.55s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2972/4261 [17:43:39<7:43:11, 21.56s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2973/4261 [17:44:00<7:42:41, 21.55s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2974/4261 [17:44:22<7:43:56, 21.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2975/4261 [17:44:44<7:42:47, 21.59s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2976/4261 [17:45:05<7:41:57, 21.57s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2977/4261 [17:45:27<7:42:55, 21.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2978/4261 [17:45:49<7:42:08, 21.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2979/4261 [17:46:10<7:41:34, 21.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2980/4261 [17:46:32<7:41:12, 21.60s/it]                                                        {'loss': 2.3314, 'learning_rate': 4.138264076454055e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2980/4261 [17:46:32<7:41:12, 21.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2981/4261 [17:46:53<7:40:29, 21.59s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2982/4261 [17:47:15<7:40:25, 21.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2983/4261 [17:47:37<7:40:10, 21.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2984/4261 [17:47:58<7:39:17, 21.58s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2985/4261 [17:48:20<7:38:34, 21.56s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2986/4261 [17:48:41<7:38:05, 21.56s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2987/4261 [17:49:03<7:37:40, 21.55s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2988/4261 [17:49:24<7:37:28, 21.56s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2989/4261 [17:49:46<7:37:11, 21.57s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2990/4261 [17:50:08<7:37:07, 21.58s/it]                                                        {'loss': 2.3169, 'learning_rate': 4.078689772975289e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2990/4261 [17:50:08<7:37:07, 21.58s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2991/4261 [17:50:29<7:36:47, 21.58s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2992/4261 [17:50:51<7:36:25, 21.58s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2993/4261 [17:51:13<7:37:34, 21.65s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2994/4261 [17:51:34<7:36:39, 21.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2995/4261 [17:51:56<7:35:49, 21.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2996/4261 [17:52:17<7:35:13, 21.59s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2997/4261 [17:52:39<7:34:28, 21.57s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2998/4261 [17:53:00<7:33:50, 21.56s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2999/4261 [17:53:22<7:33:14, 21.55s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3000/4261 [17:53:43<7:32:49, 21.55s/it]                                                        {'loss': 2.3227, 'learning_rate': 4.019437348408553e-06, 'epoch': 0.7}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3000/4261 [17:53:43<7:32:49, 21.55s/it][INFO|trainer.py:2979] 2024-04-19 10:03:23,945 >> Saving model checkpoint to /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/tmp-checkpoint-3000
[INFO|tokenization_utils_base.py:2435] 2024-04-19 10:03:40,431 >> tokenizer config file saved in /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/tmp-checkpoint-3000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-04-19 10:03:40,432 >> Special tokens file saved in /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/tmp-checkpoint-3000/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-04-19 10:03:40,433 >> added tokens file saved in /home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/tmp-checkpoint-3000/added_tokens.json
[INFO|trainer.py:3071] 2024-04-19 10:03:41,336 >> Deleting older checkpoint [/home/nfs02/wangzj/checkpoints/llama-moe/qwen/1.8b-arderu6b-moe-50wrouter/checkpoint-2000] due to args.save_total_limit
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3001/4261 [17:54:26<9:47:00, 27.95s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3002/4261 [17:54:48<9:05:06, 25.98s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3003/4261 [17:55:09<8:37:29, 24.68s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3004/4261 [17:55:31<8:18:17, 23.78s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3005/4261 [17:55:53<8:05:10, 23.18s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3006/4261 [17:56:15<7:57:45, 22.84s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3007/4261 [17:56:37<7:50:45, 22.52s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3008/4261 [17:56:58<7:45:25, 22.29s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3009/4261 [17:57:20<7:41:23, 22.11s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3010/4261 [17:57:42<7:39:45, 22.05s/it]                                                        {'loss': 2.3293, 'learning_rate': 3.960510023680506e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3010/4261 [17:57:42<7:39:45, 22.05s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3011/4261 [17:58:04<7:37:06, 21.94s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3012/4261 [17:58:25<7:34:56, 21.85s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3013/4261 [17:58:47<7:33:13, 21.79s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3014/4261 [17:59:09<7:32:06, 21.75s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3015/4261 [17:59:30<7:30:58, 21.72s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3016/4261 [17:59:52<7:30:13, 21.70s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3017/4261 [18:00:13<7:29:10, 21.66s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3018/4261 [18:00:35<7:29:44, 21.71s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3019/4261 [18:00:57<7:28:52, 21.68s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3020/4261 [18:01:18<7:27:51, 21.65s/it]                                                        {'loss': 2.3309, 'learning_rate': 3.901911002045563e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3020/4261 [18:01:18<7:27:51, 21.65s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3021/4261 [18:01:40<7:27:24, 21.65s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3022/4261 [18:02:02<7:28:20, 21.71s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3023/4261 [18:02:24<7:27:22, 21.68s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3024/4261 [18:02:45<7:26:42, 21.67s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3025/4261 [18:03:07<7:26:10, 21.66s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3026/4261 [18:03:29<7:27:00, 21.72s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3027/4261 [18:03:50<7:25:27, 21.66s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3028/4261 [18:04:12<7:24:36, 21.64s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3029/4261 [18:04:33<7:23:42, 21.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3030/4261 [18:04:55<7:23:29, 21.62s/it]                                                        {'loss': 2.3399, 'learning_rate': 3.843643468911785e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3030/4261 [18:04:55<7:23:29, 21.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3031/4261 [18:05:16<7:22:47, 21.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3032/4261 [18:05:38<7:22:14, 21.59s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3033/4261 [18:06:00<7:21:33, 21.57s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3034/4261 [18:06:21<7:22:46, 21.65s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3035/4261 [18:06:43<7:22:03, 21.63s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3036/4261 [18:07:05<7:21:17, 21.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3037/4261 [18:07:26<7:20:42, 21.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3038/4261 [18:07:48<7:19:59, 21.59s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3039/4261 [18:08:09<7:19:32, 21.58s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3040/4261 [18:08:31<7:19:03, 21.58s/it]                                                        {'loss': 2.3365, 'learning_rate': 3.785710591667727e-06, 'epoch': 0.71}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3040/4261 [18:08:31<7:19:03, 21.58s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3041/4261 [18:08:52<7:18:46, 21.58s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3042/4261 [18:09:14<7:18:00, 21.56s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3043/4261 [18:09:35<7:17:29, 21.55s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3044/4261 [18:09:57<7:17:08, 21.55s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3045/4261 [18:10:19<7:17:01, 21.56s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3046/4261 [18:10:40<7:16:55, 21.58s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3047/4261 [18:11:02<7:16:56, 21.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3048/4261 [18:11:23<7:16:33, 21.59s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3049/4261 [18:11:45<7:17:43, 21.67s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3050/4261 [18:12:07<7:16:30, 21.63s/it]                                                        {'loss': 2.3246, 'learning_rate': 3.728115519510224e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3050/4261 [18:12:07<7:16:30, 21.63s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3051/4261 [18:12:28<7:15:42, 21.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3052/4261 [18:12:50<7:15:00, 21.59s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3053/4261 [18:13:12<7:14:33, 21.58s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3054/4261 [18:13:33<7:13:53, 21.57s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3055/4261 [18:13:55<7:13:35, 21.57s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3056/4261 [18:14:16<7:13:21, 21.58s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3057/4261 [18:14:38<7:13:05, 21.58s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3058/4261 [18:14:59<7:12:36, 21.58s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3059/4261 [18:15:21<7:12:28, 21.59s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3060/4261 [18:15:43<7:11:49, 21.57s/it]                                                        {'loss': 2.3244, 'learning_rate': 3.670861383273243e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3060/4261 [18:15:43<7:11:49, 21.57s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3061/4261 [18:16:04<7:11:25, 21.57s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3062/4261 [18:16:26<7:11:13, 21.58s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3063/4261 [18:16:47<7:11:09, 21.59s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3064/4261 [18:17:09<7:10:55, 21.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3065/4261 [18:17:31<7:10:31, 21.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3066/4261 [18:17:52<7:09:56, 21.59s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3067/4261 [18:18:14<7:09:33, 21.59s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3068/4261 [18:18:35<7:09:23, 21.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3069/4261 [18:18:57<7:08:30, 21.57s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3070/4261 [18:19:18<7:08:13, 21.57s/it]                                                        {'loss': 2.3311, 'learning_rate': 3.6139512952576726e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3070/4261 [18:19:18<7:08:13, 21.57s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3071/4261 [18:19:40<7:08:01, 21.58s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3072/4261 [18:20:02<7:07:39, 21.58s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3073/4261 [18:20:23<7:07:11, 21.57s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3074/4261 [18:20:45<7:06:43, 21.57s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3075/4261 [18:21:07<7:08:12, 21.66s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3076/4261 [18:21:28<7:07:18, 21.64s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3077/4261 [18:21:50<7:06:26, 21.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3078/4261 [18:22:11<7:05:51, 21.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3079/4261 [18:22:33<7:06:55, 21.67s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3080/4261 [18:22:55<7:05:55, 21.64s/it]                                                        {'loss': 2.3167, 'learning_rate': 3.5573883490621443e-06, 'epoch': 0.72}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3080/4261 [18:22:55<7:05:55, 21.64s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3081/4261 [18:23:16<7:05:14, 21.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3082/4261 [18:23:38<7:04:48, 21.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3083/4261 [18:23:59<7:04:27, 21.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3084/4261 [18:24:21<7:04:03, 21.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3085/4261 [18:24:43<7:04:04, 21.64s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3086/4261 [18:25:04<7:03:10, 21.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3087/4261 [18:25:26<7:02:35, 21.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3088/4261 [18:25:47<7:02:09, 21.59s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3089/4261 [18:26:09<7:02:04, 21.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3090/4261 [18:26:31<7:01:41, 21.61s/it]                                                        {'loss': 2.3124, 'learning_rate': 3.5011756194148693e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3090/4261 [18:26:31<7:01:41, 21.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3091/4261 [18:26:52<7:01:02, 21.59s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3092/4261 [18:27:14<7:00:22, 21.58s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3093/4261 [18:27:35<7:00:07, 21.58s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3094/4261 [18:27:57<6:59:38, 21.58s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3095/4261 [18:28:19<6:59:06, 21.57s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3096/4261 [18:28:40<6:58:38, 21.56s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3097/4261 [18:29:02<6:58:19, 21.56s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3098/4261 [18:29:23<6:58:00, 21.57s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3099/4261 [18:29:45<6:57:49, 21.57s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3100/4261 [18:30:06<6:57:40, 21.59s/it]                                                        {'loss': 2.3157, 'learning_rate': 3.4453161620064813e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3100/4261 [18:30:06<6:57:40, 21.59s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3101/4261 [18:30:28<6:57:15, 21.58s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3102/4261 [18:30:50<6:58:30, 21.67s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3103/4261 [18:31:11<6:57:36, 21.64s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3104/4261 [18:31:33<6:58:23, 21.70s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3105/4261 [18:31:55<6:57:08, 21.65s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3106/4261 [18:32:16<6:56:09, 21.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3107/4261 [18:32:38<6:55:26, 21.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3108/4261 [18:33:00<6:56:24, 21.67s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3109/4261 [18:33:21<6:55:04, 21.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3110/4261 [18:33:43<6:54:01, 21.58s/it]                                                        {'loss': 2.3101, 'learning_rate': 3.3898130133239683e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3110/4261 [18:33:43<6:54:01, 21.58s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3111/4261 [18:34:04<6:53:26, 21.57s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3112/4261 [18:34:26<6:52:53, 21.56s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3113/4261 [18:34:47<6:52:27, 21.56s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3114/4261 [18:35:09<6:51:49, 21.54s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3115/4261 [18:35:30<6:51:29, 21.54s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3116/4261 [18:35:52<6:51:20, 21.56s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3117/4261 [18:36:14<6:51:14, 21.57s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3118/4261 [18:36:35<6:50:31, 21.55s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3119/4261 [18:36:57<6:50:15, 21.55s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3120/4261 [18:37:18<6:49:41, 21.54s/it]                                                        {'loss': 2.3256, 'learning_rate': 3.3346691904855645e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3120/4261 [18:37:18<6:49:41, 21.54s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3121/4261 [18:37:40<6:49:21, 21.55s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3122/4261 [18:38:01<6:48:50, 21.54s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3123/4261 [18:38:23<6:48:28, 21.54s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3124/4261 [18:38:45<6:50:02, 21.64s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3125/4261 [18:39:06<6:49:02, 21.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3126/4261 [18:39:28<6:48:23, 21.59s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3127/4261 [18:39:49<6:47:25, 21.56s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3128/4261 [18:40:11<6:47:03, 21.56s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3129/4261 [18:40:33<6:47:57, 21.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3130/4261 [18:40:54<6:46:55, 21.59s/it]                                                        {'loss': 2.3298, 'learning_rate': 3.279887691076775e-06, 'epoch': 0.73}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3130/4261 [18:40:54<6:46:55, 21.59s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3131/4261 [18:41:16<6:47:50, 21.66s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3132/4261 [18:41:37<6:46:43, 21.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3133/4261 [18:41:59<6:46:13, 21.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3134/4261 [18:42:21<6:45:29, 21.59s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3135/4261 [18:42:42<6:44:56, 21.58s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3136/4261 [18:43:04<6:44:32, 21.58s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3137/4261 [18:43:25<6:43:58, 21.56s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3138/4261 [18:43:47<6:43:16, 21.55s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3139/4261 [18:44:08<6:42:41, 21.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3140/4261 [18:44:30<6:44:21, 21.64s/it]                                                        {'loss': 2.3199, 'learning_rate': 3.22547149298742e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3140/4261 [18:44:30<6:44:21, 21.64s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3141/4261 [18:44:52<6:43:37, 21.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 3142/4261 [18:45:13<6:42:55, 21.60s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3143/4261 [18:45:35<6:42:07, 21.58s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3144/4261 [18:45:56<6:41:26, 21.56s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3145/4261 [18:46:18<6:42:14, 21.63s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3146/4261 [18:46:40<6:41:15, 21.59s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3147/4261 [18:47:01<6:40:24, 21.57s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3148/4261 [18:47:23<6:39:54, 21.56s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3149/4261 [18:47:44<6:39:29, 21.56s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3150/4261 [18:48:06<6:38:50, 21.54s/it]                                                        {'loss': 2.3222, 'learning_rate': 3.171423554249752e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3150/4261 [18:48:06<6:38:50, 21.54s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3151/4261 [18:48:27<6:39:58, 21.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3152/4261 [18:48:49<6:38:56, 21.58s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3153/4261 [18:49:10<6:38:06, 21.56s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3154/4261 [18:49:32<6:37:19, 21.54s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3155/4261 [18:49:53<6:36:42, 21.52s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3156/4261 [18:50:15<6:36:16, 21.52s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3157/4261 [18:50:36<6:36:01, 21.52s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3158/4261 [18:50:58<6:35:47, 21.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3159/4261 [18:51:20<6:35:28, 21.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3160/4261 [18:51:41<6:36:37, 21.61s/it]                                                        {'loss': 2.3178, 'learning_rate': 3.117746812877668e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3160/4261 [18:51:41<6:36:37, 21.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3161/4261 [18:52:03<6:35:44, 21.59s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3162/4261 [18:52:24<6:35:01, 21.57s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3163/4261 [18:52:46<6:34:27, 21.55s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3164/4261 [18:53:07<6:33:42, 21.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3165/4261 [18:53:29<6:33:08, 21.52s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3166/4261 [18:53:50<6:32:30, 21.51s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3167/4261 [18:54:12<6:33:24, 21.58s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3168/4261 [18:54:34<6:32:28, 21.54s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3169/4261 [18:54:55<6:32:03, 21.54s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3170/4261 [18:55:17<6:31:44, 21.54s/it]                                                        {'loss': 2.3238, 'learning_rate': 3.064444186706984e-06, 'epoch': 0.74}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3170/4261 [18:55:17<6:31:44, 21.54s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3171/4261 [18:55:38<6:31:21, 21.54s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3172/4261 [18:56:00<6:30:42, 21.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3173/4261 [18:56:21<6:30:21, 21.53s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3174/4261 [18:56:43<6:29:56, 21.52s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3175/4261 [18:57:04<6:29:10, 21.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3176/4261 [18:57:26<6:28:49, 21.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3177/4261 [18:57:47<6:28:27, 21.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3178/4261 [18:58:09<6:28:04, 21.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3179/4261 [18:58:30<6:27:45, 21.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3180/4261 [18:58:52<6:27:30, 21.51s/it]                                                        {'loss': 2.3344, 'learning_rate': 3.011518573236859e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3180/4261 [18:58:52<6:27:30, 21.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3181/4261 [18:59:13<6:27:21, 21.52s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3182/4261 [18:59:35<6:27:11, 21.53s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3183/4261 [18:59:56<6:26:32, 21.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3184/4261 [19:00:18<6:26:04, 21.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3185/4261 [19:00:39<6:25:47, 21.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3186/4261 [19:01:01<6:26:00, 21.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3187/4261 [19:01:22<6:25:33, 21.54s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3188/4261 [19:01:44<6:25:17, 21.54s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3189/4261 [19:02:06<6:24:37, 21.53s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3190/4261 [19:02:27<6:24:08, 21.52s/it]                                                        {'loss': 2.3337, 'learning_rate': 2.958972849472239e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3190/4261 [19:02:27<6:24:08, 21.52s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3191/4261 [19:02:49<6:24:00, 21.53s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3192/4261 [19:03:10<6:23:42, 21.54s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3193/4261 [19:03:32<6:24:52, 21.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3194/4261 [19:03:53<6:23:40, 21.57s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3195/4261 [19:04:15<6:22:59, 21.56s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3196/4261 [19:04:36<6:22:27, 21.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3197/4261 [19:04:58<6:21:45, 21.53s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3198/4261 [19:05:19<6:21:17, 21.52s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3199/4261 [19:05:41<6:21:00, 21.53s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3200/4261 [19:06:03<6:20:40, 21.53s/it]                                                        {'loss': 2.3234, 'learning_rate': 2.90680987176751e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3200/4261 [19:06:03<6:20:40, 21.53s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3201/4261 [19:06:24<6:20:00, 21.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3202/4261 [19:06:45<6:19:22, 21.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3203/4261 [19:07:07<6:19:00, 21.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3204/4261 [19:07:28<6:18:46, 21.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3205/4261 [19:07:50<6:18:27, 21.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3206/4261 [19:08:11<6:18:07, 21.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3207/4261 [19:08:33<6:17:31, 21.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3208/4261 [19:08:54<6:17:09, 21.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3209/4261 [19:09:16<6:17:04, 21.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3210/4261 [19:09:37<6:16:29, 21.49s/it]                                                        {'loss': 2.3219, 'learning_rate': 2.855032475671199e-06, 'epoch': 0.75}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3210/4261 [19:09:37<6:16:29, 21.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3211/4261 [19:09:59<6:16:12, 21.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3212/4261 [19:10:20<6:15:39, 21.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3213/4261 [19:10:42<6:16:40, 21.56s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3214/4261 [19:11:04<6:15:54, 21.54s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3215/4261 [19:11:25<6:15:21, 21.53s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3216/4261 [19:11:47<6:15:05, 21.54s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3217/4261 [19:12:08<6:14:40, 21.53s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3218/4261 [19:12:30<6:14:23, 21.54s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3219/4261 [19:12:51<6:13:49, 21.53s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3220/4261 [19:13:13<6:14:44, 21.60s/it]                                                        {'loss': 2.3225, 'learning_rate': 2.80364347577185e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3220/4261 [19:13:13<6:14:44, 21.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3221/4261 [19:13:35<6:13:50, 21.57s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3222/4261 [19:13:56<6:14:54, 21.65s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3223/4261 [19:14:18<6:13:47, 21.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3224/4261 [19:14:39<6:13:01, 21.58s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3225/4261 [19:15:01<6:12:34, 21.58s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3226/4261 [19:15:22<6:11:58, 21.56s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3227/4261 [19:15:44<6:11:30, 21.56s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3228/4261 [19:16:06<6:10:50, 21.54s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3229/4261 [19:16:27<6:10:33, 21.54s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3230/4261 [19:16:49<6:10:13, 21.55s/it]                                                        {'loss': 2.3302, 'learning_rate': 2.7526456655450217e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3230/4261 [19:16:49<6:10:13, 21.55s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3231/4261 [19:17:10<6:09:39, 21.53s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3232/4261 [19:17:32<6:09:05, 21.52s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3233/4261 [19:17:53<6:08:50, 21.53s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3234/4261 [19:18:15<6:08:30, 21.53s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3235/4261 [19:18:36<6:07:55, 21.52s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3236/4261 [19:18:58<6:07:32, 21.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3237/4261 [19:19:19<6:07:09, 21.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3238/4261 [19:19:41<6:06:45, 21.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3239/4261 [19:20:02<6:06:05, 21.49s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3240/4261 [19:20:24<6:05:42, 21.49s/it]                                                        {'loss': 2.3243, 'learning_rate': 2.702041817201423e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3240/4261 [19:20:24<6:05:42, 21.49s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3241/4261 [19:20:45<6:05:55, 21.52s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3242/4261 [19:21:07<6:06:51, 21.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3243/4261 [19:21:29<6:07:15, 21.65s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3244/4261 [19:21:50<6:06:15, 21.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3245/4261 [19:22:12<6:05:25, 21.58s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3246/4261 [19:22:33<6:04:35, 21.55s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3247/4261 [19:22:55<6:04:02, 21.54s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3248/4261 [19:23:16<6:03:34, 21.53s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3249/4261 [19:23:38<6:04:25, 21.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3250/4261 [19:24:00<6:03:43, 21.59s/it]                                                        {'loss': 2.3355, 'learning_rate': 2.6518346815362452e-06, 'epoch': 0.76}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3250/4261 [19:24:00<6:03:43, 21.59s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3251/4261 [19:24:21<6:03:06, 21.57s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3252/4261 [19:24:43<6:02:48, 21.57s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3253/4261 [19:25:04<6:02:08, 21.56s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3254/4261 [19:25:26<6:01:42, 21.55s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3255/4261 [19:25:47<6:01:12, 21.54s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3256/4261 [19:26:09<6:00:47, 21.54s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3257/4261 [19:26:30<6:00:36, 21.55s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3258/4261 [19:26:52<6:00:13, 21.55s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3259/4261 [19:27:14<6:01:16, 21.63s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3260/4261 [19:27:35<6:00:17, 21.60s/it]                                                        {'loss': 2.3126, 'learning_rate': 2.6020269877796057e-06, 'epoch': 0.76}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3260/4261 [19:27:35<6:00:17, 21.60s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3261/4261 [19:27:57<5:59:23, 21.56s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3262/4261 [19:28:18<5:58:49, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3263/4261 [19:28:40<5:59:39, 21.62s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3264/4261 [19:29:02<5:58:53, 21.60s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3265/4261 [19:29:23<5:58:08, 21.57s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3266/4261 [19:29:45<5:57:13, 21.54s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3267/4261 [19:30:06<5:56:53, 21.54s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3268/4261 [19:30:28<5:56:30, 21.54s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3269/4261 [19:30:50<5:57:13, 21.61s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3270/4261 [19:31:11<5:56:16, 21.57s/it]                                                        {'loss': 2.3259, 'learning_rate': 2.5526214434481887e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3270/4261 [19:31:11<5:56:16, 21.57s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3271/4261 [19:31:32<5:55:34, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3272/4261 [19:31:54<5:55:09, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3273/4261 [19:32:16<5:54:43, 21.54s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3274/4261 [19:32:37<5:55:38, 21.62s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3275/4261 [19:32:59<5:54:38, 21.58s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3276/4261 [19:33:20<5:53:48, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3277/4261 [19:33:42<5:53:28, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3278/4261 [19:34:03<5:52:52, 21.54s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3279/4261 [19:34:25<5:53:48, 21.62s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3280/4261 [19:34:47<5:53:05, 21.60s/it]                                                        {'loss': 2.332, 'learning_rate': 2.5036207341980876e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3280/4261 [19:34:47<5:53:05, 21.60s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3281/4261 [19:35:08<5:52:13, 21.56s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3282/4261 [19:35:30<5:51:35, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3283/4261 [19:35:51<5:51:20, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3284/4261 [19:36:13<5:50:51, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3285/4261 [19:36:35<5:51:47, 21.63s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3286/4261 [19:36:56<5:50:55, 21.60s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3287/4261 [19:37:18<5:50:20, 21.58s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3288/4261 [19:37:39<5:49:40, 21.56s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3289/4261 [19:38:01<5:49:04, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3290/4261 [19:38:22<5:48:54, 21.56s/it]                                                        {'loss': 2.3248, 'learning_rate': 2.4550275236787934e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3290/4261 [19:38:22<5:48:54, 21.56s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3291/4261 [19:38:44<5:48:24, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3292/4261 [19:39:05<5:47:59, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3293/4261 [19:39:27<5:47:31, 21.54s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3294/4261 [19:39:49<5:48:13, 21.61s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3295/4261 [19:40:10<5:47:34, 21.59s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3296/4261 [19:40:32<5:46:52, 21.57s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3297/4261 [19:40:53<5:46:32, 21.57s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3298/4261 [19:41:15<5:45:55, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3299/4261 [19:41:36<5:45:22, 21.54s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3300/4261 [19:41:58<5:45:11, 21.55s/it]                                                        {'loss': 2.3241, 'learning_rate': 2.4068444533884105e-06, 'epoch': 0.77}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3300/4261 [19:41:58<5:45:11, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3301/4261 [19:42:19<5:44:44, 21.55s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3302/4261 [19:42:41<5:44:30, 21.55s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3303/4261 [19:43:03<5:43:53, 21.54s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3304/4261 [19:43:24<5:43:22, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3305/4261 [19:43:46<5:42:56, 21.52s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3306/4261 [19:44:07<5:42:38, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3307/4261 [19:44:29<5:42:18, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3308/4261 [19:44:50<5:41:55, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3309/4261 [19:45:12<5:41:36, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3310/4261 [19:45:33<5:41:19, 21.53s/it]                                                        {'loss': 2.3174, 'learning_rate': 2.3590741425300614e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3310/4261 [19:45:33<5:41:19, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3311/4261 [19:45:55<5:41:07, 21.55s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3312/4261 [19:46:16<5:40:42, 21.54s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3313/4261 [19:46:38<5:40:10, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3314/4261 [19:46:59<5:39:35, 21.52s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3315/4261 [19:47:21<5:39:27, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3316/4261 [19:47:42<5:39:04, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3317/4261 [19:48:04<5:38:43, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3318/4261 [19:48:25<5:38:04, 21.51s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3319/4261 [19:48:47<5:37:46, 21.51s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3320/4261 [19:49:08<5:37:27, 21.52s/it]                                                        {'loss': 2.3115, 'learning_rate': 2.3117191878695124e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3320/4261 [19:49:08<5:37:27, 21.52s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3321/4261 [19:49:30<5:37:08, 21.52s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3322/4261 [19:49:52<5:36:51, 21.52s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3323/4261 [19:50:13<5:36:35, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3324/4261 [19:50:35<5:36:14, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3325/4261 [19:50:56<5:35:54, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3326/4261 [19:51:18<5:35:37, 21.54s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3327/4261 [19:51:39<5:36:29, 21.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3328/4261 [19:52:01<5:35:49, 21.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3329/4261 [19:52:23<5:34:52, 21.56s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3330/4261 [19:52:44<5:34:25, 21.55s/it]                                                        {'loss': 2.3224, 'learning_rate': 2.264782163594015e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3330/4261 [19:52:44<5:34:25, 21.55s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3331/4261 [19:53:06<5:33:48, 21.54s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3332/4261 [19:53:27<5:33:11, 21.52s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3333/4261 [19:53:49<5:32:45, 21.51s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3334/4261 [19:54:10<5:32:40, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3335/4261 [19:54:32<5:32:18, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3336/4261 [19:54:53<5:32:02, 21.54s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3337/4261 [19:55:15<5:31:40, 21.54s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3338/4261 [19:55:37<5:32:35, 21.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3339/4261 [19:55:58<5:31:37, 21.58s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3340/4261 [19:56:20<5:30:46, 21.55s/it]                                                        {'loss': 2.3262, 'learning_rate': 2.2182656211723654e-06, 'epoch': 0.78}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3340/4261 [19:56:20<5:30:46, 21.55s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3341/4261 [19:56:41<5:30:12, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3342/4261 [19:57:03<5:29:42, 21.53s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3343/4261 [19:57:24<5:29:29, 21.54s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3344/4261 [19:57:46<5:29:02, 21.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3345/4261 [19:58:07<5:28:39, 21.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3346/4261 [19:58:29<5:28:22, 21.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3347/4261 [19:58:50<5:29:00, 21.60s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3348/4261 [19:59:12<5:28:05, 21.56s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3349/4261 [19:59:33<5:27:38, 21.56s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3350/4261 [19:59:55<5:27:18, 21.56s/it]                                                        {'loss': 2.3284, 'learning_rate': 2.1721720892162213e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3350/4261 [19:59:55<5:27:18, 21.56s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3351/4261 [20:00:17<5:26:51, 21.55s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3352/4261 [20:00:38<5:26:23, 21.54s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3353/4261 [20:01:00<5:25:55, 21.54s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3354/4261 [20:01:21<5:25:38, 21.54s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3355/4261 [20:01:43<5:25:05, 21.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3356/4261 [20:02:04<5:26:09, 21.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3357/4261 [20:02:26<5:25:10, 21.58s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3358/4261 [20:02:47<5:24:34, 21.57s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3359/4261 [20:03:09<5:24:27, 21.58s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3360/4261 [20:03:31<5:24:05, 21.58s/it]                                                        {'loss': 2.3288, 'learning_rate': 2.126504073342649e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3360/4261 [20:03:31<5:24:05, 21.58s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3361/4261 [20:03:52<5:23:42, 21.58s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3362/4261 [20:04:14<5:23:14, 21.57s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3363/4261 [20:04:35<5:22:46, 21.57s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3364/4261 [20:04:57<5:22:09, 21.55s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3365/4261 [20:05:18<5:21:30, 21.53s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3366/4261 [20:05:40<5:21:25, 21.55s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3367/4261 [20:06:02<5:22:09, 21.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3368/4261 [20:06:23<5:21:19, 21.59s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3369/4261 [20:06:45<5:20:51, 21.58s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3370/4261 [20:07:06<5:20:22, 21.57s/it]                                                        {'loss': 2.3212, 'learning_rate': 2.0812640560378996e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3370/4261 [20:07:06<5:20:22, 21.57s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3371/4261 [20:07:28<5:20:03, 21.58s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3372/4261 [20:07:50<5:19:41, 21.58s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3373/4261 [20:08:11<5:19:20, 21.58s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3374/4261 [20:08:33<5:19:00, 21.58s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3375/4261 [20:08:54<5:18:23, 21.56s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3376/4261 [20:09:16<5:19:04, 21.63s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3377/4261 [20:09:38<5:19:26, 21.68s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3378/4261 [20:09:59<5:18:13, 21.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3379/4261 [20:10:21<5:17:39, 21.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3380/4261 [20:10:42<5:17:00, 21.59s/it]                                                        {'loss': 2.325, 'learning_rate': 2.036454496522483e-06, 'epoch': 0.79}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3380/4261 [20:10:42<5:17:00, 21.59s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3381/4261 [20:11:04<5:16:32, 21.58s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3382/4261 [20:11:26<5:16:02, 21.57s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3383/4261 [20:11:47<5:15:25, 21.55s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3384/4261 [20:12:09<5:14:52, 21.54s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3385/4261 [20:12:30<5:14:37, 21.55s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3386/4261 [20:12:52<5:14:26, 21.56s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3387/4261 [20:13:14<5:15:22, 21.65s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3388/4261 [20:13:35<5:14:39, 21.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3389/4261 [20:13:57<5:13:59, 21.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3390/4261 [20:14:18<5:13:24, 21.59s/it]                                                        {'loss': 2.3292, 'learning_rate': 1.9920778306174783e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3390/4261 [20:14:18<5:13:24, 21.59s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3391/4261 [20:14:40<5:12:56, 21.58s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3392/4261 [20:15:01<5:12:39, 21.59s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3393/4261 [20:15:23<5:13:43, 21.69s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3394/4261 [20:15:45<5:12:51, 21.65s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3395/4261 [20:16:07<5:12:17, 21.64s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3396/4261 [20:16:28<5:11:46, 21.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3397/4261 [20:16:50<5:12:08, 21.68s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3398/4261 [20:17:11<5:11:24, 21.65s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3399/4261 [20:17:33<5:10:43, 21.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3400/4261 [20:17:55<5:10:03, 21.61s/it]                                                        {'loss': 2.3243, 'learning_rate': 1.9481364706121274e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3400/4261 [20:17:55<5:10:03, 21.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3401/4261 [20:18:16<5:09:20, 21.58s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3402/4261 [20:18:38<5:08:52, 21.57s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3403/4261 [20:18:59<5:09:25, 21.64s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3404/4261 [20:19:21<5:08:46, 21.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3405/4261 [20:19:43<5:08:14, 21.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3406/4261 [20:20:04<5:07:36, 21.59s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3407/4261 [20:20:26<5:07:10, 21.58s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3408/4261 [20:20:48<5:07:53, 21.66s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3409/4261 [20:21:09<5:06:57, 21.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3410/4261 [20:21:31<5:06:25, 21.60s/it]                                                        {'loss': 2.3163, 'learning_rate': 1.9046328051326935e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3410/4261 [20:21:31<5:06:25, 21.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3411/4261 [20:21:52<5:06:01, 21.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3412/4261 [20:22:14<5:05:30, 21.59s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3413/4261 [20:22:36<5:06:05, 21.66s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3414/4261 [20:22:57<5:05:20, 21.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3415/4261 [20:23:19<5:04:59, 21.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3416/4261 [20:23:40<5:04:32, 21.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3417/4261 [20:24:02<5:04:05, 21.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3418/4261 [20:24:24<5:03:26, 21.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3419/4261 [20:24:45<5:03:02, 21.59s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3420/4261 [20:25:07<5:02:46, 21.60s/it]                                                        {'loss': 2.3202, 'learning_rate': 1.8615691990126306e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3420/4261 [20:25:07<5:02:46, 21.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3421/4261 [20:25:28<5:02:18, 21.59s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3422/4261 [20:25:50<5:02:01, 21.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3423/4261 [20:26:12<5:01:50, 21.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3424/4261 [20:26:33<5:01:40, 21.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3425/4261 [20:26:55<5:01:08, 21.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3426/4261 [20:27:17<5:00:47, 21.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3427/4261 [20:27:38<5:00:25, 21.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3428/4261 [20:28:00<5:01:01, 21.68s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3429/4261 [20:28:22<5:00:22, 21.66s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3430/4261 [20:28:43<4:59:48, 21.65s/it]                                                        {'loss': 2.3265, 'learning_rate': 1.818947993164033e-06, 'epoch': 0.8}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3430/4261 [20:28:43<4:59:48, 21.65s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3431/4261 [20:29:05<4:59:22, 21.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3432/4261 [20:29:26<4:58:56, 21.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3433/4261 [20:29:48<4:58:27, 21.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3434/4261 [20:30:10<4:58:05, 21.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3435/4261 [20:30:31<4:57:22, 21.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3436/4261 [20:30:53<4:57:12, 21.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3437/4261 [20:31:14<4:56:43, 21.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3438/4261 [20:31:36<4:56:34, 21.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3439/4261 [20:31:58<4:56:13, 21.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3440/4261 [20:32:19<4:55:59, 21.63s/it]                                                        {'loss': 2.3216, 'learning_rate': 1.7767715044503654e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3440/4261 [20:32:19<4:55:59, 21.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3441/4261 [20:32:41<4:55:38, 21.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3442/4261 [20:33:03<4:55:19, 21.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3443/4261 [20:33:24<4:54:59, 21.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3444/4261 [20:33:46<4:54:34, 21.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3445/4261 [20:34:08<4:54:15, 21.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3446/4261 [20:34:29<4:53:54, 21.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3447/4261 [20:34:51<4:53:37, 21.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3448/4261 [20:35:12<4:53:01, 21.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3449/4261 [20:35:34<4:52:32, 21.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3450/4261 [20:35:56<4:52:13, 21.62s/it]                                                        {'loss': 2.3231, 'learning_rate': 1.7350420255605416e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3450/4261 [20:35:56<4:52:13, 21.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3451/4261 [20:36:17<4:51:48, 21.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3452/4261 [20:36:39<4:51:07, 21.59s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3453/4261 [20:37:00<4:50:49, 21.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3454/4261 [20:37:22<4:50:31, 21.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3455/4261 [20:37:44<4:51:27, 21.70s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3456/4261 [20:38:06<4:50:34, 21.66s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3457/4261 [20:38:27<4:50:01, 21.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3458/4261 [20:38:49<4:49:24, 21.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3459/4261 [20:39:10<4:48:47, 21.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3460/4261 [20:39:32<4:48:20, 21.60s/it]                                                        {'loss': 2.3136, 'learning_rate': 1.6937618248842846e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3460/4261 [20:39:32<4:48:20, 21.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3461/4261 [20:39:54<4:48:58, 21.67s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3462/4261 [20:40:15<4:48:14, 21.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3463/4261 [20:40:37<4:47:22, 21.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3464/4261 [20:40:58<4:46:59, 21.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3465/4261 [20:41:20<4:46:29, 21.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3466/4261 [20:41:42<4:46:03, 21.59s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3467/4261 [20:42:03<4:45:38, 21.59s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3468/4261 [20:42:25<4:45:22, 21.59s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3469/4261 [20:42:46<4:45:04, 21.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3470/4261 [20:43:08<4:44:25, 21.57s/it]                                                        {'loss': 2.3168, 'learning_rate': 1.652933146388821e-06, 'epoch': 0.81}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3470/4261 [20:43:08<4:44:25, 21.57s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3471/4261 [20:43:29<4:44:09, 21.58s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3472/4261 [20:43:51<4:43:45, 21.58s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3473/4261 [20:44:13<4:43:35, 21.59s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3474/4261 [20:44:34<4:43:17, 21.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3475/4261 [20:44:56<4:43:02, 21.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3476/4261 [20:45:17<4:42:31, 21.59s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3477/4261 [20:45:39<4:42:12, 21.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3478/4261 [20:46:01<4:41:48, 21.59s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3479/4261 [20:46:22<4:41:26, 21.59s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3480/4261 [20:46:44<4:41:06, 21.60s/it]                                                        {'loss': 2.3291, 'learning_rate': 1.6125582094968983e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3480/4261 [20:46:44<4:41:06, 21.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3481/4261 [20:47:06<4:41:43, 21.67s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3482/4261 [20:47:27<4:40:57, 21.64s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3483/4261 [20:47:49<4:40:19, 21.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3484/4261 [20:48:10<4:40:01, 21.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3485/4261 [20:48:32<4:40:31, 21.69s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3486/4261 [20:48:54<4:39:48, 21.66s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3487/4261 [20:49:15<4:39:07, 21.64s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3488/4261 [20:49:37<4:38:28, 21.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3489/4261 [20:49:59<4:37:51, 21.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3490/4261 [20:50:20<4:38:28, 21.67s/it]                                                        {'loss': 2.3118, 'learning_rate': 1.5726392089661346e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3490/4261 [20:50:20<4:38:28, 21.67s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3491/4261 [20:50:42<4:37:38, 21.63s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3492/4261 [20:51:04<4:36:54, 21.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3493/4261 [20:51:25<4:36:25, 21.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3494/4261 [20:51:47<4:35:57, 21.59s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3495/4261 [20:52:08<4:35:25, 21.57s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3496/4261 [20:52:30<4:35:02, 21.57s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3497/4261 [20:52:51<4:34:46, 21.58s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3498/4261 [20:53:13<4:34:27, 21.58s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3499/4261 [20:53:35<4:34:12, 21.59s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3500/4261 [20:53:56<4:33:35, 21.57s/it]                                                        {'loss': 2.3312, 'learning_rate': 1.5331783147697322e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3500/4261 [20:53:56<4:33:35, 21.57s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3501/4261 [20:54:18<4:33:10, 21.57s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3502/4261 [20:54:39<4:32:49, 21.57s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3503/4261 [20:55:01<4:32:30, 21.57s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3504/4261 [20:55:22<4:31:52, 21.55s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3505/4261 [20:55:44<4:32:26, 21.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3506/4261 [20:56:06<4:31:39, 21.59s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3507/4261 [20:56:27<4:31:17, 21.59s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3508/4261 [20:56:49<4:30:48, 21.58s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3509/4261 [20:57:10<4:30:19, 21.57s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3510/4261 [20:57:32<4:30:54, 21.64s/it]                                                        {'loss': 2.3133, 'learning_rate': 1.4941776719784872e-06, 'epoch': 0.82}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3510/4261 [20:57:32<4:30:54, 21.64s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3511/4261 [20:57:54<4:31:19, 21.71s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3512/4261 [20:58:16<4:30:23, 21.66s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3513/4261 [20:58:37<4:29:44, 21.64s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3514/4261 [20:58:59<4:28:45, 21.59s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3515/4261 [20:59:20<4:28:16, 21.58s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3516/4261 [20:59:42<4:27:49, 21.57s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3517/4261 [21:00:03<4:27:26, 21.57s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3518/4261 [21:00:25<4:27:05, 21.57s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3519/4261 [21:00:46<4:26:47, 21.57s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3520/4261 [21:01:08<4:26:35, 21.59s/it]                                                        {'loss': 2.3246, 'learning_rate': 1.4556394006442144e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3520/4261 [21:01:08<4:26:35, 21.59s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3521/4261 [21:01:30<4:27:14, 21.67s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3522/4261 [21:01:51<4:26:34, 21.64s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3523/4261 [21:02:13<4:25:59, 21.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3524/4261 [21:02:35<4:25:33, 21.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3525/4261 [21:02:56<4:25:01, 21.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3526/4261 [21:03:18<4:24:26, 21.59s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3527/4261 [21:03:40<4:25:10, 21.68s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3528/4261 [21:04:01<4:24:16, 21.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3529/4261 [21:04:23<4:23:51, 21.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3530/4261 [21:04:44<4:23:16, 21.61s/it]                                                        {'loss': 2.3191, 'learning_rate': 1.4175655956844859e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3530/4261 [21:04:44<4:23:16, 21.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3531/4261 [21:05:06<4:23:42, 21.67s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3532/4261 [21:05:28<4:23:03, 21.65s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3533/4261 [21:05:49<4:22:35, 21.64s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3534/4261 [21:06:11<4:22:03, 21.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3535/4261 [21:06:33<4:21:30, 21.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3536/4261 [21:06:54<4:20:57, 21.60s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3537/4261 [21:07:16<4:20:39, 21.60s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3538/4261 [21:07:37<4:20:24, 21.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3539/4261 [21:07:59<4:19:48, 21.59s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3540/4261 [21:08:20<4:19:19, 21.58s/it]                                                        {'loss': 2.3319, 'learning_rate': 1.3799583267687577e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3540/4261 [21:08:20<4:19:19, 21.58s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3541/4261 [21:08:42<4:18:55, 21.58s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3542/4261 [21:09:04<4:19:26, 21.65s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3543/4261 [21:09:25<4:18:53, 21.64s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3544/4261 [21:09:47<4:18:20, 21.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3545/4261 [21:10:09<4:17:54, 21.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3546/4261 [21:10:30<4:17:24, 21.60s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3547/4261 [21:10:52<4:17:48, 21.66s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3548/4261 [21:11:14<4:17:10, 21.64s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3549/4261 [21:11:35<4:16:28, 21.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3550/4261 [21:11:57<4:15:57, 21.60s/it]                                                        {'loss': 2.3169, 'learning_rate': 1.3428196382058656e-06, 'epoch': 0.83}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3550/4261 [21:11:57<4:15:57, 21.60s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3551/4261 [21:12:18<4:15:28, 21.59s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3552/4261 [21:12:40<4:15:07, 21.59s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3553/4261 [21:13:02<4:14:53, 21.60s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3554/4261 [21:13:23<4:14:34, 21.60s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3555/4261 [21:13:45<4:14:17, 21.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3556/4261 [21:14:06<4:13:50, 21.60s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3557/4261 [21:14:28<4:13:35, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3558/4261 [21:14:50<4:13:16, 21.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3559/4261 [21:15:11<4:12:56, 21.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3560/4261 [21:15:33<4:12:23, 21.60s/it]                                                        {'loss': 2.3232, 'learning_rate': 1.3061515488328857e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3560/4261 [21:15:33<4:12:23, 21.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3561/4261 [21:15:54<4:12:03, 21.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3562/4261 [21:16:16<4:12:36, 21.68s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3563/4261 [21:16:38<4:11:54, 21.65s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3564/4261 [21:16:59<4:11:15, 21.63s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3565/4261 [21:17:21<4:10:50, 21.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3566/4261 [21:17:43<4:10:14, 21.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3567/4261 [21:18:04<4:09:47, 21.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3568/4261 [21:18:26<4:09:32, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3569/4261 [21:18:47<4:09:08, 21.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3570/4261 [21:19:09<4:08:42, 21.60s/it]                                                        {'loss': 2.3259, 'learning_rate': 1.2699560519054166e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3570/4261 [21:19:09<4:08:42, 21.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3571/4261 [21:19:31<4:08:25, 21.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3572/4261 [21:19:52<4:08:06, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3573/4261 [21:20:14<4:08:43, 21.69s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3574/4261 [21:20:36<4:08:05, 21.67s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3575/4261 [21:20:57<4:07:21, 21.63s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3576/4261 [21:21:19<4:06:58, 21.63s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3577/4261 [21:21:40<4:06:24, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3578/4261 [21:22:02<4:05:57, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3579/4261 [21:22:24<4:05:51, 21.63s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3580/4261 [21:22:45<4:05:26, 21.62s/it]                                                        {'loss': 2.3252, 'learning_rate': 1.234235114989204e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3580/4261 [21:22:45<4:05:26, 21.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3581/4261 [21:23:07<4:04:56, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3582/4261 [21:23:29<4:04:34, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3583/4261 [21:23:50<4:04:13, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3584/4261 [21:24:12<4:03:56, 21.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3585/4261 [21:24:33<4:03:31, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3586/4261 [21:24:55<4:03:08, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3587/4261 [21:25:17<4:02:42, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3588/4261 [21:25:38<4:02:20, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3589/4261 [21:26:00<4:01:46, 21.59s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3590/4261 [21:26:21<4:01:11, 21.57s/it]                                                        {'loss': 2.3294, 'learning_rate': 1.1989906798531858e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3590/4261 [21:26:21<4:01:11, 21.57s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3591/4261 [21:26:43<4:00:56, 21.58s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3592/4261 [21:27:04<4:00:39, 21.58s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3593/4261 [21:27:26<4:00:11, 21.57s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3594/4261 [21:27:48<3:59:52, 21.58s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3595/4261 [21:28:10<4:00:35, 21.68s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3596/4261 [21:28:31<3:59:46, 21.63s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3597/4261 [21:28:53<3:59:07, 21.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3598/4261 [21:29:14<3:58:53, 21.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3599/4261 [21:29:36<3:58:34, 21.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3600/4261 [21:29:57<3:58:03, 21.61s/it]                                                        {'loss': 2.3469, 'learning_rate': 1.1642246623639575e-06, 'epoch': 0.84}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3600/4261 [21:29:57<3:58:03, 21.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3601/4261 [21:30:19<3:57:43, 21.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3602/4261 [21:30:41<3:57:09, 21.59s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3603/4261 [21:31:03<3:57:44, 21.68s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3604/4261 [21:31:24<3:57:02, 21.65s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3605/4261 [21:31:46<3:56:36, 21.64s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3606/4261 [21:32:07<3:56:01, 21.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3607/4261 [21:32:29<3:55:38, 21.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3608/4261 [21:32:50<3:55:11, 21.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3609/4261 [21:33:12<3:54:54, 21.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3610/4261 [21:33:34<3:54:40, 21.63s/it]                                                        {'loss': 2.3303, 'learning_rate': 1.1299389523816095e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3610/4261 [21:33:34<3:54:40, 21.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3611/4261 [21:33:55<3:54:10, 21.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3612/4261 [21:34:17<3:53:56, 21.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3613/4261 [21:34:39<3:53:20, 21.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3614/4261 [21:35:00<3:53:03, 21.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3615/4261 [21:35:22<3:53:25, 21.68s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3616/4261 [21:35:44<3:52:55, 21.67s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3617/4261 [21:36:05<3:52:08, 21.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3618/4261 [21:36:27<3:51:46, 21.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3619/4261 [21:36:48<3:51:15, 21.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3620/4261 [21:37:10<3:50:46, 21.60s/it]                                                        {'loss': 2.319, 'learning_rate': 1.0961354136570003e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3620/4261 [21:37:10<3:50:46, 21.60s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3621/4261 [21:37:32<3:50:14, 21.58s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3622/4261 [21:37:53<3:49:55, 21.59s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3623/4261 [21:38:15<3:50:23, 21.67s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3624/4261 [21:38:37<3:50:33, 21.72s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3625/4261 [21:38:58<3:49:40, 21.67s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3626/4261 [21:39:20<3:49:09, 21.65s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3627/4261 [21:39:42<3:48:32, 21.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3628/4261 [21:40:03<3:48:04, 21.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3629/4261 [21:40:25<3:47:45, 21.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3630/4261 [21:40:46<3:47:26, 21.63s/it]                                                        {'loss': 2.3251, 'learning_rate': 1.062815883730448e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3630/4261 [21:40:46<3:47:26, 21.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3631/4261 [21:41:08<3:47:02, 21.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3632/4261 [21:41:30<3:46:26, 21.60s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3633/4261 [21:41:51<3:46:05, 21.60s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3634/4261 [21:42:13<3:45:43, 21.60s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3635/4261 [21:42:34<3:45:18, 21.60s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3636/4261 [21:42:56<3:44:45, 21.58s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3637/4261 [21:43:17<3:44:23, 21.58s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3638/4261 [21:43:39<3:44:09, 21.59s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3639/4261 [21:44:01<3:44:38, 21.67s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3640/4261 [21:44:23<3:44:06, 21.65s/it]                                                        {'loss': 2.3172, 'learning_rate': 1.029982173831836e-06, 'epoch': 0.85}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3640/4261 [21:44:23<3:44:06, 21.65s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3641/4261 [21:44:44<3:43:34, 21.64s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3642/4261 [21:45:06<3:43:01, 21.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3643/4261 [21:45:27<3:42:34, 21.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3644/4261 [21:45:49<3:42:51, 21.67s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3645/4261 [21:46:11<3:43:03, 21.73s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3646/4261 [21:46:33<3:42:03, 21.66s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3647/4261 [21:46:54<3:41:22, 21.63s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3648/4261 [21:47:16<3:40:36, 21.59s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3649/4261 [21:47:37<3:40:03, 21.57s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3650/4261 [21:47:59<3:39:34, 21.56s/it]                                                        {'loss': 2.3268, 'learning_rate': 9.976360687821652e-07, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3650/4261 [21:47:59<3:39:34, 21.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3651/4261 [21:48:20<3:39:13, 21.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3652/4261 [21:48:42<3:38:46, 21.55s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3653/4261 [21:49:03<3:38:17, 21.54s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3654/4261 [21:49:25<3:38:05, 21.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3655/4261 [21:49:46<3:37:44, 21.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3656/4261 [21:50:08<3:37:26, 21.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3657/4261 [21:50:30<3:37:11, 21.58s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3658/4261 [21:50:51<3:36:49, 21.58s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3659/4261 [21:51:13<3:36:24, 21.57s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3660/4261 [21:51:34<3:35:58, 21.56s/it]                                                        {'loss': 2.3226, 'learning_rate': 9.657793268965144e-07, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3660/4261 [21:51:34<3:35:58, 21.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3661/4261 [21:51:56<3:36:27, 21.65s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3662/4261 [21:52:18<3:35:51, 21.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3663/4261 [21:52:39<3:35:27, 21.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3664/4261 [21:53:01<3:34:49, 21.59s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3665/4261 [21:53:23<3:34:57, 21.64s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3666/4261 [21:53:44<3:34:27, 21.63s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3667/4261 [21:54:06<3:33:54, 21.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3668/4261 [21:54:27<3:33:23, 21.59s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3669/4261 [21:54:49<3:32:44, 21.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3670/4261 [21:55:10<3:32:24, 21.56s/it]                                                        {'loss': 2.3301, 'learning_rate': 9.344136798884829e-07, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3670/4261 [21:55:10<3:32:24, 21.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3671/4261 [21:55:32<3:31:55, 21.55s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3672/4261 [21:55:53<3:31:38, 21.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3673/4261 [21:56:15<3:31:06, 21.54s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3674/4261 [21:56:37<3:30:53, 21.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3675/4261 [21:56:58<3:30:29, 21.55s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3676/4261 [21:57:20<3:30:10, 21.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3677/4261 [21:57:41<3:29:42, 21.55s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3678/4261 [21:58:03<3:29:22, 21.55s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3679/4261 [21:58:24<3:29:00, 21.55s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3680/4261 [21:58:46<3:28:31, 21.53s/it]                                                        {'loss': 2.3374, 'learning_rate': 9.035408327760387e-07, 'epoch': 0.86}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3680/4261 [21:58:46<3:28:31, 21.53s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3681/4261 [21:59:08<3:28:46, 21.60s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3682/4261 [21:59:29<3:28:20, 21.59s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3683/4261 [21:59:51<3:27:47, 21.57s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3684/4261 [22:00:12<3:27:17, 21.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3685/4261 [22:00:34<3:26:50, 21.55s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3686/4261 [22:00:55<3:26:27, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3687/4261 [22:01:17<3:26:13, 21.56s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3688/4261 [22:01:38<3:25:45, 21.55s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3689/4261 [22:02:00<3:25:18, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3690/4261 [22:02:21<3:24:55, 21.53s/it]                                                        {'loss': 2.3207, 'learning_rate': 8.731624637888403e-07, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3690/4261 [22:02:21<3:24:55, 21.53s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3691/4261 [22:02:43<3:25:18, 21.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3692/4261 [22:03:05<3:24:37, 21.58s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3693/4261 [22:03:26<3:24:01, 21.55s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3694/4261 [22:03:48<3:23:33, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3695/4261 [22:04:09<3:23:11, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3696/4261 [22:04:31<3:23:33, 21.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3697/4261 [22:04:52<3:22:47, 21.57s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3698/4261 [22:05:14<3:22:16, 21.56s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3699/4261 [22:05:36<3:21:55, 21.56s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3700/4261 [22:05:57<3:21:24, 21.54s/it]                                                        {'loss': 2.3245, 'learning_rate': 8.432802242770077e-07, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3700/4261 [22:05:57<3:21:24, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3701/4261 [22:06:19<3:21:01, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3702/4261 [22:06:40<3:20:37, 21.53s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3703/4261 [22:07:02<3:20:11, 21.53s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3704/4261 [22:07:23<3:19:48, 21.52s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3705/4261 [22:07:45<3:19:23, 21.52s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3706/4261 [22:08:06<3:19:08, 21.53s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3707/4261 [22:08:28<3:18:54, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3708/4261 [22:08:49<3:18:36, 21.55s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3709/4261 [22:09:11<3:18:10, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3710/4261 [22:09:32<3:17:47, 21.54s/it]                                                        {'loss': 2.3246, 'learning_rate': 8.138957386213586e-07, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3710/4261 [22:09:32<3:17:47, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3711/4261 [22:09:54<3:17:27, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3712/4261 [22:10:15<3:16:58, 21.53s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3713/4261 [22:10:37<3:16:29, 21.51s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3714/4261 [22:10:59<3:16:56, 21.60s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3715/4261 [22:11:20<3:16:19, 21.57s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3716/4261 [22:11:42<3:15:49, 21.56s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3717/4261 [22:12:03<3:15:25, 21.55s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3718/4261 [22:12:25<3:14:55, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3719/4261 [22:12:46<3:14:31, 21.53s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3720/4261 [22:13:08<3:14:51, 21.61s/it]                                                        {'loss': 2.3196, 'learning_rate': 7.850106041451066e-07, 'epoch': 0.87}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3720/4261 [22:13:08<3:14:51, 21.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3721/4261 [22:13:30<3:14:15, 21.58s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3722/4261 [22:13:51<3:13:41, 21.56s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3723/4261 [22:14:13<3:13:19, 21.56s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3724/4261 [22:14:34<3:12:55, 21.56s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3725/4261 [22:14:56<3:12:35, 21.56s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3726/4261 [22:15:17<3:12:06, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3727/4261 [22:15:39<3:11:42, 21.54s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3728/4261 [22:16:00<3:11:20, 21.54s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3729/4261 [22:16:22<3:11:01, 21.55s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3730/4261 [22:16:43<3:10:43, 21.55s/it]                                                        {'loss': 2.3212, 'learning_rate': 7.566263910270266e-07, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3730/4261 [22:16:43<3:10:43, 21.55s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3731/4261 [22:17:05<3:10:23, 21.55s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3732/4261 [22:17:27<3:10:04, 21.56s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3733/4261 [22:17:48<3:09:38, 21.55s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3734/4261 [22:18:10<3:09:15, 21.55s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3735/4261 [22:18:31<3:08:58, 21.56s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3736/4261 [22:18:53<3:08:27, 21.54s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3737/4261 [22:19:14<3:07:55, 21.52s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3738/4261 [22:19:36<3:07:34, 21.52s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3739/4261 [22:19:57<3:07:24, 21.54s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3740/4261 [22:20:19<3:07:06, 21.55s/it]                                                        {'loss': 2.3296, 'learning_rate': 7.287446422161093e-07, 'epoch': 0.88}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3740/4261 [22:20:19<3:07:06, 21.55s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3741/4261 [22:20:41<3:07:18, 21.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3742/4261 [22:21:02<3:06:48, 21.60s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3743/4261 [22:21:24<3:07:00, 21.66s/it]