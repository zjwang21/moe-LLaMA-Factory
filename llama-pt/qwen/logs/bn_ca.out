[2024-05-13 22:14:05,101] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:11,292] [WARNING] [runner.py:203:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-05-13 22:14:11,341] [INFO] [runner.py:570:main] cmd = /mnt/vol1/huangxin/anaconda3/envs/wzjsz/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=9902 --enable_each_rank_log=None src/train_bash.py --deepspeed /root/huangxin/nanda/llm-moe-merge/config/ds.json --stage pt --flash_attn --model_name_or_path /root/huangxin/nanda/model/Qwen1.5-7B --small_path /root/huangxin/nanda/checkpoints/merge/0.5b-bn --large_path /root/huangxin/nanda/model/Qwen1.5-7B --every_k_layers_small 3 --every_k_layers_large 4 --seed 22 --max_samples 870561 --do_train --dataset bn --preprocessing_num_workers 64 --cache_dir /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache --cutoff_len 2048 --finetuning_type ca --output_dir /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07 --overwrite_output_dir --per_device_train_batch_size 8 --gradient_accumulation_steps 16 --lr_scheduler_type cosine --logging_steps 10 --save_total_limit 1 --save_only_model --save_steps 200 --learning_rate 5e-5 --num_train_epochs 1.0 --plot_loss --bf16
[2024-05-13 22:14:12,860] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:14,585] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-05-13 22:14:14,585] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-05-13 22:14:14,585] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-05-13 22:14:14,585] [INFO] [launch.py:163:main] dist_world_size=8
[2024-05-13 22:14:14,585] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-05-13 22:14:27,112] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,113] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,114] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,115] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,117] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,117] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,117] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,117] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-05-13 22:14:38,288] [INFO] [comm.py:637:init_distributed] cdb=None
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 4, device: cuda:4, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 3, device: cuda:3, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=4,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=3,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 2, device: cuda:2, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 5, device: cuda:5, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 6, device: cuda:6, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=2,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 7, device: cuda:7, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=5,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=6,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=1,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=7,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[INFO|tokenization_utils_base.py:2027] 2024-05-13 22:14:38,328 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2027] 2024-05-13 22:14:38,328 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2027] 2024-05-13 22:14:38,328 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2027] 2024-05-13 22:14:38,328 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2027] 2024-05-13 22:14:38,328 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2027] 2024-05-13 22:14:38,328 >> loading file tokenizer.json
[WARNING|logging.py:314] 2024-05-13 22:14:38,562 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:727] 2024-05-13 22:14:38,564 >> loading configuration file /root/huangxin/nanda/checkpoints/merge/0.5b-bn/config.json
[INFO|configuration_utils.py:792] 2024-05-13 22:14:38,565 >> Model config Qwen2Config {
  "_name_or_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "hidden_act": "silu",
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 2816,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_key_value_heads": 16,
  "rms_norm_eps": 1e-06,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.38.0.dev0",
  "use_cache": false,
  "use_sliding_window": false,
  "vocab_size": 151936
}

Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:727] 2024-05-13 22:14:38,567 >> loading configuration file /root/huangxin/nanda/model/Qwen1.5-7B/config.json
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
[INFO|configuration_utils.py:792] 2024-05-13 22:14:38,567 >> Model config Qwen2Config {
  "_name_or_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "rms_norm_eps": 1e-06,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.38.0.dev0",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[WARNING|logging.py:329] 2024-05-13 22:14:38,570 >> Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[INFO|configuration_utils.py:827] 2024-05-13 22:14:38,570 >> Generate config GenerationConfig {}

Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[INFO|configuration_utils.py:727] 2024-05-13 22:14:38,571 >> loading configuration file /root/huangxin/nanda/checkpoints/merge/0.5b-bn/config.json
[INFO|configuration_utils.py:792] 2024-05-13 22:14:38,571 >> Model config Qwen2Config {
  "_name_or_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "hidden_act": "silu",
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 2816,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_key_value_heads": 16,
  "rms_norm_eps": 1e-06,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.38.0.dev0",
  "use_cache": false,
  "use_sliding_window": false,
  "vocab_size": 151936
}

05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
[INFO|configuration_utils.py:727] 2024-05-13 22:14:38,572 >> loading configuration file /root/huangxin/nanda/model/Qwen1.5-7B/config.json
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
[INFO|configuration_utils.py:792] 2024-05-13 22:14:38,577 >> Model config Qwen2Config {
  "_name_or_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "rms_norm_eps": 1e-06,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.38.0.dev0",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
[INFO|modeling_utils.py:3334] 2024-05-13 22:14:38,578 >> loading weights file /root/huangxin/nanda/checkpoints/merge/0.5b-bn/model.safetensors
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
[WARNING|logging.py:329] 2024-05-13 22:14:38,822 >> You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[WARNING|logging.py:329] 2024-05-13 22:14:38,824 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[WARNING|logging.py:329] 2024-05-13 22:14:38,828 >> Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
[INFO|modeling_utils.py:4060] 2024-05-13 22:15:01,864 >> Some weights of the model checkpoint at /root/huangxin/nanda/checkpoints/merge/0.5b-bn were not used when initializing Qwen2CrossAttnGeneratorModel: ['lm_head.weight']
- This IS expected if you are initializing Qwen2CrossAttnGeneratorModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Qwen2CrossAttnGeneratorModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:4078] 2024-05-13 22:15:01,865 >> All the weights of Qwen2CrossAttnGeneratorModel were initialized from the model checkpoint at /root/huangxin/nanda/checkpoints/merge/0.5b-bn.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2CrossAttnGeneratorModel for predictions without further training.
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
[INFO|modeling_utils.py:3334] 2024-05-13 22:15:01,884 >> loading weights file /root/huangxin/nanda/model/Qwen1.5-7B/model.safetensors.index.json
[INFO|configuration_utils.py:827] 2024-05-13 22:15:01,885 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151643
}

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:15, 25.20s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:01, 20.52s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:06, 22.03s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:02, 20.75s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:20, 26.72s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:24<01:14, 24.93s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:00, 20.12s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:01, 20.42s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:54<00:56, 28.21s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:54<00:56, 28.42s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:59<01:00, 30.27s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:54<00:56, 28.33s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:00<01:01, 30.89s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:58<01:00, 30.14s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:57, 28.96s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:53<00:56, 28.13s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:28<00:30, 30.94s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:28<00:31, 31.01s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:28<00:31, 31.06s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:28<00:30, 30.89s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:30<00:31, 31.34s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:32<00:31, 31.99s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:34<00:32, 32.40s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:33<00:32, 32.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:04<00:00, 33.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:04<00:00, 31.14s/it]
[INFO|modeling_utils.py:4070] 2024-05-13 22:17:33,369 >> All model checkpoint weights were used when initializing Qwen2CrossAttnCausalLM.

[INFO|modeling_utils.py:4078] 2024-05-13 22:17:33,369 >> All the weights of Qwen2CrossAttnCausalLM were initialized from the model checkpoint at /root/huangxin/nanda/model/Qwen1.5-7B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2CrossAttnCausalLM for predictions without further training.
[INFO|configuration_utils.py:780] 2024-05-13 22:17:33,373 >> loading configuration file /root/huangxin/nanda/model/Qwen1.5-7B/generation_config.json
[INFO|configuration_utils.py:827] 2024-05-13 22:17:33,374 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "max_new_tokens": 2048
}

05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
Loading checkpoint shards: 100%|██████████| 4/4 [02:05<00:00, 33.12s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:05<00:00, 31.26s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [02:04<00:00, 33.02s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:04<00:00, 31.08s/it]
05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
Loading checkpoint shards: 100%|██████████| 4/4 [02:04<00:00, 33.09s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:04<00:00, 31.20s/it]
05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
Loading checkpoint shards: 100%|██████████| 4/4 [02:11<00:00, 33.93s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:11<00:00, 32.75s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [02:09<00:00, 33.73s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:09<00:00, 32.38s/it]
05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
Loading checkpoint shards: 100%|██████████| 4/4 [02:09<00:00, 33.69s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:09<00:00, 32.30s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [02:06<00:00, 33.30s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:06<00:00, 31.58s/it]05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......

05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:19:54 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
Using custom data configuration default-4e02b910cc3d648d
Loading Dataset Infos from /mnt/vol1/huangxin/anaconda3/envs/wzjsz/lib/python3.10/site-packages/datasets/packaged_modules/json
Overwrite dataset info from restored data version if exists.
Loading Dataset info from /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7
Found cached dataset json (/mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7)
Loading Dataset info from /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7
Dataset({
    features: ['text'],
    num_rows: 870561
})
{'text': "করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর | Suprovat Bogura\nপ্রচ্ছদ কৃষি সংবাদ করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর। ছবি-সংগৃহীত\nসুপ্রভাত বগুড়া (জাতীয়): প্রধানমন্ত্রী শেখ হাসিনা সকলকে করোন ভাইরাস থেকে নিজেদের সুরক্ষিত রাখতে নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান জানিয়ে বলেছেন, জনগণের কল্যাণের কথাই তাঁর সরকার সবচেয়ে বেশি চিন্তা করছে।\nতিনি বলেন, 'সকলকে স্ব-স্ব স্বাস্থ্য সুরক্ষিত রেখেই স্ব-স্ব কর্মস্থলে কাজ করে যেতে হবে। দেশের মানুষ যাতে কষ্ট না পায় কেননা তাঁদের কথাই আমরা বেশি চিন্তা করি। সবাই ভাল থাকেন, সুস্থ থাকেন, সেটাই কামনা করি।'\nমঙ্গলবার (৩ মে) প্রধানমন্ত্রী শেখ হাসিনা জাতীয় অর্থনৈতিক পরিষদের নির্বাহী কমিটির (একনেক) সভায় একথা বলেন। রাজধানীর শেরেবাংলা নগরের এনইসি সম্মেলন কক্ষে অনুষ্ঠিত এই সভায় ভিডিও কনফারেন্সের মাধ্যমে গণভবন থেকে সংযুক্ত হন এবং সভাপতিত্ব করেন ।\nএই ভার্চুয়াল একনেক সভায় ১৬ হাজার ২৭৬ কোটি ৩ লাখ টাকা ব্যয়ে ১০টি প্রকল্প অনুমোদন দেয়া হয়। অনুমোদিত প্রকল্পের জন্য বাংলাদেশ সরকার দেবে ১৪ হাজার ৪০১ কোটি ৫২ লাখ টাকা এবং বৈদেশিক ঋণ ১ হাজার ৮৮১ কোটি ৯৭ লাখ টাকা।\nপরে পরিকল্পনা মন্ত্রী এমএ মান্নান সভার বিষয়ে বিস্তারিত সাংবাদিকদের অবহিত করেন। প্রধানমন্ত্রী বলেন, এর আগে আমরা জাতীয় অর্থনৈতিক কাউন্সিলের সভা করে বাজেট প্রণয়নের কাজগুলো করেছি।\nতিনি বলেন, কোভিড-১৯ ভাইরাসের কারণে আজ শুধু বাংলাদেশ নয় সমগ্র বিশ্বই বলতে গেলে স্থবির হয়ে পড়েছে। এরমধ্যেও আপনারা যারা আজকে প্রকল্পগুলো তৈরী করে নিয়ে এসেছেন বা ডিজিটাল পদ্ধতিতে এই মিটিংটা যে করতে পারছি, সেজন্য আপনাদের আন্তরিক ধন্যবাদ জানাই।\nপ্রধানমন্ত্রী এসময় করেনা ভাইরাসের কারণে দেশে এবং বিদেশে মৃত্যুবরনকারী বাংলাদেশীদের জন্য শোক ও দুঃখ প্রকাশ করে তাঁদের আত্মার মাগফেরাত কামনা করেন। তিনি বলেন, 'এ ব্যাপারে যে স্বাস্থ্যবিধি দেওয়া হয়েছে দেশবাসী সেটা মেনে চলবে, এটাই আমরা চাই।'\nতিনি বলেন, 'কোভিড-১৯ এর কারণে উন্নয়নের গতিশীলতাটা কিছুটা কমে এলেও আমরা মনে করি, এই দিন থাকবে না। যে কোন প্রতিবন্ধকতা মোকাবেলা করেই আমরা এগিয়ে যেতে পারবো।' লক ডাউন শিথিল করার প্রসঙ্গে প্রধানমন্ত্রী বলেন, 'আমরা চাই না আমাদের দেশের মানুষ কষ্ট পাক।\nসেজন্য আমরা যেসব বন্ধ করে দিয়েছিলাম। এখন তা কিছু কিছু করে উন্মুক্ত করা শুরু করেছি। কারণ, দেশের খেটে খাওয়া জনগণকে থেকে শুরু করে স্বল্প আয়ের লোকজন, প্রত্যেকেই যেন তাঁদের জীবনযাত্রা সচল রাখতে পারে।'\nতাঁর সরকারের শাসনে দেশের এগিয়ে চলা এবং বর্তমান মুজিববর্ষ থেকে ২০২১ সালে স্বাধীনতার সুবর্ণ জয়ন্তী উদযাপন পর্যন্ত দেশের দারিদ্রের হারকে আরো কমিয়ে এনে বাংলাদেশকে উন্নয়নশীল দেশ হিসেবে বিশ্ব দরবারে প্রতিষ্ঠার পূর্ব নির্ধারিত লক্ষ্য অর্জনেও আশাবাদ ব্যক্ত করেন তিনি।"}
Process #0 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00000_of_00064.arrow
Process #1 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00001_of_00064.arrow
Process #2 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00002_of_00064.arrow
Process #3 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00003_of_00064.arrow
Process #4 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00004_of_00064.arrow
Process #5 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00005_of_00064.arrow
Process #6 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00006_of_00064.arrow
Process #7 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00007_of_00064.arrow
Process #8 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00008_of_00064.arrow
Process #9 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00009_of_00064.arrow
Process #10 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00010_of_00064.arrow
Process #11 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00011_of_00064.arrow
Process #12 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00012_of_00064.arrow
Process #13 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00013_of_00064.arrow
Process #14 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00014_of_00064.arrow
Process #15 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00015_of_00064.arrow
Process #16 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00016_of_00064.arrow
Process #17 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00017_of_00064.arrow
Process #18 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00018_of_00064.arrow
Process #19 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00019_of_00064.arrow
Process #20 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00020_of_00064.arrow
Process #21 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00021_of_00064.arrow
Process #22 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00022_of_00064.arrow
Process #23 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00023_of_00064.arrow
Process #24 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00024_of_00064.arrow
Process #25 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00025_of_00064.arrow
Process #26 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00026_of_00064.arrow
Process #27 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00027_of_00064.arrow
Process #28 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00028_of_00064.arrow
Process #29 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00029_of_00064.arrow
Process #30 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00030_of_00064.arrow
Process #31 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00031_of_00064.arrow
Process #32 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00032_of_00064.arrow
Process #33 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00033_of_00064.arrow
Process #34 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00034_of_00064.arrow
Process #35 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00035_of_00064.arrow
Process #36 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00036_of_00064.arrow
Process #37 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00037_of_00064.arrow
Process #38 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00038_of_00064.arrow
Process #39 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00039_of_00064.arrow
Process #40 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00040_of_00064.arrow
Process #41 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00041_of_00064.arrow
Process #42 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00042_of_00064.arrow
Process #43 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00043_of_00064.arrow
Process #44 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00044_of_00064.arrow
Process #45 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00045_of_00064.arrow
Process #46 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00046_of_00064.arrow
Process #47 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00047_of_00064.arrow
Process #48 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00048_of_00064.arrow
Process #49 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00049_of_00064.arrow
Process #50 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00050_of_00064.arrow
Process #51 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00051_of_00064.arrow
Process #52 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00052_of_00064.arrow
Process #53 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00053_of_00064.arrow
Process #54 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00054_of_00064.arrow
Process #55 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00055_of_00064.arrow
Process #56 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00056_of_00064.arrow
Process #57 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00057_of_00064.arrow
Process #58 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00058_of_00064.arrow
Process #59 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00059_of_00064.arrow
Process #60 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00060_of_00064.arrow
Process #61 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00061_of_00064.arrow
Process #62 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00062_of_00064.arrow
Process #63 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00063_of_00064.arrow
Loading cached processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_*_of_00064.arrow
Concatenating 64 shards
Process #0 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00000_of_00064.arrow
Process #1 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00001_of_00064.arrow
Process #2 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00002_of_00064.arrow
Process #3 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00003_of_00064.arrow
Process #4 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00004_of_00064.arrow
Process #5 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00005_of_00064.arrow
Process #6 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00006_of_00064.arrow
Process #7 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00007_of_00064.arrow
Process #8 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00008_of_00064.arrow
Process #9 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00009_of_00064.arrow
Process #10 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00010_of_00064.arrow
Process #11 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00011_of_00064.arrow
Process #12 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00012_of_00064.arrow
Process #13 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00013_of_00064.arrow
Process #14 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00014_of_00064.arrow
Process #15 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00015_of_00064.arrow
Process #16 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00016_of_00064.arrow
Process #17 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00017_of_00064.arrow
Process #18 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00018_of_00064.arrow
Process #19 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00019_of_00064.arrow
Process #20 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00020_of_00064.arrow
Process #21 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00021_of_00064.arrow
Process #22 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00022_of_00064.arrow
Process #23 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00023_of_00064.arrow
Process #24 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00024_of_00064.arrow
Process #25 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00025_of_00064.arrow
Process #26 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00026_of_00064.arrow
Process #27 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00027_of_00064.arrow
Process #28 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00028_of_00064.arrow
Process #29 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00029_of_00064.arrow
Process #30 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00030_of_00064.arrow
Process #31 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00031_of_00064.arrow
Process #32 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00032_of_00064.arrow
Process #33 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00033_of_00064.arrow
Process #34 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00034_of_00064.arrow
Process #35 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00035_of_00064.arrow
Process #36 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00036_of_00064.arrow
Process #37 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00037_of_00064.arrow
Process #38 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00038_of_00064.arrow
Process #39 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00039_of_00064.arrow
Process #40 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00040_of_00064.arrow
Process #41 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00041_of_00064.arrow
Process #42 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00042_of_00064.arrow
Process #43 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00043_of_00064.arrow
Process #44 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00044_of_00064.arrow
Process #45 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00045_of_00064.arrow
Process #46 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00046_of_00064.arrow
Process #47 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00047_of_00064.arrow
Process #48 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00048_of_00064.arrow
Process #49 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00049_of_00064.arrow
Process #50 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00050_of_00064.arrow
Process #51 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00051_of_00064.arrow
Process #52 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00052_of_00064.arrow
Process #53 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00053_of_00064.arrow
Process #54 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00054_of_00064.arrow
Process #55 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00055_of_00064.arrow
Process #56 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00056_of_00064.arrow
Process #57 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00057_of_00064.arrow
Process #58 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00058_of_00064.arrow
Process #59 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00059_of_00064.arrow
Process #60 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00060_of_00064.arrow
Process #61 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00061_of_00064.arrow
Process #62 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00062_of_00064.arrow
Process #63 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00063_of_00064.arrow
Spawning 64 processes
Running tokenizer on dataset (num_proc=64):   0%|          | 0/870561 [00:00<?, ? examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:36,968 >> Token indices sequence length is longer than the specified maximum sequence length for this model (91486 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00000_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   0%|          | 1000/870561 [00:08<2:00:37, 120.14 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:38,671 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34827 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00001_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   0%|          | 2000/870561 [00:09<1:02:53, 230.17 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:41,078 >> Token indices sequence length is longer than the specified maximum sequence length for this model (44816 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00002_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   0%|          | 3000/870561 [00:12<50:03, 288.83 examples/s]  Running tokenizer on dataset (num_proc=64):   0%|          | 4000/870561 [00:12<33:32, 430.51 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:43,144 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34931 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00003_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   1%|          | 5000/870561 [00:14<29:14, 493.20 examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 6000/870561 [00:14<20:20, 708.56 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:45,248 >> Token indices sequence length is longer than the specified maximum sequence length for this model (54287 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00004_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   1%|          | 7000/870561 [00:16<22:32, 638.34 examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 8000/870561 [00:16<16:56, 848.86 examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 9000/870561 [00:17<14:29, 990.76 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00005_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   1%|          | 10000/870561 [00:18<14:33, 985.26 examples/s]Running tokenizer on dataset (num_proc=64):   1%|▏         | 11000/870561 [00:19<14:26, 992.26 examples/s]Running tokenizer on dataset (num_proc=64):   1%|▏         | 12000/870561 [00:20<12:56, 1105.07 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00006_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   1%|▏         | 13000/870561 [00:20<11:03, 1292.80 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 14000/870561 [00:21<11:12, 1273.05 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 15000/870561 [00:21<09:14, 1544.22 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 16000/870561 [00:22<07:36, 1871.16 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:52,133 >> Token indices sequence length is longer than the specified maximum sequence length for this model (135847 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00007_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:52,482 >> Token indices sequence length is longer than the specified maximum sequence length for this model (57994 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):   2%|▏         | 17000/870561 [00:23<11:10, 1272.63 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 18000/870561 [00:23<09:06, 1560.04 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 19000/870561 [00:24<08:52, 1599.62 examples/s]Running tokenizer on dataset (num_proc=64):   2%|▏         | 20000/870561 [00:24<08:23, 1690.45 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:54,338 >> Token indices sequence length is longer than the specified maximum sequence length for this model (131502 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00008_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   2%|▏         | 21000/870561 [00:25<08:20, 1696.81 examples/s]Running tokenizer on dataset (num_proc=64):   3%|▎         | 22000/870561 [00:25<06:43, 2100.74 examples/s]Running tokenizer on dataset (num_proc=64):   3%|▎         | 23000/870561 [00:26<07:18, 1932.72 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00009_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   3%|▎         | 25000/870561 [00:26<05:51, 2405.39 examples/s]Running tokenizer on dataset (num_proc=64):   3%|▎         | 26000/870561 [00:27<05:26, 2586.76 examples/s]Running tokenizer on dataset (num_proc=64):   3%|▎         | 27000/870561 [00:27<07:03, 1991.67 examples/s]Running tokenizer on dataset (num_proc=64):   3%|▎         | 28000/870561 [00:28<07:18, 1921.24 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:58,312 >> Token indices sequence length is longer than the specified maximum sequence length for this model (84168 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00010_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   3%|▎         | 29000/870561 [00:29<08:17, 1692.13 examples/s]Running tokenizer on dataset (num_proc=64):   3%|▎         | 30000/870561 [00:29<06:58, 2008.82 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▎         | 32000/870561 [00:30<05:18, 2633.32 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▍         | 33000/870561 [00:30<04:50, 2882.42 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▍         | 34000/870561 [00:30<04:42, 2965.75 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:00,450 >> Token indices sequence length is longer than the specified maximum sequence length for this model (48132 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00011_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   4%|▍         | 35000/870561 [00:31<06:45, 2063.04 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:00,835 >> Token indices sequence length is longer than the specified maximum sequence length for this model (33878 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):   4%|▍         | 36000/870561 [00:31<05:43, 2429.47 examples/s]Running tokenizer on dataset (num_proc=64):   4%|▍         | 38000/870561 [00:32<04:19, 3206.08 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00012_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   4%|▍         | 39000/870561 [00:33<08:29, 1633.20 examples/s]Running tokenizer on dataset (num_proc=64):   5%|▍         | 42000/870561 [00:34<05:34, 2477.50 examples/s]Running tokenizer on dataset (num_proc=64):   5%|▍         | 43000/870561 [00:34<04:58, 2774.00 examples/s]Running tokenizer on dataset (num_proc=64):   5%|▌         | 44000/870561 [00:34<04:32, 3038.61 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:04,081 >> Token indices sequence length is longer than the specified maximum sequence length for this model (117989 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):   5%|▌         | 45000/870561 [00:35<05:09, 2671.12 examples/s]Running tokenizer on dataset (num_proc=64):   5%|▌         | 46000/870561 [00:35<04:40, 2943.75 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00013_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   5%|▌         | 47000/870561 [00:35<04:16, 3214.71 examples/s]Running tokenizer on dataset (num_proc=64):   6%|▌         | 48000/870561 [00:35<04:09, 3290.93 examples/s]Running tokenizer on dataset (num_proc=64):   6%|▌         | 49000/870561 [00:36<04:24, 3101.06 examples/s]Running tokenizer on dataset (num_proc=64):   6%|▌         | 50000/870561 [00:36<03:52, 3526.66 examples/s]Running tokenizer on dataset (num_proc=64):   6%|▌         | 51000/870561 [00:36<03:29, 3920.71 examples/s]Running tokenizer on dataset (num_proc=64):   6%|▌         | 52000/870561 [00:36<03:32, 3860.98 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:07,203 >> Token indices sequence length is longer than the specified maximum sequence length for this model (50417 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00014_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:07,411 >> Token indices sequence length is longer than the specified maximum sequence length for this model (62793 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):   6%|▌         | 53000/870561 [00:38<08:03, 1689.46 examples/s]Running tokenizer on dataset (num_proc=64):   6%|▌         | 54000/870561 [00:38<06:23, 2130.15 examples/s]Running tokenizer on dataset (num_proc=64):   6%|▋         | 55000/870561 [00:38<05:03, 2685.47 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 57000/870561 [00:38<03:50, 3535.77 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 58000/870561 [00:39<05:07, 2640.90 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 59000/870561 [00:39<04:34, 2955.65 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 60000/870561 [00:40<03:51, 3498.46 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00015_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:09,614 >> Token indices sequence length is longer than the specified maximum sequence length for this model (38283 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):   7%|▋         | 62000/870561 [00:40<03:22, 4000.07 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 63000/870561 [00:40<03:07, 4311.61 examples/s]Running tokenizer on dataset (num_proc=64):   7%|▋         | 64000/870561 [00:40<03:07, 4292.96 examples/s]Running tokenizer on dataset (num_proc=64):   8%|▊         | 66000/870561 [00:41<02:43, 4935.56 examples/s]Running tokenizer on dataset (num_proc=64):   8%|▊         | 67000/870561 [00:41<02:44, 4882.63 examples/s]Running tokenizer on dataset (num_proc=64):   8%|▊         | 68000/870561 [00:41<02:59, 4464.74 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:11,792 >> Token indices sequence length is longer than the specified maximum sequence length for this model (36034 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00016_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   8%|▊         | 69000/870561 [00:42<06:44, 1981.52 examples/s]Running tokenizer on dataset (num_proc=64):   8%|▊         | 70000/870561 [00:43<05:31, 2414.57 examples/s]Running tokenizer on dataset (num_proc=64):   8%|▊         | 71000/870561 [00:43<05:11, 2566.83 examples/s]Running tokenizer on dataset (num_proc=64):   8%|▊         | 73000/870561 [00:43<03:38, 3657.18 examples/s]Running tokenizer on dataset (num_proc=64):   9%|▊         | 75000/870561 [00:44<03:33, 3731.35 examples/s]Running tokenizer on dataset (num_proc=64):   9%|▊         | 76000/870561 [00:44<04:04, 3254.10 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:14,215 >> Token indices sequence length is longer than the specified maximum sequence length for this model (36810 > 32768). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:14,259 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34266 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):   9%|▉         | 78000/870561 [00:44<03:18, 4002.07 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00017_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   9%|▉         | 79000/870561 [00:45<02:59, 4405.26 examples/s]Running tokenizer on dataset (num_proc=64):   9%|▉         | 80000/870561 [00:45<03:24, 3858.08 examples/s]Running tokenizer on dataset (num_proc=64):   9%|▉         | 82000/870561 [00:45<02:24, 5458.97 examples/s]Running tokenizer on dataset (num_proc=64):  10%|▉         | 84000/870561 [00:45<02:11, 6003.41 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00018_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  10%|▉         | 85000/870561 [00:46<03:29, 3748.02 examples/s]Running tokenizer on dataset (num_proc=64):  10%|▉         | 87000/870561 [00:46<03:01, 4305.68 examples/s]Running tokenizer on dataset (num_proc=64):  10%|█         | 88000/870561 [00:47<04:48, 2715.99 examples/s]Running tokenizer on dataset (num_proc=64):  10%|█         | 89000/870561 [00:48<04:25, 2948.05 examples/s]Running tokenizer on dataset (num_proc=64):  10%|█         | 90000/870561 [00:48<04:21, 2982.47 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█         | 92000/870561 [00:48<03:14, 4000.63 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█         | 93000/870561 [00:48<02:59, 4327.22 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:18,525 >> Token indices sequence length is longer than the specified maximum sequence length for this model (38573 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00019_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  11%|█         | 94000/870561 [00:49<04:18, 3006.35 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█         | 96000/870561 [00:49<02:50, 4551.94 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█         | 97000/870561 [00:49<03:08, 4099.44 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█▏        | 98000/870561 [00:50<03:24, 3782.79 examples/s]Running tokenizer on dataset (num_proc=64):  11%|█▏        | 100000/870561 [00:50<02:25, 5304.95 examples/s]Running tokenizer on dataset (num_proc=64):  12%|█▏        | 102000/870561 [00:50<02:23, 5342.46 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00020_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:20,792 >> Token indices sequence length is longer than the specified maximum sequence length for this model (59603 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  12%|█▏        | 105000/870561 [00:51<02:52, 4426.31 examples/s]Running tokenizer on dataset (num_proc=64):  12%|█▏        | 106000/870561 [00:51<02:38, 4811.10 examples/s]Running tokenizer on dataset (num_proc=64):  12%|█▏        | 107000/870561 [00:51<02:38, 4817.16 examples/s]Running tokenizer on dataset (num_proc=64):  12%|█▏        | 108000/870561 [00:52<02:37, 4833.23 examples/s]Running tokenizer on dataset (num_proc=64):  13%|█▎        | 109000/870561 [00:52<03:40, 3460.84 examples/s]Running tokenizer on dataset (num_proc=64):  13%|█▎        | 110000/870561 [00:53<04:18, 2947.46 examples/s]Running tokenizer on dataset (num_proc=64):  13%|█▎        | 111000/870561 [00:53<04:16, 2955.85 examples/s]Running tokenizer on dataset (num_proc=64):  13%|█▎        | 112000/870561 [00:53<03:42, 3410.66 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:23,089 >> Token indices sequence length is longer than the specified maximum sequence length for this model (35285 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  13%|█▎        | 114000/870561 [00:53<02:36, 4824.11 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00021_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  13%|█▎        | 115000/870561 [00:54<03:21, 3746.49 examples/s]Running tokenizer on dataset (num_proc=64):  13%|█▎        | 117000/870561 [00:54<02:22, 5297.44 examples/s]Running tokenizer on dataset (num_proc=64):  14%|█▎        | 119000/870561 [00:54<02:44, 4572.34 examples/s]Running tokenizer on dataset (num_proc=64):  14%|█▍        | 122000/870561 [00:55<02:03, 6080.53 examples/s]Running tokenizer on dataset (num_proc=64):  14%|█▍        | 124000/870561 [00:55<02:24, 5157.56 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:25,315 >> Token indices sequence length is longer than the specified maximum sequence length for this model (39069 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00022_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  15%|█▍        | 127000/870561 [00:56<02:30, 4932.94 examples/s]Running tokenizer on dataset (num_proc=64):  15%|█▍        | 128000/870561 [00:56<02:30, 4927.22 examples/s]Running tokenizer on dataset (num_proc=64):  15%|█▍        | 130000/870561 [00:56<02:16, 5444.65 examples/s]Running tokenizer on dataset (num_proc=64):  15%|█▌        | 131000/870561 [00:57<02:24, 5126.23 examples/s]Running tokenizer on dataset (num_proc=64):  15%|█▌        | 132000/870561 [00:57<02:43, 4507.44 examples/s]Running tokenizer on dataset (num_proc=64):  15%|█▌        | 133000/870561 [00:58<03:39, 3362.99 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:27,774 >> Token indices sequence length is longer than the specified maximum sequence length for this model (33259 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00023_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  15%|█▌        | 134000/870561 [00:58<05:09, 2382.82 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 136000/870561 [00:59<03:37, 3382.43 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 137000/870561 [00:59<03:11, 3831.22 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 140000/870561 [00:59<02:51, 4265.22 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▌        | 141000/870561 [01:00<02:44, 4442.92 examples/s]Running tokenizer on dataset (num_proc=64):  16%|█▋        | 143000/870561 [01:00<02:05, 5813.98 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 144000/870561 [01:00<02:05, 5774.74 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 145000/870561 [01:00<02:11, 5527.92 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 146000/870561 [01:00<02:38, 4567.94 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 148000/870561 [01:01<01:55, 6281.88 examples/s]Running tokenizer on dataset (num_proc=64):  17%|█▋        | 150000/870561 [01:01<01:42, 6996.05 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00024_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  17%|█▋        | 151000/870561 [01:01<02:01, 5938.11 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:30,981 >> Token indices sequence length is longer than the specified maximum sequence length for this model (68558 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  17%|█▋        | 152000/870561 [01:01<02:17, 5214.97 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 154000/870561 [01:01<01:46, 6719.16 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 155000/870561 [01:02<02:04, 5732.60 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 156000/870561 [01:02<01:54, 6234.14 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 157000/870561 [01:02<02:50, 4192.73 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00025_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  18%|█▊        | 158000/870561 [01:03<04:05, 2904.64 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 159000/870561 [01:03<03:26, 3454.04 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 160000/870561 [01:04<04:43, 2509.34 examples/s]Running tokenizer on dataset (num_proc=64):  18%|█▊        | 161000/870561 [01:04<03:56, 3002.73 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▊        | 163000/870561 [01:04<02:42, 4359.02 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▉        | 164000/870561 [01:04<02:27, 4797.47 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▉        | 166000/870561 [01:05<02:35, 4527.38 examples/s]Running tokenizer on dataset (num_proc=64):  19%|█▉        | 168000/870561 [01:05<02:08, 5469.28 examples/s]Running tokenizer on dataset (num_proc=64):  20%|█▉        | 170000/870561 [01:05<01:40, 6958.95 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00026_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  20%|█▉        | 171000/870561 [01:06<02:41, 4332.17 examples/s]Running tokenizer on dataset (num_proc=64):  20%|█▉        | 172000/870561 [01:06<02:21, 4920.31 examples/s]Running tokenizer on dataset (num_proc=64):  20%|██        | 175000/870561 [01:06<01:27, 7906.00 examples/s]Running tokenizer on dataset (num_proc=64):  20%|██        | 177000/870561 [01:06<01:26, 8040.37 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██        | 179000/870561 [01:07<01:56, 5912.51 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██        | 181000/870561 [01:07<01:37, 7043.81 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██        | 182000/870561 [01:07<01:55, 5981.00 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██        | 183000/870561 [01:07<01:53, 6040.46 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██        | 184000/870561 [01:08<02:15, 5074.77 examples/s]Running tokenizer on dataset (num_proc=64):  21%|██▏       | 185000/870561 [01:08<03:07, 3658.28 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:38,102 >> Token indices sequence length is longer than the specified maximum sequence length for this model (43171 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  21%|██▏       | 186000/870561 [01:08<02:41, 4249.44 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00027_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  21%|██▏       | 187000/870561 [01:09<03:47, 3007.14 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 189000/870561 [01:09<02:41, 4213.94 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 190000/870561 [01:10<03:43, 3046.88 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 192000/870561 [01:10<02:39, 4265.33 examples/s]Running tokenizer on dataset (num_proc=64):  22%|██▏       | 193603/870561 [01:11<03:05, 3640.03 examples/s]Running tokenizer on dataset (num_proc=64):  23%|██▎       | 197603/870561 [01:11<01:38, 6837.64 examples/s]Running tokenizer on dataset (num_proc=64):  23%|██▎       | 199603/870561 [01:11<01:50, 6075.91 examples/s]Running tokenizer on dataset (num_proc=64):  23%|██▎       | 201603/870561 [01:11<01:50, 6046.96 examples/s]Running tokenizer on dataset (num_proc=64):  23%|██▎       | 203603/870561 [01:12<01:58, 5618.53 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▎       | 204603/870561 [01:12<02:47, 3976.90 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:42,299 >> Token indices sequence length is longer than the specified maximum sequence length for this model (63183 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  24%|██▎       | 206603/870561 [01:13<02:22, 4649.32 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▍       | 207603/870561 [01:13<02:37, 4210.45 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:43,055 >> Token indices sequence length is longer than the specified maximum sequence length for this model (57710 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  24%|██▍       | 209603/870561 [01:13<02:34, 4290.28 examples/s]Running tokenizer on dataset (num_proc=64):  24%|██▍       | 210603/870561 [01:14<02:33, 4297.47 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:43,604 >> Token indices sequence length is longer than the specified maximum sequence length for this model (53394 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  24%|██▍       | 213206/870561 [01:14<01:50, 5969.15 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:43,765 >> Token indices sequence length is longer than the specified maximum sequence length for this model (48351 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00028_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  25%|██▍       | 214206/870561 [01:14<01:54, 5720.20 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▍       | 216206/870561 [01:14<01:43, 6341.60 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▍       | 217206/870561 [01:15<01:38, 6648.55 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▌       | 218809/870561 [01:15<01:20, 8137.61 examples/s]Running tokenizer on dataset (num_proc=64):  25%|██▌       | 219809/870561 [01:16<03:19, 3267.19 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 222809/870561 [01:16<02:18, 4681.21 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:45,829 >> Token indices sequence length is longer than the specified maximum sequence length for this model (72563 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  26%|██▌       | 223809/870561 [01:16<02:21, 4568.27 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00029_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  26%|██▌       | 224809/870561 [01:16<02:11, 4925.19 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▌       | 225809/870561 [01:17<02:20, 4595.73 examples/s]Running tokenizer on dataset (num_proc=64):  26%|██▋       | 228809/870561 [01:17<01:22, 7809.56 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 230809/870561 [01:17<01:30, 7074.34 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 232809/870561 [01:17<01:49, 5820.58 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 233809/870561 [01:18<01:46, 5978.28 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 235412/870561 [01:18<01:55, 5495.92 examples/s]Running tokenizer on dataset (num_proc=64):  27%|██▋       | 236412/870561 [01:18<02:08, 4951.26 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:48,664 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34752 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00030_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  27%|██▋       | 238412/870561 [01:19<03:02, 3470.43 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 241412/870561 [01:19<02:06, 4968.26 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 243412/870561 [01:20<01:43, 6055.46 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 245412/870561 [01:20<01:49, 5685.30 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 246412/870561 [01:20<01:46, 5845.59 examples/s]Running tokenizer on dataset (num_proc=64):  28%|██▊       | 247618/870561 [01:21<02:38, 3927.44 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▊       | 248618/870561 [01:21<02:27, 4228.40 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 250618/870561 [01:21<02:21, 4380.03 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 251618/870561 [01:22<02:18, 4481.89 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00031_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  29%|██▉       | 252618/870561 [01:22<02:15, 4572.80 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 255618/870561 [01:22<01:22, 7460.11 examples/s]Running tokenizer on dataset (num_proc=64):  29%|██▉       | 256618/870561 [01:22<01:19, 7714.68 examples/s]Running tokenizer on dataset (num_proc=64):  30%|██▉       | 258618/870561 [01:22<01:03, 9702.90 examples/s]Running tokenizer on dataset (num_proc=64):  30%|██▉       | 260618/870561 [01:22<00:57, 10552.24 examples/s]Running tokenizer on dataset (num_proc=64):  30%|███       | 262618/870561 [01:23<01:34, 6413.00 examples/s] [WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:53,034 >> Token indices sequence length is longer than the specified maximum sequence length for this model (48062 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00032_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  30%|███       | 263618/870561 [01:24<03:04, 3292.69 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 266618/870561 [01:24<02:27, 4085.90 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 268618/870561 [01:25<02:00, 5001.84 examples/s]Running tokenizer on dataset (num_proc=64):  31%|███       | 271618/870561 [01:25<01:42, 5862.94 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:55,041 >> Token indices sequence length is longer than the specified maximum sequence length for this model (36675 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  31%|███▏      | 272618/870561 [01:25<02:02, 4893.46 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00033_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  32%|███▏      | 275221/870561 [01:25<01:31, 6471.86 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 276221/870561 [01:26<01:45, 5656.62 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 278221/870561 [01:26<01:59, 4953.30 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 279221/870561 [01:27<02:06, 4676.88 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 280221/870561 [01:27<02:24, 4092.10 examples/s]Running tokenizer on dataset (num_proc=64):  32%|███▏      | 281221/870561 [01:27<02:28, 3975.36 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 284221/870561 [01:27<01:31, 6420.30 examples/s]Running tokenizer on dataset (num_proc=64):  33%|███▎      | 286221/870561 [01:27<01:12, 8027.95 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:57,473 >> Token indices sequence length is longer than the specified maximum sequence length for this model (42347 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  33%|███▎      | 288221/870561 [01:28<01:16, 7632.86 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00034_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  33%|███▎      | 290221/870561 [01:28<01:33, 6202.20 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▎      | 292221/870561 [01:29<01:35, 6044.92 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▎      | 293221/870561 [01:29<02:18, 4153.96 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▍      | 295221/870561 [01:29<02:00, 4788.18 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▍      | 296221/870561 [01:30<02:13, 4315.79 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▍      | 298221/870561 [01:30<01:36, 5959.24 examples/s]Running tokenizer on dataset (num_proc=64):  34%|███▍      | 300221/870561 [01:30<01:35, 5958.39 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:00,449 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34549 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  35%|███▍      | 301221/870561 [01:31<02:08, 4436.05 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▍      | 303221/870561 [01:31<01:34, 5985.16 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00035_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  35%|███▍      | 304427/870561 [01:31<02:02, 4636.94 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▌      | 305427/870561 [01:31<01:50, 5112.68 examples/s]Running tokenizer on dataset (num_proc=64):  35%|███▌      | 307030/870561 [01:32<01:32, 6065.54 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▌      | 310030/870561 [01:32<01:01, 9160.88 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:02,007 >> Token indices sequence length is longer than the specified maximum sequence length for this model (49645 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  36%|███▌      | 312030/870561 [01:32<01:47, 5187.53 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▌      | 313030/870561 [01:33<01:51, 5014.57 examples/s]Running tokenizer on dataset (num_proc=64):  36%|███▌      | 315030/870561 [01:33<01:26, 6435.24 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:02,693 >> Token indices sequence length is longer than the specified maximum sequence length for this model (52338 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00036_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  36%|███▋      | 317030/870561 [01:33<02:00, 4575.75 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 319030/870561 [01:34<01:32, 5965.71 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 321030/870561 [01:34<01:32, 5945.73 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 322030/870561 [01:34<02:10, 4192.49 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 324030/870561 [01:35<01:46, 5140.56 examples/s]Running tokenizer on dataset (num_proc=64):  37%|███▋      | 325030/870561 [01:35<01:55, 4738.35 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:04,874 >> Token indices sequence length is longer than the specified maximum sequence length for this model (50600 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  37%|███▋      | 326030/870561 [01:35<01:47, 5080.97 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00037_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  38%|███▊      | 327030/870561 [01:35<01:42, 5320.92 examples/s]Running tokenizer on dataset (num_proc=64):  38%|███▊      | 328030/870561 [01:35<01:32, 5890.21 examples/s]Running tokenizer on dataset (num_proc=64):  38%|███▊      | 329633/870561 [01:36<01:35, 5650.13 examples/s]Running tokenizer on dataset (num_proc=64):  38%|███▊      | 330633/870561 [01:36<01:35, 5648.40 examples/s]Running tokenizer on dataset (num_proc=64):  38%|███▊      | 332633/870561 [01:36<01:23, 6437.00 examples/s]Running tokenizer on dataset (num_proc=64):  38%|███▊      | 333633/870561 [01:36<01:17, 6907.16 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▊      | 335633/870561 [01:37<01:26, 6172.93 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▉      | 337633/870561 [01:37<01:08, 7730.65 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▉      | 339633/870561 [01:37<01:07, 7823.47 examples/s]Running tokenizer on dataset (num_proc=64):  39%|███▉      | 341236/870561 [01:38<01:58, 4458.30 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:07,729 >> Token indices sequence length is longer than the specified maximum sequence length for this model (40995 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  39%|███▉      | 342236/870561 [01:38<01:49, 4806.89 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00038_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  40%|███▉      | 344236/870561 [01:38<01:29, 5893.92 examples/s]Running tokenizer on dataset (num_proc=64):  40%|███▉      | 345236/870561 [01:39<01:56, 4522.16 examples/s]Running tokenizer on dataset (num_proc=64):  40%|████      | 348236/870561 [01:39<01:19, 6542.00 examples/s]Running tokenizer on dataset (num_proc=64):  40%|████      | 349236/870561 [01:39<01:27, 5945.31 examples/s]Running tokenizer on dataset (num_proc=64):  40%|████      | 350236/870561 [01:40<02:09, 4027.70 examples/s]Running tokenizer on dataset (num_proc=64):  40%|████      | 351236/870561 [01:40<01:59, 4356.27 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:09,669 >> Token indices sequence length is longer than the specified maximum sequence length for this model (35136 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  41%|████      | 353236/870561 [01:40<01:41, 5085.54 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00039_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  41%|████      | 354839/870561 [01:40<01:29, 5755.04 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 355839/870561 [01:40<01:24, 6108.26 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 356839/870561 [01:40<01:24, 6099.79 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████      | 358839/870561 [01:41<01:19, 6424.36 examples/s]Running tokenizer on dataset (num_proc=64):  41%|████▏     | 360442/870561 [01:41<01:11, 7122.87 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 361442/870561 [01:41<01:10, 7197.63 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 364442/870561 [01:41<01:05, 7708.22 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 367442/870561 [01:42<00:59, 8445.20 examples/s]Running tokenizer on dataset (num_proc=64):  42%|████▏     | 368442/870561 [01:42<01:32, 5443.61 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00040_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  42%|████▏     | 369442/870561 [01:43<02:19, 3598.66 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 371442/870561 [01:43<01:38, 5042.96 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 372442/870561 [01:43<01:39, 5015.00 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 373442/870561 [01:43<01:36, 5137.50 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 375442/870561 [01:44<01:28, 5603.96 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 376442/870561 [01:44<01:31, 5411.43 examples/s]Running tokenizer on dataset (num_proc=64):  43%|████▎     | 378045/870561 [01:45<01:58, 4173.20 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:14,379 >> Token indices sequence length is longer than the specified maximum sequence length for this model (41275 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00041_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  44%|████▎     | 379045/870561 [01:45<02:09, 3786.29 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▎     | 380045/870561 [01:45<02:04, 3943.07 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 384045/870561 [01:45<01:00, 8044.30 examples/s]Running tokenizer on dataset (num_proc=64):  44%|████▍     | 386045/870561 [01:46<01:28, 5501.65 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▍     | 389045/870561 [01:46<01:00, 7955.45 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▍     | 390648/870561 [01:46<01:11, 6730.70 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▌     | 393648/870561 [01:47<00:59, 8056.05 examples/s]Running tokenizer on dataset (num_proc=64):  45%|████▌     | 395648/870561 [01:47<01:02, 7609.42 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00042_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:17,577 >> Token indices sequence length is longer than the specified maximum sequence length for this model (33296 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  46%|████▌     | 397648/870561 [01:48<01:47, 4411.17 examples/s]Running tokenizer on dataset (num_proc=64):  46%|████▌     | 399251/870561 [01:48<01:54, 4113.96 examples/s]Running tokenizer on dataset (num_proc=64):  46%|████▋     | 403251/870561 [01:48<01:09, 6717.86 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 405251/870561 [01:49<01:22, 5668.14 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00043_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  47%|████▋     | 407251/870561 [01:50<01:59, 3863.16 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 409251/870561 [01:50<01:38, 4704.08 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 411251/870561 [01:50<01:20, 5671.72 examples/s]Running tokenizer on dataset (num_proc=64):  47%|████▋     | 413251/870561 [01:51<01:15, 6072.45 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 414251/870561 [01:51<01:10, 6469.11 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 416251/870561 [01:51<00:56, 7971.40 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 418251/870561 [01:51<01:15, 5971.81 examples/s]Running tokenizer on dataset (num_proc=64):  48%|████▊     | 420251/870561 [01:51<00:59, 7533.86 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▊     | 422251/870561 [01:52<01:06, 6763.04 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▊     | 424251/870561 [01:52<01:30, 4912.31 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00044_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  49%|████▉     | 425251/870561 [01:53<01:31, 4859.97 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▉     | 426251/870561 [01:53<01:46, 4181.00 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▉     | 427251/870561 [01:53<01:43, 4270.61 examples/s]Running tokenizer on dataset (num_proc=64):  49%|████▉     | 429854/870561 [01:53<01:13, 5988.05 examples/s]Running tokenizer on dataset (num_proc=64):  50%|████▉     | 432457/870561 [01:54<00:52, 8294.36 examples/s]Running tokenizer on dataset (num_proc=64):  50%|████▉     | 434457/870561 [01:54<00:59, 7375.64 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:24,125 >> Token indices sequence length is longer than the specified maximum sequence length for this model (51167 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  50%|█████     | 436457/870561 [01:55<01:35, 4542.58 examples/s]Running tokenizer on dataset (num_proc=64):  50%|█████     | 437457/870561 [01:55<01:31, 4756.66 examples/s]Running tokenizer on dataset (num_proc=64):  50%|█████     | 438457/870561 [01:55<01:22, 5236.32 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:24,905 >> Token indices sequence length is longer than the specified maximum sequence length for this model (58248 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00045_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  51%|█████     | 440457/870561 [01:55<01:09, 6162.96 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 442060/870561 [01:56<01:29, 4811.65 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████     | 445060/870561 [01:56<01:03, 6657.17 examples/s]Running tokenizer on dataset (num_proc=64):  51%|█████▏    | 448060/870561 [01:56<00:47, 8826.08 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 450060/870561 [01:56<00:42, 9941.38 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 452060/870561 [01:57<00:40, 10305.43 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00046_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 454060/870561 [01:57<01:21, 5117.58 examples/s] [WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:27,783 >> Token indices sequence length is longer than the specified maximum sequence length for this model (72358 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 455060/870561 [01:58<01:59, 3490.30 examples/s]Running tokenizer on dataset (num_proc=64):  52%|█████▏    | 456663/870561 [01:58<01:44, 3956.98 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 458663/870561 [01:59<01:17, 5288.04 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 460663/870561 [01:59<01:03, 6425.45 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 462663/870561 [01:59<00:59, 6871.44 examples/s]Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 463663/870561 [01:59<01:05, 6196.92 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00047_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  53%|█████▎    | 465266/870561 [02:00<01:12, 5593.70 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▎    | 466266/870561 [02:00<01:06, 6054.99 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 468266/870561 [02:00<01:26, 4636.87 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 469266/870561 [02:00<01:23, 4786.12 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 470266/870561 [02:01<01:24, 4729.34 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 472266/870561 [02:01<01:00, 6556.80 examples/s]Running tokenizer on dataset (num_proc=64):  54%|█████▍    | 474266/870561 [02:01<00:46, 8446.69 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▍    | 476266/870561 [02:01<00:53, 7332.23 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▍    | 477266/870561 [02:01<00:52, 7453.99 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▌    | 479266/870561 [02:02<00:44, 8758.62 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:31,717 >> Token indices sequence length is longer than the specified maximum sequence length for this model (134405 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00048_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:31,883 >> Token indices sequence length is longer than the specified maximum sequence length for this model (37397 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  55%|█████▌    | 480869/870561 [02:02<01:34, 4116.89 examples/s]Running tokenizer on dataset (num_proc=64):  55%|█████▌    | 482869/870561 [02:03<01:20, 4809.75 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 483869/870561 [02:03<01:21, 4773.42 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 484869/870561 [02:03<01:38, 3899.06 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 487869/870561 [02:04<01:06, 5777.77 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▌    | 488869/870561 [02:04<01:09, 5530.80 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00049_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:33,923 >> Token indices sequence length is longer than the specified maximum sequence length for this model (56382 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  56%|█████▋    | 490472/870561 [02:04<01:11, 5317.96 examples/s]Running tokenizer on dataset (num_proc=64):  56%|█████▋    | 491472/870561 [02:04<01:05, 5761.12 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 492472/870561 [02:04<01:10, 5344.16 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 493472/870561 [02:05<01:06, 5675.51 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 494472/870561 [02:05<01:05, 5723.19 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 496472/870561 [02:05<01:27, 4252.22 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 499472/870561 [02:06<00:59, 6251.07 examples/s]Running tokenizer on dataset (num_proc=64):  57%|█████▋    | 500472/870561 [02:06<01:07, 5501.31 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 502472/870561 [02:06<00:50, 7247.26 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 503472/870561 [02:06<00:55, 6614.94 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 506075/870561 [02:07<00:47, 7600.46 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:36,477 >> Token indices sequence length is longer than the specified maximum sequence length for this model (37028 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 507075/870561 [02:07<00:52, 6866.27 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:36,601 >> Token indices sequence length is longer than the specified maximum sequence length for this model (51709 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00050_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 508075/870561 [02:07<01:14, 4845.47 examples/s]Running tokenizer on dataset (num_proc=64):  58%|█████▊    | 509075/870561 [02:07<01:24, 4264.10 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▊    | 511075/870561 [02:08<01:11, 5033.61 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 512075/870561 [02:08<01:14, 4832.71 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 513075/870561 [02:08<01:12, 4955.28 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 514075/870561 [02:09<01:35, 3724.13 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 515075/870561 [02:09<01:25, 4138.17 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:38,858 >> Token indices sequence length is longer than the specified maximum sequence length for this model (37922 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 516075/870561 [02:09<01:27, 4071.88 examples/s]Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 516678/870561 [02:09<01:21, 4338.16 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:39,094 >> Token indices sequence length is longer than the specified maximum sequence length for this model (43982 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  59%|█████▉    | 517678/870561 [02:09<01:17, 4571.43 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00051_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  60%|█████▉    | 519678/870561 [02:10<00:59, 5876.76 examples/s]Running tokenizer on dataset (num_proc=64):  60%|█████▉    | 521678/870561 [02:10<00:46, 7446.51 examples/s]Running tokenizer on dataset (num_proc=64):  60%|██████    | 522678/870561 [02:10<00:51, 6720.35 examples/s]Running tokenizer on dataset (num_proc=64):  60%|██████    | 523678/870561 [02:10<00:51, 6783.72 examples/s]Running tokenizer on dataset (num_proc=64):  60%|██████    | 524678/870561 [02:10<00:57, 6027.72 examples/s]Running tokenizer on dataset (num_proc=64):  60%|██████    | 526678/870561 [02:11<01:19, 4313.40 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████    | 528678/870561 [02:11<01:01, 5519.30 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████    | 530678/870561 [02:11<00:46, 7330.83 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████    | 532678/870561 [02:12<00:49, 6885.79 examples/s]Running tokenizer on dataset (num_proc=64):  61%|██████▏   | 533678/870561 [02:12<01:06, 5036.95 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:41,967 >> Token indices sequence length is longer than the specified maximum sequence length for this model (37283 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  61%|██████▏   | 534678/870561 [02:12<01:07, 5007.03 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00052_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 535678/870561 [02:13<01:17, 4293.72 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 536678/870561 [02:13<01:13, 4554.72 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 537678/870561 [02:13<01:03, 5280.44 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 538678/870561 [02:13<00:59, 5535.84 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 539678/870561 [02:13<01:03, 5235.08 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 541281/870561 [02:14<01:05, 5007.43 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 542281/870561 [02:14<01:05, 4983.75 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 542884/870561 [02:14<01:13, 4440.58 examples/s]Running tokenizer on dataset (num_proc=64):  62%|██████▏   | 543884/870561 [02:14<01:04, 5085.92 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 546884/870561 [02:14<00:34, 9407.46 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00053_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 548884/870561 [02:15<00:45, 7045.45 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 549884/870561 [02:15<00:43, 7315.32 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 550884/870561 [02:15<00:47, 6753.21 examples/s]Running tokenizer on dataset (num_proc=64):  63%|██████▎   | 551884/870561 [02:15<01:06, 4817.07 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▎   | 552884/870561 [02:15<01:02, 5119.72 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▎   | 553884/870561 [02:16<01:03, 4976.21 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▎   | 554884/870561 [02:16<01:03, 4953.85 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 555884/870561 [02:16<01:16, 4127.71 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 556884/870561 [02:16<01:09, 4483.04 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00054_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 558884/870561 [02:17<00:47, 6593.95 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 559884/870561 [02:17<00:51, 6007.42 examples/s]Running tokenizer on dataset (num_proc=64):  64%|██████▍   | 560884/870561 [02:17<00:49, 6248.59 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▍   | 561884/870561 [02:17<01:11, 4331.07 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▍   | 563884/870561 [02:17<00:48, 6334.37 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▍   | 564884/870561 [02:18<01:14, 4081.29 examples/s]Running tokenizer on dataset (num_proc=64):  65%|██████▌   | 566884/870561 [02:19<01:17, 3908.28 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:48,603 >> Token indices sequence length is longer than the specified maximum sequence length for this model (45244 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00055_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  65%|██████▌   | 569884/870561 [02:19<01:04, 4648.77 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▌   | 570884/870561 [02:19<01:04, 4681.43 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▌   | 572884/870561 [02:19<00:48, 6116.05 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▌   | 574884/870561 [02:19<00:37, 7891.88 examples/s]Running tokenizer on dataset (num_proc=64):  66%|██████▋   | 577884/870561 [02:20<00:33, 8834.29 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 579487/870561 [02:20<00:51, 5647.89 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 580487/870561 [02:21<00:50, 5760.97 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 581487/870561 [02:21<01:00, 4756.90 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 582487/870561 [02:21<00:57, 4982.13 examples/s]05/13/2024 22:22:50 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:50,966 >> Token indices sequence length is longer than the specified maximum sequence length for this model (57714 > 32768). Running this sequence through the model will result in indexing errors
05/13/2024 22:22:51 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00056_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:51,199 >> Token indices sequence length is longer than the specified maximum sequence length for this model (45101 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 584487/870561 [02:21<00:57, 5011.24 examples/s]Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 585487/870561 [02:22<00:51, 5486.19 examples/s]05/13/2024 22:22:51 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
Running tokenizer on dataset (num_proc=64):  67%|██████▋   | 587487/870561 [02:22<00:42, 6609.56 examples/s]05/13/2024 22:22:51 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 589090/870561 [02:22<00:43, 6416.80 examples/s]05/13/2024 22:22:51 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
05/13/2024 22:22:52 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 592090/870561 [02:22<00:40, 6923.27 examples/s]05/13/2024 22:22:52 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 594090/870561 [02:23<00:55, 4995.06 examples/s]Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 595090/870561 [02:23<00:54, 5087.32 examples/s]Dataset({
    features: ['text'],
    num_rows: 870561
})Dataset({
    features: ['text'],
    num_rows: 870561
})

{'text': "করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর | Suprovat Bogura\nপ্রচ্ছদ কৃষি সংবাদ করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর। ছবি-সংগৃহীত\nসুপ্রভাত বগুড়া (জাতীয়): প্রধানমন্ত্রী শেখ হাসিনা সকলকে করোন ভাইরাস থেকে নিজেদের সুরক্ষিত রাখতে নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান জানিয়ে বলেছেন, জনগণের কল্যাণের কথাই তাঁর সরকার সবচেয়ে বেশি চিন্তা করছে।\nতিনি বলেন, 'সকলকে স্ব-স্ব স্বাস্থ্য সুরক্ষিত রেখেই স্ব-স্ব কর্মস্থলে কাজ করে যেতে হবে। দেশের মানুষ যাতে কষ্ট না পায় কেননা তাঁদের কথাই আমরা বেশি চিন্তা করি। সবাই ভাল থাকেন, সুস্থ থাকেন, সেটাই কামনা করি।'\nমঙ্গলবার (৩ মে) প্রধানমন্ত্রী শেখ হাসিনা জাতীয় অর্থনৈতিক পরিষদের নির্বাহী কমিটির (একনেক) সভায় একথা বলেন। রাজধানীর শেরেবাংলা নগরের এনইসি সম্মেলন কক্ষে অনুষ্ঠিত এই সভায় ভিডিও কনফারেন্সের মাধ্যমে গণভবন থেকে সংযুক্ত হন এবং সভাপতিত্ব করেন ।\nএই ভার্চুয়াল একনেক সভায় ১৬ হাজার ২৭৬ কোটি ৩ লাখ টাকা ব্যয়ে ১০টি প্রকল্প অনুমোদন দেয়া হয়। অনুমোদিত প্রকল্পের জন্য বাংলাদেশ সরকার দেবে ১৪ হাজার ৪০১ কোটি ৫২ লাখ টাকা এবং বৈদেশিক ঋণ ১ হাজার ৮৮১ কোটি ৯৭ লাখ টাকা।\nপরে পরিকল্পনা মন্ত্রী এমএ মান্নান সভার বিষয়ে বিস্তারিত সাংবাদিকদের অবহিত করেন। প্রধানমন্ত্রী বলেন, এর আগে আমরা জাতীয় অর্থনৈতিক কাউন্সিলের সভা করে বাজেট প্রণয়নের কাজগুলো করেছি।\nতিনি বলেন, কোভিড-১৯ ভাইরাসের কারণে আজ শুধু বাংলাদেশ নয় সমগ্র বিশ্বই বলতে গেলে স্থবির হয়ে পড়েছে। এরমধ্যেও আপনারা যারা আজকে প্রকল্পগুলো তৈরী করে নিয়ে এসেছেন বা ডিজিটাল পদ্ধতিতে এই মিটিংটা যে করতে পারছি, সেজন্য আপনাদের আন্তরিক ধন্যবাদ জানাই।\nপ্রধানমন্ত্রী এসময় করেনা ভাইরাসের কারণে দেশে এবং বিদেশে মৃত্যুবরনকারী বাংলাদেশীদের জন্য শোক ও দুঃখ প্রকাশ করে তাঁদের আত্মার মাগফেরাত কামনা করেন। তিনি বলেন, 'এ ব্যাপারে যে স্বাস্থ্যবিধি দেওয়া হয়েছে দেশবাসী সেটা মেনে চলবে, এটাই আমরা চাই।'\nতিনি বলেন, 'কোভিড-১৯ এর কারণে উন্নয়নের গতিশীলতাটা কিছুটা কমে এলেও আমরা মনে করি, এই দিন থাকবে না। যে কোন প্রতিবন্ধকতা মোকাবেলা করেই আমরা এগিয়ে যেতে পারবো।' লক ডাউন শিথিল করার প্রসঙ্গে প্রধানমন্ত্রী বলেন, 'আমরা চাই না আমাদের দেশের মানুষ কষ্ট পাক।\nসেজন্য আমরা যেসব বন্ধ করে দিয়েছিলাম। এখন তা কিছু কিছু করে উন্মুক্ত করা শুরু করেছি। কারণ, দেশের খেটে খাওয়া জনগণকে থেকে শুরু করে স্বল্প আয়ের লোকজন, প্রত্যেকেই যেন তাঁদের জীবনযাত্রা সচল রাখতে পারে।'\nতাঁর সরকারের শাসনে দেশের এগিয়ে চলা এবং বর্তমান মুজিববর্ষ থেকে ২০২১ সালে স্বাধীনতার সুবর্ণ জয়ন্তী উদযাপন পর্যন্ত দেশের দারিদ্রের হারকে আরো কমিয়ে এনে বাংলাদেশকে উন্নয়নশীল দেশ হিসেবে বিশ্ব দরবারে প্রতিষ্ঠার পূর্ব নির্ধারিত লক্ষ্য অর্জনেও আশাবাদ ব্যক্ত করেন তিনি।"}{'text': "করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর | Suprovat Bogura\nপ্রচ্ছদ কৃষি সংবাদ করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর। ছবি-সংগৃহীত\nসুপ্রভাত বগুড়া (জাতীয়): প্রধানমন্ত্রী শেখ হাসিনা সকলকে করোন ভাইরাস থেকে নিজেদের সুরক্ষিত রাখতে নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান জানিয়ে বলেছেন, জনগণের কল্যাণের কথাই তাঁর সরকার সবচেয়ে বেশি চিন্তা করছে।\nতিনি বলেন, 'সকলকে স্ব-স্ব স্বাস্থ্য সুরক্ষিত রেখেই স্ব-স্ব কর্মস্থলে কাজ করে যেতে হবে। দেশের মানুষ যাতে কষ্ট না পায় কেননা তাঁদের কথাই আমরা বেশি চিন্তা করি। সবাই ভাল থাকেন, সুস্থ থাকেন, সেটাই কামনা করি।'\nমঙ্গলবার (৩ মে) প্রধানমন্ত্রী শেখ হাসিনা জাতীয় অর্থনৈতিক পরিষদের নির্বাহী কমিটির (একনেক) সভায় একথা বলেন। রাজধানীর শেরেবাংলা নগরের এনইসি সম্মেলন কক্ষে অনুষ্ঠিত এই সভায় ভিডিও কনফারেন্সের মাধ্যমে গণভবন থেকে সংযুক্ত হন এবং সভাপতিত্ব করেন ।\nএই ভার্চুয়াল একনেক সভায় ১৬ হাজার ২৭৬ কোটি ৩ লাখ টাকা ব্যয়ে ১০টি প্রকল্প অনুমোদন দেয়া হয়। অনুমোদিত প্রকল্পের জন্য বাংলাদেশ সরকার দেবে ১৪ হাজার ৪০১ কোটি ৫২ লাখ টাকা এবং বৈদেশিক ঋণ ১ হাজার ৮৮১ কোটি ৯৭ লাখ টাকা।\nপরে পরিকল্পনা মন্ত্রী এমএ মান্নান সভার বিষয়ে বিস্তারিত সাংবাদিকদের অবহিত করেন। প্রধানমন্ত্রী বলেন, এর আগে আমরা জাতীয় অর্থনৈতিক কাউন্সিলের সভা করে বাজেট প্রণয়নের কাজগুলো করেছি।\nতিনি বলেন, কোভিড-১৯ ভাইরাসের কারণে আজ শুধু বাংলাদেশ নয় সমগ্র বিশ্বই বলতে গেলে স্থবির হয়ে পড়েছে। এরমধ্যেও আপনারা যারা আজকে প্রকল্পগুলো তৈরী করে নিয়ে এসেছেন বা ডিজিটাল পদ্ধতিতে এই মিটিংটা যে করতে পারছি, সেজন্য আপনাদের আন্তরিক ধন্যবাদ জানাই।\nপ্রধানমন্ত্রী এসময় করেনা ভাইরাসের কারণে দেশে এবং বিদেশে মৃত্যুবরনকারী বাংলাদেশীদের জন্য শোক ও দুঃখ প্রকাশ করে তাঁদের আত্মার মাগফেরাত কামনা করেন। তিনি বলেন, 'এ ব্যাপারে যে স্বাস্থ্যবিধি দেওয়া হয়েছে দেশবাসী সেটা মেনে চলবে, এটাই আমরা চাই।'\nতিনি বলেন, 'কোভিড-১৯ এর কারণে উন্নয়নের গতিশীলতাটা কিছুটা কমে এলেও আমরা মনে করি, এই দিন থাকবে না। যে কোন প্রতিবন্ধকতা মোকাবেলা করেই আমরা এগিয়ে যেতে পারবো।' লক ডাউন শিথিল করার প্রসঙ্গে প্রধানমন্ত্রী বলেন, 'আমরা চাই না আমাদের দেশের মানুষ কষ্ট পাক।\nসেজন্য আমরা যেসব বন্ধ করে দিয়েছিলাম। এখন তা কিছু কিছু করে উন্মুক্ত করা শুরু করেছি। কারণ, দেশের খেটে খাওয়া জনগণকে থেকে শুরু করে স্বল্প আয়ের লোকজন, প্রত্যেকেই যেন তাঁদের জীবনযাত্রা সচল রাখতে পারে।'\nতাঁর সরকারের শাসনে দেশের এগিয়ে চলা এবং বর্তমান মুজিববর্ষ থেকে ২০২১ সালে স্বাধীনতার সুবর্ণ জয়ন্তী উদযাপন পর্যন্ত দেশের দারিদ্রের হারকে আরো কমিয়ে এনে বাংলাদেশকে উন্নয়নশীল দেশ হিসেবে বিশ্ব দরবারে প্রতিষ্ঠার পূর্ব নির্ধারিত লক্ষ্য অর্জনেও আশাবাদ ব্যক্ত করেন তিনি।"}

Dataset({
    features: ['text'],
    num_rows: 870561
})Dataset({
    features: ['text'],
    num_rows: 870561
})

{'text': "করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর | Suprovat Bogura\nপ্রচ্ছদ কৃষি সংবাদ করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর। ছবি-সংগৃহীত\nসুপ্রভাত বগুড়া (জাতীয়): প্রধানমন্ত্রী শেখ হাসিনা সকলকে করোন ভাইরাস থেকে নিজেদের সুরক্ষিত রাখতে নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান জানিয়ে বলেছেন, জনগণের কল্যাণের কথাই তাঁর সরকার সবচেয়ে বেশি চিন্তা করছে।\nতিনি বলেন, 'সকলকে স্ব-স্ব স্বাস্থ্য সুরক্ষিত রেখেই স্ব-স্ব কর্মস্থলে কাজ করে যেতে হবে। দেশের মানুষ যাতে কষ্ট না পায় কেননা তাঁদের কথাই আমরা বেশি চিন্তা করি। সবাই ভাল থাকেন, সুস্থ থাকেন, সেটাই কামনা করি।'\nমঙ্গলবার (৩ মে) প্রধানমন্ত্রী শেখ হাসিনা জাতীয় অর্থনৈতিক পরিষদের নির্বাহী কমিটির (একনেক) সভায় একথা বলেন। রাজধানীর শেরেবাংলা নগরের এনইসি সম্মেলন কক্ষে অনুষ্ঠিত এই সভায় ভিডিও কনফারেন্সের মাধ্যমে গণভবন থেকে সংযুক্ত হন এবং সভাপতিত্ব করেন ।\nএই ভার্চুয়াল একনেক সভায় ১৬ হাজার ২৭৬ কোটি ৩ লাখ টাকা ব্যয়ে ১০টি প্রকল্প অনুমোদন দেয়া হয়। অনুমোদিত প্রকল্পের জন্য বাংলাদেশ সরকার দেবে ১৪ হাজার ৪০১ কোটি ৫২ লাখ টাকা এবং বৈদেশিক ঋণ ১ হাজার ৮৮১ কোটি ৯৭ লাখ টাকা।\nপরে পরিকল্পনা মন্ত্রী এমএ মান্নান সভার বিষয়ে বিস্তারিত সাংবাদিকদের অবহিত করেন। প্রধানমন্ত্রী বলেন, এর আগে আমরা জাতীয় অর্থনৈতিক কাউন্সিলের সভা করে বাজেট প্রণয়নের কাজগুলো করেছি।\nতিনি বলেন, কোভিড-১৯ ভাইরাসের কারণে আজ শুধু বাংলাদেশ নয় সমগ্র বিশ্বই বলতে গেলে স্থবির হয়ে পড়েছে। এরমধ্যেও আপনারা যারা আজকে প্রকল্পগুলো তৈরী করে নিয়ে এসেছেন বা ডিজিটাল পদ্ধতিতে এই মিটিংটা যে করতে পারছি, সেজন্য আপনাদের আন্তরিক ধন্যবাদ জানাই।\nপ্রধানমন্ত্রী এসময় করেনা ভাইরাসের কারণে দেশে এবং বিদেশে মৃত্যুবরনকারী বাংলাদেশীদের জন্য শোক ও দুঃখ প্রকাশ করে তাঁদের আত্মার মাগফেরাত কামনা করেন। তিনি বলেন, 'এ ব্যাপারে যে স্বাস্থ্যবিধি দেওয়া হয়েছে দেশবাসী সেটা মেনে চলবে, এটাই আমরা চাই।'\nতিনি বলেন, 'কোভিড-১৯ এর কারণে উন্নয়নের গতিশীলতাটা কিছুটা কমে এলেও আমরা মনে করি, এই দিন থাকবে না। যে কোন প্রতিবন্ধকতা মোকাবেলা করেই আমরা এগিয়ে যেতে পারবো।' লক ডাউন শিথিল করার প্রসঙ্গে প্রধানমন্ত্রী বলেন, 'আমরা চাই না আমাদের দেশের মানুষ কষ্ট পাক।\nসেজন্য আমরা যেসব বন্ধ করে দিয়েছিলাম। এখন তা কিছু কিছু করে উন্মুক্ত করা শুরু করেছি। কারণ, দেশের খেটে খাওয়া জনগণকে থেকে শুরু করে স্বল্প আয়ের লোকজন, প্রত্যেকেই যেন তাঁদের জীবনযাত্রা সচল রাখতে পারে।'\nতাঁর সরকারের শাসনে দেশের এগিয়ে চলা এবং বর্তমান মুজিববর্ষ থেকে ২০২১ সালে স্বাধীনতার সুবর্ণ জয়ন্তী উদযাপন পর্যন্ত দেশের দারিদ্রের হারকে আরো কমিয়ে এনে বাংলাদেশকে উন্নয়নশীল দেশ হিসেবে বিশ্ব দরবারে প্রতিষ্ঠার পূর্ব নির্ধারিত লক্ষ্য অর্জনেও আশাবাদ ব্যক্ত করেন তিনি।"}{'text': "করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর | Suprovat Bogura\nপ্রচ্ছদ কৃষি সংবাদ করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর। ছবি-সংগৃহীত\nসুপ্রভাত বগুড়া (জাতীয়): প্রধানমন্ত্রী শেখ হাসিনা সকলকে করোন ভাইরাস থেকে নিজেদের সুরক্ষিত রাখতে নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান জানিয়ে বলেছেন, জনগণের কল্যাণের কথাই তাঁর সরকার সবচেয়ে বেশি চিন্তা করছে।\nতিনি বলেন, 'সকলকে স্ব-স্ব স্বাস্থ্য সুরক্ষিত রেখেই স্ব-স্ব কর্মস্থলে কাজ করে যেতে হবে। দেশের মানুষ যাতে কষ্ট না পায় কেননা তাঁদের কথাই আমরা বেশি চিন্তা করি। সবাই ভাল থাকেন, সুস্থ থাকেন, সেটাই কামনা করি।'\nমঙ্গলবার (৩ মে) প্রধানমন্ত্রী শেখ হাসিনা জাতীয় অর্থনৈতিক পরিষদের নির্বাহী কমিটির (একনেক) সভায় একথা বলেন। রাজধানীর শেরেবাংলা নগরের এনইসি সম্মেলন কক্ষে অনুষ্ঠিত এই সভায় ভিডিও কনফারেন্সের মাধ্যমে গণভবন থেকে সংযুক্ত হন এবং সভাপতিত্ব করেন ।\nএই ভার্চুয়াল একনেক সভায় ১৬ হাজার ২৭৬ কোটি ৩ লাখ টাকা ব্যয়ে ১০টি প্রকল্প অনুমোদন দেয়া হয়। অনুমোদিত প্রকল্পের জন্য বাংলাদেশ সরকার দেবে ১৪ হাজার ৪০১ কোটি ৫২ লাখ টাকা এবং বৈদেশিক ঋণ ১ হাজার ৮৮১ কোটি ৯৭ লাখ টাকা।\nপরে পরিকল্পনা মন্ত্রী এমএ মান্নান সভার বিষয়ে বিস্তারিত সাংবাদিকদের অবহিত করেন। প্রধানমন্ত্রী বলেন, এর আগে আমরা জাতীয় অর্থনৈতিক কাউন্সিলের সভা করে বাজেট প্রণয়নের কাজগুলো করেছি।\nতিনি বলেন, কোভিড-১৯ ভাইরাসের কারণে আজ শুধু বাংলাদেশ নয় সমগ্র বিশ্বই বলতে গেলে স্থবির হয়ে পড়েছে। এরমধ্যেও আপনারা যারা আজকে প্রকল্পগুলো তৈরী করে নিয়ে এসেছেন বা ডিজিটাল পদ্ধতিতে এই মিটিংটা যে করতে পারছি, সেজন্য আপনাদের আন্তরিক ধন্যবাদ জানাই।\nপ্রধানমন্ত্রী এসময় করেনা ভাইরাসের কারণে দেশে এবং বিদেশে মৃত্যুবরনকারী বাংলাদেশীদের জন্য শোক ও দুঃখ প্রকাশ করে তাঁদের আত্মার মাগফেরাত কামনা করেন। তিনি বলেন, 'এ ব্যাপারে যে স্বাস্থ্যবিধি দেওয়া হয়েছে দেশবাসী সেটা মেনে চলবে, এটাই আমরা চাই।'\nতিনি বলেন, 'কোভিড-১৯ এর কারণে উন্নয়নের গতিশীলতাটা কিছুটা কমে এলেও আমরা মনে করি, এই দিন থাকবে না। যে কোন প্রতিবন্ধকতা মোকাবেলা করেই আমরা এগিয়ে যেতে পারবো।' লক ডাউন শিথিল করার প্রসঙ্গে প্রধানমন্ত্রী বলেন, 'আমরা চাই না আমাদের দেশের মানুষ কষ্ট পাক।\nসেজন্য আমরা যেসব বন্ধ করে দিয়েছিলাম। এখন তা কিছু কিছু করে উন্মুক্ত করা শুরু করেছি। কারণ, দেশের খেটে খাওয়া জনগণকে থেকে শুরু করে স্বল্প আয়ের লোকজন, প্রত্যেকেই যেন তাঁদের জীবনযাত্রা সচল রাখতে পারে।'\nতাঁর সরকারের শাসনে দেশের এগিয়ে চলা এবং বর্তমান মুজিববর্ষ থেকে ২০২১ সালে স্বাধীনতার সুবর্ণ জয়ন্তী উদযাপন পর্যন্ত দেশের দারিদ্রের হারকে আরো কমিয়ে এনে বাংলাদেশকে উন্নয়নশীল দেশ হিসেবে বিশ্ব দরবারে প্রতিষ্ঠার পূর্ব নির্ধারিত লক্ষ্য অর্জনেও আশাবাদ ব্যক্ত করেন তিনি।"}

Dataset({
    features: ['text'],
    num_rows: 870561
})
{'text': "করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর | Suprovat Bogura\nপ্রচ্ছদ কৃষি সংবাদ করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর। ছবি-সংগৃহীত\nসুপ্রভাত বগুড়া (জাতীয়): প্রধানমন্ত্রী শেখ হাসিনা সকলকে করোন ভাইরাস থেকে নিজেদের সুরক্ষিত রাখতে নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান জানিয়ে বলেছেন, জনগণের কল্যাণের কথাই তাঁর সরকার সবচেয়ে বেশি চিন্তা করছে।\nতিনি বলেন, 'সকলকে স্ব-স্ব স্বাস্থ্য সুরক্ষিত রেখেই স্ব-স্ব কর্মস্থলে কাজ করে যেতে হবে। দেশের মানুষ যাতে কষ্ট না পায় কেননা তাঁদের কথাই আমরা বেশি চিন্তা করি। সবাই ভাল থাকেন, সুস্থ থাকেন, সেটাই কামনা করি।'\nমঙ্গলবার (৩ মে) প্রধানমন্ত্রী শেখ হাসিনা জাতীয় অর্থনৈতিক পরিষদের নির্বাহী কমিটির (একনেক) সভায় একথা বলেন। রাজধানীর শেরেবাংলা নগরের এনইসি সম্মেলন কক্ষে অনুষ্ঠিত এই সভায় ভিডিও কনফারেন্সের মাধ্যমে গণভবন থেকে সংযুক্ত হন এবং সভাপতিত্ব করেন ।\nএই ভার্চুয়াল একনেক সভায় ১৬ হাজার ২৭৬ কোটি ৩ লাখ টাকা ব্যয়ে ১০টি প্রকল্প অনুমোদন দেয়া হয়। অনুমোদিত প্রকল্পের জন্য বাংলাদেশ সরকার দেবে ১৪ হাজার ৪০১ কোটি ৫২ লাখ টাকা এবং বৈদেশিক ঋণ ১ হাজার ৮৮১ কোটি ৯৭ লাখ টাকা।\nপরে পরিকল্পনা মন্ত্রী এমএ মান্নান সভার বিষয়ে বিস্তারিত সাংবাদিকদের অবহিত করেন। প্রধানমন্ত্রী বলেন, এর আগে আমরা জাতীয় অর্থনৈতিক কাউন্সিলের সভা করে বাজেট প্রণয়নের কাজগুলো করেছি।\nতিনি বলেন, কোভিড-১৯ ভাইরাসের কারণে আজ শুধু বাংলাদেশ নয় সমগ্র বিশ্বই বলতে গেলে স্থবির হয়ে পড়েছে। এরমধ্যেও আপনারা যারা আজকে প্রকল্পগুলো তৈরী করে নিয়ে এসেছেন বা ডিজিটাল পদ্ধতিতে এই মিটিংটা যে করতে পারছি, সেজন্য আপনাদের আন্তরিক ধন্যবাদ জানাই।\nপ্রধানমন্ত্রী এসময় করেনা ভাইরাসের কারণে দেশে এবং বিদেশে মৃত্যুবরনকারী বাংলাদেশীদের জন্য শোক ও দুঃখ প্রকাশ করে তাঁদের আত্মার মাগফেরাত কামনা করেন। তিনি বলেন, 'এ ব্যাপারে যে স্বাস্থ্যবিধি দেওয়া হয়েছে দেশবাসী সেটা মেনে চলবে, এটাই আমরা চাই।'\nতিনি বলেন, 'কোভিড-১৯ এর কারণে উন্নয়নের গতিশীলতাটা কিছুটা কমে এলেও আমরা মনে করি, এই দিন থাকবে না। যে কোন প্রতিবন্ধকতা মোকাবেলা করেই আমরা এগিয়ে যেতে পারবো।' লক ডাউন শিথিল করার প্রসঙ্গে প্রধানমন্ত্রী বলেন, 'আমরা চাই না আমাদের দেশের মানুষ কষ্ট পাক।\nসেজন্য আমরা যেসব বন্ধ করে দিয়েছিলাম। এখন তা কিছু কিছু করে উন্মুক্ত করা শুরু করেছি। কারণ, দেশের খেটে খাওয়া জনগণকে থেকে শুরু করে স্বল্প আয়ের লোকজন, প্রত্যেকেই যেন তাঁদের জীবনযাত্রা সচল রাখতে পারে।'\nতাঁর সরকারের শাসনে দেশের এগিয়ে চলা এবং বর্তমান মুজিববর্ষ থেকে ২০২১ সালে স্বাধীনতার সুবর্ণ জয়ন্তী উদযাপন পর্যন্ত দেশের দারিদ্রের হারকে আরো কমিয়ে এনে বাংলাদেশকে উন্নয়নশীল দেশ হিসেবে বিশ্ব দরবারে প্রতিষ্ঠার পূর্ব নির্ধারিত লক্ষ্য অর্জনেও আশাবাদ ব্যক্ত করেন তিনি।"}
Dataset({
    features: ['text'],
    num_rows: 870561
})
{'text': "করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর | Suprovat Bogura\nপ্রচ্ছদ কৃষি সংবাদ করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর। ছবি-সংগৃহীত\nসুপ্রভাত বগুড়া (জাতীয়): প্রধানমন্ত্রী শেখ হাসিনা সকলকে করোন ভাইরাস থেকে নিজেদের সুরক্ষিত রাখতে নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান জানিয়ে বলেছেন, জনগণের কল্যাণের কথাই তাঁর সরকার সবচেয়ে বেশি চিন্তা করছে।\nতিনি বলেন, 'সকলকে স্ব-স্ব স্বাস্থ্য সুরক্ষিত রেখেই স্ব-স্ব কর্মস্থলে কাজ করে যেতে হবে। দেশের মানুষ যাতে কষ্ট না পায় কেননা তাঁদের কথাই আমরা বেশি চিন্তা করি। সবাই ভাল থাকেন, সুস্থ থাকেন, সেটাই কামনা করি।'\nমঙ্গলবার (৩ মে) প্রধানমন্ত্রী শেখ হাসিনা জাতীয় অর্থনৈতিক পরিষদের নির্বাহী কমিটির (একনেক) সভায় একথা বলেন। রাজধানীর শেরেবাংলা নগরের এনইসি সম্মেলন কক্ষে অনুষ্ঠিত এই সভায় ভিডিও কনফারেন্সের মাধ্যমে গণভবন থেকে সংযুক্ত হন এবং সভাপতিত্ব করেন ।\nএই ভার্চুয়াল একনেক সভায় ১৬ হাজার ২৭৬ কোটি ৩ লাখ টাকা ব্যয়ে ১০টি প্রকল্প অনুমোদন দেয়া হয়। অনুমোদিত প্রকল্পের জন্য বাংলাদেশ সরকার দেবে ১৪ হাজার ৪০১ কোটি ৫২ লাখ টাকা এবং বৈদেশিক ঋণ ১ হাজার ৮৮১ কোটি ৯৭ লাখ টাকা।\nপরে পরিকল্পনা মন্ত্রী এমএ মান্নান সভার বিষয়ে বিস্তারিত সাংবাদিকদের অবহিত করেন। প্রধানমন্ত্রী বলেন, এর আগে আমরা জাতীয় অর্থনৈতিক কাউন্সিলের সভা করে বাজেট প্রণয়নের কাজগুলো করেছি।\nতিনি বলেন, কোভিড-১৯ ভাইরাসের কারণে আজ শুধু বাংলাদেশ নয় সমগ্র বিশ্বই বলতে গেলে স্থবির হয়ে পড়েছে। এরমধ্যেও আপনারা যারা আজকে প্রকল্পগুলো তৈরী করে নিয়ে এসেছেন বা ডিজিটাল পদ্ধতিতে এই মিটিংটা যে করতে পারছি, সেজন্য আপনাদের আন্তরিক ধন্যবাদ জানাই।\nপ্রধানমন্ত্রী এসময় করেনা ভাইরাসের কারণে দেশে এবং বিদেশে মৃত্যুবরনকারী বাংলাদেশীদের জন্য শোক ও দুঃখ প্রকাশ করে তাঁদের আত্মার মাগফেরাত কামনা করেন। তিনি বলেন, 'এ ব্যাপারে যে স্বাস্থ্যবিধি দেওয়া হয়েছে দেশবাসী সেটা মেনে চলবে, এটাই আমরা চাই।'\nতিনি বলেন, 'কোভিড-১৯ এর কারণে উন্নয়নের গতিশীলতাটা কিছুটা কমে এলেও আমরা মনে করি, এই দিন থাকবে না। যে কোন প্রতিবন্ধকতা মোকাবেলা করেই আমরা এগিয়ে যেতে পারবো।' লক ডাউন শিথিল করার প্রসঙ্গে প্রধানমন্ত্রী বলেন, 'আমরা চাই না আমাদের দেশের মানুষ কষ্ট পাক।\nসেজন্য আমরা যেসব বন্ধ করে দিয়েছিলাম। এখন তা কিছু কিছু করে উন্মুক্ত করা শুরু করেছি। কারণ, দেশের খেটে খাওয়া জনগণকে থেকে শুরু করে স্বল্প আয়ের লোকজন, প্রত্যেকেই যেন তাঁদের জীবনযাত্রা সচল রাখতে পারে।'\nতাঁর সরকারের শাসনে দেশের এগিয়ে চলা এবং বর্তমান মুজিববর্ষ থেকে ২০২১ সালে স্বাধীনতার সুবর্ণ জয়ন্তী উদযাপন পর্যন্ত দেশের দারিদ্রের হারকে আরো কমিয়ে এনে বাংলাদেশকে উন্নয়নশীল দেশ হিসেবে বিশ্ব দরবারে প্রতিষ্ঠার পূর্ব নির্ধারিত লক্ষ্য অর্জনেও আশাবাদ ব্যক্ত করেন তিনি।"}
Dataset({
    features: ['text'],
    num_rows: 870561
})
{'text': "করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর | Suprovat Bogura\nপ্রচ্ছদ কৃষি সংবাদ করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর\nকরোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর। ছবি-সংগৃহীত\nসুপ্রভাত বগুড়া (জাতীয়): প্রধানমন্ত্রী শেখ হাসিনা সকলকে করোন ভাইরাস থেকে নিজেদের সুরক্ষিত রাখতে নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান জানিয়ে বলেছেন, জনগণের কল্যাণের কথাই তাঁর সরকার সবচেয়ে বেশি চিন্তা করছে।\nতিনি বলেন, 'সকলকে স্ব-স্ব স্বাস্থ্য সুরক্ষিত রেখেই স্ব-স্ব কর্মস্থলে কাজ করে যেতে হবে। দেশের মানুষ যাতে কষ্ট না পায় কেননা তাঁদের কথাই আমরা বেশি চিন্তা করি। সবাই ভাল থাকেন, সুস্থ থাকেন, সেটাই কামনা করি।'\nমঙ্গলবার (৩ মে) প্রধানমন্ত্রী শেখ হাসিনা জাতীয় অর্থনৈতিক পরিষদের নির্বাহী কমিটির (একনেক) সভায় একথা বলেন। রাজধানীর শেরেবাংলা নগরের এনইসি সম্মেলন কক্ষে অনুষ্ঠিত এই সভায় ভিডিও কনফারেন্সের মাধ্যমে গণভবন থেকে সংযুক্ত হন এবং সভাপতিত্ব করেন ।\nএই ভার্চুয়াল একনেক সভায় ১৬ হাজার ২৭৬ কোটি ৩ লাখ টাকা ব্যয়ে ১০টি প্রকল্প অনুমোদন দেয়া হয়। অনুমোদিত প্রকল্পের জন্য বাংলাদেশ সরকার দেবে ১৪ হাজার ৪০১ কোটি ৫২ লাখ টাকা এবং বৈদেশিক ঋণ ১ হাজার ৮৮১ কোটি ৯৭ লাখ টাকা।\nপরে পরিকল্পনা মন্ত্রী এমএ মান্নান সভার বিষয়ে বিস্তারিত সাংবাদিকদের অবহিত করেন। প্রধানমন্ত্রী বলেন, এর আগে আমরা জাতীয় অর্থনৈতিক কাউন্সিলের সভা করে বাজেট প্রণয়নের কাজগুলো করেছি।\nতিনি বলেন, কোভিড-১৯ ভাইরাসের কারণে আজ শুধু বাংলাদেশ নয় সমগ্র বিশ্বই বলতে গেলে স্থবির হয়ে পড়েছে। এরমধ্যেও আপনারা যারা আজকে প্রকল্পগুলো তৈরী করে নিয়ে এসেছেন বা ডিজিটাল পদ্ধতিতে এই মিটিংটা যে করতে পারছি, সেজন্য আপনাদের আন্তরিক ধন্যবাদ জানাই।\nপ্রধানমন্ত্রী এসময় করেনা ভাইরাসের কারণে দেশে এবং বিদেশে মৃত্যুবরনকারী বাংলাদেশীদের জন্য শোক ও দুঃখ প্রকাশ করে তাঁদের আত্মার মাগফেরাত কামনা করেন। তিনি বলেন, 'এ ব্যাপারে যে স্বাস্থ্যবিধি দেওয়া হয়েছে দেশবাসী সেটা মেনে চলবে, এটাই আমরা চাই।'\nতিনি বলেন, 'কোভিড-১৯ এর কারণে উন্নয়নের গতিশীলতাটা কিছুটা কমে এলেও আমরা মনে করি, এই দিন থাকবে না। যে কোন প্রতিবন্ধকতা মোকাবেলা করেই আমরা এগিয়ে যেতে পারবো।' লক ডাউন শিথিল করার প্রসঙ্গে প্রধানমন্ত্রী বলেন, 'আমরা চাই না আমাদের দেশের মানুষ কষ্ট পাক।\nসেজন্য আমরা যেসব বন্ধ করে দিয়েছিলাম। এখন তা কিছু কিছু করে উন্মুক্ত করা শুরু করেছি। কারণ, দেশের খেটে খাওয়া জনগণকে থেকে শুরু করে স্বল্প আয়ের লোকজন, প্রত্যেকেই যেন তাঁদের জীবনযাত্রা সচল রাখতে পারে।'\nতাঁর সরকারের শাসনে দেশের এগিয়ে চলা এবং বর্তমান মুজিববর্ষ থেকে ২০২১ সালে স্বাধীনতার সুবর্ণ জয়ন্তী উদযাপন পর্যন্ত দেশের দারিদ্রের হারকে আরো কমিয়ে এনে বাংলাদেশকে উন্নয়নশীল দেশ হিসেবে বিশ্ব দরবারে প্রতিষ্ঠার পূর্ব নির্ধারিত লক্ষ্য অর্জনেও আশাবাদ ব্যক্ত করেন তিনি।"}
Running tokenizer on dataset (num_proc=64):  68%|██████▊   | 596090/870561 [02:24<01:08, 4019.52 examples/s]Running tokenizer on dataset (num_proc=64):  69%|██████▊   | 597090/870561 [02:24<01:18, 3492.79 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:54,050 >> Token indices sequence length is longer than the specified maximum sequence length for this model (59485 > 32768). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:54,176 >> Token indices sequence length is longer than the specified maximum sequence length for this model (55088 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  69%|██████▉   | 598693/870561 [02:24<01:08, 3993.29 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00057_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  69%|██████▉   | 600693/870561 [02:25<00:55, 4869.06 examples/s]Running tokenizer on dataset (num_proc=64):  69%|██████▉   | 601693/870561 [02:25<00:52, 5109.53 examples/s]Running tokenizer on dataset (num_proc=64):  69%|██████▉   | 604693/870561 [02:25<00:37, 7171.10 examples/s]Running tokenizer on dataset (num_proc=64):  70%|██████▉   | 606693/870561 [02:25<00:33, 7853.30 examples/s]Running tokenizer on dataset (num_proc=64):  70%|██████▉   | 608693/870561 [02:26<00:31, 8193.08 examples/s]Running tokenizer on dataset (num_proc=64):  70%|███████   | 609693/870561 [02:26<00:41, 6295.46 examples/s]Running tokenizer on dataset (num_proc=64):  70%|███████   | 610693/870561 [02:26<01:00, 4268.34 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:56,266 >> Token indices sequence length is longer than the specified maximum sequence length for this model (35305 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00058_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  70%|███████   | 612693/870561 [02:27<00:52, 4948.69 examples/s]Running tokenizer on dataset (num_proc=64):  70%|███████   | 613693/870561 [02:27<00:52, 4936.95 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████   | 614296/870561 [02:27<00:53, 4807.02 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████   | 615296/870561 [02:27<00:48, 5212.73 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████   | 619296/870561 [02:27<00:30, 8275.02 examples/s]Running tokenizer on dataset (num_proc=64):  71%|███████▏  | 620296/870561 [02:28<01:02, 3975.31 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 623296/870561 [02:28<00:41, 5943.13 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 624296/870561 [02:29<00:48, 5040.58 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 625296/870561 [02:29<00:59, 4100.03 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 626296/870561 [02:30<01:13, 3331.93 examples/s]Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 628898/870561 [02:30<00:47, 5127.07 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:59,824 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34743 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  72%|███████▏  | 629898/870561 [02:30<00:44, 5408.28 examples/s]Running tokenizer on dataset (num_proc=64):  73%|███████▎  | 632898/870561 [02:30<00:27, 8626.05 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00059_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  73%|███████▎  | 635898/870561 [02:30<00:22, 10441.07 examples/s]Running tokenizer on dataset (num_proc=64):  73%|███████▎  | 637898/870561 [02:31<00:25, 9097.44 examples/s] Running tokenizer on dataset (num_proc=64):  73%|███████▎  | 639501/870561 [02:31<00:38, 6033.97 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▎  | 640501/870561 [02:31<00:38, 5954.48 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 642501/870561 [02:32<00:34, 6542.75 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 643501/870561 [02:32<00:45, 5014.36 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:23:01,997 >> Token indices sequence length is longer than the specified maximum sequence length for this model (35689 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 644501/870561 [02:32<00:45, 4989.81 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 645501/870561 [02:32<00:39, 5649.44 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00060_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 647501/870561 [02:33<00:39, 5664.57 examples/s]Running tokenizer on dataset (num_proc=64):  74%|███████▍  | 648501/870561 [02:33<00:36, 6159.02 examples/s]Running tokenizer on dataset (num_proc=64):  75%|███████▍  | 650103/870561 [02:33<00:44, 4998.71 examples/s]Running tokenizer on dataset (num_proc=64):  75%|███████▍  | 652103/870561 [02:33<00:31, 6923.06 examples/s]Running tokenizer on dataset (num_proc=64):  75%|███████▌  | 654103/870561 [02:35<01:04, 3362.98 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00061_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  75%|███████▌  | 655103/870561 [02:35<00:57, 3758.56 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▌  | 657705/870561 [02:35<00:36, 5770.67 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▌  | 659705/870561 [02:35<00:30, 6994.04 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▌  | 662705/870561 [02:35<00:24, 8479.28 examples/s]Running tokenizer on dataset (num_proc=64):  76%|███████▋  | 664705/870561 [02:35<00:21, 9379.39 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 666705/870561 [02:36<00:23, 8665.94 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 668705/870561 [02:36<00:36, 5490.44 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 669705/870561 [02:36<00:37, 5385.92 examples/s]Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 670705/870561 [02:37<00:41, 4855.99 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:23:06,758 >> Token indices sequence length is longer than the specified maximum sequence length for this model (53577 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 671705/870561 [02:37<00:46, 4293.11 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00062_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  77%|███████▋  | 672705/870561 [02:37<00:45, 4325.77 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 674705/870561 [02:38<00:33, 5780.89 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 676705/870561 [02:38<00:25, 7654.88 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 678307/870561 [02:38<00:27, 6998.08 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 679307/870561 [02:38<00:29, 6578.28 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 681307/870561 [02:39<00:50, 3735.88 examples/s]Running tokenizer on dataset (num_proc=64):  78%|███████▊  | 683307/870561 [02:39<00:40, 4589.76 examples/s]Running tokenizer on dataset (num_proc=64):  79%|███████▊  | 684307/870561 [02:39<00:36, 5037.63 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:23:09,218 >> Token indices sequence length is longer than the specified maximum sequence length for this model (38273 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  79%|███████▉  | 686307/870561 [02:39<00:26, 6860.18 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:23:09,514 >> Token indices sequence length is longer than the specified maximum sequence length for this model (33240 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  79%|███████▉  | 688307/870561 [02:40<00:24, 7523.78 examples/s]Running tokenizer on dataset (num_proc=64):  79%|███████▉  | 690307/870561 [02:40<00:21, 8256.35 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00063_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  80%|███████▉  | 692307/870561 [02:40<00:27, 6530.86 examples/s]Running tokenizer on dataset (num_proc=64):  80%|███████▉  | 694307/870561 [02:40<00:21, 8142.11 examples/s]Running tokenizer on dataset (num_proc=64):  80%|███████▉  | 695909/870561 [02:41<00:24, 7010.15 examples/s]Running tokenizer on dataset (num_proc=64):  80%|████████  | 696909/870561 [02:41<00:32, 5366.47 examples/s]Running tokenizer on dataset (num_proc=64):  80%|████████  | 699909/870561 [02:42<00:38, 4461.73 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 700909/870561 [02:42<00:35, 4728.12 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 702909/870561 [02:42<00:28, 5800.48 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 704909/870561 [02:43<00:25, 6409.83 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████  | 705909/870561 [02:43<00:34, 4718.56 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████▏ | 707511/870561 [02:43<00:32, 5041.90 examples/s]Running tokenizer on dataset (num_proc=64):  81%|████████▏ | 708511/870561 [02:44<00:37, 4340.57 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 709511/870561 [02:44<00:34, 4611.89 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 710511/870561 [02:44<00:30, 5168.83 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 712511/870561 [02:44<00:23, 6792.18 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 713511/870561 [02:44<00:22, 6856.33 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 714511/870561 [02:44<00:22, 6846.13 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 715511/870561 [02:44<00:21, 7202.44 examples/s]Running tokenizer on dataset (num_proc=64):  82%|████████▏ | 717511/870561 [02:45<00:21, 7142.92 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 718511/870561 [02:45<00:21, 7205.16 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 719511/870561 [02:45<00:27, 5493.37 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 721113/870561 [02:46<00:29, 5015.01 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 723113/870561 [02:46<00:26, 5636.13 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 724113/870561 [02:46<00:23, 6150.78 examples/s]Running tokenizer on dataset (num_proc=64):  83%|████████▎ | 725715/870561 [02:47<00:43, 3338.11 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▍ | 729715/870561 [02:47<00:21, 6639.68 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▍ | 731715/870561 [02:48<00:31, 4386.70 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▍ | 733317/870561 [02:48<00:35, 3815.91 examples/s]Running tokenizer on dataset (num_proc=64):  84%|████████▍ | 734317/870561 [02:49<00:32, 4212.22 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▍ | 737317/870561 [02:49<00:21, 6167.33 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▍ | 738919/870561 [02:49<00:22, 5884.90 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▌ | 741919/870561 [02:49<00:15, 8469.45 examples/s]Running tokenizer on dataset (num_proc=64):  85%|████████▌ | 743919/870561 [02:50<00:22, 5603.52 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 745919/870561 [02:50<00:21, 5916.60 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 747919/870561 [02:50<00:20, 6052.97 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 748919/870561 [02:51<00:35, 3413.98 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▌ | 749919/870561 [02:52<00:33, 3558.58 examples/s]Running tokenizer on dataset (num_proc=64):  86%|████████▋ | 750919/870561 [02:52<00:33, 3571.60 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 753521/870561 [02:52<00:25, 4623.81 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 754521/870561 [02:53<00:31, 3664.70 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 755521/870561 [02:53<00:30, 3800.73 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 757521/870561 [02:53<00:24, 4650.83 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 758521/870561 [02:53<00:22, 4981.10 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 759521/870561 [02:54<00:22, 5011.99 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 760521/870561 [02:54<00:22, 4957.18 examples/s]Running tokenizer on dataset (num_proc=64):  87%|████████▋ | 761521/870561 [02:54<00:20, 5419.69 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 762521/870561 [02:54<00:17, 6032.98 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 763521/870561 [02:55<00:30, 3481.50 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 765521/870561 [02:55<00:21, 4813.24 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 767521/870561 [02:55<00:15, 6570.94 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 768521/870561 [02:55<00:14, 6984.17 examples/s]Running tokenizer on dataset (num_proc=64):  88%|████████▊ | 769521/870561 [02:56<00:27, 3695.16 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▊ | 770521/870561 [02:56<00:32, 3034.38 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▊ | 771521/870561 [02:57<00:30, 3240.52 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 773521/870561 [02:57<00:27, 3543.28 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 775123/870561 [02:58<00:29, 3192.82 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 777123/870561 [02:58<00:21, 4379.71 examples/s]Running tokenizer on dataset (num_proc=64):  89%|████████▉ | 778123/870561 [02:58<00:20, 4429.42 examples/s]Running tokenizer on dataset (num_proc=64):  90%|████████▉ | 780123/870561 [02:58<00:14, 6085.67 examples/s]Running tokenizer on dataset (num_proc=64):  90%|████████▉ | 781123/870561 [02:58<00:15, 5674.18 examples/s]Running tokenizer on dataset (num_proc=64):  90%|████████▉ | 782725/870561 [02:59<00:16, 5393.52 examples/s]Running tokenizer on dataset (num_proc=64):  90%|█████████ | 784725/870561 [02:59<00:21, 3911.67 examples/s]Running tokenizer on dataset (num_proc=64):  90%|█████████ | 787725/870561 [03:00<00:13, 6116.14 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████ | 789327/870561 [03:00<00:19, 4275.12 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████ | 790327/870561 [03:01<00:23, 3394.15 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████ | 792327/870561 [03:01<00:22, 3524.01 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████ | 793327/870561 [03:02<00:22, 3368.66 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████▏| 795327/870561 [03:02<00:21, 3463.15 examples/s]Running tokenizer on dataset (num_proc=64):  91%|█████████▏| 795929/870561 [03:02<00:20, 3613.38 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 796929/870561 [03:03<00:20, 3583.13 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 798929/870561 [03:03<00:14, 4988.95 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 800929/870561 [03:03<00:16, 4325.86 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 802929/870561 [03:04<00:17, 3900.21 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 803929/870561 [03:04<00:15, 4356.32 examples/s]Running tokenizer on dataset (num_proc=64):  92%|█████████▏| 804929/870561 [03:04<00:15, 4125.05 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 805929/870561 [03:05<00:14, 4499.17 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 806531/870561 [03:05<00:18, 3441.36 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 807531/870561 [03:06<00:25, 2459.72 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 810133/870561 [03:06<00:17, 3357.69 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 811133/870561 [03:06<00:16, 3602.42 examples/s]Running tokenizer on dataset (num_proc=64):  93%|█████████▎| 813133/870561 [03:08<00:22, 2502.93 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▎| 814133/870561 [03:08<00:20, 2774.82 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▎| 815133/870561 [03:08<00:17, 3231.35 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 817133/870561 [03:09<00:16, 3247.94 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 818133/870561 [03:09<00:14, 3731.05 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 819133/870561 [03:09<00:12, 4151.45 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 820133/870561 [03:09<00:14, 3596.38 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 821133/870561 [03:10<00:16, 2977.41 examples/s]Running tokenizer on dataset (num_proc=64):  94%|█████████▍| 822133/870561 [03:10<00:18, 2608.58 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▍| 822735/870561 [03:11<00:19, 2415.58 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▍| 824735/870561 [03:11<00:12, 3686.91 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▍| 825735/870561 [03:11<00:11, 3792.80 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▍| 826735/870561 [03:11<00:11, 3917.84 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▌| 827337/870561 [03:12<00:17, 2529.18 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▌| 828337/870561 [03:12<00:16, 2527.81 examples/s]Running tokenizer on dataset (num_proc=64):  95%|█████████▌| 829939/870561 [03:13<00:15, 2660.60 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 831939/870561 [03:13<00:12, 3062.41 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 832939/870561 [03:14<00:10, 3474.88 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 833939/870561 [03:14<00:15, 2365.85 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 834939/870561 [03:15<00:12, 2760.53 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 835541/870561 [03:15<00:16, 2173.37 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 836541/870561 [03:15<00:12, 2619.07 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▌| 837541/870561 [03:16<00:15, 2195.95 examples/s]Running tokenizer on dataset (num_proc=64):  96%|█████████▋| 838541/870561 [03:16<00:11, 2852.37 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 840541/870561 [03:17<00:12, 2484.62 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 841143/870561 [03:17<00:11, 2660.43 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 842143/870561 [03:18<00:11, 2484.62 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 843143/870561 [03:18<00:12, 2166.27 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 844143/870561 [03:19<00:12, 2095.68 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 845143/870561 [03:19<00:13, 1856.51 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 846143/870561 [03:20<00:11, 2044.44 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 846745/870561 [03:20<00:14, 1634.53 examples/s]Running tokenizer on dataset (num_proc=64):  97%|█████████▋| 848745/870561 [03:21<00:08, 2485.09 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 849745/870561 [03:21<00:08, 2394.56 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 850745/870561 [03:22<00:08, 2321.17 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 851745/870561 [03:23<00:11, 1585.68 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 852347/870561 [03:23<00:11, 1585.28 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 853347/870561 [03:24<00:10, 1711.73 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 854347/870561 [03:24<00:08, 1887.55 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 855347/870561 [03:24<00:06, 2236.82 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 855949/870561 [03:25<00:05, 2450.16 examples/s]Running tokenizer on dataset (num_proc=64):  98%|█████████▊| 856949/870561 [03:26<00:08, 1545.00 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▊| 857949/870561 [03:26<00:06, 1984.61 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▊| 858551/870561 [03:27<00:10, 1124.73 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▊| 859551/870561 [03:27<00:07, 1516.91 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▉| 860551/870561 [03:28<00:06, 1434.61 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▉| 861551/870561 [03:29<00:05, 1626.72 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▉| 862551/870561 [03:30<00:07, 1077.48 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▉| 864153/870561 [03:31<00:04, 1508.14 examples/s]Running tokenizer on dataset (num_proc=64):  99%|█████████▉| 865153/870561 [03:33<00:06, 823.52 examples/s] Running tokenizer on dataset (num_proc=64): 100%|█████████▉| 866755/870561 [03:34<00:02, 1288.24 examples/s]Running tokenizer on dataset (num_proc=64): 100%|█████████▉| 867755/870561 [03:35<00:03, 928.15 examples/s] Running tokenizer on dataset (num_proc=64): 100%|█████████▉| 868357/870561 [03:36<00:02, 905.63 examples/s]Running tokenizer on dataset (num_proc=64): 100%|█████████▉| 869357/870561 [03:38<00:01, 741.70 examples/s]Running tokenizer on dataset (num_proc=64): 100%|█████████▉| 869959/870561 [03:38<00:00, 866.39 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 870561/870561 [03:41<00:00, 540.62 examples/s]Running tokenizer on dataset (num_proc=64): 100%|██████████| 870561/870561 [03:42<00:00, 3917.55 examples/s]
Concatenating 64 shards
input_ids:
[146775, 72258, 26927, 233, 86548, 41312, 35178, 106, 26927, 233, 146775, 49128, 105, 58908, 146227, 49128, 107, 11125, 120, 35178, 101, 80178, 250, 35178, 101, 80178, 250, 35178, 243, 72258, 52806, 106, 146711, 52806, 98, 146227, 58908, 35178, 107, 148015, 49128, 107, 148015, 148222, 49128, 105, 58908, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 146026, 80178, 100, 61356, 35178, 106, 58908, 86548, 58908, 35178, 248, 146227, 49128, 108, 35178, 228, 148291, 52806, 105, 49128, 101, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 72258, 760, 6299, 39394, 266, 41548, 5690, 198, 146838, 52806, 108, 148431, 52806, 249, 148156, 35178, 243, 26927, 225, 148481, 61356, 35178, 116, 11125, 224, 146026, 49128, 99, 35178, 243, 72258, 26927, 233, 86548, 41312, 35178, 106, 26927, 233, 146775, 49128, 105, 58908, 146227, 49128, 107, 11125, 120, 35178, 101, 80178, 250, 35178, 101, 80178, 250, 35178, 243, 72258, 52806, 106, 146711, 52806, 98, 146227, 58908, 35178, 107, 148015, 49128, 107, 148015, 148222, 49128, 105, 58908, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 146026, 80178, 100, 61356, 35178, 106, 58908, 86548, 58908, 35178, 248, 146227, 49128, 108, 35178, 228, 148291, 52806, 105, 49128, 101, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 72258, 198, 146775, 72258, 26927, 233, 86548, 41312, 35178, 106, 26927, 233, 146775, 49128, 105, 58908, 146227, 49128, 107, 11125, 120, 35178, 101, 80178, 250, 35178, 101, 80178, 250, 35178, 243, 72258, 52806, 106, 146711, 52806, 98, 146227, 58908, 35178, 107, 148015, 49128, 107, 148015, 148222, 49128, 105, 58908, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 146026, 80178, 100, 61356, 35178, 106, 58908, 86548, 58908, 35178, 248, 146227, 49128, 108, 35178, 228, 148291, 52806, 105, 49128, 101, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 72258, 198, 146775, 72258, 26927, 233, 86548, 41312, 35178, 106, 26927, 233, 146775, 49128, 105, 58908, 146227, 49128, 107, 11125, 120, 35178, 101, 80178, 250, 35178, 101, 80178, 250, 35178, 243, 72258, 52806, 106, 146711, 52806, 98, 146227, 58908, 35178, 107, 148015, 49128, 107, 148015, 148222, 49128, 105, 58908, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 146026, 80178, 100, 61356, 35178, 106, 58908, 86548, 58908, 35178, 248, 146227, 49128, 108, 35178, 228, 148291, 52806, 105, 49128, 101, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 72258, 146031, 35178, 249, 146026, 61356, 12, 146711, 11125, 224, 148787, 26927, 225, 148291, 26927, 222, 147645, 198, 146711, 26927, 223, 146838, 52806, 108, 148222, 49128, 97, 35178, 105, 148787, 26927, 223, 148124, 11125, 120, 41312, 320, 148204, 49128, 97, 26927, 222, 146834, 11125, 120, 1648, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 35178, 114, 58908, 149526, 35178, 117, 49128, 116, 80178, 101, 41312, 35178, 116, 146775, 146227, 146775, 58908, 35178, 243, 72258, 26927, 233, 86548, 35178, 255, 49128, 229, 72258, 49128, 116, 35178, 98, 58908, 146775, 58908, 35178, 101, 80178, 250, 58908, 148156, 58908, 72258, 35178, 116, 26927, 223, 72258, 146775, 52806, 115, 80178, 97, 35178, 108, 49128, 244, 147645, 58908, 35178, 101, 80178, 250, 35178, 101, 80178, 250, 35178, 243, 72258, 52806, 106, 146711, 52806, 98, 146227, 58908, 35178, 107, 148015, 49128, 107, 148015, 148222, 49128, 105, 58908, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 146026, 80178, 100, 61356, 35178, 106, 58908, 86548, 58908, 35178, 248, 146227, 49128, 108, 35178, 228, 148291, 52806, 105, 49128, 101, 35178, 250, 49128, 101, 80178, 107, 11125, 120, 58908, 35178, 105, 146227, 58908, 148972, 58908, 86548, 11, 35178, 250, 86548, 148787, 148194, 58908, 72258, 35178, 243, 146227, 52806, 107, 49128, 96, 58908, 72258, 35178, 243, 148015, 49128, 229, 35178, 97, 49128, 223, 72258, 35178, 116, 72258, 146775, 49128, 108, 35178, 116, 146026, 148431, 58908, 146834, 11125, 120, 58908, 35178, 105, 58908, 148125, 61356, 35178, 248, 80178, 101, 52806, 97, 41312, 35178, 243, 72258, 148972, 58908, 146031, 198, 147645, 80178, 101, 61356, 35178, 105, 146227, 58908, 86548, 11, 364, 146711, 146775, 146227, 146775, 58908, 35178, 116, 52806, 105, 12, 146711, 52806, 105, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 35178, 116, 26927, 223, 72258, 146775, 52806, 115, 80178, 97, 35178, 108, 58908, 149526, 58908, 148868, 35178, 116, 52806, 105, 12, 146711, 52806, 105, 35178, 243, 72258, 52806, 106, 146711, 52806, 98, 146227, 58908, 35178, 243, 49128, 250, 35178, 243, 72258, 58908, 35178, 107, 58908, 147645, 58908, 35178, 117, 146026, 58908, 146031, 35178, 99, 58908, 148125, 58908, 72258, 35178, 106, 49128, 101, 26927, 223, 148481, 35178, 107, 49128, 97, 58908, 35178, 243, 148481, 52806, 253, 35178, 101, 41312, 35178, 103, 49128, 107, 11125, 120, 35178, 243, 58908, 86548, 86548, 41312, 35178, 97, 49128, 223, 148156, 58908, 72258, 35178, 243, 148015, 49128, 229, 35178, 228, 146415, 72258, 41312, 35178, 105, 58908, 148125, 61356, 35178, 248, 80178, 101, 52806, 97, 41312, 35178, 243, 72258, 61356, 146031, 35178, 116, 146026, 49128, 229, 35178, 255, 49128, 110, 35178, 98, 49128, 243, 58908, 86548, 11, 35178, 116, 26927, 223, 146711, 52806, 98, 35178, 98, 49128, 243, 58908, 86548, 11, 35178, 116, 58908, 147338, 49128, 229, 35178, 243, 49128, 106, 86548, 41312, 35178, 243, 72258, 61356, 146031, 1248, 146415, 148571, 52806, 245, 146227, 146026, 49128, 108, 320, 26927, 102, 35178, 106, 58908, 8, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 35178, 114, 58908, 149526, 35178, 117, 49128, 116, 80178, 101, 41312, 35178, 250, 49128, 97, 26927, 222, 146834, 11125, 120, 35178, 227, 72258, 52806, 98, 86548, 26927, 230, 147645, 80178, 243, 35178, 103, 72258, 80178, 115, 148156, 58908, 72258, 35178, 101, 61356, 72258, 52806, 105, 49128, 117, 26927, 222, 35178, 243, 146415, 80178, 253, 61356, 72258, 320, 149525, 146775, 86548, 58908, 146775, 8, 35178, 116, 148222, 49128, 107, 11125, 120, 35178, 237, 146775, 148015, 41312, 35178, 105, 146227, 58908, 86548, 146031, 35178, 108, 49128, 250, 147997, 49128, 101, 26927, 222, 72258, 35178, 114, 58908, 72258, 58908, 146026, 49128, 224, 146227, 41312, 35178, 101, 148787, 72258, 58908, 72258, 35178, 237, 86548, 148868, 146711, 61356, 35178, 116, 146415, 52806, 106, 58908, 146227, 86548, 35178, 243, 146775, 52806, 115, 58908, 35178, 227, 86548, 26927, 223, 148481, 52806, 254, 80178, 97, 35178, 237, 148868, 35178, 116, 148222, 49128, 107, 11125, 120, 35178, 255, 80178, 94, 80178, 241, 35178, 243, 86548, 150262, 49128, 108, 58908, 86548, 52806, 116, 58908, 72258, 35178, 106, 49128, 100, 52806, 107, 146415, 58908, 35178, 245, 148194, 148222, 146026, 86548, 35178, 98, 58908, 146775, 58908, 35178, 116, 11125, 224, 146834, 26927, 223, 146775, 52806, 97, 35178, 117, 86548, 35178, 237, 146026, 11125, 224, 35178, 116, 148222, 49128, 103, 147645, 80178, 97, 52806, 105, 35178, 243, 72258, 58908, 86548, 220, 146031, 198, 149525, 148868, 35178, 255, 49128, 108, 52806, 248, 26927, 223, 146834, 11125, 120, 41312, 146227, 35178, 237, 146775, 86548, 58908, 146775, 35178, 116, 148222, 49128, 107, 11125, 120, 220, 26927, 100, 26927, 105, 35178, 117, 49128, 250, 49128, 108, 220, 26927, 101, 26927, 255, 26927, 105, 35178, 243, 26927, 233, 147338, 61356, 220, 26927, 102, 35178, 110, 49128, 244, 35178, 253, 49128, 243, 41312, 35178, 105, 52806, 107, 146834, 11125, 120, 58908, 220, 26927, 100, 26927, 99, 147338, 61356, 35178, 103, 52806, 108, 146775, 146227, 52806, 103, 35178, 227, 86548, 26927, 223, 146415, 26927, 233, 148156, 86548, 35178, 99, 58908, 146834, 11125, 120, 41312, 35178, 117, 146834, 11125, 120, 146031, 35178, 227, 86548, 26927, 223, 146415, 26927, 233, 148156, 80178, 97, 35178, 103, 52806, 108, 146775, 146227, 52806, 103, 58908, 72258, 35178, 250, 86548, 52806, 107, 35178, 105, 49128, 224, 146227, 49128, 99, 58908, 148125, 35178, 116, 72258, 146775, 49128, 108, 35178, 99, 58908, 146026, 58908, 220, 26927, 100, 26927, 103, 35178, 117, 49128, 250, 49128, 108, 220, 26927, 103, 26927, 99, 26927, 100, 35178, 243, 26927, 233, 147338, 61356, 220, 26927, 104, 26927, 101, 35178, 110, 49128, 244, 35178, 253, 49128, 243, 41312, 35178, 237, 146026, 11125, 224, 35178, 105, 26927, 230, 148156, 58908, 148125, 80178, 243, 35178, 233, 148194, 220, 26927, 100, 35178, 117, 49128, 250, 49128, 108, 220, 26927, 106, 26927, 106, 26927, 100, 35178, 243, 26927, 233, 147338, 61356, 220, 26927, 107, 26927, 255, 35178, 110, 49128, 244, 35178, 253, 49128, 243, 41312, 146031, 198, 146838, 72258, 58908, 35178, 103, 72258, 80178, 243, 146227, 52806, 103, 86548, 41312, 35178, 106, 86548, 52806, 97, 52806, 108, 26927, 222, 35178, 237, 146415, 149525, 35178, 106, 49128, 101, 52806, 101, 49128, 101, 35178, 116, 148222, 49128, 108, 35178, 105, 80178, 115, 146834, 11125, 120, 58908, 35178, 105, 80178, 116, 52806, 97, 49128, 108, 80178, 97, 35178, 116, 49128, 224, 146026, 49128, 99, 80178, 243, 148156, 58908, 72258, 35178, 227, 146026, 148291, 80178, 97, 35178, 243, 72258, 58908, 86548, 146031, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 35178, 105, 146227, 58908, 86548, 11, 35178, 237, 72258, 35178, 228, 148787, 58908, 35178, 228, 146415, 72258, 41312, 35178, 250, 49128, 97, 26927, 222, 146834, 11125, 120, 35178, 227, 72258, 52806, 98, 86548, 26927, 230, 147645, 80178, 243, 35178, 243, 49128, 231, 86548, 52806, 116, 80178, 110, 58908, 72258, 35178, 116, 148222, 41312, 35178, 243, 72258, 58908, 35178, 105, 49128, 250, 58908, 147338, 35178, 103, 52806, 108, 148194, 146834, 11125, 120, 86548, 58908, 72258, 35178, 243, 49128, 250, 148787, 26927, 223, 146227, 26927, 233, 35178, 243, 72258, 58908, 148972, 61356, 146031, 198, 147645, 80178, 101, 61356, 35178, 105, 146227, 58908, 86548, 11, 35178, 243, 26927, 233, 148222, 80178, 94, 12, 26927, 100, 26927, 107, 35178, 255, 49128, 229, 72258, 49128, 116, 58908, 72258, 35178, 243, 49128, 108, 148194, 58908, 35178, 228, 148204, 35178, 114, 26927, 223, 147997, 26927, 223, 35178, 105, 49128, 224, 146227, 49128, 99, 58908, 148125, 35178, 101, 146834, 11125, 120, 35178, 116, 146415, 148787, 52806, 108, 35178, 105, 80178, 114, 52806, 105, 148868, 35178, 105, 146227, 147645, 58908, 35178, 245, 58908, 146227, 58908, 35178, 116, 52806, 98, 146026, 61356, 72258, 35178, 117, 146834, 11125, 120, 58908, 35178, 103, 148124, 11125, 120, 58908, 148972, 58908, 146031, 35178, 237, 72258, 146415, 147997, 52806, 107, 58908, 148873, 35178, 228, 146838, 86548, 49128, 108, 41312, 35178, 107, 49128, 108, 41312, 35178, 228, 148204, 146775, 58908, 35178, 103, 52806, 108, 146775, 146227, 52806, 103, 148787, 26927, 223, 146227, 26927, 233, 35178, 97, 26927, 230, 72258, 26927, 222, 35178, 243, 72258, 58908, 35178, 101, 80178, 107, 11125, 120, 58908, 35178, 237, 146711, 58908, 148972, 58908, 86548, 35178, 105, 41312, 35178, 94, 80178, 250, 80178, 253, 49128, 110, 35178, 103, 148156, 52806, 100, 147645, 80178, 97, 58908, 35178, 237, 148868, 35178, 106, 80178, 253, 80178, 224, 147338, 41312, 35178, 107, 58908, 35178, 243, 72258, 147645, 58908, 35178, 103, 49128, 108, 148972, 61356, 11, 35178, 116, 58908, 148204, 86548, 52806, 107, 35178, 228, 146838, 86548, 49128, 99, 58908, 72258, 35178, 228, 86548, 52806, 97, 72258, 80178, 243, 35178, 100, 86548, 52806, 107, 146026, 49128, 99, 35178, 250, 49128, 101, 49128, 229, 146031, 198, 146838, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 35178, 237, 146711, 146415, 146834, 11125, 120, 35178, 243, 72258, 58908, 86548, 41312, 35178, 255, 49128, 229, 72258, 49128, 116, 58908, 72258, 35178, 243, 49128, 108, 148194, 58908, 35178, 99, 58908, 148125, 58908, 35178, 237, 146026, 11125, 224, 35178, 105, 80178, 99, 58908, 148125, 58908, 35178, 106, 26927, 225, 147645, 52806, 107, 26927, 223, 146026, 72258, 86548, 146775, 49128, 108, 26927, 222, 35178, 105, 49128, 224, 146227, 49128, 99, 58908, 148125, 26927, 222, 148156, 58908, 72258, 35178, 250, 86548, 52806, 107, 35178, 114, 26927, 233, 146775, 35178, 241, 35178, 99, 26927, 223, 11125, 225, 149526, 35178, 103, 52806, 108, 146775, 49128, 114, 35178, 243, 72258, 58908, 35178, 97, 49128, 223, 148156, 58908, 72258, 35178, 228, 147645, 52806, 106, 49128, 108, 35178, 106, 49128, 245, 150262, 58908, 72258, 49128, 97, 35178, 243, 49128, 106, 86548, 41312, 35178, 243, 72258, 58908, 86548, 146031, 35178, 97, 80178, 101, 61356, 35178, 105, 146227, 58908, 86548, 11, 364, 149525, 35178, 105, 52806, 107, 49128, 103, 49128, 108, 58908, 35178, 107, 58908, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 146026, 80178, 100, 61356, 35178, 99, 58908, 148873, 146834, 11125, 120, 41312, 35178, 117, 146834, 11125, 120, 58908, 148972, 58908, 35178, 99, 58908, 148125, 146026, 49128, 116, 26927, 222, 35178, 116, 58908, 147338, 41312, 35178, 106, 58908, 86548, 58908, 35178, 248, 146227, 146026, 58908, 11, 35178, 237, 147338]
inputs:
করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর | Suprovat Bogura
প্রচ্ছদ কৃষি সংবাদ করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর
করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর
করোনা মোকাবেলায় নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান প্রধানমন্ত্রীর। ছবি-সংগৃহীত
সুপ্রভাত বগুড়া (জাতীয়): প্রধানমন্ত্রী শেখ হাসিনা সকলকে করোন ভাইরাস থেকে নিজেদের সুরক্ষিত রাখতে নিজ নিজ কর্মস্থলে যথাযথভাবে স্বাস্থ্যবিধি মেনে চলার আহ্বান জানিয়ে বলেছেন, জনগণের কল্যাণের কথাই তাঁর সরকার সবচেয়ে বেশি চিন্তা করছে।
তিনি বলেন, 'সকলকে স্ব-স্ব স্বাস্থ্য সুরক্ষিত রেখেই স্ব-স্ব কর্মস্থলে কাজ করে যেতে হবে। দেশের মানুষ যাতে কষ্ট না পায় কেননা তাঁদের কথাই আমরা বেশি চিন্তা করি। সবাই ভাল থাকেন, সুস্থ থাকেন, সেটাই কামনা করি।'
মঙ্গলবার (৩ মে) প্রধানমন্ত্রী শেখ হাসিনা জাতীয় অর্থনৈতিক পরিষদের নির্বাহী কমিটির (একনেক) সভায় একথা বলেন। রাজধানীর শেরেবাংলা নগরের এনইসি সম্মেলন কক্ষে অনুষ্ঠিত এই সভায় ভিডিও কনফারেন্সের মাধ্যমে গণভবন থেকে সংযুক্ত হন এবং সভাপতিত্ব করেন ।
এই ভার্চুয়াল একনেক সভায় ১৬ হাজার ২৭৬ কোটি ৩ লাখ টাকা ব্যয়ে ১০টি প্রকল্প অনুমোদন দেয়া হয়। অনুমোদিত প্রকল্পের জন্য বাংলাদেশ সরকার দেবে ১৪ হাজার ৪০১ কোটি ৫২ লাখ টাকা এবং বৈদেশিক ঋণ ১ হাজার ৮৮১ কোটি ৯৭ লাখ টাকা।
পরে পরিকল্পনা মন্ত্রী এমএ মান্নান সভার বিষয়ে বিস্তারিত সাংবাদিকদের অবহিত করেন। প্রধানমন্ত্রী বলেন, এর আগে আমরা জাতীয় অর্থনৈতিক কাউন্সিলের সভা করে বাজেট প্রণয়নের কাজগুলো করেছি।
তিনি বলেন, কোভিড-১৯ ভাইরাসের কারণে আজ শুধু বাংলাদেশ নয় সমগ্র বিশ্বই বলতে গেলে স্থবির হয়ে পড়েছে। এরমধ্যেও আপনারা যারা আজকে প্রকল্পগুলো তৈরী করে নিয়ে এসেছেন বা ডিজিটাল পদ্ধতিতে এই মিটিংটা যে করতে পারছি, সেজন্য আপনাদের আন্তরিক ধন্যবাদ জানাই।
প্রধানমন্ত্রী এসময় করেনা ভাইরাসের কারণে দেশে এবং বিদেশে মৃত্যুবরনকারী বাংলাদেশীদের জন্য শোক ও দুঃখ প্রকাশ করে তাঁদের আত্মার মাগফেরাত কামনা করেন। তিনি বলেন, 'এ ব্যাপারে যে স্বাস্থ্যবিধি দেওয়া হয়েছে দেশবাসী সেটা মেনে চলবে, এট
Caching indices mapping at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-05fe019f3d8af394.arrow
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Qwen2CrossAttnMergeModel(
  (small): Qwen2CrossAttnGeneratorModel(
    (embed_tokens): Embedding(151936, 1024)
    (layers): ModuleList(
      (0): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (1): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (2): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (3): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (4): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (5): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (6): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (7): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (8): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (9): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (10): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (11): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (12): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (13): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (14): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (15): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (16): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (17): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (18): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (19): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (20): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (21): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (22): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (23): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
    )
    (norm): Qwen2RMSNorm()
  )
  (large): Qwen2CrossAttnCausalLM(
    (model): Qwen2CrossAttnModel(
      (embed_tokens): Embedding(151936, 4096)
      (layers): ModuleList(
        (0): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (1): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (2): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (3): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (4): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (5): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (6): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (7): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (8): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (9): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (10): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (11): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (12): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (13): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (14): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (15): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (16): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (17): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (18): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (19): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (20): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (21): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (22): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (23): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (24): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (25): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (26): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (27): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (28): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (29): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (30): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (31): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
      )
      (norm): Qwen2RMSNorm()
    )
    (lm_head): Linear(in_features=4096, out_features=151936, bias=False)
  )
  (align_modules): CrossAttn(
    (merge_modules): ModuleList(
      (0): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (1): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (2): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (3): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (4): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (5): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (6): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (7): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
    )
  )
)
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:586] 2024-05-13 22:24:12,847 >> Using auto half precision backend
[2024-05-13 22:24:13,060] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.3, git-hash=unknown, git-branch=unknown
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
[2024-05-13 22:24:55,353] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-05-13 22:24:55,355] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-05-13 22:24:55,356] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-05-13 22:24:55,361] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2024-05-13 22:24:55,361] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2024-05-13 22:24:55,362] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-05-13 22:24:55,362] [INFO] [stage_1_and_2.py:147:__init__] Reduce bucket size 500000000
[2024-05-13 22:24:55,362] [INFO] [stage_1_and_2.py:148:__init__] Allgather bucket size 500000000
[2024-05-13 22:24:55,362] [INFO] [stage_1_and_2.py:149:__init__] CPU Offload: False
[2024-05-13 22:24:55,362] [INFO] [stage_1_and_2.py:150:__init__] Round robin gradient partitioning: False
[2024-05-13 22:24:57,611] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states
[2024-05-13 22:24:57,612] [INFO] [utils.py:803:see_memory_usage] MA 17.29 GB         Max_MA 17.29 GB         CA 17.43 GB         Max_CA 17 GB 
[2024-05-13 22:24:57,612] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 154.52 GB, percent = 15.3%
[2024-05-13 22:24:57,794] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states
[2024-05-13 22:24:57,795] [INFO] [utils.py:803:see_memory_usage] MA 17.82 GB         Max_MA 18.62 GB         CA 18.76 GB         Max_CA 19 GB 
[2024-05-13 22:24:57,795] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 153.59 GB, percent = 15.2%
[2024-05-13 22:24:57,795] [INFO] [stage_1_and_2.py:514:__init__] optimizer state initialized
[2024-05-13 22:24:57,961] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer
[2024-05-13 22:24:57,962] [INFO] [utils.py:803:see_memory_usage] MA 17.82 GB         Max_MA 17.82 GB         CA 18.76 GB         Max_CA 19 GB 
[2024-05-13 22:24:57,962] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 151.9 GB, percent = 15.1%
[2024-05-13 22:24:57,963] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2024-05-13 22:24:57,963] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-05-13 22:24:57,963] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-05-13 22:24:57,963] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05, 5e-05], mom=[(0.9, 0.999), (0.9, 0.999)]
[2024-05-13 22:24:57,965] [INFO] [config.py:974:print] DeepSpeedEngine configuration:
[2024-05-13 22:24:57,965] [INFO] [config.py:978:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-05-13 22:24:57,965] [INFO] [config.py:978:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-05-13 22:24:57,965] [INFO] [config.py:978:print]   amp_enabled .................. False
[2024-05-13 22:24:57,965] [INFO] [config.py:978:print]   amp_params ................... False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   bfloat16_enabled ............. True
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   checkpoint_parallel_write_pipeline  False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   checkpoint_tag_validation_enabled  True
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   checkpoint_tag_validation_fail  False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7efdf935a5f0>
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   communication_data_type ...... None
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   curriculum_enabled_legacy .... False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   curriculum_params_legacy ..... False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   data_efficiency_enabled ...... False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   dataloader_drop_last ......... False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   disable_allgather ............ False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   dump_state ................... False
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   dynamic_loss_scale_args ...... None
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_enabled ........... False
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_gas_boundary_resolution  1
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_layer_num ......... 0
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_max_iter .......... 100
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_stability ......... 1e-06
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_tol ............... 0.01
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_verbose ........... False
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   elasticity_enabled ........... False
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   fp16_auto_cast ............... None
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   fp16_enabled ................. False
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   fp16_master_weights_and_gradients  False
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   global_rank .................. 0
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   grad_accum_dtype ............. None
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   gradient_accumulation_steps .. 16
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   gradient_clipping ............ 1.0
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   gradient_predivide_factor .... 1.0
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   initial_dynamic_scale ........ 1
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   load_universal_checkpoint .... False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   loss_scale ................... 1.0
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   memory_breakdown ............. False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   mics_hierarchial_params_gather  False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   mics_shard_size .............. -1
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   optimizer_legacy_fusion ...... False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   optimizer_name ............... None
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   optimizer_params ............. None
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   pld_enabled .................. False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   pld_params ................... False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   prescale_gradients ........... False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   scheduler_name ............... None
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   scheduler_params ............. None
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   seq_parallel_communication_data_type  torch.float32
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   sparse_attention ............. None
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   sparse_gradients_enabled ..... False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   steps_per_print .............. inf
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   train_batch_size ............. 1024
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   train_micro_batch_size_per_gpu  8
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   use_node_local_storage ....... False
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   wall_clock_breakdown ......... False
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   weight_quantization_config ... None
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   world_size ................... 8
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   zero_allow_untested_optimizer  True
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   zero_enabled ................. True
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   zero_force_ds_cpu_optimizer .. True
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   zero_optimization_stage ...... 2
[2024-05-13 22:24:57,969] [INFO] [config.py:964:print_user_config]   json = {
    "train_batch_size": 1.024000e+03, 
    "train_micro_batch_size_per_gpu": 8, 
    "gradient_accumulation_steps": 16, 
    "gradient_clipping": 1.0, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "initial_scale_power": 16, 
        "loss_scale_window": 1000, 
        "hysteresis": 2, 
        "min_loss_scale": 1e-09
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 5.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 5.000000e+08, 
        "contiguous_gradients": true
    }, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }
}
[INFO|trainer.py:1747] 2024-05-13 22:24:57,969 >> ***** Running training *****
[INFO|trainer.py:1748] 2024-05-13 22:24:57,969 >>   Num examples = 1,084,187
[INFO|trainer.py:1749] 2024-05-13 22:24:57,969 >>   Num Epochs = 1
[INFO|trainer.py:1750] 2024-05-13 22:24:57,969 >>   Instantaneous batch size per device = 8
[INFO|trainer.py:1753] 2024-05-13 22:24:57,969 >>   Total train batch size (w. parallel, distributed & accumulation) = 1,024
[INFO|trainer.py:1754] 2024-05-13 22:24:57,969 >>   Gradient Accumulation steps = 16
[INFO|trainer.py:1755] 2024-05-13 22:24:57,969 >>   Total optimization steps = 1,058
[INFO|trainer.py:1756] 2024-05-13 22:24:57,971 >>   Number of trainable parameters = 570,589,184
  0%|          | 0/1058 [00:00<?, ?it/s]  0%|          | 1/1058 [02:09<38:04:30, 129.68s/it]  0%|          | 2/1058 [04:17<37:45:26, 128.72s/it]  0%|          | 3/1058 [06:25<37:34:31, 128.22s/it]  0%|          | 4/1058 [08:33<37:34:41, 128.35s/it]  0%|          | 5/1058 [10:42<37:32:57, 128.37s/it]  1%|          | 6/1058 [12:50<37:31:22, 128.41s/it]  1%|          | 7/1058 [14:58<37:24:45, 128.15s/it]  1%|          | 8/1058 [17:06<37:20:25, 128.02s/it]  1%|          | 9/1058 [19:13<37:16:31, 127.92s/it]  1%|          | 10/1058 [21:21<37:11:58, 127.78s/it]                                                     {'loss': 10.273, 'learning_rate': 4.9988979367702804e-05, 'epoch': 0.01}
  1%|          | 10/1058 [21:21<37:11:58, 127.78s/it]  1%|          | 11/1058 [23:29<37:14:30, 128.05s/it]  1%|          | 12/1058 [25:38<37:15:48, 128.25s/it]  1%|          | 13/1058 [27:47<37:15:00, 128.33s/it]  1%|▏         | 14/1058 [29:55<37:12:35, 128.31s/it]  1%|▏         | 15/1058 [32:03<37:07:45, 128.16s/it]  2%|▏         | 16/1058 [34:10<37:01:44, 127.93s/it]  2%|▏         | 17/1058 [36:18<37:01:30, 128.04s/it]  2%|▏         | 18/1058 [38:26<36:54:38, 127.77s/it]  2%|▏         | 19/1058 [40:33<36:53:05, 127.80s/it]  2%|▏         | 20/1058 [42:42<36:53:34, 127.95s/it]                                                     {'loss': 7.0916, 'learning_rate': 4.995592718715809e-05, 'epoch': 0.02}
  2%|▏         | 20/1058 [42:42<36:53:34, 127.95s/it]  2%|▏         | 21/1058 [44:50<36:53:15, 128.06s/it]  2%|▏         | 22/1058 [46:58<36:52:11, 128.12s/it]  2%|▏         | 23/1058 [49:07<36:50:31, 128.15s/it]  2%|▏         | 24/1058 [51:15<36:48:52, 128.17s/it]  2%|▏         | 25/1058 [53:23<36:46:59, 128.19s/it]  2%|▏         | 26/1058 [55:31<36:44:56, 128.19s/it]  3%|▎         | 27/1058 [57:39<36:42:43, 128.19s/it]  3%|▎         | 28/1058 [59:48<36:40:46, 128.20s/it]  3%|▎         | 29/1058 [1:01:56<36:38:31, 128.19s/it]  3%|▎         | 30/1058 [1:04:04<36:36:38, 128.21s/it]                                                       {'loss': 4.9599, 'learning_rate': 4.9900872598840156e-05, 'epoch': 0.03}
  3%|▎         | 30/1058 [1:04:04<36:36:38, 128.21s/it]  3%|▎         | 31/1058 [1:06:12<36:34:37, 128.22s/it]  3%|▎         | 32/1058 [1:08:20<36:29:23, 128.03s/it]  3%|▎         | 33/1058 [1:10:27<36:23:05, 127.79s/it]  3%|▎         | 34/1058 [1:12:35<36:22:37, 127.89s/it]  3%|▎         | 35/1058 [1:14:43<36:21:22, 127.94s/it]  3%|▎         | 36/1058 [1:16:51<36:19:32, 127.96s/it]  3%|▎         | 37/1058 [1:18:59<36:18:02, 127.99s/it]  4%|▎         | 38/1058 [1:21:08<36:16:43, 128.04s/it]  4%|▎         | 39/1058 [1:23:15<36:14:00, 128.01s/it]  4%|▍         | 40/1058 [1:25:22<36:06:36, 127.70s/it]                                                       {'loss': 4.4131, 'learning_rate': 4.9823864141658905e-05, 'epoch': 0.04}
  4%|▍         | 40/1058 [1:25:22<36:06:36, 127.70s/it]  4%|▍         | 41/1058 [1:27:30<36:06:06, 127.79s/it]  4%|▍         | 42/1058 [1:29:37<35:59:33, 127.53s/it]  4%|▍         | 43/1058 [1:31:45<35:58:08, 127.57s/it]  4%|▍         | 44/1058 [1:33:53<35:59:00, 127.75s/it]  4%|▍         | 45/1058 [1:36:00<35:53:54, 127.58s/it]  4%|▍         | 46/1058 [1:38:08<35:51:51, 127.58s/it]  4%|▍         | 47/1058 [1:40:15<35:46:20, 127.38s/it]  5%|▍         | 48/1058 [1:42:23<35:46:22, 127.51s/it]  5%|▍         | 49/1058 [1:44:30<35:41:10, 127.32s/it]  5%|▍         | 50/1058 [1:46:37<35:41:31, 127.47s/it]                                                       {'loss': 4.1544, 'learning_rate': 4.9724969710165594e-05, 'epoch': 0.05}
  5%|▍         | 50/1058 [1:46:37<35:41:31, 127.47s/it]  5%|▍         | 51/1058 [1:48:45<35:42:15, 127.64s/it]  5%|▍         | 52/1058 [1:50:53<35:37:17, 127.47s/it]  5%|▌         | 53/1058 [1:53:01<35:38:05, 127.65s/it]  5%|▌         | 54/1058 [1:55:09<35:37:25, 127.73s/it]  5%|▌         | 55/1058 [1:57:16<35:32:07, 127.54s/it]  5%|▌         | 56/1058 [1:59:24<35:33:27, 127.75s/it]  5%|▌         | 57/1058 [2:01:32<35:33:08, 127.86s/it]  5%|▌         | 58/1058 [2:03:40<35:32:48, 127.97s/it]  6%|▌         | 59/1058 [2:05:48<35:30:33, 127.96s/it]  6%|▌         | 60/1058 [2:07:55<35:23:33, 127.67s/it]                                                       {'loss': 4.0253, 'learning_rate': 4.9604276494693455e-05, 'epoch': 0.06}
  6%|▌         | 60/1058 [2:07:55<35:23:33, 127.67s/it]  6%|▌         | 61/1058 [2:10:03<35:23:18, 127.78s/it]  6%|▌         | 62/1058 [2:12:11<35:23:14, 127.91s/it]  6%|▌         | 63/1058 [2:14:20<35:22:25, 127.99s/it]  6%|▌         | 64/1058 [2:16:27<35:16:07, 127.73s/it]  6%|▌         | 65/1058 [2:18:35<35:14:42, 127.78s/it]  6%|▌         | 66/1058 [2:20:42<35:08:52, 127.55s/it]  6%|▋         | 67/1058 [2:22:49<35:07:37, 127.61s/it]  6%|▋         | 68/1058 [2:24:57<35:07:02, 127.70s/it]  7%|▋         | 69/1058 [2:27:04<35:02:29, 127.55s/it]  7%|▋         | 70/1058 [2:29:13<35:03:26, 127.74s/it]                                                       {'loss': 3.9819, 'learning_rate': 4.9461890904486387e-05, 'epoch': 0.07}
  7%|▋         | 70/1058 [2:29:13<35:03:26, 127.74s/it]  7%|▋         | 71/1058 [2:31:21<35:03:48, 127.89s/it]  7%|▋         | 72/1058 [2:33:28<34:58:53, 127.72s/it]  7%|▋         | 73/1058 [2:35:36<34:56:16, 127.69s/it]  7%|▋         | 74/1058 [2:37:44<34:57:19, 127.89s/it]  7%|▋         | 75/1058 [2:39:53<34:58:19, 128.08s/it]  7%|▋         | 76/1058 [2:42:01<34:58:06, 128.19s/it]  7%|▋         | 77/1058 [2:44:08<34:51:16, 127.91s/it]  7%|▋         | 78/1058 [2:46:16<34:50:08, 127.97s/it]  7%|▋         | 79/1058 [2:48:25<34:48:35, 128.00s/it]  8%|▊         | 80/1058 [2:50:32<34:44:15, 127.87s/it]                                                       {'loss': 3.9284, 'learning_rate': 4.9297938473883104e-05, 'epoch': 0.08}
  8%|▊         | 80/1058 [2:50:32<34:44:15, 127.87s/it]  8%|▊         | 81/1058 [2:52:41<34:46:21, 128.13s/it]  8%|▊         | 82/1058 [2:54:50<34:46:51, 128.29s/it]  8%|▊         | 83/1058 [2:56:58<34:45:58, 128.37s/it]  8%|▊         | 84/1058 [2:59:06<34:39:38, 128.11s/it]  8%|▊         | 85/1058 [3:01:14<34:38:47, 128.19s/it]  8%|▊         | 86/1058 [3:03:21<34:32:27, 127.93s/it]  8%|▊         | 87/1058 [3:05:30<34:33:25, 128.12s/it]  8%|▊         | 88/1058 [3:07:37<34:28:23, 127.94s/it]  8%|▊         | 89/1058 [3:09:46<34:29:02, 128.11s/it]  9%|▊         | 90/1058 [3:11:55<34:30:28, 128.34s/it]                                                       {'loss': 3.7096, 'learning_rate': 4.9112563751639765e-05, 'epoch': 0.09}
  9%|▊         | 90/1058 [3:11:55<34:30:28, 128.34s/it]  9%|▊         | 91/1058 [3:14:04<34:30:32, 128.47s/it]  9%|▊         | 92/1058 [3:16:12<34:29:31, 128.54s/it]  9%|▉         | 93/1058 [3:18:20<34:22:56, 128.27s/it]  9%|▉         | 94/1058 [3:20:28<34:20:45, 128.26s/it]  9%|▉         | 95/1058 [3:22:36<34:15:32, 128.07s/it]  9%|▉         | 96/1058 [3:24:45<34:17:25, 128.32s/it]  9%|▉         | 97/1058 [3:26:53<34:17:41, 128.47s/it]  9%|▉         | 98/1058 [3:29:02<34:17:33, 128.60s/it]  9%|▉         | 99/1058 [3:31:11<34:16:02, 128.64s/it]  9%|▉         | 100/1058 [3:33:20<34:14:58, 128.70s/it]                                                        {'loss': 3.3951, 'learning_rate': 4.890593017348846e-05, 'epoch': 0.09}
  9%|▉         | 100/1058 [3:33:20<34:14:58, 128.70s/it] 10%|▉         | 101/1058 [3:35:29<34:12:13, 128.67s/it] 10%|▉         | 102/1058 [3:37:37<34:10:32, 128.69s/it] 10%|▉         | 103/1058 [3:39:46<34:08:43, 128.72s/it] 10%|▉         | 104/1058 [3:41:54<34:03:54, 128.55s/it] 10%|▉         | 105/1058 [3:44:02<33:57:45, 128.30s/it] 10%|█         | 106/1058 [3:46:10<33:55:08, 128.27s/it] 10%|█         | 107/1058 [3:48:18<33:50:47, 128.13s/it] 10%|█         | 108/1058 [3:50:27<33:51:59, 128.34s/it] 10%|█         | 109/1058 [3:52:36<33:51:54, 128.47s/it] 10%|█         | 110/1058 [3:54:44<33:51:16, 128.56s/it]                                                        {'loss': 3.2926, 'learning_rate': 4.8678219918043984e-05, 'epoch': 0.1}
 10%|█         | 110/1058 [3:54:44<33:51:16, 128.56s/it] 10%|█         | 111/1058 [3:56:52<33:45:47, 128.35s/it] 11%|█         | 112/1058 [3:59:01<33:45:22, 128.46s/it] 11%|█         | 113/1058 [4:01:10<33:46:40, 128.68s/it] 11%|█         | 114/1058 [4:03:19<33:45:58, 128.77s/it] 11%|█         | 115/1058 [4:05:28<33:44:28, 128.81s/it] 11%|█         | 116/1058 [4:07:37<33:42:47, 128.84s/it] 11%|█         | 117/1058 [4:09:46<33:41:19, 128.88s/it] 11%|█         | 118/1058 [4:11:55<33:38:12, 128.82s/it] 11%|█         | 119/1058 [4:14:03<33:35:27, 128.78s/it] 11%|█▏        | 120/1058 [4:16:12<33:33:01, 128.76s/it]                                                        {'loss': 3.2662, 'learning_rate': 4.8429633746185975e-05, 'epoch': 0.11}
 11%|█▏        | 120/1058 [4:16:12<33:33:01, 128.76s/it] 11%|█▏        | 121/1058 [4:18:21<33:31:49, 128.83s/it] 12%|█▏        | 122/1058 [4:20:29<33:26:06, 128.60s/it] 12%|█▏        | 123/1058 [4:22:37<33:22:10, 128.48s/it] 12%|█▏        | 124/1058 [4:24:45<33:16:33, 128.26s/it] 12%|█▏        | 125/1058 [4:26:53<33:15:51, 128.35s/it] 12%|█▏        | 126/1058 [4:29:02<33:16:06, 128.50s/it] 12%|█▏        | 127/1058 [4:31:11<33:16:02, 128.64s/it] 12%|█▏        | 128/1058 [4:33:20<33:15:19, 128.73s/it] 12%|█▏        | 129/1058 [4:35:29<33:13:49, 128.77s/it] 12%|█▏        | 130/1058 [4:37:38<33:12:11, 128.81s/it]                                                        {'loss': 3.2293, 'learning_rate': 4.816039082405799e-05, 'epoch': 0.12}
 12%|█▏        | 130/1058 [4:37:38<33:12:11, 128.81s/it] 12%|█▏        | 131/1058 [4:39:47<33:10:06, 128.81s/it] 12%|█▏        | 132/1058 [4:41:56<33:08:07, 128.82s/it] 13%|█▎        | 133/1058 [4:44:05<33:06:41, 128.87s/it] 13%|█▎        | 134/1058 [4:46:14<33:04:43, 128.88s/it] 13%|█▎        | 135/1058 [4:48:22<33:02:36, 128.88s/it] 13%|█▎        | 136/1058 [4:50:31<33:00:54, 128.91s/it] 13%|█▎        | 137/1058 [4:52:40<32:58:50, 128.91s/it] 13%|█▎        | 138/1058 [4:54:49<32:56:07, 128.88s/it] 13%|█▎        | 139/1058 [4:56:58<32:53:17, 128.83s/it] 13%|█▎        | 140/1058 [4:59:06<32:47:15, 128.58s/it]                                                        {'loss': 3.216, 'learning_rate': 4.787072852983949e-05, 'epoch': 0.13}
 13%|█▎        | 140/1058 [4:59:06<32:47:15, 128.58s/it] 13%|█▎        | 141/1058 [5:01:15<32:46:33, 128.67s/it] 13%|█▎        | 142/1058 [5:03:24<32:45:40, 128.76s/it] 14%|█▎        | 143/1058 [5:05:33<32:43:51, 128.78s/it] 14%|█▎        | 144/1058 [5:07:42<32:43:07, 128.87s/it] 14%|█▎        | 145/1058 [5:09:50<32:38:14, 128.69s/it] 14%|█▍        | 146/1058 [5:11:58<32:33:22, 128.51s/it] 14%|█▍        | 147/1058 [5:14:06<32:29:54, 128.42s/it] 14%|█▍        | 148/1058 [5:16:14<32:25:33, 128.28s/it] 14%|█▍        | 149/1058 [5:18:23<32:26:16, 128.47s/it] 14%|█▍        | 150/1058 [5:20:32<32:26:13, 128.61s/it]                                                        {'loss': 3.1565, 'learning_rate': 4.756090224446127e-05, 'epoch': 0.14}
 14%|█▍        | 150/1058 [5:20:32<32:26:13, 128.61s/it] 14%|█▍        | 151/1058 [5:22:41<32:26:13, 128.75s/it] 14%|█▍        | 152/1058 [5:24:49<32:21:20, 128.57s/it] 14%|█▍        | 153/1058 [5:26:57<32:18:05, 128.49s/it] 15%|█▍        | 154/1058 [5:29:05<32:13:24, 128.32s/it] 15%|█▍        | 155/1058 [5:31:14<32:12:45, 128.42s/it] 15%|█▍        | 156/1058 [5:33:23<32:12:56, 128.58s/it] 15%|█▍        | 157/1058 [5:35:32<32:12:20, 128.68s/it] 15%|█▍        | 158/1058 [5:37:41<32:11:29, 128.77s/it] 15%|█▌        | 159/1058 [5:39:50<32:10:08, 128.82s/it] 15%|█▌        | 160/1058 [5:41:59<32:07:55, 128.81s/it]                                                        {'loss': 3.0934, 'learning_rate': 4.72311851264487e-05, 'epoch': 0.15}
 15%|█▌        | 160/1058 [5:41:59<32:07:55, 128.81s/it] 15%|█▌        | 161/1058 [5:44:08<32:05:58, 128.83s/it] 15%|█▌        | 162/1058 [5:46:16<32:04:24, 128.87s/it] 15%|█▌        | 163/1058 [5:48:25<32:02:16, 128.87s/it] 16%|█▌        | 164/1058 [5:50:34<32:00:31, 128.89s/it] 16%|█▌        | 165/1058 [5:52:43<31:58:58, 128.93s/it] 16%|█▌        | 166/1058 [5:54:52<31:57:08, 128.96s/it] 16%|█▌        | 167/1058 [5:57:01<31:54:53, 128.95s/it] 16%|█▌        | 168/1058 [5:59:10<31:50:49, 128.82s/it] 16%|█▌        | 169/1058 [6:01:18<31:47:43, 128.76s/it] 16%|█▌        | 170/1058 [6:03:27<31:46:33, 128.82s/it]                                                        {'loss': 3.0117, 'learning_rate': 4.688186787109136e-05, 'epoch': 0.16}
 16%|█▌        | 170/1058 [6:03:27<31:46:33, 128.82s/it] 16%|█▌        | 171/1058 [6:05:36<31:45:07, 128.87s/it] 16%|█▋        | 172/1058 [6:07:44<31:38:17, 128.55s/it] 16%|█▋        | 173/1058 [6:09:53<31:36:35, 128.58s/it] 16%|█▋        | 174/1058 [6:12:00<31:30:30, 128.31s/it] 17%|█▋        | 175/1058 [6:14:09<31:31:00, 128.49s/it] 17%|█▋        | 176/1058 [6:16:19<31:31:39, 128.68s/it] 17%|█▋        | 177/1058 [6:18:28<31:31:23, 128.81s/it] 17%|█▋        | 178/1058 [6:20:37<31:30:46, 128.92s/it] 17%|█▋        | 179/1058 [6:22:46<31:29:33, 128.98s/it] 17%|█▋        | 180/1058 [6:24:55<31:28:05, 129.03s/it]                                                        {'loss': 2.8987, 'learning_rate': 4.651325845415136e-05, 'epoch': 0.17}
 17%|█▋        | 180/1058 [6:24:55<31:28:05, 129.03s/it] 17%|█▋        | 181/1058 [6:27:03<31:21:49, 128.75s/it] 17%|█▋        | 182/1058 [6:29:12<31:21:03, 128.84s/it] 17%|█▋        | 183/1058 [6:31:21<31:20:20, 128.94s/it] 17%|█▋        | 184/1058 [6:33:30<31:18:51, 128.98s/it] 17%|█▋        | 185/1058 [6:35:39<31:16:02, 128.94s/it] 18%|█▊        | 186/1058 [6:37:48<31:11:19, 128.76s/it] 18%|█▊        | 187/1058 [6:39:56<31:08:23, 128.71s/it] 18%|█▊        | 188/1058 [6:42:04<31:02:46, 128.47s/it] 18%|█▊        | 189/1058 [6:44:13<31:03:43, 128.68s/it] 18%|█▊        | 190/1058 [6:46:21<30:58:48, 128.49s/it]                                                        {'loss': 2.8021, 'learning_rate': 4.612568186033633e-05, 'epoch': 0.18}
 18%|█▊        | 190/1058 [6:46:21<30:58:48, 128.49s/it] 18%|█▊        | 191/1058 [6:48:30<30:57:37, 128.56s/it] 18%|█▊        | 192/1058 [6:50:39<30:57:47, 128.72s/it] 18%|█▊        | 193/1058 [6:52:48<30:57:15, 128.83s/it] 18%|█▊        | 194/1058 [6:54:57<30:52:56, 128.68s/it] 18%|█▊        | 195/1058 [6:57:05<30:49:50, 128.61s/it] 19%|█▊        | 196/1058 [6:59:13<30:46:27, 128.52s/it] 19%|█▊        | 197/1058 [7:01:22<30:43:27, 128.46s/it] 19%|█▊        | 198/1058 [7:03:31<30:44:42, 128.70s/it] 19%|█▉        | 199/1058 [7:05:40<30:44:14, 128.82s/it] 19%|█▉        | 200/1058 [7:07:48<30:37:39, 128.51s/it]                                                        {'loss': 2.7433, 'learning_rate': 4.571947979677647e-05, 'epoch': 0.19}
 19%|█▉        | 200/1058 [7:07:48<30:37:39, 128.51s/it][INFO|trainer.py:2979] 2024-05-14 05:32:54,746 >> Saving model checkpoint to /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200
[INFO|configuration_utils.py:473] 2024-05-14 05:32:54,751 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200/config.json
[INFO|configuration_utils.py:595] 2024-05-14 05:32:54,755 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200/generation_config.json
[INFO|modeling_utils.py:2540] 2024-05-14 05:33:11,606 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-05-14 05:33:11,611 >> tokenizer config file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-05-14 05:33:11,613 >> Special tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-05-14 05:33:11,615 >> added tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200/added_tokens.json
 19%|█▉        | 201/1058 [7:10:23<32:29:01, 136.45s/it] 19%|█▉        | 202/1058 [7:12:32<31:55:52, 134.29s/it] 19%|█▉        | 203/1058 [7:14:41<31:32:22, 132.80s/it] 19%|█▉        | 204/1058 [7:16:51<31:14:57, 131.73s/it] 19%|█▉        | 205/1058 [7:19:00<31:01:55, 130.97s/it] 19%|█▉        | 206/1058 [7:21:09<30:50:56, 130.35s/it] 20%|█▉        | 207/1058 [7:23:17<30:39:43, 129.71s/it] 20%|█▉        | 208/1058 [7:25:26<30:35:08, 129.54s/it] 20%|█▉        | 209/1058 [7:27:35<30:31:33, 129.44s/it] 20%|█▉        | 210/1058 [7:29:44<30:28:01, 129.34s/it]                                                        {'loss': 2.6989, 'learning_rate': 4.529501039175824e-05, 'epoch': 0.2}
 20%|█▉        | 210/1058 [7:29:44<30:28:01, 129.34s/it] 20%|█▉        | 211/1058 [7:31:54<30:25:16, 129.30s/it] 20%|██        | 212/1058 [7:34:03<30:22:25, 129.25s/it] 20%|██        | 213/1058 [7:36:12<30:19:38, 129.21s/it] 20%|██        | 214/1058 [7:38:21<30:17:21, 129.20s/it] 20%|██        | 215/1058 [7:40:30<30:15:10, 129.19s/it] 20%|██        | 216/1058 [7:42:39<30:12:36, 129.16s/it] 21%|██        | 217/1058 [7:44:48<30:10:28, 129.17s/it] 21%|██        | 218/1058 [7:46:58<30:08:04, 129.15s/it] 21%|██        | 219/1058 [7:49:07<30:06:03, 129.16s/it] 21%|██        | 220/1058 [7:51:15<29:59:04, 128.81s/it]                                                        {'loss': 2.67, 'learning_rate': 4.485264787898037e-05, 'epoch': 0.21}
 21%|██        | 220/1058 [7:51:15<29:59:04, 128.81s/it] 21%|██        | 221/1058 [7:53:24<29:57:08, 128.83s/it] 21%|██        | 222/1058 [7:55:33<29:56:29, 128.93s/it] 21%|██        | 223/1058 [7:57:42<29:56:05, 129.06s/it] 21%|██        | 224/1058 [7:59:50<29:50:43, 128.83s/it] 21%|██▏       | 225/1058 [8:01:59<29:49:29, 128.89s/it] 21%|██▏       | 226/1058 [8:04:07<29:43:35, 128.62s/it] 21%|██▏       | 227/1058 [8:06:16<29:42:50, 128.73s/it] 22%|██▏       | 228/1058 [8:08:26<29:42:23, 128.85s/it] 22%|██▏       | 229/1058 [8:10:35<29:41:43, 128.96s/it] 22%|██▏       | 230/1058 [8:12:44<29:40:37, 129.03s/it]                                                        {'loss': 2.6368, 'learning_rate': 4.43927822676105e-05, 'epoch': 0.22}
 22%|██▏       | 230/1058 [8:12:44<29:40:37, 129.03s/it] 22%|██▏       | 231/1058 [8:14:53<29:39:00, 129.07s/it] 22%|██▏       | 232/1058 [8:17:02<29:37:10, 129.09s/it] 22%|██▏       | 233/1058 [8:19:10<29:30:44, 128.78s/it] 22%|██▏       | 234/1058 [8:21:19<29:28:31, 128.78s/it] 22%|██▏       | 235/1058 [8:23:27<29:23:26, 128.56s/it] 22%|██▏       | 236/1058 [8:25:36<29:22:21, 128.64s/it] 22%|██▏       | 237/1058 [8:27:44<29:17:06, 128.41s/it] 22%|██▏       | 238/1058 [8:29:53<29:17:48, 128.62s/it] 23%|██▎       | 239/1058 [8:32:01<29:13:09, 128.44s/it] 23%|██▎       | 240/1058 [8:34:10<29:13:39, 128.63s/it]                                                        {'loss': 2.606, 'learning_rate': 4.3915818998433344e-05, 'epoch': 0.23}
 23%|██▎       | 240/1058 [8:34:10<29:13:39, 128.63s/it] 23%|██▎       | 241/1058 [8:36:19<29:13:41, 128.79s/it] 23%|██▎       | 242/1058 [8:38:28<29:13:11, 128.91s/it] 23%|██▎       | 243/1058 [8:40:38<29:12:26, 129.01s/it] 23%|██▎       | 244/1058 [8:42:47<29:11:10, 129.08s/it] 23%|██▎       | 245/1058 [8:44:56<29:09:59, 129.15s/it] 23%|██▎       | 246/1058 [8:47:05<29:08:01, 129.16s/it] 23%|██▎       | 247/1058 [8:49:15<29:06:04, 129.18s/it] 23%|██▎       | 248/1058 [8:51:24<29:03:58, 129.18s/it] 24%|██▎       | 249/1058 [8:53:33<29:02:19, 129.22s/it] 24%|██▎       | 250/1058 [8:55:41<28:55:01, 128.84s/it]                                                        {'loss': 2.5764, 'learning_rate': 4.342217858639362e-05, 'epoch': 0.24}
 24%|██▎       | 250/1058 [8:55:41<28:55:01, 128.84s/it] 24%|██▎       | 251/1058 [8:57:50<28:53:06, 128.86s/it] 24%|██▍       | 252/1058 [8:59:58<28:47:01, 128.56s/it] 24%|██▍       | 253/1058 [9:02:07<28:46:48, 128.71s/it] 24%|██▍       | 254/1058 [9:04:16<28:46:52, 128.87s/it] 24%|██▍       | 255/1058 [9:06:24<28:41:58, 128.67s/it] 24%|██▍       | 256/1058 [9:08:33<28:39:04, 128.61s/it] 24%|██▍       | 257/1058 [9:10:42<28:39:08, 128.77s/it] 24%|██▍       | 258/1058 [9:12:51<28:38:55, 128.92s/it] 24%|██▍       | 259/1058 [9:14:59<28:32:37, 128.61s/it] 25%|██▍       | 260/1058 [9:17:08<28:31:07, 128.66s/it]                                                        {'loss': 2.5395, 'learning_rate': 4.291229624984876e-05, 'epoch': 0.25}
 25%|██▍       | 260/1058 [9:17:08<28:31:07, 128.66s/it] 25%|██▍       | 261/1058 [9:19:17<28:30:58, 128.81s/it] 25%|██▍       | 262/1058 [9:21:26<28:30:20, 128.92s/it] 25%|██▍       | 263/1058 [9:23:35<28:28:43, 128.96s/it] 25%|██▍       | 264/1058 [9:25:43<28:22:16, 128.63s/it] 25%|██▌       | 265/1058 [9:27:52<28:21:25, 128.73s/it] 25%|██▌       | 266/1058 [9:30:01<28:19:45, 128.77s/it] 25%|██▌       | 267/1058 [9:32:09<28:15:16, 128.59s/it] 25%|██▌       | 268/1058 [9:34:18<28:15:28, 128.77s/it] 25%|██▌       | 269/1058 [9:36:28<28:15:59, 128.97s/it] 26%|██▌       | 270/1058 [9:38:36<28:09:53, 128.67s/it]                                                        {'loss': 2.5124, 'learning_rate': 4.238662152685846e-05, 'epoch': 0.26}
 26%|██▌       | 270/1058 [9:38:36<28:09:53, 128.67s/it] 26%|██▌       | 271/1058 [9:40:44<28:07:49, 128.68s/it] 26%|██▌       | 272/1058 [9:42:54<28:07:53, 128.85s/it] 26%|██▌       | 273/1058 [9:45:02<28:02:53, 128.63s/it] 26%|██▌       | 274/1058 [9:47:11<28:02:26, 128.76s/it] 26%|██▌       | 275/1058 [9:49:20<28:02:02, 128.89s/it] 26%|██▌       | 276/1058 [9:51:29<28:00:46, 128.96s/it] 26%|██▌       | 277/1058 [9:53:38<27:59:16, 129.01s/it] 26%|██▋       | 278/1058 [9:55:46<27:53:53, 128.76s/it] 26%|██▋       | 279/1058 [9:57:55<27:51:26, 128.74s/it] 26%|██▋       | 280/1058 [10:00:04<27:51:28, 128.90s/it]                                                         {'loss': 2.498, 'learning_rate': 4.184561787884911e-05, 'epoch': 0.26}
 26%|██▋       | 280/1058 [10:00:04<27:51:28, 128.90s/it] 27%|██▋       | 281/1058 [10:02:14<27:50:52, 129.02s/it] 27%|██▋       | 282/1058 [10:04:23<27:49:14, 129.07s/it] 27%|██▋       | 283/1058 [10:06:32<27:47:48, 129.12s/it] 27%|██▋       | 284/1058 [10:08:41<27:45:40, 129.12s/it] 27%|██▋       | 285/1058 [10:10:51<27:44:27, 129.19s/it] 27%|██▋       | 286/1058 [10:13:00<27:42:31, 129.21s/it] 27%|██▋       | 287/1058 [10:15:09<27:39:58, 129.18s/it] 27%|██▋       | 288/1058 [10:17:18<27:38:02, 129.20s/it] 27%|██▋       | 289/1058 [10:19:27<27:35:31, 129.17s/it] 27%|██▋       | 290/1058 [10:21:37<27:33:30, 129.18s/it]                                                         {'loss': 2.4836, 'learning_rate': 4.1289762282002796e-05, 'epoch': 0.27}
 27%|██▋       | 290/1058 [10:21:37<27:33:30, 129.18s/it] 28%|██▊       | 291/1058 [10:23:45<27:29:43, 129.05s/it] 28%|██▊       | 292/1058 [10:25:54<27:24:28, 128.81s/it] 28%|██▊       | 293/1058 [10:28:02<27:20:55, 128.70s/it] 28%|██▊       | 294/1058 [10:30:10<27:17:37, 128.61s/it] 28%|██▊       | 295/1058 [10:32:19<27:14:37, 128.54s/it] 28%|██▊       | 296/1058 [10:34:27<27:12:31, 128.55s/it] 28%|██▊       | 297/1058 [10:36:37<27:13:10, 128.77s/it] 28%|██▊       | 298/1058 [10:38:45<27:08:09, 128.54s/it] 28%|██▊       | 299/1058 [10:40:54<27:07:32, 128.66s/it] 28%|██▊       | 300/1058 [10:43:03<27:07:39, 128.84s/it]                                                         {'loss': 2.4515, 'learning_rate': 4.0719544806730987e-05, 'epoch': 0.28}
 28%|██▊       | 300/1058 [10:43:03<27:07:39, 128.84s/it] 28%|██▊       | 301/1058 [10:45:11<27:02:49, 128.63s/it] 29%|██▊       | 302/1058 [10:47:20<27:02:09, 128.74s/it] 29%|██▊       | 303/1058 [10:49:29<27:01:39, 128.87s/it] 29%|██▊       | 304/1058 [10:51:38<27:00:28, 128.95s/it] 29%|██▉       | 305/1058 [10:53:47<26:56:39, 128.82s/it] 29%|██▉       | 306/1058 [10:55:56<26:55:52, 128.93s/it] 29%|██▉       | 307/1058 [10:58:05<26:54:43, 129.01s/it] 29%|██▉       | 308/1058 [11:00:14<26:53:32, 129.08s/it] 29%|██▉       | 309/1058 [11:02:24<26:51:39, 129.10s/it] 29%|██▉       | 310/1058 [11:04:33<26:49:48, 129.13s/it]                                                         {'loss': 2.4348, 'learning_rate': 4.013546818560362e-05, 'epoch': 0.29}
 29%|██▉       | 310/1058 [11:04:33<26:49:48, 129.13s/it] 29%|██▉       | 311/1058 [11:06:42<26:47:58, 129.16s/it] 29%|██▉       | 312/1058 [11:08:51<26:46:03, 129.17s/it] 30%|██▉       | 313/1058 [11:11:00<26:44:03, 129.19s/it] 30%|██▉       | 314/1058 [11:13:10<26:42:10, 129.21s/it] 30%|██▉       | 315/1058 [11:15:19<26:40:16, 129.23s/it] 30%|██▉       | 316/1058 [11:17:28<26:37:57, 129.22s/it] 30%|██▉       | 317/1058 [11:19:37<26:35:57, 129.23s/it] 30%|███       | 318/1058 [11:21:47<26:33:28, 129.20s/it] 30%|███       | 319/1058 [11:23:56<26:30:56, 129.17s/it] 30%|███       | 320/1058 [11:26:05<26:28:55, 129.18s/it]                                                         {'loss': 2.4184, 'learning_rate': 3.9538047370114694e-05, 'epoch': 0.3}
 30%|███       | 320/1058 [11:26:05<26:28:55, 129.18s/it] 30%|███       | 321/1058 [11:28:14<26:26:54, 129.19s/it] 30%|███       | 322/1058 [11:30:23<26:24:46, 129.19s/it] 31%|███       | 323/1058 [11:32:32<26:19:30, 128.94s/it] 31%|███       | 324/1058 [11:34:41<26:18:08, 129.00s/it] 31%|███       | 325/1058 [11:36:50<26:16:41, 129.06s/it] 31%|███       | 326/1058 [11:38:59<26:15:10, 129.11s/it] 31%|███       | 327/1058 [11:41:09<26:13:51, 129.18s/it] 31%|███       | 328/1058 [11:43:18<26:11:41, 129.18s/it] 31%|███       | 329/1058 [11:45:26<26:06:46, 128.95s/it] 31%|███       | 330/1058 [11:47:35<26:03:40, 128.87s/it]                                                         {'loss': 2.4029, 'learning_rate': 3.892780907667495e-05, 'epoch': 0.31}
 31%|███       | 330/1058 [11:47:35<26:03:40, 128.87s/it] 31%|███▏      | 331/1058 [11:49:44<26:02:15, 128.93s/it] 31%|███▏      | 332/1058 [11:51:52<25:57:41, 128.74s/it] 31%|███▏      | 333/1058 [11:54:01<25:56:52, 128.84s/it] 32%|███▏      | 334/1058 [11:56:10<25:55:52, 128.94s/it] 32%|███▏      | 335/1058 [11:58:19<25:52:20, 128.82s/it] 32%|███▏      | 336/1058 [12:00:27<25:48:55, 128.72s/it] 32%|███▏      | 337/1058 [12:02:37<25:48:19, 128.85s/it] 32%|███▏      | 338/1058 [12:04:45<25:46:16, 128.86s/it] 32%|███▏      | 339/1058 [12:06:54<25:41:17, 128.62s/it] 32%|███▏      | 340/1058 [12:09:02<25:39:24, 128.64s/it]                                                         {'loss': 2.3778, 'learning_rate': 3.830529132223202e-05, 'epoch': 0.32}
 32%|███▏      | 340/1058 [12:09:02<25:39:24, 128.64s/it] 32%|███▏      | 341/1058 [12:11:10<25:35:47, 128.52s/it] 32%|███▏      | 342/1058 [12:13:20<25:36:22, 128.75s/it] 32%|███▏      | 343/1058 [12:15:28<25:31:04, 128.48s/it] 33%|███▎      | 344/1058 [12:17:37<25:30:38, 128.63s/it] 33%|███▎      | 345/1058 [12:19:45<25:26:44, 128.48s/it] 33%|███▎      | 346/1058 [12:21:54<25:26:49, 128.67s/it] 33%|███▎      | 347/1058 [12:24:03<25:26:25, 128.81s/it] 33%|███▎      | 348/1058 [12:26:11<25:21:37, 128.59s/it] 33%|███▎      | 349/1058 [12:28:20<25:20:37, 128.69s/it] 33%|███▎      | 350/1058 [12:30:28<25:15:43, 128.45s/it]                                                         {'loss': 2.3647, 'learning_rate': 3.7671042949927535e-05, 'epoch': 0.33}
 33%|███▎      | 350/1058 [12:30:28<25:15:43, 128.45s/it] 33%|███▎      | 351/1058 [12:32:37<25:14:45, 128.55s/it] 33%|███▎      | 352/1058 [12:34:45<25:10:23, 128.36s/it] 33%|███▎      | 353/1058 [12:36:54<25:10:49, 128.58s/it] 33%|███▎      | 354/1058 [12:39:03<25:11:11, 128.79s/it] 34%|███▎      | 355/1058 [12:41:12<25:11:18, 128.99s/it] 34%|███▎      | 356/1058 [12:43:22<25:10:15, 129.08s/it] 34%|███▎      | 357/1058 [12:45:31<25:08:49, 129.14s/it] 34%|███▍      | 358/1058 [12:47:40<25:07:13, 129.19s/it] 34%|███▍      | 359/1058 [12:49:49<25:02:03, 128.93s/it] 34%|███▍      | 360/1058 [12:51:58<25:00:54, 129.02s/it]                                                         {'loss': 2.3453, 'learning_rate': 3.702562314520919e-05, 'epoch': 0.34}
 34%|███▍      | 360/1058 [12:51:58<25:00:54, 129.02s/it] 34%|███▍      | 361/1058 [12:54:07<24:59:30, 129.08s/it] 34%|███▍      | 362/1058 [12:56:16<24:57:53, 129.13s/it] 34%|███▍      | 363/1058 [12:58:26<24:56:58, 129.23s/it] 34%|███▍      | 364/1058 [13:00:35<24:55:26, 129.29s/it] 34%|███▍      | 365/1058 [13:02:44<24:53:15, 129.29s/it] 35%|███▍      | 366/1058 [13:04:53<24:47:28, 128.97s/it] 35%|███▍      | 367/1058 [13:07:02<24:46:13, 129.05s/it] 35%|███▍      | 368/1058 [13:09:11<24:45:02, 129.13s/it] 35%|███▍      | 369/1058 [13:11:21<24:43:41, 129.20s/it] 35%|███▍      | 370/1058 [13:13:29<24:40:03, 129.07s/it]                                                         {'loss': 2.3329, 'learning_rate': 3.6369600942824606e-05, 'epoch': 0.35}
 35%|███▍      | 370/1058 [13:13:29<24:40:03, 129.07s/it] 35%|███▌      | 371/1058 [13:15:38<24:35:39, 128.88s/it] 35%|███▌      | 372/1058 [13:17:47<24:33:50, 128.91s/it] 35%|███▌      | 373/1058 [13:19:55<24:29:01, 128.67s/it] 35%|███▌      | 374/1058 [13:22:04<24:28:48, 128.84s/it] 35%|███▌      | 375/1058 [13:24:12<24:24:02, 128.61s/it] 36%|███▌      | 376/1058 [13:26:21<24:23:52, 128.79s/it] 36%|███▌      | 377/1058 [13:28:31<24:23:26, 128.94s/it] 36%|███▌      | 378/1058 [13:30:40<24:22:19, 129.03s/it] 36%|███▌      | 379/1058 [13:32:49<24:20:39, 129.07s/it] 36%|███▌      | 380/1058 [13:34:58<24:18:50, 129.10s/it]                                                         {'loss': 2.323, 'learning_rate': 3.570355472513148e-05, 'epoch': 0.36}
 36%|███▌      | 380/1058 [13:34:58<24:18:50, 129.10s/it] 36%|███▌      | 381/1058 [13:37:06<24:13:17, 128.80s/it] 36%|███▌      | 382/1058 [13:39:15<24:12:13, 128.90s/it] 36%|███▌      | 383/1058 [13:41:25<24:11:05, 128.99s/it] 36%|███▋      | 384/1058 [13:43:34<24:10:03, 129.08s/it] 36%|███▋      | 385/1058 [13:45:43<24:08:09, 129.11s/it] 36%|███▋      | 386/1058 [13:47:52<24:03:26, 128.88s/it] 37%|███▋      | 387/1058 [13:50:01<24:01:58, 128.94s/it] 37%|███▋      | 388/1058 [13:52:10<24:01:34, 129.10s/it] 37%|███▋      | 389/1058 [13:54:19<24:00:02, 129.15s/it] 37%|███▋      | 390/1058 [13:56:28<23:55:16, 128.92s/it]                                                         {'loss': 2.3156, 'learning_rate': 3.5028071712166456e-05, 'epoch': 0.37}
 37%|███▋      | 390/1058 [13:56:28<23:55:16, 128.92s/it] 37%|███▋      | 391/1058 [13:58:36<23:51:53, 128.81s/it] 37%|███▋      | 392/1058 [14:00:46<23:51:15, 128.94s/it] 37%|███▋      | 393/1058 [14:02:55<23:50:05, 129.03s/it] 37%|███▋      | 394/1058 [14:05:04<23:48:26, 129.08s/it] 37%|███▋      | 395/1058 [14:07:13<23:45:57, 129.05s/it] 37%|███▋      | 396/1058 [14:09:21<23:41:30, 128.84s/it] 38%|███▊      | 397/1058 [14:11:30<23:39:14, 128.83s/it] 38%|███▊      | 398/1058 [14:13:38<23:34:17, 128.57s/it] 38%|███▊      | 399/1058 [14:15:47<23:34:43, 128.81s/it] 38%|███▊      | 400/1058 [14:17:56<23:30:42, 128.64s/it]                                                         {'loss': 2.2843, 'learning_rate': 3.434374744392225e-05, 'epoch': 0.38}
 38%|███▊      | 400/1058 [14:17:56<23:30:42, 128.64s/it][INFO|trainer.py:2979] 2024-05-14 12:43:02,357 >> Saving model checkpoint to /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400
[INFO|configuration_utils.py:473] 2024-05-14 12:43:02,364 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400/config.json
[INFO|configuration_utils.py:595] 2024-05-14 12:43:02,369 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400/generation_config.json
[INFO|modeling_utils.py:2540] 2024-05-14 12:43:24,202 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-05-14 12:43:24,212 >> tokenizer config file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-05-14 12:43:24,216 >> Special tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-05-14 12:43:24,219 >> added tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400/added_tokens.json
[INFO|trainer.py:3071] 2024-05-14 12:43:25,159 >> Deleting older checkpoint [/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/checkpoint-200] due to args.save_total_limit
 38%|███▊      | 401/1058 [14:20:35<25:10:37, 137.96s/it] 38%|███▊      | 402/1058 [14:22:45<24:40:06, 135.38s/it] 38%|███▊      | 403/1058 [14:24:54<24:18:14, 133.58s/it] 38%|███▊      | 404/1058 [14:27:03<24:02:13, 132.31s/it] 38%|███▊      | 405/1058 [14:29:13<23:49:49, 131.38s/it] 38%|███▊      | 406/1058 [14:31:22<23:40:29, 130.72s/it] 38%|███▊      | 407/1058 [14:33:31<23:33:29, 130.28s/it] 39%|███▊      | 408/1058 [14:35:40<23:28:24, 130.01s/it] 39%|███▊      | 409/1058 [14:37:50<23:23:44, 129.78s/it] 39%|███▉      | 410/1058 [14:39:59<23:19:52, 129.62s/it]                                                         {'loss': 2.2928, 'learning_rate': 3.365118525528946e-05, 'epoch': 0.39}
 39%|███▉      | 410/1058 [14:39:59<23:19:52, 129.62s/it] 39%|███▉      | 411/1058 [14:42:08<23:16:29, 129.50s/it] 39%|███▉      | 412/1058 [14:44:17<23:12:05, 129.30s/it] 39%|███▉      | 413/1058 [14:46:25<23:06:57, 129.02s/it] 39%|███▉      | 414/1058 [14:48:35<23:06:02, 129.13s/it] 39%|███▉      | 415/1058 [14:50:44<23:04:15, 129.17s/it] 39%|███▉      | 416/1058 [14:52:53<23:02:21, 129.19s/it] 39%|███▉      | 417/1058 [14:55:03<23:00:44, 129.24s/it] 40%|███▉      | 418/1058 [14:57:12<22:58:15, 129.21s/it] 40%|███▉      | 419/1058 [14:59:21<22:56:22, 129.24s/it] 40%|███▉      | 420/1058 [15:01:30<22:54:08, 129.23s/it]                                                         {'loss': 2.2685, 'learning_rate': 3.295099574412598e-05, 'epoch': 0.4}
 40%|███▉      | 420/1058 [15:01:30<22:54:08, 129.23s/it] 40%|███▉      | 421/1058 [15:03:40<22:52:11, 129.25s/it] 40%|███▉      | 422/1058 [15:05:49<22:49:55, 129.24s/it] 40%|███▉      | 423/1058 [15:07:58<22:47:46, 129.24s/it] 40%|████      | 424/1058 [15:10:07<22:45:41, 129.24s/it] 40%|████      | 425/1058 [15:12:17<22:43:35, 129.25s/it] 40%|████      | 426/1058 [15:14:25<22:38:08, 128.94s/it] 40%|████      | 427/1058 [15:16:34<22:36:11, 128.96s/it] 40%|████      | 428/1058 [15:18:43<22:34:49, 129.03s/it] 41%|████      | 429/1058 [15:20:52<22:33:22, 129.10s/it] 41%|████      | 430/1058 [15:23:01<22:31:40, 129.14s/it]                                                         {'loss': 2.255, 'learning_rate': 3.22437962329231e-05, 'epoch': 0.41}
 41%|████      | 430/1058 [15:23:01<22:31:40, 129.14s/it] 41%|████      | 431/1058 [15:25:11<22:29:48, 129.17s/it] 41%|████      | 432/1058 [15:27:20<22:27:50, 129.19s/it] 41%|████      | 433/1058 [15:29:29<22:25:55, 129.21s/it] 41%|████      | 434/1058 [15:31:38<22:23:46, 129.21s/it] 41%|████      | 435/1058 [15:33:48<22:21:30, 129.20s/it] 41%|████      | 436/1058 [15:35:57<22:19:30, 129.21s/it] 41%|████▏     | 437/1058 [15:38:06<22:17:23, 129.22s/it] 41%|████▏     | 438/1058 [15:40:15<22:13:06, 129.01s/it] 41%|████▏     | 439/1058 [15:42:23<22:10:40, 128.98s/it] 42%|████▏     | 440/1058 [15:44:32<22:07:05, 128.84s/it]                                                         {'loss': 2.2401, 'learning_rate': 3.15302102245427e-05, 'epoch': 0.42}
 42%|████▏     | 440/1058 [15:44:32<22:07:05, 128.84s/it] 42%|████▏     | 441/1058 [15:46:41<22:04:16, 128.78s/it] 42%|████▏     | 442/1058 [15:48:50<22:03:27, 128.91s/it] 42%|████▏     | 443/1058 [15:50:59<22:02:24, 129.02s/it] 42%|████▏     | 444/1058 [15:53:08<22:00:56, 129.08s/it] 42%|████▏     | 445/1058 [15:55:18<21:59:14, 129.13s/it] 42%|████▏     | 446/1058 [15:57:27<21:57:21, 129.15s/it] 42%|████▏     | 447/1058 [15:59:36<21:54:20, 129.07s/it] 42%|████▏     | 448/1058 [16:01:44<21:50:04, 128.86s/it] 42%|████▏     | 449/1058 [16:03:53<21:49:01, 128.97s/it] 43%|████▎     | 450/1058 [16:06:03<21:47:57, 129.08s/it]                                                         {'loss': 2.2246, 'learning_rate': 3.081086685250565e-05, 'epoch': 0.43}
 43%|████▎     | 450/1058 [16:06:03<21:47:57, 129.08s/it] 43%|████▎     | 451/1058 [16:08:12<21:46:58, 129.19s/it] 43%|████▎     | 452/1058 [16:10:21<21:45:03, 129.21s/it] 43%|████▎     | 453/1058 [16:12:31<21:43:12, 129.24s/it] 43%|████▎     | 454/1058 [16:14:40<21:40:59, 129.24s/it] 43%|████▎     | 455/1058 [16:16:49<21:38:45, 129.23s/it] 43%|████▎     | 456/1058 [16:18:58<21:36:41, 129.24s/it] 43%|████▎     | 457/1058 [16:21:08<21:34:28, 129.23s/it] 43%|████▎     | 458/1058 [16:23:17<21:32:30, 129.25s/it] 43%|████▎     | 459/1058 [16:25:25<21:28:36, 129.08s/it] 43%|████▎     | 460/1058 [16:27:34<21:25:29, 128.98s/it]                                                         {'loss': 2.2196, 'learning_rate': 3.008640032631585e-05, 'epoch': 0.43}
 43%|████▎     | 460/1058 [16:27:34<21:25:29, 128.98s/it] 44%|████▎     | 461/1058 [16:29:43<21:23:52, 129.03s/it] 44%|████▎     | 462/1058 [16:31:53<21:22:16, 129.09s/it] 44%|████▍     | 463/1058 [16:34:02<21:19:55, 129.07s/it] 44%|████▍     | 464/1058 [16:36:10<21:15:17, 128.82s/it] 44%|████▍     | 465/1058 [16:38:19<21:14:33, 128.96s/it] 44%|████▍     | 466/1058 [16:40:28<21:13:32, 129.08s/it] 44%|████▍     | 467/1058 [16:42:38<21:11:56, 129.13s/it] 44%|████▍     | 468/1058 [16:44:47<21:10:25, 129.20s/it] 44%|████▍     | 469/1058 [16:46:56<21:08:50, 129.25s/it] 44%|████▍     | 470/1058 [16:49:06<21:06:54, 129.28s/it]                                                         {'loss': 2.2005, 'learning_rate': 2.9357449372309028e-05, 'epoch': 0.44}
 44%|████▍     | 470/1058 [16:49:06<21:06:54, 129.28s/it] 45%|████▍     | 471/1058 [16:51:15<21:04:38, 129.27s/it] 45%|████▍     | 472/1058 [16:53:24<21:02:26, 129.26s/it] 45%|████▍     | 473/1058 [16:55:33<20:59:59, 129.23s/it] 45%|████▍     | 474/1058 [16:57:43<20:57:58, 129.24s/it] 45%|████▍     | 475/1058 [16:59:52<20:55:43, 129.23s/it] 45%|████▍     | 476/1058 [17:02:01<20:53:18, 129.21s/it] 45%|████▌     | 477/1058 [17:04:10<20:50:09, 129.10s/it] 45%|████▌     | 478/1058 [17:06:18<20:45:02, 128.80s/it] 45%|████▌     | 479/1058 [17:08:27<20:44:09, 128.93s/it] 45%|████▌     | 480/1058 [17:10:37<20:43:06, 129.04s/it]                                                         {'loss': 2.1854, 'learning_rate': 2.8624656670519335e-05, 'epoch': 0.45}
 45%|████▌     | 480/1058 [17:10:37<20:43:06, 129.04s/it] 45%|████▌     | 481/1058 [17:12:46<20:41:57, 129.15s/it] 46%|████▌     | 482/1058 [17:14:55<20:40:18, 129.20s/it] 46%|████▌     | 483/1058 [17:17:04<20:37:59, 129.18s/it] 46%|████▌     | 484/1058 [17:19:14<20:36:14, 129.22s/it] 46%|████▌     | 485/1058 [17:21:22<20:31:25, 128.95s/it] 46%|████▌     | 486/1058 [17:23:31<20:28:54, 128.91s/it] 46%|████▌     | 487/1058 [17:25:40<20:28:28, 129.09s/it] 46%|████▌     | 488/1058 [17:27:50<20:27:22, 129.20s/it] 46%|████▌     | 489/1058 [17:29:59<20:25:30, 129.23s/it] 46%|████▋     | 490/1058 [17:32:08<20:21:25, 129.02s/it]                                                         {'loss': 2.1778, 'learning_rate': 2.7888668288060095e-05, 'epoch': 0.46}
 46%|████▋     | 490/1058 [17:32:08<20:21:25, 129.02s/it] 46%|████▋     | 491/1058 [17:34:17<20:18:58, 128.99s/it] 47%|████▋     | 492/1058 [17:36:26<20:17:38, 129.08s/it] 47%|████▋     | 493/1058 [17:38:35<20:16:08, 129.15s/it] 47%|████▋     | 494/1058 [17:40:44<20:14:28, 129.20s/it] 47%|████▋     | 495/1058 [17:42:54<20:12:37, 129.23s/it] 47%|████▋     | 496/1058 [17:45:03<20:10:23, 129.22s/it] 47%|████▋     | 497/1058 [17:47:12<20:08:46, 129.28s/it] 47%|████▋     | 498/1058 [17:49:22<20:07:18, 129.36s/it] 47%|████▋     | 499/1058 [17:51:31<20:05:05, 129.35s/it] 47%|████▋     | 500/1058 [17:53:41<20:02:53, 129.34s/it]                                                         {'loss': 2.1648, 'learning_rate': 2.7150133109518344e-05, 'epoch': 0.47}
 47%|████▋     | 500/1058 [17:53:41<20:02:53, 129.34s/it] 47%|████▋     | 501/1058 [17:55:50<20:00:58, 129.37s/it] 47%|████▋     | 502/1058 [17:57:59<19:58:33, 129.34s/it] 48%|████▊     | 503/1058 [18:00:09<19:56:21, 129.34s/it] 48%|████▊     | 504/1058 [18:02:18<19:53:58, 129.31s/it] 48%|████▊     | 505/1058 [18:04:27<19:51:30, 129.28s/it] 48%|████▊     | 506/1058 [18:06:36<19:46:59, 129.02s/it] 48%|████▊     | 507/1058 [18:08:45<19:45:32, 129.10s/it] 48%|████▊     | 508/1058 [18:10:54<19:43:47, 129.14s/it] 48%|████▊     | 509/1058 [18:13:03<19:41:43, 129.15s/it] 48%|████▊     | 510/1058 [18:15:12<19:39:53, 129.19s/it]                                                         {'loss': 2.1616, 'learning_rate': 2.6409702264865398e-05, 'epoch': 0.48}
 48%|████▊     | 510/1058 [18:15:12<19:39:53, 129.19s/it] 48%|████▊     | 511/1058 [18:17:22<19:38:10, 129.23s/it] 48%|████▊     | 512/1058 [18:19:31<19:35:26, 129.17s/it] 48%|████▊     | 513/1058 [18:21:39<19:30:52, 128.90s/it] 49%|████▊     | 514/1058 [18:23:48<19:29:45, 129.02s/it] 49%|████▊     | 515/1058 [18:25:58<19:28:16, 129.09s/it] 49%|████▉     | 516/1058 [18:28:07<19:26:36, 129.15s/it] 49%|████▉     | 517/1058 [18:30:16<19:24:32, 129.15s/it] 49%|████▉     | 518/1058 [18:32:25<19:22:40, 129.19s/it] 49%|████▉     | 519/1058 [18:34:35<19:20:34, 129.19s/it] 49%|████▉     | 520/1058 [18:36:44<19:18:23, 129.19s/it]                                                         {'loss': 2.1453, 'learning_rate': 2.566802855538768e-05, 'epoch': 0.49}
 49%|████▉     | 520/1058 [18:36:44<19:18:23, 129.19s/it] 49%|████▉     | 521/1058 [18:38:53<19:16:34, 129.23s/it] 49%|████▉     | 522/1058 [18:41:02<19:14:33, 129.24s/it] 49%|████▉     | 523/1058 [18:43:11<19:10:27, 129.02s/it] 50%|████▉     | 524/1058 [18:45:19<19:06:46, 128.85s/it] 50%|████▉     | 525/1058 [18:47:28<19:04:33, 128.84s/it] 50%|████▉     | 526/1058 [18:49:37<19:01:23, 128.73s/it] 50%|████▉     | 527/1058 [18:51:46<19:01:10, 128.95s/it] 50%|████▉     | 528/1058 [18:53:55<18:59:59, 129.06s/it] 50%|█████     | 529/1058 [18:56:05<18:58:20, 129.11s/it] 50%|█████     | 530/1058 [18:58:14<18:56:54, 129.19s/it]                                                         {'loss': 2.1357, 'learning_rate': 2.4925765878144117e-05, 'epoch': 0.5}
 50%|█████     | 530/1058 [18:58:14<18:56:54, 129.19s/it] 50%|█████     | 531/1058 [19:00:23<18:55:22, 129.27s/it] 50%|█████     | 532/1058 [19:02:33<18:53:16, 129.27s/it] 50%|█████     | 533/1058 [19:04:41<18:48:13, 128.94s/it] 50%|█████     | 534/1058 [19:06:50<18:46:23, 128.98s/it] 51%|█████     | 535/1058 [19:08:58<18:42:02, 128.72s/it] 51%|█████     | 536/1058 [19:11:07<18:39:58, 128.73s/it] 51%|█████     | 537/1058 [19:13:16<18:39:28, 128.92s/it] 51%|█████     | 538/1058 [19:15:25<18:37:04, 128.89s/it] 51%|█████     | 539/1058 [19:17:34<18:34:00, 128.79s/it] 51%|█████     | 540/1058 [19:19:43<18:33:05, 128.93s/it]                                                         {'loss': 2.1323, 'learning_rate': 2.4183568649457436e-05, 'epoch': 0.51}
 51%|█████     | 540/1058 [19:19:43<18:33:05, 128.93s/it] 51%|█████     | 541/1058 [19:21:52<18:32:05, 129.06s/it] 51%|█████     | 542/1058 [19:24:02<18:30:40, 129.15s/it] 51%|█████▏    | 543/1058 [19:26:11<18:28:58, 129.20s/it] 51%|█████▏    | 544/1058 [19:28:20<18:26:55, 129.21s/it] 52%|█████▏    | 545/1058 [19:30:29<18:24:55, 129.23s/it] 52%|█████▏    | 546/1058 [19:32:39<18:23:07, 129.27s/it] 52%|█████▏    | 547/1058 [19:34:48<18:21:18, 129.31s/it] 52%|█████▏    | 548/1058 [19:36:57<18:19:11, 129.32s/it] 52%|█████▏    | 549/1058 [19:39:07<18:17:08, 129.33s/it] 52%|█████▏    | 550/1058 [19:41:16<18:15:14, 129.36s/it]                                                         {'loss': 2.1164, 'learning_rate': 2.344209122794757e-05, 'epoch': 0.52}
 52%|█████▏    | 550/1058 [19:41:16<18:15:14, 129.36s/it] 52%|█████▏    | 551/1058 [19:43:25<18:10:45, 129.08s/it] 52%|█████▏    | 552/1058 [19:45:34<18:08:15, 129.04s/it] 52%|█████▏    | 553/1058 [19:47:43<18:06:35, 129.10s/it] 52%|█████▏    | 554/1058 [19:49:51<18:02:07, 128.82s/it] 52%|█████▏    | 555/1058 [19:52:00<17:59:49, 128.81s/it] 53%|█████▎    | 556/1058 [19:54:09<17:59:02, 128.97s/it] 53%|█████▎    | 557/1058 [19:56:19<17:57:47, 129.08s/it] 53%|█████▎    | 558/1058 [19:58:28<17:56:11, 129.14s/it] 53%|█████▎    | 559/1058 [20:00:37<17:54:24, 129.19s/it] 53%|█████▎    | 560/1058 [20:02:46<17:52:32, 129.22s/it]                                                         {'loss': 2.1088, 'learning_rate': 2.2701987337616052e-05, 'epoch': 0.53}
 53%|█████▎    | 560/1058 [20:02:46<17:52:32, 129.22s/it] 53%|█████▎    | 561/1058 [20:04:56<17:50:33, 129.24s/it] 53%|█████▎    | 562/1058 [20:07:05<17:47:46, 129.17s/it] 53%|█████▎    | 563/1058 [20:09:13<17:42:34, 128.80s/it] 53%|█████▎    | 564/1058 [20:11:22<17:41:09, 128.89s/it] 53%|█████▎    | 565/1058 [20:13:30<17:38:02, 128.77s/it] 53%|█████▎    | 566/1058 [20:15:38<17:34:37, 128.61s/it] 54%|█████▎    | 567/1058 [20:17:48<17:33:57, 128.79s/it] 54%|█████▎    | 568/1058 [20:19:57<17:33:08, 128.96s/it] 54%|█████▍    | 569/1058 [20:22:06<17:31:48, 129.06s/it] 54%|█████▍    | 570/1058 [20:24:15<17:27:52, 128.84s/it]                                                         {'loss': 2.0952, 'learning_rate': 2.1963909491489844e-05, 'epoch': 0.54}
 54%|█████▍    | 570/1058 [20:24:15<17:27:52, 128.84s/it] 54%|█████▍    | 571/1058 [20:26:24<17:26:40, 128.95s/it] 54%|█████▍    | 572/1058 [20:28:33<17:25:20, 129.05s/it] 54%|█████▍    | 573/1058 [20:30:41<17:21:05, 128.79s/it] 54%|█████▍    | 574/1058 [20:32:50<17:19:02, 128.81s/it] 54%|█████▍    | 575/1058 [20:34:59<17:15:52, 128.68s/it] 54%|█████▍    | 576/1058 [20:37:07<17:12:59, 128.59s/it] 55%|█████▍    | 577/1058 [20:39:16<17:12:46, 128.83s/it] 55%|█████▍    | 578/1058 [20:41:26<17:11:47, 128.97s/it] 55%|█████▍    | 579/1058 [20:43:35<17:10:19, 129.06s/it] 55%|█████▍    | 580/1058 [20:45:44<17:07:39, 129.00s/it]                                                         {'loss': 2.0879, 'learning_rate': 2.1228508416332876e-05, 'epoch': 0.55}
 55%|█████▍    | 580/1058 [20:45:44<17:07:39, 129.00s/it] 55%|█████▍    | 581/1058 [20:47:52<17:04:24, 128.86s/it] 55%|█████▌    | 582/1058 [20:50:02<17:03:23, 129.00s/it] 55%|█████▌    | 583/1058 [20:52:10<16:59:27, 128.77s/it] 55%|█████▌    | 584/1058 [20:54:19<16:57:52, 128.84s/it] 55%|█████▌    | 585/1058 [20:56:27<16:53:29, 128.56s/it] 55%|█████▌    | 586/1058 [20:58:36<16:52:03, 128.65s/it] 55%|█████▌    | 587/1058 [21:00:45<16:51:22, 128.84s/it] 56%|█████▌    | 588/1058 [21:02:54<16:50:25, 128.99s/it] 56%|█████▌    | 589/1058 [21:05:03<16:48:46, 129.05s/it] 56%|█████▌    | 590/1058 [21:07:12<16:45:33, 128.92s/it]                                                         {'loss': 2.0735, 'learning_rate': 2.0496432478932347e-05, 'epoch': 0.56}
 56%|█████▌    | 590/1058 [21:07:12<16:45:33, 128.92s/it] 56%|█████▌    | 591/1058 [21:09:21<16:42:24, 128.79s/it] 56%|█████▌    | 592/1058 [21:11:29<16:40:03, 128.76s/it] 56%|█████▌    | 593/1058 [21:13:38<16:36:59, 128.64s/it] 56%|█████▌    | 594/1058 [21:15:47<16:36:05, 128.80s/it] 56%|█████▌    | 595/1058 [21:17:55<16:31:54, 128.54s/it] 56%|█████▋    | 596/1058 [21:20:04<16:31:20, 128.75s/it] 56%|█████▋    | 597/1058 [21:22:12<16:28:16, 128.63s/it] 57%|█████▋    | 598/1058 [21:24:21<16:26:46, 128.71s/it] 57%|█████▋    | 599/1058 [21:26:29<16:22:45, 128.47s/it] 57%|█████▋    | 600/1058 [21:28:38<16:21:38, 128.60s/it]                                                         {'loss': 2.0647, 'learning_rate': 1.9768327114465843e-05, 'epoch': 0.57}
 57%|█████▋    | 600/1058 [21:28:38<16:21:38, 128.60s/it][INFO|trainer.py:2979] 2024-05-14 19:53:44,674 >> Saving model checkpoint to /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600
[INFO|configuration_utils.py:473] 2024-05-14 19:53:44,679 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600/config.json
[INFO|configuration_utils.py:595] 2024-05-14 19:53:44,683 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600/generation_config.json
[INFO|modeling_utils.py:2540] 2024-05-14 19:54:00,984 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-05-14 19:54:00,989 >> tokenizer config file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-05-14 19:54:00,992 >> Special tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-05-14 19:54:00,993 >> added tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600/added_tokens.json
[INFO|trainer.py:3071] 2024-05-14 19:54:01,899 >> Deleting older checkpoint [/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/checkpoint-400] due to args.save_total_limit
 57%|█████▋    | 601/1058 [21:31:12<17:18:02, 136.29s/it] 57%|█████▋    | 602/1058 [21:33:21<16:59:50, 134.19s/it] 57%|█████▋    | 603/1058 [21:35:31<16:46:26, 132.72s/it] 57%|█████▋    | 604/1058 [21:37:40<16:36:37, 131.71s/it] 57%|█████▋    | 605/1058 [21:39:49<16:28:52, 130.98s/it] 57%|█████▋    | 606/1058 [21:41:59<16:23:04, 130.50s/it] 57%|█████▋    | 607/1058 [21:44:08<16:17:56, 130.10s/it] 57%|█████▋    | 608/1058 [21:46:17<16:13:25, 129.79s/it] 58%|█████▊    | 609/1058 [21:48:25<16:08:14, 129.39s/it] 58%|█████▊    | 610/1058 [21:50:35<16:05:39, 129.33s/it]                                                         {'loss': 2.0504, 'learning_rate': 1.9044834257452995e-05, 'epoch': 0.58}
 58%|█████▊    | 610/1058 [21:50:35<16:05:39, 129.33s/it] 58%|█████▊    | 611/1058 [21:52:44<16:03:31, 129.33s/it] 58%|█████▊    | 612/1058 [21:54:54<16:02:02, 129.42s/it] 58%|█████▊    | 613/1058 [21:57:03<15:59:34, 129.38s/it] 58%|█████▊    | 614/1058 [21:59:12<15:56:04, 129.20s/it] 58%|█████▊    | 615/1058 [22:01:20<15:52:40, 129.03s/it] 58%|█████▊    | 616/1058 [22:03:30<15:50:55, 129.08s/it] 58%|█████▊    | 617/1058 [22:05:39<15:49:04, 129.12s/it] 58%|█████▊    | 618/1058 [22:07:48<15:47:24, 129.19s/it] 59%|█████▊    | 619/1058 [22:09:57<15:45:19, 129.20s/it] 59%|█████▊    | 620/1058 [22:12:07<15:43:11, 129.20s/it]                                                         {'loss': 2.0383, 'learning_rate': 1.8326591775793543e-05, 'epoch': 0.59}
 59%|█████▊    | 620/1058 [22:12:07<15:43:11, 129.20s/it] 59%|█████▊    | 621/1058 [22:14:15<15:39:02, 128.93s/it] 59%|█████▉    | 622/1058 [22:16:24<15:37:24, 129.00s/it] 59%|█████▉    | 623/1058 [22:18:33<15:35:43, 129.06s/it] 59%|█████▉    | 624/1058 [22:20:42<15:33:59, 129.12s/it] 59%|█████▉    | 625/1058 [22:22:52<15:32:13, 129.18s/it] 59%|█████▉    | 626/1058 [22:25:01<15:30:08, 129.19s/it] 59%|█████▉    | 627/1058 [22:27:10<15:28:24, 129.25s/it] 59%|█████▉    | 628/1058 [22:29:19<15:25:40, 129.16s/it] 59%|█████▉    | 629/1058 [22:31:28<15:21:28, 128.88s/it] 60%|█████▉    | 630/1058 [22:33:36<15:19:16, 128.87s/it]                                                         {'loss': 2.0382, 'learning_rate': 1.761423290839075e-05, 'epoch': 0.6}
 60%|█████▉    | 630/1058 [22:33:36<15:19:16, 128.87s/it] 60%|█████▉    | 631/1058 [22:35:45<15:15:43, 128.67s/it] 60%|█████▉    | 632/1058 [22:37:54<15:14:34, 128.81s/it] 60%|█████▉    | 633/1058 [22:40:02<15:10:48, 128.59s/it] 60%|█████▉    | 634/1058 [22:42:11<15:09:43, 128.74s/it] 60%|██████    | 635/1058 [22:44:20<15:07:54, 128.78s/it] 60%|██████    | 636/1058 [22:46:28<15:04:29, 128.60s/it] 60%|██████    | 637/1058 [22:48:37<15:03:51, 128.82s/it] 60%|██████    | 638/1058 [22:50:47<15:03:05, 129.01s/it] 60%|██████    | 639/1058 [22:52:56<15:01:38, 129.11s/it] 60%|██████    | 640/1058 [22:55:05<14:59:57, 129.18s/it]                                                         {'loss': 2.0478, 'learning_rate': 1.6908385706855908e-05, 'epoch': 0.6}
 60%|██████    | 640/1058 [22:55:05<14:59:57, 129.18s/it] 61%|██████    | 641/1058 [22:57:15<14:58:05, 129.22s/it] 61%|██████    | 642/1058 [22:59:24<14:56:12, 129.26s/it] 61%|██████    | 643/1058 [23:01:33<14:54:07, 129.27s/it] 61%|██████    | 644/1058 [23:03:43<14:51:57, 129.27s/it] 61%|██████    | 645/1058 [23:05:52<14:50:01, 129.30s/it] 61%|██████    | 646/1058 [23:08:01<14:48:05, 129.33s/it] 61%|██████    | 647/1058 [23:10:11<14:46:06, 129.36s/it] 61%|██████    | 648/1058 [23:12:20<14:43:42, 129.32s/it] 61%|██████▏   | 649/1058 [23:14:29<14:41:24, 129.30s/it] 61%|██████▏   | 650/1058 [23:16:39<14:39:26, 129.33s/it]                                                         {'loss': 2.0404, 'learning_rate': 1.62096724817863e-05, 'epoch': 0.61}
 61%|██████▏   | 650/1058 [23:16:39<14:39:26, 129.33s/it] 62%|██████▏   | 651/1058 [23:18:48<14:37:12, 129.32s/it] 62%|██████▏   | 652/1058 [23:20:56<14:33:15, 129.05s/it] 62%|██████▏   | 653/1058 [23:23:06<14:31:11, 129.07s/it] 62%|██████▏   | 654/1058 [23:25:15<14:29:30, 129.13s/it] 62%|██████▏   | 655/1058 [23:27:24<14:27:31, 129.16s/it] 62%|██████▏   | 656/1058 [23:29:32<14:23:16, 128.85s/it] 62%|██████▏   | 657/1058 [23:31:41<14:21:43, 128.94s/it] 62%|██████▏   | 658/1058 [23:33:51<14:20:25, 129.06s/it] 62%|██████▏   | 659/1058 [23:36:00<14:17:53, 129.01s/it] 62%|██████▏   | 660/1058 [23:38:08<14:14:26, 128.81s/it]                                                         {'loss': 2.0242, 'learning_rate': 1.551870925410472e-05, 'epoch': 0.62}
 62%|██████▏   | 660/1058 [23:38:08<14:14:26, 128.81s/it] 62%|██████▏   | 661/1058 [23:40:17<14:13:06, 128.93s/it] 63%|██████▎   | 662/1058 [23:42:27<14:11:45, 129.05s/it] 63%|██████▎   | 663/1058 [23:44:36<14:09:43, 129.07s/it] 63%|██████▎   | 664/1058 [23:46:44<14:05:52, 128.81s/it] 63%|██████▎   | 665/1058 [23:48:53<14:03:58, 128.85s/it] 63%|██████▎   | 666/1058 [23:51:01<14:00:05, 128.59s/it] 63%|██████▎   | 667/1058 [23:53:10<13:59:15, 128.79s/it] 63%|██████▎   | 668/1058 [23:55:19<13:57:57, 128.92s/it] 63%|██████▎   | 669/1058 [23:57:27<13:54:18, 128.68s/it] 63%|██████▎   | 670/1058 [23:59:36<13:53:03, 128.82s/it]                                                         {'loss': 2.0144, 'learning_rate': 1.483610521194419e-05, 'epoch': 0.63}
 63%|██████▎   | 670/1058 [23:59:37<13:53:03, 128.82s/it] 63%|██████▎   | 671/1058 [24:01:46<13:51:53, 128.97s/it] 64%|██████▎   | 672/1058 [24:03:55<13:50:25, 129.08s/it] 64%|██████▎   | 673/1058 [24:06:04<13:48:40, 129.14s/it] 64%|██████▎   | 674/1058 [24:08:14<13:46:57, 129.21s/it] 64%|██████▍   | 675/1058 [24:10:23<13:44:46, 129.21s/it] 64%|██████▍   | 676/1058 [24:12:32<13:42:51, 129.25s/it] 64%|██████▍   | 677/1058 [24:14:42<13:40:56, 129.28s/it] 64%|██████▍   | 678/1058 [24:16:51<13:38:45, 129.28s/it] 64%|██████▍   | 679/1058 [24:18:59<13:34:13, 128.90s/it] 64%|██████▍   | 680/1058 [24:21:08<13:32:25, 128.96s/it]                                                         {'loss': 2.0088, 'learning_rate': 1.4162462173557007e-05, 'epoch': 0.64}
 64%|██████▍   | 680/1058 [24:21:08<13:32:25, 128.96s/it] 64%|██████▍   | 681/1058 [24:23:17<13:30:49, 129.04s/it] 64%|██████▍   | 682/1058 [24:25:27<13:29:35, 129.19s/it] 65%|██████▍   | 683/1058 [24:27:36<13:27:56, 129.27s/it] 65%|██████▍   | 684/1058 [24:29:45<13:23:45, 128.94s/it] 65%|██████▍   | 685/1058 [24:31:54<13:21:46, 128.97s/it] 65%|██████▍   | 686/1058 [24:34:03<13:20:05, 129.05s/it] 65%|██████▍   | 687/1058 [24:36:12<13:18:28, 129.13s/it] 65%|██████▌   | 688/1058 [24:38:22<13:16:51, 129.22s/it] 65%|██████▌   | 689/1058 [24:40:31<13:14:50, 129.24s/it] 65%|██████▌   | 690/1058 [24:42:40<13:12:56, 129.28s/it]                                                         {'loss': 2.004, 'learning_rate': 1.3498374056721197e-05, 'epoch': 0.65}
 65%|██████▌   | 690/1058 [24:42:40<13:12:56, 129.28s/it] 65%|██████▌   | 691/1058 [24:44:49<13:10:38, 129.26s/it] 65%|██████▌   | 692/1058 [24:46:59<13:08:36, 129.28s/it] 66%|██████▌   | 693/1058 [24:49:08<13:06:31, 129.29s/it] 66%|██████▌   | 694/1058 [24:51:17<13:04:29, 129.31s/it] 66%|██████▌   | 695/1058 [24:53:27<13:02:11, 129.29s/it] 66%|██████▌   | 696/1058 [24:55:36<13:00:02, 129.29s/it] 66%|██████▌   | 697/1058 [24:57:45<12:57:58, 129.30s/it] 66%|██████▌   | 698/1058 [24:59:54<12:55:09, 129.19s/it] 66%|██████▌   | 699/1058 [25:02:02<12:51:09, 128.89s/it] 66%|██████▌   | 700/1058 [25:04:12<12:49:49, 129.02s/it]                                                         {'loss': 1.9988, 'learning_rate': 1.2844426355112657e-05, 'epoch': 0.66}
 66%|██████▌   | 700/1058 [25:04:12<12:49:49, 129.02s/it] 66%|██████▋   | 701/1058 [25:06:21<12:48:11, 129.11s/it] 66%|██████▋   | 702/1058 [25:08:30<12:46:33, 129.20s/it] 66%|██████▋   | 703/1058 [25:10:39<12:42:31, 128.88s/it] 67%|██████▋   | 704/1058 [25:12:47<12:40:17, 128.86s/it] 67%|██████▋   | 705/1058 [25:14:57<12:39:01, 129.01s/it] 67%|██████▋   | 706/1058 [25:17:06<12:37:11, 129.07s/it] 67%|██████▋   | 707/1058 [25:19:15<12:35:40, 129.18s/it] 67%|██████▋   | 708/1058 [25:21:25<12:33:52, 129.24s/it] 67%|██████▋   | 709/1058 [25:23:34<12:31:24, 129.18s/it] 67%|██████▋   | 710/1058 [25:25:42<12:27:15, 128.84s/it]                                                         {'loss': 1.9897, 'learning_rate': 1.2201195622104264e-05, 'epoch': 0.67}
 67%|██████▋   | 710/1058 [25:25:42<12:27:15, 128.84s/it] 67%|██████▋   | 711/1058 [25:27:51<12:25:46, 128.95s/it] 67%|██████▋   | 712/1058 [25:30:00<12:23:58, 129.01s/it] 67%|██████▋   | 713/1058 [25:32:09<12:22:11, 129.08s/it] 67%|██████▋   | 714/1058 [25:34:19<12:20:23, 129.14s/it] 68%|██████▊   | 715/1058 [25:36:28<12:18:31, 129.19s/it] 68%|██████▊   | 716/1058 [25:38:37<12:16:45, 129.26s/it] 68%|██████▊   | 717/1058 [25:40:47<12:14:50, 129.30s/it] 68%|██████▊   | 718/1058 [25:42:55<12:11:09, 129.03s/it] 68%|██████▊   | 719/1058 [25:45:04<12:08:57, 129.02s/it] 68%|██████▊   | 720/1058 [25:47:14<12:07:26, 129.13s/it]                                                         {'loss': 1.9818, 'learning_rate': 1.1569248962447279e-05, 'epoch': 0.68}
 68%|██████▊   | 720/1058 [25:47:14<12:07:26, 129.13s/it] 68%|██████▊   | 721/1058 [25:49:23<12:05:26, 129.16s/it] 68%|██████▊   | 722/1058 [25:51:32<12:03:29, 129.20s/it] 68%|██████▊   | 723/1058 [25:53:41<12:01:34, 129.24s/it] 68%|██████▊   | 724/1058 [25:55:51<11:59:39, 129.28s/it] 69%|██████▊   | 725/1058 [25:58:00<11:57:42, 129.32s/it] 69%|██████▊   | 726/1058 [26:00:10<11:55:33, 129.32s/it] 69%|██████▊   | 727/1058 [26:02:19<11:53:22, 129.31s/it] 69%|██████▉   | 728/1058 [26:04:28<11:50:24, 129.17s/it] 69%|██████▉   | 729/1058 [26:06:36<11:47:35, 129.04s/it] 69%|██████▉   | 730/1058 [26:08:46<11:45:44, 129.10s/it]                                                         {'loss': 1.9812, 'learning_rate': 1.0949143532283108e-05, 'epoch': 0.69}
 69%|██████▉   | 730/1058 [26:08:46<11:45:44, 129.10s/it] 69%|██████▉   | 731/1058 [26:10:55<11:43:48, 129.14s/it] 69%|██████▉   | 732/1058 [26:13:04<11:41:45, 129.16s/it] 69%|██████▉   | 733/1058 [26:15:13<11:39:52, 129.21s/it] 69%|██████▉   | 734/1058 [26:17:23<11:37:38, 129.19s/it] 69%|██████▉   | 735/1058 [26:19:32<11:35:44, 129.24s/it] 70%|██████▉   | 736/1058 [26:21:41<11:33:54, 129.30s/it] 70%|██████▉   | 737/1058 [26:23:51<11:32:07, 129.37s/it] 70%|██████▉   | 738/1058 [26:26:00<11:30:06, 129.39s/it] 70%|██████▉   | 739/1058 [26:28:10<11:28:15, 129.45s/it] 70%|██████▉   | 740/1058 [26:30:19<11:25:48, 129.40s/it]                                                         {'loss': 1.9706, 'learning_rate': 1.0341426047926252e-05, 'epoch': 0.7}
 70%|██████▉   | 740/1058 [26:30:19<11:25:48, 129.40s/it] 70%|███████   | 741/1058 [26:32:29<11:23:28, 129.37s/it] 70%|███████   | 742/1058 [26:34:37<11:19:11, 128.96s/it] 70%|███████   | 743/1058 [26:36:46<11:17:19, 129.01s/it] 70%|███████   | 744/1058 [26:38:55<11:15:49, 129.14s/it] 70%|███████   | 745/1058 [26:41:04<11:12:37, 128.94s/it] 71%|███████   | 746/1058 [26:43:12<11:10:04, 128.86s/it] 71%|███████   | 747/1058 [26:45:22<11:08:57, 129.06s/it] 71%|███████   | 748/1058 [26:47:31<11:06:32, 129.01s/it] 71%|███████   | 749/1058 [26:49:39<11:02:54, 128.72s/it] 71%|███████   | 750/1058 [26:51:48<11:01:35, 128.88s/it]                                                         {'loss': 1.9707, 'learning_rate': 9.746632303851569e-06, 'epoch': 0.71}
 71%|███████   | 750/1058 [26:51:48<11:01:35, 128.88s/it] 71%|███████   | 751/1058 [26:53:57<11:00:12, 129.03s/it] 71%|███████   | 752/1058 [26:56:07<10:58:42, 129.16s/it] 71%|███████   | 753/1058 [26:58:16<10:56:45, 129.20s/it] 71%|███████▏  | 754/1058 [27:00:26<10:55:01, 129.28s/it] 71%|███████▏  | 755/1058 [27:02:35<10:52:58, 129.30s/it] 71%|███████▏  | 756/1058 [27:04:44<10:50:50, 129.31s/it] 72%|███████▏  | 757/1058 [27:06:54<10:48:47, 129.33s/it] 72%|███████▏  | 758/1058 [27:09:03<10:46:38, 129.33s/it] 72%|███████▏  | 759/1058 [27:11:12<10:44:29, 129.33s/it] 72%|███████▏  | 760/1058 [27:13:22<10:42:23, 129.34s/it]                                                         {'loss': 1.966, 'learning_rate': 9.165286700310746e-06, 'epoch': 0.72}
 72%|███████▏  | 760/1058 [27:13:22<10:42:23, 129.34s/it] 72%|███████▏  | 761/1058 [27:15:31<10:40:05, 129.31s/it] 72%|███████▏  | 762/1058 [27:17:40<10:38:04, 129.34s/it] 72%|███████▏  | 763/1058 [27:19:50<10:35:59, 129.35s/it] 72%|███████▏  | 764/1058 [27:21:59<10:33:54, 129.37s/it] 72%|███████▏  | 765/1058 [27:24:08<10:31:43, 129.36s/it] 72%|███████▏  | 766/1058 [27:26:18<10:29:38, 129.38s/it] 72%|███████▏  | 767/1058 [27:28:27<10:27:28, 129.38s/it] 73%|███████▎  | 768/1058 [27:30:37<10:25:35, 129.43s/it] 73%|███████▎  | 769/1058 [27:32:46<10:23:24, 129.43s/it] 73%|███████▎  | 770/1058 [27:34:55<10:21:01, 129.38s/it]                                                         {'loss': 1.9569, 'learning_rate': 8.597901780994524e-06, 'epoch': 0.73}
 73%|███████▎  | 770/1058 [27:34:55<10:21:01, 129.38s/it] 73%|███████▎  | 771/1058 [27:37:05<10:18:45, 129.36s/it] 73%|███████▎  | 772/1058 [27:39:13<10:15:10, 129.06s/it] 73%|███████▎  | 773/1058 [27:41:22<10:13:11, 129.09s/it] 73%|███████▎  | 774/1058 [27:43:31<10:11:01, 129.09s/it] 73%|███████▎  | 775/1058 [27:45:40<10:07:55, 128.89s/it] 73%|███████▎  | 776/1058 [27:47:49<10:06:24, 129.02s/it] 73%|███████▎  | 777/1058 [27:49:59<10:04:44, 129.13s/it] 74%|███████▎  | 778/1058 [27:52:08<10:02:56, 129.20s/it] 74%|███████▎  | 779/1058 [27:54:17<10:01:02, 129.26s/it] 74%|███████▎  | 780/1058 [27:56:27<9:59:09, 129.31s/it]                                                         {'loss': 1.9535, 'learning_rate': 8.044977781148242e-06, 'epoch': 0.74}
 74%|███████▎  | 780/1058 [27:56:27<9:59:09, 129.31s/it] 74%|███████▍  | 781/1058 [27:58:36<9:57:19, 129.39s/it] 74%|███████▍  | 782/1058 [28:00:46<9:55:25, 129.44s/it] 74%|███████▍  | 783/1058 [28:02:55<9:53:21, 129.46s/it] 74%|███████▍  | 784/1058 [28:05:05<9:51:14, 129.47s/it] 74%|███████▍  | 785/1058 [28:07:14<9:48:38, 129.37s/it] 74%|███████▍  | 786/1058 [28:09:22<9:44:55, 129.03s/it] 74%|███████▍  | 787/1058 [28:11:32<9:43:16, 129.14s/it] 74%|███████▍  | 788/1058 [28:13:41<9:41:29, 129.22s/it] 75%|███████▍  | 789/1058 [28:15:51<9:39:42, 129.30s/it] 75%|███████▍  | 790/1058 [28:18:00<9:37:47, 129.36s/it]                                                        {'loss': 1.9481, 'learning_rate': 7.507002186539147e-06, 'epoch': 0.75}
 75%|███████▍  | 790/1058 [28:18:00<9:37:47, 129.36s/it] 75%|███████▍  | 791/1058 [28:20:10<9:35:54, 129.42s/it] 75%|███████▍  | 792/1058 [28:22:18<9:32:11, 129.07s/it] 75%|███████▍  | 793/1058 [28:24:27<9:29:37, 128.97s/it] 75%|███████▌  | 794/1058 [28:26:35<9:26:45, 128.81s/it] 75%|███████▌  | 795/1058 [28:28:44<9:24:39, 128.82s/it] 75%|███████▌  | 796/1058 [28:30:53<9:23:05, 128.95s/it] 75%|███████▌  | 797/1058 [28:33:02<9:21:21, 129.05s/it] 75%|███████▌  | 798/1058 [28:35:12<9:19:28, 129.11s/it] 76%|███████▌  | 799/1058 [28:37:21<9:17:46, 129.22s/it] 76%|███████▌  | 800/1058 [28:39:30<9:15:53, 129.28s/it]                                                        {'loss': 1.9446, 'learning_rate': 6.984449303664287e-06, 'epoch': 0.76}
 76%|███████▌  | 800/1058 [28:39:30<9:15:53, 129.28s/it][INFO|trainer.py:2979] 2024-05-15 03:04:37,146 >> Saving model checkpoint to /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800
[INFO|configuration_utils.py:473] 2024-05-15 03:04:37,152 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800/config.json
[INFO|configuration_utils.py:595] 2024-05-15 03:04:37,157 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800/generation_config.json
[INFO|modeling_utils.py:2540] 2024-05-15 03:04:53,977 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-05-15 03:04:53,985 >> tokenizer config file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-05-15 03:04:53,989 >> Special tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-05-15 03:04:53,993 >> added tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800/added_tokens.json
[INFO|trainer.py:3071] 2024-05-15 03:04:54,916 >> Deleting older checkpoint [/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/checkpoint-600] due to args.save_total_limit
 76%|███████▌  | 801/1058 [28:42:06<9:47:01, 137.05s/it] 76%|███████▌  | 802/1058 [28:44:15<9:35:02, 134.77s/it] 76%|███████▌  | 803/1058 [28:46:25<9:26:00, 133.18s/it] 76%|███████▌  | 804/1058 [28:48:34<9:19:11, 132.09s/it] 76%|███████▌  | 805/1058 [28:50:44<9:13:40, 131.31s/it] 76%|███████▌  | 806/1058 [28:52:53<9:09:11, 130.76s/it] 76%|███████▋  | 807/1058 [28:55:03<9:05:24, 130.38s/it] 76%|███████▋  | 808/1058 [28:57:12<9:02:14, 130.14s/it] 76%|███████▋  | 809/1058 [28:59:21<8:58:46, 129.83s/it] 77%|███████▋  | 810/1058 [29:01:30<8:55:02, 129.45s/it]                                                        {'loss': 1.9438, 'learning_rate': 6.477779841577899e-06, 'epoch': 0.77}
 77%|███████▋  | 810/1058 [29:01:30<8:55:02, 129.45s/it] 77%|███████▋  | 811/1058 [29:03:39<8:52:52, 129.44s/it] 77%|███████▋  | 812/1058 [29:05:49<8:50:48, 129.47s/it] 77%|███████▋  | 813/1058 [29:07:58<8:48:37, 129.46s/it] 77%|███████▋  | 814/1058 [29:10:08<8:46:25, 129.45s/it] 77%|███████▋  | 815/1058 [29:12:16<8:43:29, 129.26s/it] 77%|███████▋  | 816/1058 [29:14:25<8:40:30, 129.05s/it] 77%|███████▋  | 817/1058 [29:16:34<8:38:51, 129.18s/it] 77%|███████▋  | 818/1058 [29:18:44<8:36:56, 129.24s/it] 77%|███████▋  | 819/1058 [29:20:53<8:35:03, 129.30s/it] 78%|███████▊  | 820/1058 [29:23:03<8:33:01, 129.34s/it]                                                        {'loss': 1.9396, 'learning_rate': 5.987440505707023e-06, 'epoch': 0.77}
 78%|███████▊  | 820/1058 [29:23:03<8:33:01, 129.34s/it] 78%|███████▊  | 821/1058 [29:25:12<8:30:59, 129.36s/it] 78%|███████▊  | 822/1058 [29:27:22<8:28:59, 129.41s/it] 78%|███████▊  | 823/1058 [29:29:31<8:26:52, 129.41s/it] 78%|███████▊  | 824/1058 [29:31:41<8:24:44, 129.42s/it] 78%|███████▊  | 825/1058 [29:33:50<8:22:28, 129.39s/it] 78%|███████▊  | 826/1058 [29:35:59<8:20:20, 129.40s/it] 78%|███████▊  | 827/1058 [29:38:08<8:16:55, 129.07s/it] 78%|███████▊  | 828/1058 [29:40:17<8:14:59, 129.13s/it] 78%|███████▊  | 829/1058 [29:42:26<8:13:10, 129.21s/it] 78%|███████▊  | 830/1058 [29:44:36<8:11:23, 129.31s/it]                                                        {'loss': 1.9329, 'learning_rate': 5.5138636040133555e-06, 'epoch': 0.78}
 78%|███████▊  | 830/1058 [29:44:36<8:11:23, 129.31s/it] 79%|███████▊  | 831/1058 [29:46:45<8:09:33, 129.40s/it] 79%|███████▊  | 832/1058 [29:48:55<8:07:20, 129.38s/it] 79%|███████▊  | 833/1058 [29:51:04<8:05:17, 129.41s/it] 79%|███████▉  | 834/1058 [29:53:14<8:03:12, 129.43s/it] 79%|███████▉  | 835/1058 [29:55:23<8:01:02, 129.43s/it] 79%|███████▉  | 836/1058 [29:57:33<7:58:53, 129.43s/it] 79%|███████▉  | 837/1058 [29:59:42<7:56:46, 129.44s/it] 79%|███████▉  | 838/1058 [30:01:51<7:54:36, 129.44s/it] 79%|███████▉  | 839/1058 [30:04:01<7:52:29, 129.45s/it] 79%|███████▉  | 840/1058 [30:06:10<7:50:12, 129.41s/it]                                                        {'loss': 1.9323, 'learning_rate': 5.057466665848757e-06, 'epoch': 0.79}
 79%|███████▉  | 840/1058 [30:06:10<7:50:12, 129.41s/it] 79%|███████▉  | 841/1058 [30:08:19<7:47:16, 129.20s/it] 80%|███████▉  | 842/1058 [30:10:28<7:44:36, 129.06s/it] 80%|███████▉  | 843/1058 [30:12:37<7:42:16, 129.01s/it] 80%|███████▉  | 844/1058 [30:14:45<7:39:26, 128.82s/it] 80%|███████▉  | 845/1058 [30:16:54<7:37:51, 128.97s/it] 80%|███████▉  | 846/1058 [30:19:03<7:35:08, 128.81s/it] 80%|████████  | 847/1058 [30:21:12<7:33:09, 128.86s/it] 80%|████████  | 848/1058 [30:23:21<7:31:30, 129.00s/it] 80%|████████  | 849/1058 [30:25:30<7:29:39, 129.09s/it] 80%|████████  | 850/1058 [30:27:39<7:27:08, 128.98s/it]                                                        {'loss': 1.9289, 'learning_rate': 4.618652073840188e-06, 'epoch': 0.8}
 80%|████████  | 850/1058 [30:27:39<7:27:08, 128.98s/it] 80%|████████  | 851/1058 [30:29:47<7:24:24, 128.81s/it] 81%|████████  | 852/1058 [30:31:56<7:22:24, 128.86s/it] 81%|████████  | 853/1058 [30:34:05<7:19:29, 128.63s/it] 81%|████████  | 854/1058 [30:36:14<7:17:55, 128.80s/it] 81%|████████  | 855/1058 [30:38:22<7:15:01, 128.58s/it] 81%|████████  | 856/1058 [30:40:31<7:13:28, 128.75s/it] 81%|████████  | 857/1058 [30:42:39<7:10:47, 128.59s/it] 81%|████████  | 858/1058 [30:44:48<7:08:57, 128.69s/it] 81%|████████  | 859/1058 [30:46:57<7:06:42, 128.66s/it] 81%|████████▏ | 860/1058 [30:49:06<7:04:47, 128.73s/it]                                                        {'loss': 1.9222, 'learning_rate': 4.197806709128865e-06, 'epoch': 0.81}
 81%|████████▏ | 860/1058 [30:49:06<7:04:47, 128.73s/it] 81%|████████▏ | 861/1058 [30:51:14<7:02:17, 128.61s/it] 81%|████████▏ | 862/1058 [30:53:23<7:00:42, 128.79s/it] 82%|████████▏ | 863/1058 [30:55:33<6:59:13, 128.99s/it] 82%|████████▏ | 864/1058 [30:57:42<6:57:17, 129.06s/it] 82%|████████▏ | 865/1058 [30:59:50<6:54:25, 128.84s/it] 82%|████████▏ | 866/1058 [31:01:59<6:52:42, 128.97s/it] 82%|████████▏ | 867/1058 [31:04:08<6:50:19, 128.90s/it] 82%|████████▏ | 868/1058 [31:06:17<6:47:47, 128.78s/it] 82%|████████▏ | 869/1058 [31:08:26<6:45:59, 128.89s/it] 82%|████████▏ | 870/1058 [31:10:34<6:43:06, 128.65s/it]                                                        {'loss': 1.9245, 'learning_rate': 3.7953016102762696e-06, 'epoch': 0.82}
 82%|████████▏ | 870/1058 [31:10:34<6:43:06, 128.65s/it] 82%|████████▏ | 871/1058 [31:12:43<6:41:26, 128.81s/it] 82%|████████▏ | 872/1058 [31:14:53<6:39:58, 129.03s/it] 83%|████████▎ | 873/1058 [31:17:02<6:38:20, 129.19s/it] 83%|████████▎ | 874/1058 [31:19:12<6:36:21, 129.25s/it] 83%|████████▎ | 875/1058 [31:21:20<6:33:09, 128.90s/it] 83%|████████▎ | 876/1058 [31:23:29<6:31:03, 128.92s/it] 83%|████████▎ | 877/1058 [31:25:38<6:29:26, 129.09s/it] 83%|████████▎ | 878/1058 [31:27:47<6:26:43, 128.91s/it] 83%|████████▎ | 879/1058 [31:29:55<6:24:28, 128.88s/it] 83%|████████▎ | 880/1058 [31:32:05<6:22:50, 129.05s/it]                                                        {'loss': 1.9252, 'learning_rate': 3.4114916461377625e-06, 'epoch': 0.83}
 83%|████████▎ | 880/1058 [31:32:05<6:22:50, 129.05s/it] 83%|████████▎ | 881/1058 [31:34:14<6:21:01, 129.16s/it] 83%|████████▎ | 882/1058 [31:36:23<6:18:56, 129.18s/it] 83%|████████▎ | 883/1058 [31:38:33<6:16:53, 129.22s/it] 84%|████████▎ | 884/1058 [31:40:42<6:14:50, 129.25s/it] 84%|████████▎ | 885/1058 [31:42:51<6:12:47, 129.29s/it] 84%|████████▎ | 886/1058 [31:45:01<6:10:43, 129.32s/it] 84%|████████▍ | 887/1058 [31:47:10<6:08:34, 129.33s/it] 84%|████████▍ | 888/1058 [31:49:20<6:06:27, 129.34s/it] 84%|████████▍ | 889/1058 [31:51:29<6:04:20, 129.35s/it] 84%|████████▍ | 890/1058 [31:53:38<6:02:16, 129.38s/it]                                                        {'loss': 1.9178, 'learning_rate': 3.0467152029922926e-06, 'epoch': 0.84}
 84%|████████▍ | 890/1058 [31:53:38<6:02:16, 129.38s/it] 84%|████████▍ | 891/1058 [31:55:48<6:00:07, 129.39s/it] 84%|████████▍ | 892/1058 [31:57:57<5:57:58, 129.39s/it] 84%|████████▍ | 893/1058 [32:00:07<5:55:48, 129.39s/it] 84%|████████▍ | 894/1058 [32:02:16<5:53:38, 129.38s/it] 85%|████████▍ | 895/1058 [32:04:25<5:51:31, 129.40s/it] 85%|████████▍ | 896/1058 [32:06:34<5:49:04, 129.29s/it] 85%|████████▍ | 897/1058 [32:08:43<5:46:22, 129.08s/it] 85%|████████▍ | 898/1058 [32:10:52<5:44:26, 129.16s/it] 85%|████████▍ | 899/1058 [32:13:02<5:42:28, 129.23s/it] 85%|████████▌ | 900/1058 [32:15:11<5:40:26, 129.28s/it]                                                        {'loss': 1.924, 'learning_rate': 2.701293886203912e-06, 'epoch': 0.85}
 85%|████████▌ | 900/1058 [32:15:11<5:40:26, 129.28s/it] 85%|████████▌ | 901/1058 [32:17:21<5:38:22, 129.32s/it] 85%|████████▌ | 902/1058 [32:19:30<5:36:18, 129.35s/it] 85%|████████▌ | 903/1058 [32:21:39<5:34:11, 129.37s/it] 85%|████████▌ | 904/1058 [32:23:49<5:32:01, 129.36s/it] 86%|████████▌ | 905/1058 [32:25:58<5:29:52, 129.36s/it] 86%|████████▌ | 906/1058 [32:28:08<5:27:44, 129.37s/it] 86%|████████▌ | 907/1058 [32:30:17<5:25:38, 129.40s/it] 86%|████████▌ | 908/1058 [32:32:26<5:23:32, 129.42s/it] 86%|████████▌ | 909/1058 [32:34:36<5:21:19, 129.39s/it] 86%|████████▌ | 910/1058 [32:36:45<5:19:10, 129.39s/it]                                                        {'loss': 1.9157, 'learning_rate': 2.3755322366782155e-06, 'epoch': 0.86}
 86%|████████▌ | 910/1058 [32:36:45<5:19:10, 129.39s/it] 86%|████████▌ | 911/1058 [32:38:54<5:16:58, 129.38s/it] 86%|████████▌ | 912/1058 [32:41:04<5:14:48, 129.37s/it] 86%|████████▋ | 913/1058 [32:43:13<5:12:42, 129.40s/it] 86%|████████▋ | 914/1058 [32:45:23<5:10:34, 129.41s/it] 86%|████████▋ | 915/1058 [32:47:32<5:08:23, 129.40s/it] 87%|████████▋ | 916/1058 [32:49:42<5:06:15, 129.41s/it] 87%|████████▋ | 917/1058 [32:51:51<5:04:09, 129.43s/it] 87%|████████▋ | 918/1058 [32:54:00<5:01:57, 129.41s/it] 87%|████████▋ | 919/1058 [32:56:09<4:59:27, 129.26s/it] 87%|████████▋ | 920/1058 [32:58:17<4:56:31, 128.92s/it]                                                        {'loss': 1.9178, 'learning_rate': 2.0697174623636794e-06, 'epoch': 0.87}
 87%|████████▋ | 920/1058 [32:58:17<4:56:31, 128.92s/it] 87%|████████▋ | 921/1058 [33:00:27<4:54:37, 129.04s/it] 87%|████████▋ | 922/1058 [33:02:36<4:52:42, 129.13s/it] 87%|████████▋ | 923/1058 [33:04:45<4:50:40, 129.19s/it] 87%|████████▋ | 924/1058 [33:06:55<4:48:37, 129.24s/it] 87%|████████▋ | 925/1058 [33:09:04<4:46:33, 129.27s/it] 88%|████████▊ | 926/1058 [33:11:12<4:43:45, 128.98s/it] 88%|████████▊ | 927/1058 [33:13:21<4:41:35, 128.97s/it] 88%|████████▊ | 928/1058 [33:15:31<4:39:38, 129.07s/it] 88%|████████▊ | 929/1058 [33:17:40<4:37:41, 129.16s/it] 88%|████████▊ | 930/1058 [33:19:49<4:35:38, 129.21s/it]                                                        {'loss': 1.9139, 'learning_rate': 1.7841191850345967e-06, 'epoch': 0.88}
 88%|████████▊ | 930/1058 [33:19:49<4:35:38, 129.21s/it] 88%|████████▊ | 931/1058 [33:21:59<4:33:36, 129.26s/it] 88%|████████▊ | 932/1058 [33:24:08<4:31:34, 129.32s/it] 88%|████████▊ | 933/1058 [33:26:18<4:29:28, 129.34s/it] 88%|████████▊ | 934/1058 [33:28:27<4:27:20, 129.36s/it] 88%|████████▊ | 935/1058 [33:30:36<4:25:13, 129.37s/it] 88%|████████▊ | 936/1058 [33:32:46<4:23:05, 129.39s/it] 89%|████████▊ | 937/1058 [33:34:55<4:20:53, 129.37s/it] 89%|████████▊ | 938/1058 [33:37:04<4:18:40, 129.34s/it] 89%|████████▉ | 939/1058 [33:39:14<4:16:32, 129.35s/it] 89%|████████▉ | 940/1058 [33:41:22<4:13:44, 129.02s/it]                                                        {'loss': 1.9169, 'learning_rate': 1.5189892025789049e-06, 'epoch': 0.89}
 89%|████████▉ | 940/1058 [33:41:22<4:13:44, 129.02s/it] 89%|████████▉ | 941/1058 [33:43:31<4:11:31, 128.99s/it] 89%|████████▉ | 942/1058 [33:45:39<4:08:49, 128.70s/it] 89%|████████▉ | 943/1058 [33:47:48<4:07:00, 128.88s/it] 89%|████████▉ | 944/1058 [33:49:58<4:05:11, 129.05s/it] 89%|████████▉ | 945/1058 [33:52:07<4:03:12, 129.14s/it] 89%|████████▉ | 946/1058 [33:54:16<4:01:11, 129.21s/it] 90%|████████▉ | 947/1058 [33:56:26<3:59:10, 129.28s/it] 90%|████████▉ | 948/1058 [33:58:35<3:57:03, 129.30s/it] 90%|████████▉ | 949/1058 [34:00:45<3:54:56, 129.32s/it] 90%|████████▉ | 950/1058 [34:02:54<3:52:42, 129.28s/it]                                                        {'loss': 1.9118, 'learning_rate': 1.2745612670004153e-06, 'epoch': 0.9}
 90%|████████▉ | 950/1058 [34:02:54<3:52:42, 129.28s/it] 90%|████████▉ | 951/1058 [34:05:02<3:50:11, 129.08s/it] 90%|████████▉ | 952/1058 [34:07:12<3:48:09, 129.15s/it] 90%|█████████ | 953/1058 [34:09:21<3:46:09, 129.23s/it] 90%|█████████ | 954/1058 [34:11:31<3:44:05, 129.29s/it] 90%|█████████ | 955/1058 [34:13:40<3:41:59, 129.31s/it] 90%|█████████ | 956/1058 [34:15:49<3:39:51, 129.33s/it] 90%|█████████ | 957/1058 [34:17:59<3:37:43, 129.35s/it] 91%|█████████ | 958/1058 [34:20:08<3:35:34, 129.35s/it] 91%|█████████ | 959/1058 [34:22:17<3:33:26, 129.36s/it] 91%|█████████ | 960/1058 [34:24:27<3:31:17, 129.36s/it]                                                        {'loss': 1.9092, 'learning_rate': 1.0510508783312224e-06, 'epoch': 0.91}
 91%|█████████ | 960/1058 [34:24:27<3:31:17, 129.36s/it] 91%|█████████ | 961/1058 [34:26:36<3:29:09, 129.38s/it] 91%|█████████ | 962/1058 [34:28:46<3:27:00, 129.38s/it] 91%|█████████ | 963/1058 [34:30:55<3:24:52, 129.39s/it] 91%|█████████ | 964/1058 [34:33:04<3:22:42, 129.39s/it] 91%|█████████ | 965/1058 [34:35:14<3:20:32, 129.38s/it] 91%|█████████▏| 966/1058 [34:37:23<3:18:22, 129.38s/it] 91%|█████████▏| 967/1058 [34:39:33<3:16:12, 129.37s/it] 91%|█████████▏| 968/1058 [34:41:42<3:14:02, 129.36s/it] 92%|█████████▏| 969/1058 [34:43:51<3:11:53, 129.37s/it] 92%|█████████▏| 970/1058 [34:46:01<3:09:42, 129.35s/it]                                                        {'loss': 1.9094, 'learning_rate': 8.486550946359778e-07, 'epoch': 0.92}
 92%|█████████▏| 970/1058 [34:46:01<3:09:42, 129.35s/it] 92%|█████████▏| 971/1058 [34:48:10<3:07:35, 129.37s/it] 92%|█████████▏| 972/1058 [34:50:19<3:05:25, 129.36s/it] 92%|█████████▏| 973/1058 [34:52:29<3:03:16, 129.37s/it] 92%|█████████▏| 974/1058 [34:54:38<3:01:07, 129.38s/it] 92%|█████████▏| 975/1058 [34:56:48<2:59:00, 129.41s/it] 92%|█████████▏| 976/1058 [34:58:57<2:56:51, 129.41s/it] 92%|█████████▏| 977/1058 [35:01:06<2:54:41, 129.41s/it] 92%|█████████▏| 978/1058 [35:03:16<2:52:33, 129.42s/it] 93%|█████████▎| 979/1058 [35:05:25<2:50:20, 129.37s/it] 93%|█████████▎| 980/1058 [35:07:35<2:48:12, 129.39s/it]                                                        {'loss': 1.9101, 'learning_rate': 6.675523582755222e-07, 'epoch': 0.93}
 93%|█████████▎| 980/1058 [35:07:35<2:48:12, 129.39s/it] 93%|█████████▎| 981/1058 [35:09:44<2:46:03, 129.39s/it] 93%|█████████▎| 982/1058 [35:11:53<2:43:55, 129.42s/it] 93%|█████████▎| 983/1058 [35:14:03<2:41:45, 129.41s/it] 93%|█████████▎| 984/1058 [35:16:12<2:39:32, 129.36s/it] 93%|█████████▎| 985/1058 [35:18:21<2:37:22, 129.35s/it] 93%|█████████▎| 986/1058 [35:20:31<2:35:13, 129.35s/it] 93%|█████████▎| 987/1058 [35:22:40<2:33:06, 129.39s/it] 93%|█████████▎| 988/1058 [35:24:50<2:30:58, 129.41s/it] 93%|█████████▎| 989/1058 [35:26:59<2:28:46, 129.36s/it] 94%|█████████▎| 990/1058 [35:29:08<2:26:25, 129.20s/it]                                                        {'loss': 1.9082, 'learning_rate': 5.079023385830939e-07, 'epoch': 0.94}
 94%|█████████▎| 990/1058 [35:29:08<2:26:25, 129.20s/it] 94%|█████████▎| 991/1058 [35:31:16<2:23:57, 128.92s/it] 94%|█████████▍| 992/1058 [35:33:25<2:21:56, 129.04s/it] 94%|█████████▍| 993/1058 [35:35:35<2:19:53, 129.13s/it] 94%|█████████▍| 994/1058 [35:37:44<2:17:48, 129.20s/it] 94%|█████████▍| 995/1058 [35:39:53<2:15:44, 129.29s/it] 94%|█████████▍| 996/1058 [35:42:03<2:13:38, 129.33s/it] 94%|█████████▍| 997/1058 [35:44:12<2:11:29, 129.34s/it] 94%|█████████▍| 998/1058 [35:46:22<2:09:19, 129.33s/it] 94%|█████████▍| 999/1058 [35:48:31<2:07:08, 129.30s/it] 95%|█████████▍| 1000/1058 [35:50:40<2:04:58, 129.29s/it]                                                         {'loss': 1.9109, 'learning_rate': 3.6984579109176074e-07, 'epoch': 0.94}
 95%|█████████▍| 1000/1058 [35:50:40<2:04:58, 129.29s/it][INFO|trainer.py:2979] 2024-05-15 10:15:46,883 >> Saving model checkpoint to /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000
[INFO|configuration_utils.py:473] 2024-05-15 10:15:46,888 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000/config.json
[INFO|configuration_utils.py:595] 2024-05-15 10:15:46,892 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000/generation_config.json
[INFO|modeling_utils.py:2540] 2024-05-15 10:16:03,756 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-05-15 10:16:03,774 >> tokenizer config file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-05-15 10:16:03,778 >> Special tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-05-15 10:16:03,781 >> added tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000/added_tokens.json
[INFO|trainer.py:3071] 2024-05-15 10:16:04,702 >> Deleting older checkpoint [/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/checkpoint-600] due to args.save_total_limit
[INFO|trainer.py:3071] 2024-05-15 10:16:04,706 >> Deleting older checkpoint [/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/checkpoint-800] due to args.save_total_limit
 95%|█████████▍| 1001/1058 [35:53:15<2:10:12, 137.06s/it] 95%|█████████▍| 1002/1058 [35:55:25<2:05:49, 134.81s/it] 95%|█████████▍| 1003/1058 [35:57:34<2:02:01, 133.11s/it] 95%|█████████▍| 1004/1058 [35:59:42<1:58:26, 131.61s/it] 95%|█████████▍| 1005/1058 [36:01:51<1:55:34, 130.83s/it] 95%|█████████▌| 1006/1058 [36:03:59<1:52:39, 129.99s/it] 95%|█████████▌| 1007/1058 [36:06:08<1:50:16, 129.74s/it] 95%|█████████▌| 1008/1058 [36:08:18<1:48:01, 129.62s/it] 95%|█████████▌| 1009/1058 [36:10:27<1:45:48, 129.56s/it] 95%|█████████▌| 1010/1058 [36:12:36<1:43:35, 129.48s/it]                                                         {'loss': 1.9112, 'learning_rate': 2.535044334372072e-07, 'epoch': 0.95}
 95%|█████████▌| 1010/1058 [36:12:36<1:43:35, 129.48s/it] 96%|█████████▌| 1011/1058 [36:14:44<1:41:05, 129.06s/it] 96%|█████████▌| 1012/1058 [36:16:54<1:38:58, 129.09s/it] 96%|█████████▌| 1013/1058 [36:19:03<1:36:53, 129.20s/it] 96%|█████████▌| 1014/1058 [36:21:12<1:34:47, 129.25s/it] 96%|█████████▌| 1015/1058 [36:23:21<1:32:23, 128.93s/it] 96%|█████████▌| 1016/1058 [36:25:30<1:30:17, 128.98s/it] 96%|█████████▌| 1017/1058 [36:27:39<1:28:13, 129.11s/it] 96%|█████████▌| 1018/1058 [36:29:48<1:26:07, 129.20s/it] 96%|█████████▋| 1019/1058 [36:31:57<1:23:51, 129.00s/it] 96%|█████████▋| 1020/1058 [36:34:06<1:21:41, 129.00s/it]                                                         {'loss': 1.9091, 'learning_rate': 1.589808380453306e-07, 'epoch': 0.96}
 96%|█████████▋| 1020/1058 [36:34:06<1:21:41, 129.00s/it] 97%|█████████▋| 1021/1058 [36:36:16<1:19:38, 129.15s/it] 97%|█████████▋| 1022/1058 [36:38:25<1:17:31, 129.22s/it] 97%|█████████▋| 1023/1058 [36:40:34<1:15:23, 129.25s/it] 97%|█████████▋| 1024/1058 [36:42:44<1:13:15, 129.28s/it] 97%|█████████▋| 1025/1058 [36:44:53<1:11:06, 129.30s/it] 97%|█████████▋| 1026/1058 [36:47:02<1:08:57, 129.31s/it] 97%|█████████▋| 1027/1058 [36:49:12<1:06:48, 129.30s/it] 97%|█████████▋| 1028/1058 [36:51:21<1:04:38, 129.29s/it] 97%|█████████▋| 1029/1058 [36:53:29<1:02:20, 128.97s/it] 97%|█████████▋| 1030/1058 [36:55:38<1:00:13, 129.06s/it]                                                         {'loss': 1.908, 'learning_rate': 8.635834169918311e-08, 'epoch': 0.97}
 97%|█████████▋| 1030/1058 [36:55:38<1:00:13, 129.06s/it] 97%|█████████▋| 1031/1058 [36:57:48<58:07, 129.16s/it]   98%|█████████▊| 1032/1058 [36:59:57<56:00, 129.23s/it] 98%|█████████▊| 1033/1058 [37:02:06<53:51, 129.25s/it] 98%|█████████▊| 1034/1058 [37:04:16<51:42, 129.29s/it] 98%|█████████▊| 1035/1058 [37:06:25<49:34, 129.34s/it] 98%|█████████▊| 1036/1058 [37:08:35<47:25, 129.35s/it] 98%|█████████▊| 1037/1058 [37:10:44<45:16, 129.37s/it] 98%|█████████▊| 1038/1058 [37:12:52<43:01, 129.07s/it] 98%|█████████▊| 1039/1058 [37:15:02<40:52, 129.09s/it] 98%|█████████▊| 1040/1058 [37:17:11<38:44, 129.15s/it]                                                       {'loss': 1.9094, 'learning_rate': 3.5700972065066954e-08, 'epoch': 0.98}
 98%|█████████▊| 1040/1058 [37:17:11<38:44, 129.15s/it] 98%|█████████▊| 1041/1058 [37:19:20<36:36, 129.20s/it] 98%|█████████▊| 1042/1058 [37:21:29<34:23, 128.96s/it] 99%|█████████▊| 1043/1058 [37:23:37<32:13, 128.92s/it] 99%|█████████▊| 1044/1058 [37:25:47<30:06, 129.07s/it] 99%|█████████▉| 1045/1058 [37:27:56<27:58, 129.15s/it] 99%|█████████▉| 1046/1058 [37:30:05<25:50, 129.20s/it] 99%|█████████▉| 1047/1058 [37:32:15<23:41, 129.26s/it] 99%|█████████▉| 1048/1058 [37:34:24<21:33, 129.31s/it] 99%|█████████▉| 1049/1058 [37:36:34<19:24, 129.34s/it] 99%|█████████▉| 1050/1058 [37:38:43<17:14, 129.37s/it]                                                       {'loss': 1.9048, 'learning_rate': 7.053391242492491e-09, 'epoch': 0.99}
 99%|█████████▉| 1050/1058 [37:38:43<17:14, 129.37s/it] 99%|█████████▉| 1051/1058 [37:40:53<15:05, 129.39s/it] 99%|█████████▉| 1052/1058 [37:43:01<12:54, 129.09s/it]100%|█████████▉| 1053/1058 [37:45:10<10:45, 129.03s/it]100%|█████████▉| 1054/1058 [37:47:19<08:36, 129.15s/it]100%|█████████▉| 1055/1058 [37:49:29<06:27, 129.21s/it]100%|█████████▉| 1056/1058 [37:51:38<04:18, 129.22s/it]100%|█████████▉| 1057/1058 [37:53:47<02:09, 129.27s/it]100%|██████████| 1058/1058 [37:55:57<00:00, 129.31s/it][INFO|trainer.py:1988] 2024-05-15 12:20:55,124 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                       {'train_runtime': 136557.154, 'train_samples_per_second': 7.939, 'train_steps_per_second': 0.008, 'train_loss': 2.482775608848759, 'epoch': 1.0}
100%|██████████| 1058/1058 [37:55:57<00:00, 129.31s/it]100%|██████████| 1058/1058 [37:55:57<00:00, 129.07s/it]
[INFO|trainer.py:2979] 2024-05-15 12:21:03,320 >> Saving model checkpoint to /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07
[INFO|configuration_utils.py:473] 2024-05-15 12:21:03,323 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/config.json
[INFO|configuration_utils.py:595] 2024-05-15 12:21:03,328 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/generation_config.json
[2024-05-15 12:21:06,709] [INFO] [launch.py:347:main] Process 279774 exits successfully.
[2024-05-15 12:21:06,712] [INFO] [launch.py:347:main] Process 279772 exits successfully.
[2024-05-15 12:21:06,714] [INFO] [launch.py:347:main] Process 279778 exits successfully.
[2024-05-15 12:21:06,722] [INFO] [launch.py:347:main] Process 279777 exits successfully.
[2024-05-15 12:21:07,730] [INFO] [launch.py:347:main] Process 279776 exits successfully.
[2024-05-15 12:21:07,731] [INFO] [launch.py:347:main] Process 279775 exits successfully.
[2024-05-15 12:21:07,732] [INFO] [launch.py:347:main] Process 279773 exits successfully.
[INFO|modeling_utils.py:2540] 2024-05-15 12:21:23,527 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-05-15 12:21:23,533 >> tokenizer config file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-05-15 12:21:23,535 >> Special tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-05-15 12:21:23,537 >> added tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/added_tokens.json
***** train metrics *****
  epoch                    =                1.0
  train_loss               =             2.4828
  train_runtime            = 1 day, 13:55:57.15
  train_samples_per_second =              7.939
  train_steps_per_second   =              0.008
Figure saved: /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/training_loss.png
05/15/2024 12:21:25 - WARNING - llmtuner.extras.ploting - No metric eval_loss to plot.
[INFO|modelcard.py:452] 2024-05-15 12:21:25,250 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
[2024-05-15 12:21:27,832] [INFO] [launch.py:347:main] Process 279771 exits successfully.
