[2024-05-13 22:14:05,101] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:11,292] [WARNING] [runner.py:203:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-05-13 22:14:11,341] [INFO] [runner.py:570:main] cmd = /mnt/vol1/huangxin/anaconda3/envs/wzjsz/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=9902 --enable_each_rank_log=None src/train_bash.py --deepspeed /root/huangxin/nanda/llm-moe-merge/config/ds.json --stage pt --flash_attn --model_name_or_path /root/huangxin/nanda/model/Qwen1.5-7B --small_path /root/huangxin/nanda/checkpoints/merge/0.5b-bn --large_path /root/huangxin/nanda/model/Qwen1.5-7B --every_k_layers_small 3 --every_k_layers_large 4 --seed 22 --max_samples 870561 --do_train --dataset bn --preprocessing_num_workers 64 --cache_dir /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache --cutoff_len 2048 --finetuning_type ca --output_dir /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07 --overwrite_output_dir --per_device_train_batch_size 8 --gradient_accumulation_steps 16 --lr_scheduler_type cosine --logging_steps 10 --save_total_limit 1 --save_only_model --save_steps 200 --learning_rate 5e-5 --num_train_epochs 1.0 --plot_loss --bf16
[2024-05-13 22:14:12,860] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:14,585] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-05-13 22:14:14,585] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-05-13 22:14:14,585] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-05-13 22:14:14,585] [INFO] [launch.py:163:main] dist_world_size=8
[2024-05-13 22:14:14,585] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-05-13 22:14:27,112] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,113] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,114] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,115] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,117] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,117] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,117] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:27,117] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-13 22:14:38,287] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-05-13 22:14:38,288] [INFO] [comm.py:637:init_distributed] cdb=None
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 4, device: cuda:4, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 3, device: cuda:3, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=4,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=3,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 2, device: cuda:2, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 5, device: cuda:5, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 6, device: cuda:6, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=2,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 7, device: cuda:7, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=5,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=6,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=1,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=7,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
05/13/2024 22:14:38 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/root/huangxin/nanda/llm-moe-merge/config/ds.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/runs/May13_22-14-38_i-fvgceljl,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=200,
save_strategy=steps,
save_total_limit=1,
seed=22,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[INFO|tokenization_utils_base.py:2027] 2024-05-13 22:14:38,328 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2027] 2024-05-13 22:14:38,328 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2027] 2024-05-13 22:14:38,328 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2027] 2024-05-13 22:14:38,328 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2027] 2024-05-13 22:14:38,328 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2027] 2024-05-13 22:14:38,328 >> loading file tokenizer.json
[WARNING|logging.py:314] 2024-05-13 22:14:38,562 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:727] 2024-05-13 22:14:38,564 >> loading configuration file /root/huangxin/nanda/checkpoints/merge/0.5b-bn/config.json
[INFO|configuration_utils.py:792] 2024-05-13 22:14:38,565 >> Model config Qwen2Config {
  "_name_or_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "hidden_act": "silu",
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 2816,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_key_value_heads": 16,
  "rms_norm_eps": 1e-06,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.38.0.dev0",
  "use_cache": false,
  "use_sliding_window": false,
  "vocab_size": 151936
}

Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:727] 2024-05-13 22:14:38,567 >> loading configuration file /root/huangxin/nanda/model/Qwen1.5-7B/config.json
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
[INFO|configuration_utils.py:792] 2024-05-13 22:14:38,567 >> Model config Qwen2Config {
  "_name_or_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "rms_norm_eps": 1e-06,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.38.0.dev0",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[WARNING|logging.py:329] 2024-05-13 22:14:38,570 >> Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[INFO|configuration_utils.py:827] 2024-05-13 22:14:38,570 >> Generate config GenerationConfig {}

Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[INFO|configuration_utils.py:727] 2024-05-13 22:14:38,571 >> loading configuration file /root/huangxin/nanda/checkpoints/merge/0.5b-bn/config.json
[INFO|configuration_utils.py:792] 2024-05-13 22:14:38,571 >> Model config Qwen2Config {
  "_name_or_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "hidden_act": "silu",
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 2816,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_key_value_heads": 16,
  "rms_norm_eps": 1e-06,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.38.0.dev0",
  "use_cache": false,
  "use_sliding_window": false,
  "vocab_size": 151936
}

05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
[INFO|configuration_utils.py:727] 2024-05-13 22:14:38,572 >> loading configuration file /root/huangxin/nanda/model/Qwen1.5-7B/config.json
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
[INFO|configuration_utils.py:792] 2024-05-13 22:14:38,577 >> Model config Qwen2Config {
  "_name_or_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "rms_norm_eps": 1e-06,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.38.0.dev0",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
[INFO|modeling_utils.py:3334] 2024-05-13 22:14:38,578 >> loading weights file /root/huangxin/nanda/checkpoints/merge/0.5b-bn/model.safetensors
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - Initializing cross attention model.
05/13/2024 22:14:38 - INFO - llmtuner.model.loader - CrossAttnConfig {
  "attention_dropout": 0.0,
  "every_k_layers_large": 4,
  "every_k_layers_small": 3,
  "freeze_large": true,
  "freeze_small": true,
  "initializer_range": 0.02,
  "large_hidden_size": 4096,
  "large_layers": 32,
  "large_path": "/root/huangxin/nanda/model/Qwen1.5-7B",
  "model_type": "qwen2_cross_attn",
  "num_heads": 16,
  "num_layers_to_align": 8,
  "small_hidden_size": 1024,
  "small_layers": 24,
  "small_path": "/root/huangxin/nanda/checkpoints/merge/0.5b-bn",
  "transformers_version": "4.38.0.dev0"
}

Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnMergeModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Enable flash attention for small and large model.
05/13/2024 22:14:38 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init small models......
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
[WARNING|logging.py:329] 2024-05-13 22:14:38,822 >> You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[WARNING|logging.py:329] 2024-05-13 22:14:38,824 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[WARNING|logging.py:329] 2024-05-13 22:14:38,828 >> Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2CrossAttnGeneratorModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
[INFO|modeling_utils.py:4060] 2024-05-13 22:15:01,864 >> Some weights of the model checkpoint at /root/huangxin/nanda/checkpoints/merge/0.5b-bn were not used when initializing Qwen2CrossAttnGeneratorModel: ['lm_head.weight']
- This IS expected if you are initializing Qwen2CrossAttnGeneratorModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Qwen2CrossAttnGeneratorModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:4078] 2024-05-13 22:15:01,865 >> All the weights of Qwen2CrossAttnGeneratorModel were initialized from the model checkpoint at /root/huangxin/nanda/checkpoints/merge/0.5b-bn.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2CrossAttnGeneratorModel for predictions without further training.
05/13/2024 22:15:01 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init large models......
[INFO|modeling_utils.py:3334] 2024-05-13 22:15:01,884 >> loading weights file /root/huangxin/nanda/model/Qwen1.5-7B/model.safetensors.index.json
[INFO|configuration_utils.py:827] 2024-05-13 22:15:01,885 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151643
}

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|       | 1/4 [00:25<01:15, 25.20s/it]Loading checkpoint shards:  25%|       | 1/4 [00:20<01:01, 20.52s/it]Loading checkpoint shards:  25%|       | 1/4 [00:22<01:06, 22.03s/it]Loading checkpoint shards:  25%|       | 1/4 [00:20<01:02, 20.75s/it]Loading checkpoint shards:  25%|       | 1/4 [00:26<01:20, 26.72s/it]Loading checkpoint shards:  25%|       | 1/4 [00:24<01:14, 24.93s/it]Loading checkpoint shards:  25%|       | 1/4 [00:20<01:00, 20.12s/it]Loading checkpoint shards:  25%|       | 1/4 [00:20<01:01, 20.42s/it]Loading checkpoint shards:  50%|     | 2/4 [00:54<00:56, 28.21s/it]Loading checkpoint shards:  50%|     | 2/4 [00:54<00:56, 28.42s/it]Loading checkpoint shards:  50%|     | 2/4 [00:59<01:00, 30.27s/it]Loading checkpoint shards:  50%|     | 2/4 [00:54<00:56, 28.33s/it]Loading checkpoint shards:  50%|     | 2/4 [01:00<01:01, 30.89s/it]Loading checkpoint shards:  50%|     | 2/4 [00:58<01:00, 30.14s/it]Loading checkpoint shards:  50%|     | 2/4 [00:55<00:57, 28.96s/it]Loading checkpoint shards:  50%|     | 2/4 [00:53<00:56, 28.13s/it]Loading checkpoint shards:  75%|  | 3/4 [01:28<00:30, 30.94s/it]Loading checkpoint shards:  75%|  | 3/4 [01:28<00:31, 31.01s/it]Loading checkpoint shards:  75%|  | 3/4 [01:28<00:31, 31.06s/it]Loading checkpoint shards:  75%|  | 3/4 [01:28<00:30, 30.89s/it]Loading checkpoint shards:  75%|  | 3/4 [01:30<00:31, 31.34s/it]Loading checkpoint shards:  75%|  | 3/4 [01:32<00:31, 31.99s/it]Loading checkpoint shards:  75%|  | 3/4 [01:34<00:32, 32.40s/it]Loading checkpoint shards:  75%|  | 3/4 [01:33<00:32, 32.07s/it]Loading checkpoint shards: 100%|| 4/4 [02:04<00:00, 33.05s/it]Loading checkpoint shards: 100%|| 4/4 [02:04<00:00, 31.14s/it]
[INFO|modeling_utils.py:4070] 2024-05-13 22:17:33,369 >> All model checkpoint weights were used when initializing Qwen2CrossAttnCausalLM.

[INFO|modeling_utils.py:4078] 2024-05-13 22:17:33,369 >> All the weights of Qwen2CrossAttnCausalLM were initialized from the model checkpoint at /root/huangxin/nanda/model/Qwen1.5-7B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2CrossAttnCausalLM for predictions without further training.
[INFO|configuration_utils.py:780] 2024-05-13 22:17:33,373 >> loading configuration file /root/huangxin/nanda/model/Qwen1.5-7B/generation_config.json
[INFO|configuration_utils.py:827] 2024-05-13 22:17:33,374 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151643,
  "max_new_tokens": 2048
}

05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
Loading checkpoint shards: 100%|| 4/4 [02:05<00:00, 33.12s/it]Loading checkpoint shards: 100%|| 4/4 [02:05<00:00, 31.26s/it]
Loading checkpoint shards: 100%|| 4/4 [02:04<00:00, 33.02s/it]Loading checkpoint shards: 100%|| 4/4 [02:04<00:00, 31.08s/it]
05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
Loading checkpoint shards: 100%|| 4/4 [02:04<00:00, 33.09s/it]Loading checkpoint shards: 100%|| 4/4 [02:04<00:00, 31.20s/it]
05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
Loading checkpoint shards: 100%|| 4/4 [02:11<00:00, 33.93s/it]Loading checkpoint shards: 100%|| 4/4 [02:11<00:00, 32.75s/it]
Loading checkpoint shards: 100%|| 4/4 [02:09<00:00, 33.73s/it]Loading checkpoint shards: 100%|| 4/4 [02:09<00:00, 32.38s/it]
05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
Loading checkpoint shards: 100%|| 4/4 [02:09<00:00, 33.69s/it]Loading checkpoint shards: 100%|| 4/4 [02:09<00:00, 32.30s/it]
Loading checkpoint shards: 100%|| 4/4 [02:06<00:00, 33.30s/it]Loading checkpoint shards: 100%|| 4/4 [02:06<00:00, 31.58s/it]05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......

05/13/2024 22:17:33 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - init merge modules......
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the small model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Freeze the parameters of the large model.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.src.models.qwen2_cross_attention.modeling_merge - Mark the parameters of the merge modules trainable.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - Gradient checkpointing enabled.
05/13/2024 22:17:39 - WARNING - llmtuner.model.loader - Current model does not support gradient checkpointing.
05/13/2024 22:17:39 - INFO - llmtuner.model.loader - trainable params: 570589184 || all params: 8755901440 || trainable%: 6.5166
05/13/2024 22:19:54 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
Using custom data configuration default-4e02b910cc3d648d
Loading Dataset Infos from /mnt/vol1/huangxin/anaconda3/envs/wzjsz/lib/python3.10/site-packages/datasets/packaged_modules/json
Overwrite dataset info from restored data version if exists.
Loading Dataset info from /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7
Found cached dataset json (/mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7)
Loading Dataset info from /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7
Dataset({
    features: ['text'],
    num_rows: 870561
})
{'text': "           | Suprovat Bogura\n             \n          \n           -\n  ():                    ,         \n , ' -    -                     ,  ,   '\n ( )         ()                       \n                                       \n            ,            \n , -                              ,     \n                      , '         ,   '\n , '-          ,             '       , '       \n               ,          ,       '\n                                     "}
Process #0 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00000_of_00064.arrow
Process #1 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00001_of_00064.arrow
Process #2 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00002_of_00064.arrow
Process #3 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00003_of_00064.arrow
Process #4 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00004_of_00064.arrow
Process #5 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00005_of_00064.arrow
Process #6 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00006_of_00064.arrow
Process #7 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00007_of_00064.arrow
Process #8 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00008_of_00064.arrow
Process #9 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00009_of_00064.arrow
Process #10 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00010_of_00064.arrow
Process #11 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00011_of_00064.arrow
Process #12 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00012_of_00064.arrow
Process #13 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00013_of_00064.arrow
Process #14 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00014_of_00064.arrow
Process #15 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00015_of_00064.arrow
Process #16 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00016_of_00064.arrow
Process #17 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00017_of_00064.arrow
Process #18 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00018_of_00064.arrow
Process #19 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00019_of_00064.arrow
Process #20 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00020_of_00064.arrow
Process #21 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00021_of_00064.arrow
Process #22 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00022_of_00064.arrow
Process #23 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00023_of_00064.arrow
Process #24 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00024_of_00064.arrow
Process #25 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00025_of_00064.arrow
Process #26 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00026_of_00064.arrow
Process #27 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00027_of_00064.arrow
Process #28 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00028_of_00064.arrow
Process #29 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00029_of_00064.arrow
Process #30 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00030_of_00064.arrow
Process #31 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00031_of_00064.arrow
Process #32 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00032_of_00064.arrow
Process #33 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00033_of_00064.arrow
Process #34 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00034_of_00064.arrow
Process #35 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00035_of_00064.arrow
Process #36 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00036_of_00064.arrow
Process #37 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00037_of_00064.arrow
Process #38 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00038_of_00064.arrow
Process #39 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00039_of_00064.arrow
Process #40 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00040_of_00064.arrow
Process #41 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00041_of_00064.arrow
Process #42 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00042_of_00064.arrow
Process #43 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00043_of_00064.arrow
Process #44 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00044_of_00064.arrow
Process #45 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00045_of_00064.arrow
Process #46 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00046_of_00064.arrow
Process #47 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00047_of_00064.arrow
Process #48 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00048_of_00064.arrow
Process #49 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00049_of_00064.arrow
Process #50 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00050_of_00064.arrow
Process #51 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00051_of_00064.arrow
Process #52 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00052_of_00064.arrow
Process #53 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00053_of_00064.arrow
Process #54 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00054_of_00064.arrow
Process #55 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00055_of_00064.arrow
Process #56 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00056_of_00064.arrow
Process #57 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00057_of_00064.arrow
Process #58 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00058_of_00064.arrow
Process #59 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00059_of_00064.arrow
Process #60 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00060_of_00064.arrow
Process #61 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00061_of_00064.arrow
Process #62 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00062_of_00064.arrow
Process #63 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_00063_of_00064.arrow
Loading cached processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-36f9adef9062c652_*_of_00064.arrow
Concatenating 64 shards
Process #0 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00000_of_00064.arrow
Process #1 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00001_of_00064.arrow
Process #2 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00002_of_00064.arrow
Process #3 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00003_of_00064.arrow
Process #4 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00004_of_00064.arrow
Process #5 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00005_of_00064.arrow
Process #6 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00006_of_00064.arrow
Process #7 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00007_of_00064.arrow
Process #8 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00008_of_00064.arrow
Process #9 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00009_of_00064.arrow
Process #10 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00010_of_00064.arrow
Process #11 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00011_of_00064.arrow
Process #12 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00012_of_00064.arrow
Process #13 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00013_of_00064.arrow
Process #14 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00014_of_00064.arrow
Process #15 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00015_of_00064.arrow
Process #16 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00016_of_00064.arrow
Process #17 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00017_of_00064.arrow
Process #18 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00018_of_00064.arrow
Process #19 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00019_of_00064.arrow
Process #20 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00020_of_00064.arrow
Process #21 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00021_of_00064.arrow
Process #22 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00022_of_00064.arrow
Process #23 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00023_of_00064.arrow
Process #24 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00024_of_00064.arrow
Process #25 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00025_of_00064.arrow
Process #26 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00026_of_00064.arrow
Process #27 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00027_of_00064.arrow
Process #28 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00028_of_00064.arrow
Process #29 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00029_of_00064.arrow
Process #30 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00030_of_00064.arrow
Process #31 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00031_of_00064.arrow
Process #32 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00032_of_00064.arrow
Process #33 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00033_of_00064.arrow
Process #34 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00034_of_00064.arrow
Process #35 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00035_of_00064.arrow
Process #36 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00036_of_00064.arrow
Process #37 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00037_of_00064.arrow
Process #38 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00038_of_00064.arrow
Process #39 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00039_of_00064.arrow
Process #40 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00040_of_00064.arrow
Process #41 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00041_of_00064.arrow
Process #42 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00042_of_00064.arrow
Process #43 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00043_of_00064.arrow
Process #44 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00044_of_00064.arrow
Process #45 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00045_of_00064.arrow
Process #46 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00046_of_00064.arrow
Process #47 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00047_of_00064.arrow
Process #48 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00048_of_00064.arrow
Process #49 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00049_of_00064.arrow
Process #50 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00050_of_00064.arrow
Process #51 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00051_of_00064.arrow
Process #52 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00052_of_00064.arrow
Process #53 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00053_of_00064.arrow
Process #54 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00054_of_00064.arrow
Process #55 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00055_of_00064.arrow
Process #56 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00056_of_00064.arrow
Process #57 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00057_of_00064.arrow
Process #58 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00058_of_00064.arrow
Process #59 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00059_of_00064.arrow
Process #60 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00060_of_00064.arrow
Process #61 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00061_of_00064.arrow
Process #62 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00062_of_00064.arrow
Process #63 will write at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00063_of_00064.arrow
Spawning 64 processes
Running tokenizer on dataset (num_proc=64):   0%|          | 0/870561 [00:00<?, ? examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:36,968 >> Token indices sequence length is longer than the specified maximum sequence length for this model (91486 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00000_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   0%|          | 1000/870561 [00:08<2:00:37, 120.14 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:38,671 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34827 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00001_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   0%|          | 2000/870561 [00:09<1:02:53, 230.17 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:41,078 >> Token indices sequence length is longer than the specified maximum sequence length for this model (44816 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00002_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   0%|          | 3000/870561 [00:12<50:03, 288.83 examples/s]  Running tokenizer on dataset (num_proc=64):   0%|          | 4000/870561 [00:12<33:32, 430.51 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:43,144 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34931 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00003_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   1%|          | 5000/870561 [00:14<29:14, 493.20 examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 6000/870561 [00:14<20:20, 708.56 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:45,248 >> Token indices sequence length is longer than the specified maximum sequence length for this model (54287 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00004_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   1%|          | 7000/870561 [00:16<22:32, 638.34 examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 8000/870561 [00:16<16:56, 848.86 examples/s]Running tokenizer on dataset (num_proc=64):   1%|          | 9000/870561 [00:17<14:29, 990.76 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00005_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   1%|          | 10000/870561 [00:18<14:33, 985.26 examples/s]Running tokenizer on dataset (num_proc=64):   1%|         | 11000/870561 [00:19<14:26, 992.26 examples/s]Running tokenizer on dataset (num_proc=64):   1%|         | 12000/870561 [00:20<12:56, 1105.07 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00006_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   1%|         | 13000/870561 [00:20<11:03, 1292.80 examples/s]Running tokenizer on dataset (num_proc=64):   2%|         | 14000/870561 [00:21<11:12, 1273.05 examples/s]Running tokenizer on dataset (num_proc=64):   2%|         | 15000/870561 [00:21<09:14, 1544.22 examples/s]Running tokenizer on dataset (num_proc=64):   2%|         | 16000/870561 [00:22<07:36, 1871.16 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:52,133 >> Token indices sequence length is longer than the specified maximum sequence length for this model (135847 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00007_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:52,482 >> Token indices sequence length is longer than the specified maximum sequence length for this model (57994 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):   2%|         | 17000/870561 [00:23<11:10, 1272.63 examples/s]Running tokenizer on dataset (num_proc=64):   2%|         | 18000/870561 [00:23<09:06, 1560.04 examples/s]Running tokenizer on dataset (num_proc=64):   2%|         | 19000/870561 [00:24<08:52, 1599.62 examples/s]Running tokenizer on dataset (num_proc=64):   2%|         | 20000/870561 [00:24<08:23, 1690.45 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:54,338 >> Token indices sequence length is longer than the specified maximum sequence length for this model (131502 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00008_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   2%|         | 21000/870561 [00:25<08:20, 1696.81 examples/s]Running tokenizer on dataset (num_proc=64):   3%|         | 22000/870561 [00:25<06:43, 2100.74 examples/s]Running tokenizer on dataset (num_proc=64):   3%|         | 23000/870561 [00:26<07:18, 1932.72 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00009_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   3%|         | 25000/870561 [00:26<05:51, 2405.39 examples/s]Running tokenizer on dataset (num_proc=64):   3%|         | 26000/870561 [00:27<05:26, 2586.76 examples/s]Running tokenizer on dataset (num_proc=64):   3%|         | 27000/870561 [00:27<07:03, 1991.67 examples/s]Running tokenizer on dataset (num_proc=64):   3%|         | 28000/870561 [00:28<07:18, 1921.24 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:20:58,312 >> Token indices sequence length is longer than the specified maximum sequence length for this model (84168 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00010_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   3%|         | 29000/870561 [00:29<08:17, 1692.13 examples/s]Running tokenizer on dataset (num_proc=64):   3%|         | 30000/870561 [00:29<06:58, 2008.82 examples/s]Running tokenizer on dataset (num_proc=64):   4%|         | 32000/870561 [00:30<05:18, 2633.32 examples/s]Running tokenizer on dataset (num_proc=64):   4%|         | 33000/870561 [00:30<04:50, 2882.42 examples/s]Running tokenizer on dataset (num_proc=64):   4%|         | 34000/870561 [00:30<04:42, 2965.75 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:00,450 >> Token indices sequence length is longer than the specified maximum sequence length for this model (48132 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00011_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   4%|         | 35000/870561 [00:31<06:45, 2063.04 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:00,835 >> Token indices sequence length is longer than the specified maximum sequence length for this model (33878 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):   4%|         | 36000/870561 [00:31<05:43, 2429.47 examples/s]Running tokenizer on dataset (num_proc=64):   4%|         | 38000/870561 [00:32<04:19, 3206.08 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00012_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   4%|         | 39000/870561 [00:33<08:29, 1633.20 examples/s]Running tokenizer on dataset (num_proc=64):   5%|         | 42000/870561 [00:34<05:34, 2477.50 examples/s]Running tokenizer on dataset (num_proc=64):   5%|         | 43000/870561 [00:34<04:58, 2774.00 examples/s]Running tokenizer on dataset (num_proc=64):   5%|         | 44000/870561 [00:34<04:32, 3038.61 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:04,081 >> Token indices sequence length is longer than the specified maximum sequence length for this model (117989 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):   5%|         | 45000/870561 [00:35<05:09, 2671.12 examples/s]Running tokenizer on dataset (num_proc=64):   5%|         | 46000/870561 [00:35<04:40, 2943.75 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00013_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   5%|         | 47000/870561 [00:35<04:16, 3214.71 examples/s]Running tokenizer on dataset (num_proc=64):   6%|         | 48000/870561 [00:35<04:09, 3290.93 examples/s]Running tokenizer on dataset (num_proc=64):   6%|         | 49000/870561 [00:36<04:24, 3101.06 examples/s]Running tokenizer on dataset (num_proc=64):   6%|         | 50000/870561 [00:36<03:52, 3526.66 examples/s]Running tokenizer on dataset (num_proc=64):   6%|         | 51000/870561 [00:36<03:29, 3920.71 examples/s]Running tokenizer on dataset (num_proc=64):   6%|         | 52000/870561 [00:36<03:32, 3860.98 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:07,203 >> Token indices sequence length is longer than the specified maximum sequence length for this model (50417 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00014_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:07,411 >> Token indices sequence length is longer than the specified maximum sequence length for this model (62793 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):   6%|         | 53000/870561 [00:38<08:03, 1689.46 examples/s]Running tokenizer on dataset (num_proc=64):   6%|         | 54000/870561 [00:38<06:23, 2130.15 examples/s]Running tokenizer on dataset (num_proc=64):   6%|         | 55000/870561 [00:38<05:03, 2685.47 examples/s]Running tokenizer on dataset (num_proc=64):   7%|         | 57000/870561 [00:38<03:50, 3535.77 examples/s]Running tokenizer on dataset (num_proc=64):   7%|         | 58000/870561 [00:39<05:07, 2640.90 examples/s]Running tokenizer on dataset (num_proc=64):   7%|         | 59000/870561 [00:39<04:34, 2955.65 examples/s]Running tokenizer on dataset (num_proc=64):   7%|         | 60000/870561 [00:40<03:51, 3498.46 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00015_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:09,614 >> Token indices sequence length is longer than the specified maximum sequence length for this model (38283 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):   7%|         | 62000/870561 [00:40<03:22, 4000.07 examples/s]Running tokenizer on dataset (num_proc=64):   7%|         | 63000/870561 [00:40<03:07, 4311.61 examples/s]Running tokenizer on dataset (num_proc=64):   7%|         | 64000/870561 [00:40<03:07, 4292.96 examples/s]Running tokenizer on dataset (num_proc=64):   8%|         | 66000/870561 [00:41<02:43, 4935.56 examples/s]Running tokenizer on dataset (num_proc=64):   8%|         | 67000/870561 [00:41<02:44, 4882.63 examples/s]Running tokenizer on dataset (num_proc=64):   8%|         | 68000/870561 [00:41<02:59, 4464.74 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:11,792 >> Token indices sequence length is longer than the specified maximum sequence length for this model (36034 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00016_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   8%|         | 69000/870561 [00:42<06:44, 1981.52 examples/s]Running tokenizer on dataset (num_proc=64):   8%|         | 70000/870561 [00:43<05:31, 2414.57 examples/s]Running tokenizer on dataset (num_proc=64):   8%|         | 71000/870561 [00:43<05:11, 2566.83 examples/s]Running tokenizer on dataset (num_proc=64):   8%|         | 73000/870561 [00:43<03:38, 3657.18 examples/s]Running tokenizer on dataset (num_proc=64):   9%|         | 75000/870561 [00:44<03:33, 3731.35 examples/s]Running tokenizer on dataset (num_proc=64):   9%|         | 76000/870561 [00:44<04:04, 3254.10 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:14,215 >> Token indices sequence length is longer than the specified maximum sequence length for this model (36810 > 32768). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:14,259 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34266 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):   9%|         | 78000/870561 [00:44<03:18, 4002.07 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00017_of_00064.arrow
Running tokenizer on dataset (num_proc=64):   9%|         | 79000/870561 [00:45<02:59, 4405.26 examples/s]Running tokenizer on dataset (num_proc=64):   9%|         | 80000/870561 [00:45<03:24, 3858.08 examples/s]Running tokenizer on dataset (num_proc=64):   9%|         | 82000/870561 [00:45<02:24, 5458.97 examples/s]Running tokenizer on dataset (num_proc=64):  10%|         | 84000/870561 [00:45<02:11, 6003.41 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00018_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  10%|         | 85000/870561 [00:46<03:29, 3748.02 examples/s]Running tokenizer on dataset (num_proc=64):  10%|         | 87000/870561 [00:46<03:01, 4305.68 examples/s]Running tokenizer on dataset (num_proc=64):  10%|         | 88000/870561 [00:47<04:48, 2715.99 examples/s]Running tokenizer on dataset (num_proc=64):  10%|         | 89000/870561 [00:48<04:25, 2948.05 examples/s]Running tokenizer on dataset (num_proc=64):  10%|         | 90000/870561 [00:48<04:21, 2982.47 examples/s]Running tokenizer on dataset (num_proc=64):  11%|         | 92000/870561 [00:48<03:14, 4000.63 examples/s]Running tokenizer on dataset (num_proc=64):  11%|         | 93000/870561 [00:48<02:59, 4327.22 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:18,525 >> Token indices sequence length is longer than the specified maximum sequence length for this model (38573 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00019_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  11%|         | 94000/870561 [00:49<04:18, 3006.35 examples/s]Running tokenizer on dataset (num_proc=64):  11%|         | 96000/870561 [00:49<02:50, 4551.94 examples/s]Running tokenizer on dataset (num_proc=64):  11%|         | 97000/870561 [00:49<03:08, 4099.44 examples/s]Running tokenizer on dataset (num_proc=64):  11%|        | 98000/870561 [00:50<03:24, 3782.79 examples/s]Running tokenizer on dataset (num_proc=64):  11%|        | 100000/870561 [00:50<02:25, 5304.95 examples/s]Running tokenizer on dataset (num_proc=64):  12%|        | 102000/870561 [00:50<02:23, 5342.46 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00020_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:20,792 >> Token indices sequence length is longer than the specified maximum sequence length for this model (59603 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  12%|        | 105000/870561 [00:51<02:52, 4426.31 examples/s]Running tokenizer on dataset (num_proc=64):  12%|        | 106000/870561 [00:51<02:38, 4811.10 examples/s]Running tokenizer on dataset (num_proc=64):  12%|        | 107000/870561 [00:51<02:38, 4817.16 examples/s]Running tokenizer on dataset (num_proc=64):  12%|        | 108000/870561 [00:52<02:37, 4833.23 examples/s]Running tokenizer on dataset (num_proc=64):  13%|        | 109000/870561 [00:52<03:40, 3460.84 examples/s]Running tokenizer on dataset (num_proc=64):  13%|        | 110000/870561 [00:53<04:18, 2947.46 examples/s]Running tokenizer on dataset (num_proc=64):  13%|        | 111000/870561 [00:53<04:16, 2955.85 examples/s]Running tokenizer on dataset (num_proc=64):  13%|        | 112000/870561 [00:53<03:42, 3410.66 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:23,089 >> Token indices sequence length is longer than the specified maximum sequence length for this model (35285 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  13%|        | 114000/870561 [00:53<02:36, 4824.11 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00021_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  13%|        | 115000/870561 [00:54<03:21, 3746.49 examples/s]Running tokenizer on dataset (num_proc=64):  13%|        | 117000/870561 [00:54<02:22, 5297.44 examples/s]Running tokenizer on dataset (num_proc=64):  14%|        | 119000/870561 [00:54<02:44, 4572.34 examples/s]Running tokenizer on dataset (num_proc=64):  14%|        | 122000/870561 [00:55<02:03, 6080.53 examples/s]Running tokenizer on dataset (num_proc=64):  14%|        | 124000/870561 [00:55<02:24, 5157.56 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:25,315 >> Token indices sequence length is longer than the specified maximum sequence length for this model (39069 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00022_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  15%|        | 127000/870561 [00:56<02:30, 4932.94 examples/s]Running tokenizer on dataset (num_proc=64):  15%|        | 128000/870561 [00:56<02:30, 4927.22 examples/s]Running tokenizer on dataset (num_proc=64):  15%|        | 130000/870561 [00:56<02:16, 5444.65 examples/s]Running tokenizer on dataset (num_proc=64):  15%|        | 131000/870561 [00:57<02:24, 5126.23 examples/s]Running tokenizer on dataset (num_proc=64):  15%|        | 132000/870561 [00:57<02:43, 4507.44 examples/s]Running tokenizer on dataset (num_proc=64):  15%|        | 133000/870561 [00:58<03:39, 3362.99 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:27,774 >> Token indices sequence length is longer than the specified maximum sequence length for this model (33259 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00023_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  15%|        | 134000/870561 [00:58<05:09, 2382.82 examples/s]Running tokenizer on dataset (num_proc=64):  16%|        | 136000/870561 [00:59<03:37, 3382.43 examples/s]Running tokenizer on dataset (num_proc=64):  16%|        | 137000/870561 [00:59<03:11, 3831.22 examples/s]Running tokenizer on dataset (num_proc=64):  16%|        | 140000/870561 [00:59<02:51, 4265.22 examples/s]Running tokenizer on dataset (num_proc=64):  16%|        | 141000/870561 [01:00<02:44, 4442.92 examples/s]Running tokenizer on dataset (num_proc=64):  16%|        | 143000/870561 [01:00<02:05, 5813.98 examples/s]Running tokenizer on dataset (num_proc=64):  17%|        | 144000/870561 [01:00<02:05, 5774.74 examples/s]Running tokenizer on dataset (num_proc=64):  17%|        | 145000/870561 [01:00<02:11, 5527.92 examples/s]Running tokenizer on dataset (num_proc=64):  17%|        | 146000/870561 [01:00<02:38, 4567.94 examples/s]Running tokenizer on dataset (num_proc=64):  17%|        | 148000/870561 [01:01<01:55, 6281.88 examples/s]Running tokenizer on dataset (num_proc=64):  17%|        | 150000/870561 [01:01<01:42, 6996.05 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00024_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  17%|        | 151000/870561 [01:01<02:01, 5938.11 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:30,981 >> Token indices sequence length is longer than the specified maximum sequence length for this model (68558 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  17%|        | 152000/870561 [01:01<02:17, 5214.97 examples/s]Running tokenizer on dataset (num_proc=64):  18%|        | 154000/870561 [01:01<01:46, 6719.16 examples/s]Running tokenizer on dataset (num_proc=64):  18%|        | 155000/870561 [01:02<02:04, 5732.60 examples/s]Running tokenizer on dataset (num_proc=64):  18%|        | 156000/870561 [01:02<01:54, 6234.14 examples/s]Running tokenizer on dataset (num_proc=64):  18%|        | 157000/870561 [01:02<02:50, 4192.73 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00025_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  18%|        | 158000/870561 [01:03<04:05, 2904.64 examples/s]Running tokenizer on dataset (num_proc=64):  18%|        | 159000/870561 [01:03<03:26, 3454.04 examples/s]Running tokenizer on dataset (num_proc=64):  18%|        | 160000/870561 [01:04<04:43, 2509.34 examples/s]Running tokenizer on dataset (num_proc=64):  18%|        | 161000/870561 [01:04<03:56, 3002.73 examples/s]Running tokenizer on dataset (num_proc=64):  19%|        | 163000/870561 [01:04<02:42, 4359.02 examples/s]Running tokenizer on dataset (num_proc=64):  19%|        | 164000/870561 [01:04<02:27, 4797.47 examples/s]Running tokenizer on dataset (num_proc=64):  19%|        | 166000/870561 [01:05<02:35, 4527.38 examples/s]Running tokenizer on dataset (num_proc=64):  19%|        | 168000/870561 [01:05<02:08, 5469.28 examples/s]Running tokenizer on dataset (num_proc=64):  20%|        | 170000/870561 [01:05<01:40, 6958.95 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00026_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  20%|        | 171000/870561 [01:06<02:41, 4332.17 examples/s]Running tokenizer on dataset (num_proc=64):  20%|        | 172000/870561 [01:06<02:21, 4920.31 examples/s]Running tokenizer on dataset (num_proc=64):  20%|        | 175000/870561 [01:06<01:27, 7906.00 examples/s]Running tokenizer on dataset (num_proc=64):  20%|        | 177000/870561 [01:06<01:26, 8040.37 examples/s]Running tokenizer on dataset (num_proc=64):  21%|        | 179000/870561 [01:07<01:56, 5912.51 examples/s]Running tokenizer on dataset (num_proc=64):  21%|        | 181000/870561 [01:07<01:37, 7043.81 examples/s]Running tokenizer on dataset (num_proc=64):  21%|        | 182000/870561 [01:07<01:55, 5981.00 examples/s]Running tokenizer on dataset (num_proc=64):  21%|        | 183000/870561 [01:07<01:53, 6040.46 examples/s]Running tokenizer on dataset (num_proc=64):  21%|        | 184000/870561 [01:08<02:15, 5074.77 examples/s]Running tokenizer on dataset (num_proc=64):  21%|       | 185000/870561 [01:08<03:07, 3658.28 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:38,102 >> Token indices sequence length is longer than the specified maximum sequence length for this model (43171 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  21%|       | 186000/870561 [01:08<02:41, 4249.44 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00027_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  21%|       | 187000/870561 [01:09<03:47, 3007.14 examples/s]Running tokenizer on dataset (num_proc=64):  22%|       | 189000/870561 [01:09<02:41, 4213.94 examples/s]Running tokenizer on dataset (num_proc=64):  22%|       | 190000/870561 [01:10<03:43, 3046.88 examples/s]Running tokenizer on dataset (num_proc=64):  22%|       | 192000/870561 [01:10<02:39, 4265.33 examples/s]Running tokenizer on dataset (num_proc=64):  22%|       | 193603/870561 [01:11<03:05, 3640.03 examples/s]Running tokenizer on dataset (num_proc=64):  23%|       | 197603/870561 [01:11<01:38, 6837.64 examples/s]Running tokenizer on dataset (num_proc=64):  23%|       | 199603/870561 [01:11<01:50, 6075.91 examples/s]Running tokenizer on dataset (num_proc=64):  23%|       | 201603/870561 [01:11<01:50, 6046.96 examples/s]Running tokenizer on dataset (num_proc=64):  23%|       | 203603/870561 [01:12<01:58, 5618.53 examples/s]Running tokenizer on dataset (num_proc=64):  24%|       | 204603/870561 [01:12<02:47, 3976.90 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:42,299 >> Token indices sequence length is longer than the specified maximum sequence length for this model (63183 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  24%|       | 206603/870561 [01:13<02:22, 4649.32 examples/s]Running tokenizer on dataset (num_proc=64):  24%|       | 207603/870561 [01:13<02:37, 4210.45 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:43,055 >> Token indices sequence length is longer than the specified maximum sequence length for this model (57710 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  24%|       | 209603/870561 [01:13<02:34, 4290.28 examples/s]Running tokenizer on dataset (num_proc=64):  24%|       | 210603/870561 [01:14<02:33, 4297.47 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:43,604 >> Token indices sequence length is longer than the specified maximum sequence length for this model (53394 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  24%|       | 213206/870561 [01:14<01:50, 5969.15 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:43,765 >> Token indices sequence length is longer than the specified maximum sequence length for this model (48351 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00028_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  25%|       | 214206/870561 [01:14<01:54, 5720.20 examples/s]Running tokenizer on dataset (num_proc=64):  25%|       | 216206/870561 [01:14<01:43, 6341.60 examples/s]Running tokenizer on dataset (num_proc=64):  25%|       | 217206/870561 [01:15<01:38, 6648.55 examples/s]Running tokenizer on dataset (num_proc=64):  25%|       | 218809/870561 [01:15<01:20, 8137.61 examples/s]Running tokenizer on dataset (num_proc=64):  25%|       | 219809/870561 [01:16<03:19, 3267.19 examples/s]Running tokenizer on dataset (num_proc=64):  26%|       | 222809/870561 [01:16<02:18, 4681.21 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:45,829 >> Token indices sequence length is longer than the specified maximum sequence length for this model (72563 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  26%|       | 223809/870561 [01:16<02:21, 4568.27 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00029_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  26%|       | 224809/870561 [01:16<02:11, 4925.19 examples/s]Running tokenizer on dataset (num_proc=64):  26%|       | 225809/870561 [01:17<02:20, 4595.73 examples/s]Running tokenizer on dataset (num_proc=64):  26%|       | 228809/870561 [01:17<01:22, 7809.56 examples/s]Running tokenizer on dataset (num_proc=64):  27%|       | 230809/870561 [01:17<01:30, 7074.34 examples/s]Running tokenizer on dataset (num_proc=64):  27%|       | 232809/870561 [01:17<01:49, 5820.58 examples/s]Running tokenizer on dataset (num_proc=64):  27%|       | 233809/870561 [01:18<01:46, 5978.28 examples/s]Running tokenizer on dataset (num_proc=64):  27%|       | 235412/870561 [01:18<01:55, 5495.92 examples/s]Running tokenizer on dataset (num_proc=64):  27%|       | 236412/870561 [01:18<02:08, 4951.26 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:48,664 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34752 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00030_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  27%|       | 238412/870561 [01:19<03:02, 3470.43 examples/s]Running tokenizer on dataset (num_proc=64):  28%|       | 241412/870561 [01:19<02:06, 4968.26 examples/s]Running tokenizer on dataset (num_proc=64):  28%|       | 243412/870561 [01:20<01:43, 6055.46 examples/s]Running tokenizer on dataset (num_proc=64):  28%|       | 245412/870561 [01:20<01:49, 5685.30 examples/s]Running tokenizer on dataset (num_proc=64):  28%|       | 246412/870561 [01:20<01:46, 5845.59 examples/s]Running tokenizer on dataset (num_proc=64):  28%|       | 247618/870561 [01:21<02:38, 3927.44 examples/s]Running tokenizer on dataset (num_proc=64):  29%|       | 248618/870561 [01:21<02:27, 4228.40 examples/s]Running tokenizer on dataset (num_proc=64):  29%|       | 250618/870561 [01:21<02:21, 4380.03 examples/s]Running tokenizer on dataset (num_proc=64):  29%|       | 251618/870561 [01:22<02:18, 4481.89 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00031_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  29%|       | 252618/870561 [01:22<02:15, 4572.80 examples/s]Running tokenizer on dataset (num_proc=64):  29%|       | 255618/870561 [01:22<01:22, 7460.11 examples/s]Running tokenizer on dataset (num_proc=64):  29%|       | 256618/870561 [01:22<01:19, 7714.68 examples/s]Running tokenizer on dataset (num_proc=64):  30%|       | 258618/870561 [01:22<01:03, 9702.90 examples/s]Running tokenizer on dataset (num_proc=64):  30%|       | 260618/870561 [01:22<00:57, 10552.24 examples/s]Running tokenizer on dataset (num_proc=64):  30%|       | 262618/870561 [01:23<01:34, 6413.00 examples/s] [WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:53,034 >> Token indices sequence length is longer than the specified maximum sequence length for this model (48062 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00032_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  30%|       | 263618/870561 [01:24<03:04, 3292.69 examples/s]Running tokenizer on dataset (num_proc=64):  31%|       | 266618/870561 [01:24<02:27, 4085.90 examples/s]Running tokenizer on dataset (num_proc=64):  31%|       | 268618/870561 [01:25<02:00, 5001.84 examples/s]Running tokenizer on dataset (num_proc=64):  31%|       | 271618/870561 [01:25<01:42, 5862.94 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:55,041 >> Token indices sequence length is longer than the specified maximum sequence length for this model (36675 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  31%|      | 272618/870561 [01:25<02:02, 4893.46 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00033_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  32%|      | 275221/870561 [01:25<01:31, 6471.86 examples/s]Running tokenizer on dataset (num_proc=64):  32%|      | 276221/870561 [01:26<01:45, 5656.62 examples/s]Running tokenizer on dataset (num_proc=64):  32%|      | 278221/870561 [01:26<01:59, 4953.30 examples/s]Running tokenizer on dataset (num_proc=64):  32%|      | 279221/870561 [01:27<02:06, 4676.88 examples/s]Running tokenizer on dataset (num_proc=64):  32%|      | 280221/870561 [01:27<02:24, 4092.10 examples/s]Running tokenizer on dataset (num_proc=64):  32%|      | 281221/870561 [01:27<02:28, 3975.36 examples/s]Running tokenizer on dataset (num_proc=64):  33%|      | 284221/870561 [01:27<01:31, 6420.30 examples/s]Running tokenizer on dataset (num_proc=64):  33%|      | 286221/870561 [01:27<01:12, 8027.95 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:21:57,473 >> Token indices sequence length is longer than the specified maximum sequence length for this model (42347 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  33%|      | 288221/870561 [01:28<01:16, 7632.86 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00034_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  33%|      | 290221/870561 [01:28<01:33, 6202.20 examples/s]Running tokenizer on dataset (num_proc=64):  34%|      | 292221/870561 [01:29<01:35, 6044.92 examples/s]Running tokenizer on dataset (num_proc=64):  34%|      | 293221/870561 [01:29<02:18, 4153.96 examples/s]Running tokenizer on dataset (num_proc=64):  34%|      | 295221/870561 [01:29<02:00, 4788.18 examples/s]Running tokenizer on dataset (num_proc=64):  34%|      | 296221/870561 [01:30<02:13, 4315.79 examples/s]Running tokenizer on dataset (num_proc=64):  34%|      | 298221/870561 [01:30<01:36, 5959.24 examples/s]Running tokenizer on dataset (num_proc=64):  34%|      | 300221/870561 [01:30<01:35, 5958.39 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:00,449 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34549 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  35%|      | 301221/870561 [01:31<02:08, 4436.05 examples/s]Running tokenizer on dataset (num_proc=64):  35%|      | 303221/870561 [01:31<01:34, 5985.16 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00035_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  35%|      | 304427/870561 [01:31<02:02, 4636.94 examples/s]Running tokenizer on dataset (num_proc=64):  35%|      | 305427/870561 [01:31<01:50, 5112.68 examples/s]Running tokenizer on dataset (num_proc=64):  35%|      | 307030/870561 [01:32<01:32, 6065.54 examples/s]Running tokenizer on dataset (num_proc=64):  36%|      | 310030/870561 [01:32<01:01, 9160.88 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:02,007 >> Token indices sequence length is longer than the specified maximum sequence length for this model (49645 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  36%|      | 312030/870561 [01:32<01:47, 5187.53 examples/s]Running tokenizer on dataset (num_proc=64):  36%|      | 313030/870561 [01:33<01:51, 5014.57 examples/s]Running tokenizer on dataset (num_proc=64):  36%|      | 315030/870561 [01:33<01:26, 6435.24 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:02,693 >> Token indices sequence length is longer than the specified maximum sequence length for this model (52338 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00036_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  36%|      | 317030/870561 [01:33<02:00, 4575.75 examples/s]Running tokenizer on dataset (num_proc=64):  37%|      | 319030/870561 [01:34<01:32, 5965.71 examples/s]Running tokenizer on dataset (num_proc=64):  37%|      | 321030/870561 [01:34<01:32, 5945.73 examples/s]Running tokenizer on dataset (num_proc=64):  37%|      | 322030/870561 [01:34<02:10, 4192.49 examples/s]Running tokenizer on dataset (num_proc=64):  37%|      | 324030/870561 [01:35<01:46, 5140.56 examples/s]Running tokenizer on dataset (num_proc=64):  37%|      | 325030/870561 [01:35<01:55, 4738.35 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:04,874 >> Token indices sequence length is longer than the specified maximum sequence length for this model (50600 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  37%|      | 326030/870561 [01:35<01:47, 5080.97 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00037_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  38%|      | 327030/870561 [01:35<01:42, 5320.92 examples/s]Running tokenizer on dataset (num_proc=64):  38%|      | 328030/870561 [01:35<01:32, 5890.21 examples/s]Running tokenizer on dataset (num_proc=64):  38%|      | 329633/870561 [01:36<01:35, 5650.13 examples/s]Running tokenizer on dataset (num_proc=64):  38%|      | 330633/870561 [01:36<01:35, 5648.40 examples/s]Running tokenizer on dataset (num_proc=64):  38%|      | 332633/870561 [01:36<01:23, 6437.00 examples/s]Running tokenizer on dataset (num_proc=64):  38%|      | 333633/870561 [01:36<01:17, 6907.16 examples/s]Running tokenizer on dataset (num_proc=64):  39%|      | 335633/870561 [01:37<01:26, 6172.93 examples/s]Running tokenizer on dataset (num_proc=64):  39%|      | 337633/870561 [01:37<01:08, 7730.65 examples/s]Running tokenizer on dataset (num_proc=64):  39%|      | 339633/870561 [01:37<01:07, 7823.47 examples/s]Running tokenizer on dataset (num_proc=64):  39%|      | 341236/870561 [01:38<01:58, 4458.30 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:07,729 >> Token indices sequence length is longer than the specified maximum sequence length for this model (40995 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  39%|      | 342236/870561 [01:38<01:49, 4806.89 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00038_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  40%|      | 344236/870561 [01:38<01:29, 5893.92 examples/s]Running tokenizer on dataset (num_proc=64):  40%|      | 345236/870561 [01:39<01:56, 4522.16 examples/s]Running tokenizer on dataset (num_proc=64):  40%|      | 348236/870561 [01:39<01:19, 6542.00 examples/s]Running tokenizer on dataset (num_proc=64):  40%|      | 349236/870561 [01:39<01:27, 5945.31 examples/s]Running tokenizer on dataset (num_proc=64):  40%|      | 350236/870561 [01:40<02:09, 4027.70 examples/s]Running tokenizer on dataset (num_proc=64):  40%|      | 351236/870561 [01:40<01:59, 4356.27 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:09,669 >> Token indices sequence length is longer than the specified maximum sequence length for this model (35136 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  41%|      | 353236/870561 [01:40<01:41, 5085.54 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00039_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  41%|      | 354839/870561 [01:40<01:29, 5755.04 examples/s]Running tokenizer on dataset (num_proc=64):  41%|      | 355839/870561 [01:40<01:24, 6108.26 examples/s]Running tokenizer on dataset (num_proc=64):  41%|      | 356839/870561 [01:40<01:24, 6099.79 examples/s]Running tokenizer on dataset (num_proc=64):  41%|      | 358839/870561 [01:41<01:19, 6424.36 examples/s]Running tokenizer on dataset (num_proc=64):  41%|     | 360442/870561 [01:41<01:11, 7122.87 examples/s]Running tokenizer on dataset (num_proc=64):  42%|     | 361442/870561 [01:41<01:10, 7197.63 examples/s]Running tokenizer on dataset (num_proc=64):  42%|     | 364442/870561 [01:41<01:05, 7708.22 examples/s]Running tokenizer on dataset (num_proc=64):  42%|     | 367442/870561 [01:42<00:59, 8445.20 examples/s]Running tokenizer on dataset (num_proc=64):  42%|     | 368442/870561 [01:42<01:32, 5443.61 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00040_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  42%|     | 369442/870561 [01:43<02:19, 3598.66 examples/s]Running tokenizer on dataset (num_proc=64):  43%|     | 371442/870561 [01:43<01:38, 5042.96 examples/s]Running tokenizer on dataset (num_proc=64):  43%|     | 372442/870561 [01:43<01:39, 5015.00 examples/s]Running tokenizer on dataset (num_proc=64):  43%|     | 373442/870561 [01:43<01:36, 5137.50 examples/s]Running tokenizer on dataset (num_proc=64):  43%|     | 375442/870561 [01:44<01:28, 5603.96 examples/s]Running tokenizer on dataset (num_proc=64):  43%|     | 376442/870561 [01:44<01:31, 5411.43 examples/s]Running tokenizer on dataset (num_proc=64):  43%|     | 378045/870561 [01:45<01:58, 4173.20 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:14,379 >> Token indices sequence length is longer than the specified maximum sequence length for this model (41275 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00041_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  44%|     | 379045/870561 [01:45<02:09, 3786.29 examples/s]Running tokenizer on dataset (num_proc=64):  44%|     | 380045/870561 [01:45<02:04, 3943.07 examples/s]Running tokenizer on dataset (num_proc=64):  44%|     | 384045/870561 [01:45<01:00, 8044.30 examples/s]Running tokenizer on dataset (num_proc=64):  44%|     | 386045/870561 [01:46<01:28, 5501.65 examples/s]Running tokenizer on dataset (num_proc=64):  45%|     | 389045/870561 [01:46<01:00, 7955.45 examples/s]Running tokenizer on dataset (num_proc=64):  45%|     | 390648/870561 [01:46<01:11, 6730.70 examples/s]Running tokenizer on dataset (num_proc=64):  45%|     | 393648/870561 [01:47<00:59, 8056.05 examples/s]Running tokenizer on dataset (num_proc=64):  45%|     | 395648/870561 [01:47<01:02, 7609.42 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00042_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:17,577 >> Token indices sequence length is longer than the specified maximum sequence length for this model (33296 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  46%|     | 397648/870561 [01:48<01:47, 4411.17 examples/s]Running tokenizer on dataset (num_proc=64):  46%|     | 399251/870561 [01:48<01:54, 4113.96 examples/s]Running tokenizer on dataset (num_proc=64):  46%|     | 403251/870561 [01:48<01:09, 6717.86 examples/s]Running tokenizer on dataset (num_proc=64):  47%|     | 405251/870561 [01:49<01:22, 5668.14 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00043_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  47%|     | 407251/870561 [01:50<01:59, 3863.16 examples/s]Running tokenizer on dataset (num_proc=64):  47%|     | 409251/870561 [01:50<01:38, 4704.08 examples/s]Running tokenizer on dataset (num_proc=64):  47%|     | 411251/870561 [01:50<01:20, 5671.72 examples/s]Running tokenizer on dataset (num_proc=64):  47%|     | 413251/870561 [01:51<01:15, 6072.45 examples/s]Running tokenizer on dataset (num_proc=64):  48%|     | 414251/870561 [01:51<01:10, 6469.11 examples/s]Running tokenizer on dataset (num_proc=64):  48%|     | 416251/870561 [01:51<00:56, 7971.40 examples/s]Running tokenizer on dataset (num_proc=64):  48%|     | 418251/870561 [01:51<01:15, 5971.81 examples/s]Running tokenizer on dataset (num_proc=64):  48%|     | 420251/870561 [01:51<00:59, 7533.86 examples/s]Running tokenizer on dataset (num_proc=64):  49%|     | 422251/870561 [01:52<01:06, 6763.04 examples/s]Running tokenizer on dataset (num_proc=64):  49%|     | 424251/870561 [01:52<01:30, 4912.31 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00044_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  49%|     | 425251/870561 [01:53<01:31, 4859.97 examples/s]Running tokenizer on dataset (num_proc=64):  49%|     | 426251/870561 [01:53<01:46, 4181.00 examples/s]Running tokenizer on dataset (num_proc=64):  49%|     | 427251/870561 [01:53<01:43, 4270.61 examples/s]Running tokenizer on dataset (num_proc=64):  49%|     | 429854/870561 [01:53<01:13, 5988.05 examples/s]Running tokenizer on dataset (num_proc=64):  50%|     | 432457/870561 [01:54<00:52, 8294.36 examples/s]Running tokenizer on dataset (num_proc=64):  50%|     | 434457/870561 [01:54<00:59, 7375.64 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:24,125 >> Token indices sequence length is longer than the specified maximum sequence length for this model (51167 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  50%|     | 436457/870561 [01:55<01:35, 4542.58 examples/s]Running tokenizer on dataset (num_proc=64):  50%|     | 437457/870561 [01:55<01:31, 4756.66 examples/s]Running tokenizer on dataset (num_proc=64):  50%|     | 438457/870561 [01:55<01:22, 5236.32 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:24,905 >> Token indices sequence length is longer than the specified maximum sequence length for this model (58248 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00045_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  51%|     | 440457/870561 [01:55<01:09, 6162.96 examples/s]Running tokenizer on dataset (num_proc=64):  51%|     | 442060/870561 [01:56<01:29, 4811.65 examples/s]Running tokenizer on dataset (num_proc=64):  51%|     | 445060/870561 [01:56<01:03, 6657.17 examples/s]Running tokenizer on dataset (num_proc=64):  51%|    | 448060/870561 [01:56<00:47, 8826.08 examples/s]Running tokenizer on dataset (num_proc=64):  52%|    | 450060/870561 [01:56<00:42, 9941.38 examples/s]Running tokenizer on dataset (num_proc=64):  52%|    | 452060/870561 [01:57<00:40, 10305.43 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00046_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  52%|    | 454060/870561 [01:57<01:21, 5117.58 examples/s] [WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:27,783 >> Token indices sequence length is longer than the specified maximum sequence length for this model (72358 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  52%|    | 455060/870561 [01:58<01:59, 3490.30 examples/s]Running tokenizer on dataset (num_proc=64):  52%|    | 456663/870561 [01:58<01:44, 3956.98 examples/s]Running tokenizer on dataset (num_proc=64):  53%|    | 458663/870561 [01:59<01:17, 5288.04 examples/s]Running tokenizer on dataset (num_proc=64):  53%|    | 460663/870561 [01:59<01:03, 6425.45 examples/s]Running tokenizer on dataset (num_proc=64):  53%|    | 462663/870561 [01:59<00:59, 6871.44 examples/s]Running tokenizer on dataset (num_proc=64):  53%|    | 463663/870561 [01:59<01:05, 6196.92 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00047_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  53%|    | 465266/870561 [02:00<01:12, 5593.70 examples/s]Running tokenizer on dataset (num_proc=64):  54%|    | 466266/870561 [02:00<01:06, 6054.99 examples/s]Running tokenizer on dataset (num_proc=64):  54%|    | 468266/870561 [02:00<01:26, 4636.87 examples/s]Running tokenizer on dataset (num_proc=64):  54%|    | 469266/870561 [02:00<01:23, 4786.12 examples/s]Running tokenizer on dataset (num_proc=64):  54%|    | 470266/870561 [02:01<01:24, 4729.34 examples/s]Running tokenizer on dataset (num_proc=64):  54%|    | 472266/870561 [02:01<01:00, 6556.80 examples/s]Running tokenizer on dataset (num_proc=64):  54%|    | 474266/870561 [02:01<00:46, 8446.69 examples/s]Running tokenizer on dataset (num_proc=64):  55%|    | 476266/870561 [02:01<00:53, 7332.23 examples/s]Running tokenizer on dataset (num_proc=64):  55%|    | 477266/870561 [02:01<00:52, 7453.99 examples/s]Running tokenizer on dataset (num_proc=64):  55%|    | 479266/870561 [02:02<00:44, 8758.62 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:31,717 >> Token indices sequence length is longer than the specified maximum sequence length for this model (134405 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00048_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:31,883 >> Token indices sequence length is longer than the specified maximum sequence length for this model (37397 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  55%|    | 480869/870561 [02:02<01:34, 4116.89 examples/s]Running tokenizer on dataset (num_proc=64):  55%|    | 482869/870561 [02:03<01:20, 4809.75 examples/s]Running tokenizer on dataset (num_proc=64):  56%|    | 483869/870561 [02:03<01:21, 4773.42 examples/s]Running tokenizer on dataset (num_proc=64):  56%|    | 484869/870561 [02:03<01:38, 3899.06 examples/s]Running tokenizer on dataset (num_proc=64):  56%|    | 487869/870561 [02:04<01:06, 5777.77 examples/s]Running tokenizer on dataset (num_proc=64):  56%|    | 488869/870561 [02:04<01:09, 5530.80 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00049_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:33,923 >> Token indices sequence length is longer than the specified maximum sequence length for this model (56382 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  56%|    | 490472/870561 [02:04<01:11, 5317.96 examples/s]Running tokenizer on dataset (num_proc=64):  56%|    | 491472/870561 [02:04<01:05, 5761.12 examples/s]Running tokenizer on dataset (num_proc=64):  57%|    | 492472/870561 [02:04<01:10, 5344.16 examples/s]Running tokenizer on dataset (num_proc=64):  57%|    | 493472/870561 [02:05<01:06, 5675.51 examples/s]Running tokenizer on dataset (num_proc=64):  57%|    | 494472/870561 [02:05<01:05, 5723.19 examples/s]Running tokenizer on dataset (num_proc=64):  57%|    | 496472/870561 [02:05<01:27, 4252.22 examples/s]Running tokenizer on dataset (num_proc=64):  57%|    | 499472/870561 [02:06<00:59, 6251.07 examples/s]Running tokenizer on dataset (num_proc=64):  57%|    | 500472/870561 [02:06<01:07, 5501.31 examples/s]Running tokenizer on dataset (num_proc=64):  58%|    | 502472/870561 [02:06<00:50, 7247.26 examples/s]Running tokenizer on dataset (num_proc=64):  58%|    | 503472/870561 [02:06<00:55, 6614.94 examples/s]Running tokenizer on dataset (num_proc=64):  58%|    | 506075/870561 [02:07<00:47, 7600.46 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:36,477 >> Token indices sequence length is longer than the specified maximum sequence length for this model (37028 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  58%|    | 507075/870561 [02:07<00:52, 6866.27 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:36,601 >> Token indices sequence length is longer than the specified maximum sequence length for this model (51709 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00050_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  58%|    | 508075/870561 [02:07<01:14, 4845.47 examples/s]Running tokenizer on dataset (num_proc=64):  58%|    | 509075/870561 [02:07<01:24, 4264.10 examples/s]Running tokenizer on dataset (num_proc=64):  59%|    | 511075/870561 [02:08<01:11, 5033.61 examples/s]Running tokenizer on dataset (num_proc=64):  59%|    | 512075/870561 [02:08<01:14, 4832.71 examples/s]Running tokenizer on dataset (num_proc=64):  59%|    | 513075/870561 [02:08<01:12, 4955.28 examples/s]Running tokenizer on dataset (num_proc=64):  59%|    | 514075/870561 [02:09<01:35, 3724.13 examples/s]Running tokenizer on dataset (num_proc=64):  59%|    | 515075/870561 [02:09<01:25, 4138.17 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:38,858 >> Token indices sequence length is longer than the specified maximum sequence length for this model (37922 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  59%|    | 516075/870561 [02:09<01:27, 4071.88 examples/s]Running tokenizer on dataset (num_proc=64):  59%|    | 516678/870561 [02:09<01:21, 4338.16 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:39,094 >> Token indices sequence length is longer than the specified maximum sequence length for this model (43982 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  59%|    | 517678/870561 [02:09<01:17, 4571.43 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00051_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  60%|    | 519678/870561 [02:10<00:59, 5876.76 examples/s]Running tokenizer on dataset (num_proc=64):  60%|    | 521678/870561 [02:10<00:46, 7446.51 examples/s]Running tokenizer on dataset (num_proc=64):  60%|    | 522678/870561 [02:10<00:51, 6720.35 examples/s]Running tokenizer on dataset (num_proc=64):  60%|    | 523678/870561 [02:10<00:51, 6783.72 examples/s]Running tokenizer on dataset (num_proc=64):  60%|    | 524678/870561 [02:10<00:57, 6027.72 examples/s]Running tokenizer on dataset (num_proc=64):  60%|    | 526678/870561 [02:11<01:19, 4313.40 examples/s]Running tokenizer on dataset (num_proc=64):  61%|    | 528678/870561 [02:11<01:01, 5519.30 examples/s]Running tokenizer on dataset (num_proc=64):  61%|    | 530678/870561 [02:11<00:46, 7330.83 examples/s]Running tokenizer on dataset (num_proc=64):  61%|    | 532678/870561 [02:12<00:49, 6885.79 examples/s]Running tokenizer on dataset (num_proc=64):  61%|   | 533678/870561 [02:12<01:06, 5036.95 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:41,967 >> Token indices sequence length is longer than the specified maximum sequence length for this model (37283 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  61%|   | 534678/870561 [02:12<01:07, 5007.03 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00052_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  62%|   | 535678/870561 [02:13<01:17, 4293.72 examples/s]Running tokenizer on dataset (num_proc=64):  62%|   | 536678/870561 [02:13<01:13, 4554.72 examples/s]Running tokenizer on dataset (num_proc=64):  62%|   | 537678/870561 [02:13<01:03, 5280.44 examples/s]Running tokenizer on dataset (num_proc=64):  62%|   | 538678/870561 [02:13<00:59, 5535.84 examples/s]Running tokenizer on dataset (num_proc=64):  62%|   | 539678/870561 [02:13<01:03, 5235.08 examples/s]Running tokenizer on dataset (num_proc=64):  62%|   | 541281/870561 [02:14<01:05, 5007.43 examples/s]Running tokenizer on dataset (num_proc=64):  62%|   | 542281/870561 [02:14<01:05, 4983.75 examples/s]Running tokenizer on dataset (num_proc=64):  62%|   | 542884/870561 [02:14<01:13, 4440.58 examples/s]Running tokenizer on dataset (num_proc=64):  62%|   | 543884/870561 [02:14<01:04, 5085.92 examples/s]Running tokenizer on dataset (num_proc=64):  63%|   | 546884/870561 [02:14<00:34, 9407.46 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00053_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  63%|   | 548884/870561 [02:15<00:45, 7045.45 examples/s]Running tokenizer on dataset (num_proc=64):  63%|   | 549884/870561 [02:15<00:43, 7315.32 examples/s]Running tokenizer on dataset (num_proc=64):  63%|   | 550884/870561 [02:15<00:47, 6753.21 examples/s]Running tokenizer on dataset (num_proc=64):  63%|   | 551884/870561 [02:15<01:06, 4817.07 examples/s]Running tokenizer on dataset (num_proc=64):  64%|   | 552884/870561 [02:15<01:02, 5119.72 examples/s]Running tokenizer on dataset (num_proc=64):  64%|   | 553884/870561 [02:16<01:03, 4976.21 examples/s]Running tokenizer on dataset (num_proc=64):  64%|   | 554884/870561 [02:16<01:03, 4953.85 examples/s]Running tokenizer on dataset (num_proc=64):  64%|   | 555884/870561 [02:16<01:16, 4127.71 examples/s]Running tokenizer on dataset (num_proc=64):  64%|   | 556884/870561 [02:16<01:09, 4483.04 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00054_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  64%|   | 558884/870561 [02:17<00:47, 6593.95 examples/s]Running tokenizer on dataset (num_proc=64):  64%|   | 559884/870561 [02:17<00:51, 6007.42 examples/s]Running tokenizer on dataset (num_proc=64):  64%|   | 560884/870561 [02:17<00:49, 6248.59 examples/s]Running tokenizer on dataset (num_proc=64):  65%|   | 561884/870561 [02:17<01:11, 4331.07 examples/s]Running tokenizer on dataset (num_proc=64):  65%|   | 563884/870561 [02:17<00:48, 6334.37 examples/s]Running tokenizer on dataset (num_proc=64):  65%|   | 564884/870561 [02:18<01:14, 4081.29 examples/s]Running tokenizer on dataset (num_proc=64):  65%|   | 566884/870561 [02:19<01:17, 3908.28 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:48,603 >> Token indices sequence length is longer than the specified maximum sequence length for this model (45244 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00055_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  65%|   | 569884/870561 [02:19<01:04, 4648.77 examples/s]Running tokenizer on dataset (num_proc=64):  66%|   | 570884/870561 [02:19<01:04, 4681.43 examples/s]Running tokenizer on dataset (num_proc=64):  66%|   | 572884/870561 [02:19<00:48, 6116.05 examples/s]Running tokenizer on dataset (num_proc=64):  66%|   | 574884/870561 [02:19<00:37, 7891.88 examples/s]Running tokenizer on dataset (num_proc=64):  66%|   | 577884/870561 [02:20<00:33, 8834.29 examples/s]Running tokenizer on dataset (num_proc=64):  67%|   | 579487/870561 [02:20<00:51, 5647.89 examples/s]Running tokenizer on dataset (num_proc=64):  67%|   | 580487/870561 [02:21<00:50, 5760.97 examples/s]Running tokenizer on dataset (num_proc=64):  67%|   | 581487/870561 [02:21<01:00, 4756.90 examples/s]Running tokenizer on dataset (num_proc=64):  67%|   | 582487/870561 [02:21<00:57, 4982.13 examples/s]05/13/2024 22:22:50 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:50,966 >> Token indices sequence length is longer than the specified maximum sequence length for this model (57714 > 32768). Running this sequence through the model will result in indexing errors
05/13/2024 22:22:51 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00056_of_00064.arrow
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:51,199 >> Token indices sequence length is longer than the specified maximum sequence length for this model (45101 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  67%|   | 584487/870561 [02:21<00:57, 5011.24 examples/s]Running tokenizer on dataset (num_proc=64):  67%|   | 585487/870561 [02:22<00:51, 5486.19 examples/s]05/13/2024 22:22:51 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
Running tokenizer on dataset (num_proc=64):  67%|   | 587487/870561 [02:22<00:42, 6609.56 examples/s]05/13/2024 22:22:51 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
Running tokenizer on dataset (num_proc=64):  68%|   | 589090/870561 [02:22<00:43, 6416.80 examples/s]05/13/2024 22:22:51 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
05/13/2024 22:22:52 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
Running tokenizer on dataset (num_proc=64):  68%|   | 592090/870561 [02:22<00:40, 6923.27 examples/s]05/13/2024 22:22:52 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/bn.jsonl.
Running tokenizer on dataset (num_proc=64):  68%|   | 594090/870561 [02:23<00:55, 4995.06 examples/s]Running tokenizer on dataset (num_proc=64):  68%|   | 595090/870561 [02:23<00:54, 5087.32 examples/s]Dataset({
    features: ['text'],
    num_rows: 870561
})Dataset({
    features: ['text'],
    num_rows: 870561
})

{'text': "           | Suprovat Bogura\n             \n          \n           -\n  ():                    ,         \n , ' -    -                     ,  ,   '\n ( )         ()                       \n                                       \n            ,            \n , -                              ,     \n                      , '         ,   '\n , '-          ,             '       , '       \n               ,          ,       '\n                                     "}{'text': "           | Suprovat Bogura\n             \n          \n           -\n  ():                    ,         \n , ' -    -                     ,  ,   '\n ( )         ()                       \n                                       \n            ,            \n , -                              ,     \n                      , '         ,   '\n , '-          ,             '       , '       \n               ,          ,       '\n                                     "}

Dataset({
    features: ['text'],
    num_rows: 870561
})Dataset({
    features: ['text'],
    num_rows: 870561
})

{'text': "           | Suprovat Bogura\n             \n          \n           -\n  ():                    ,         \n , ' -    -                     ,  ,   '\n ( )         ()                       \n                                       \n            ,            \n , -                              ,     \n                      , '         ,   '\n , '-          ,             '       , '       \n               ,          ,       '\n                                     "}{'text': "           | Suprovat Bogura\n             \n          \n           -\n  ():                    ,         \n , ' -    -                     ,  ,   '\n ( )         ()                       \n                                       \n            ,            \n , -                              ,     \n                      , '         ,   '\n , '-          ,             '       , '       \n               ,          ,       '\n                                     "}

Dataset({
    features: ['text'],
    num_rows: 870561
})
{'text': "           | Suprovat Bogura\n             \n          \n           -\n  ():                    ,         \n , ' -    -                     ,  ,   '\n ( )         ()                       \n                                       \n            ,            \n , -                              ,     \n                      , '         ,   '\n , '-          ,             '       , '       \n               ,          ,       '\n                                     "}
Dataset({
    features: ['text'],
    num_rows: 870561
})
{'text': "           | Suprovat Bogura\n             \n          \n           -\n  ():                    ,         \n , ' -    -                     ,  ,   '\n ( )         ()                       \n                                       \n            ,            \n , -                              ,     \n                      , '         ,   '\n , '-          ,             '       , '       \n               ,          ,       '\n                                     "}
Dataset({
    features: ['text'],
    num_rows: 870561
})
{'text': "           | Suprovat Bogura\n             \n          \n           -\n  ():                    ,         \n , ' -    -                     ,  ,   '\n ( )         ()                       \n                                       \n            ,            \n , -                              ,     \n                      , '         ,   '\n , '-          ,             '       , '       \n               ,          ,       '\n                                     "}
Running tokenizer on dataset (num_proc=64):  68%|   | 596090/870561 [02:24<01:08, 4019.52 examples/s]Running tokenizer on dataset (num_proc=64):  69%|   | 597090/870561 [02:24<01:18, 3492.79 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:54,050 >> Token indices sequence length is longer than the specified maximum sequence length for this model (59485 > 32768). Running this sequence through the model will result in indexing errors
[WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:54,176 >> Token indices sequence length is longer than the specified maximum sequence length for this model (55088 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  69%|   | 598693/870561 [02:24<01:08, 3993.29 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00057_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  69%|   | 600693/870561 [02:25<00:55, 4869.06 examples/s]Running tokenizer on dataset (num_proc=64):  69%|   | 601693/870561 [02:25<00:52, 5109.53 examples/s]Running tokenizer on dataset (num_proc=64):  69%|   | 604693/870561 [02:25<00:37, 7171.10 examples/s]Running tokenizer on dataset (num_proc=64):  70%|   | 606693/870561 [02:25<00:33, 7853.30 examples/s]Running tokenizer on dataset (num_proc=64):  70%|   | 608693/870561 [02:26<00:31, 8193.08 examples/s]Running tokenizer on dataset (num_proc=64):  70%|   | 609693/870561 [02:26<00:41, 6295.46 examples/s]Running tokenizer on dataset (num_proc=64):  70%|   | 610693/870561 [02:26<01:00, 4268.34 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:56,266 >> Token indices sequence length is longer than the specified maximum sequence length for this model (35305 > 32768). Running this sequence through the model will result in indexing errors
Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00058_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  70%|   | 612693/870561 [02:27<00:52, 4948.69 examples/s]Running tokenizer on dataset (num_proc=64):  70%|   | 613693/870561 [02:27<00:52, 4936.95 examples/s]Running tokenizer on dataset (num_proc=64):  71%|   | 614296/870561 [02:27<00:53, 4807.02 examples/s]Running tokenizer on dataset (num_proc=64):  71%|   | 615296/870561 [02:27<00:48, 5212.73 examples/s]Running tokenizer on dataset (num_proc=64):  71%|   | 619296/870561 [02:27<00:30, 8275.02 examples/s]Running tokenizer on dataset (num_proc=64):  71%|  | 620296/870561 [02:28<01:02, 3975.31 examples/s]Running tokenizer on dataset (num_proc=64):  72%|  | 623296/870561 [02:28<00:41, 5943.13 examples/s]Running tokenizer on dataset (num_proc=64):  72%|  | 624296/870561 [02:29<00:48, 5040.58 examples/s]Running tokenizer on dataset (num_proc=64):  72%|  | 625296/870561 [02:29<00:59, 4100.03 examples/s]Running tokenizer on dataset (num_proc=64):  72%|  | 626296/870561 [02:30<01:13, 3331.93 examples/s]Running tokenizer on dataset (num_proc=64):  72%|  | 628898/870561 [02:30<00:47, 5127.07 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:22:59,824 >> Token indices sequence length is longer than the specified maximum sequence length for this model (34743 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  72%|  | 629898/870561 [02:30<00:44, 5408.28 examples/s]Running tokenizer on dataset (num_proc=64):  73%|  | 632898/870561 [02:30<00:27, 8626.05 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00059_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  73%|  | 635898/870561 [02:30<00:22, 10441.07 examples/s]Running tokenizer on dataset (num_proc=64):  73%|  | 637898/870561 [02:31<00:25, 9097.44 examples/s] Running tokenizer on dataset (num_proc=64):  73%|  | 639501/870561 [02:31<00:38, 6033.97 examples/s]Running tokenizer on dataset (num_proc=64):  74%|  | 640501/870561 [02:31<00:38, 5954.48 examples/s]Running tokenizer on dataset (num_proc=64):  74%|  | 642501/870561 [02:32<00:34, 6542.75 examples/s]Running tokenizer on dataset (num_proc=64):  74%|  | 643501/870561 [02:32<00:45, 5014.36 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:23:01,997 >> Token indices sequence length is longer than the specified maximum sequence length for this model (35689 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  74%|  | 644501/870561 [02:32<00:45, 4989.81 examples/s]Running tokenizer on dataset (num_proc=64):  74%|  | 645501/870561 [02:32<00:39, 5649.44 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00060_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  74%|  | 647501/870561 [02:33<00:39, 5664.57 examples/s]Running tokenizer on dataset (num_proc=64):  74%|  | 648501/870561 [02:33<00:36, 6159.02 examples/s]Running tokenizer on dataset (num_proc=64):  75%|  | 650103/870561 [02:33<00:44, 4998.71 examples/s]Running tokenizer on dataset (num_proc=64):  75%|  | 652103/870561 [02:33<00:31, 6923.06 examples/s]Running tokenizer on dataset (num_proc=64):  75%|  | 654103/870561 [02:35<01:04, 3362.98 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00061_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  75%|  | 655103/870561 [02:35<00:57, 3758.56 examples/s]Running tokenizer on dataset (num_proc=64):  76%|  | 657705/870561 [02:35<00:36, 5770.67 examples/s]Running tokenizer on dataset (num_proc=64):  76%|  | 659705/870561 [02:35<00:30, 6994.04 examples/s]Running tokenizer on dataset (num_proc=64):  76%|  | 662705/870561 [02:35<00:24, 8479.28 examples/s]Running tokenizer on dataset (num_proc=64):  76%|  | 664705/870561 [02:35<00:21, 9379.39 examples/s]Running tokenizer on dataset (num_proc=64):  77%|  | 666705/870561 [02:36<00:23, 8665.94 examples/s]Running tokenizer on dataset (num_proc=64):  77%|  | 668705/870561 [02:36<00:36, 5490.44 examples/s]Running tokenizer on dataset (num_proc=64):  77%|  | 669705/870561 [02:36<00:37, 5385.92 examples/s]Running tokenizer on dataset (num_proc=64):  77%|  | 670705/870561 [02:37<00:41, 4855.99 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:23:06,758 >> Token indices sequence length is longer than the specified maximum sequence length for this model (53577 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  77%|  | 671705/870561 [02:37<00:46, 4293.11 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00062_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  77%|  | 672705/870561 [02:37<00:45, 4325.77 examples/s]Running tokenizer on dataset (num_proc=64):  78%|  | 674705/870561 [02:38<00:33, 5780.89 examples/s]Running tokenizer on dataset (num_proc=64):  78%|  | 676705/870561 [02:38<00:25, 7654.88 examples/s]Running tokenizer on dataset (num_proc=64):  78%|  | 678307/870561 [02:38<00:27, 6998.08 examples/s]Running tokenizer on dataset (num_proc=64):  78%|  | 679307/870561 [02:38<00:29, 6578.28 examples/s]Running tokenizer on dataset (num_proc=64):  78%|  | 681307/870561 [02:39<00:50, 3735.88 examples/s]Running tokenizer on dataset (num_proc=64):  78%|  | 683307/870561 [02:39<00:40, 4589.76 examples/s]Running tokenizer on dataset (num_proc=64):  79%|  | 684307/870561 [02:39<00:36, 5037.63 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:23:09,218 >> Token indices sequence length is longer than the specified maximum sequence length for this model (38273 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  79%|  | 686307/870561 [02:39<00:26, 6860.18 examples/s][WARNING|tokenization_utils_base.py:3843] 2024-05-13 22:23:09,514 >> Token indices sequence length is longer than the specified maximum sequence length for this model (33240 > 32768). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset (num_proc=64):  79%|  | 688307/870561 [02:40<00:24, 7523.78 examples/s]Running tokenizer on dataset (num_proc=64):  79%|  | 690307/870561 [02:40<00:21, 8256.35 examples/s]Caching processed dataset at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-eb8ee3ebbf428de5_00063_of_00064.arrow
Running tokenizer on dataset (num_proc=64):  80%|  | 692307/870561 [02:40<00:27, 6530.86 examples/s]Running tokenizer on dataset (num_proc=64):  80%|  | 694307/870561 [02:40<00:21, 8142.11 examples/s]Running tokenizer on dataset (num_proc=64):  80%|  | 695909/870561 [02:41<00:24, 7010.15 examples/s]Running tokenizer on dataset (num_proc=64):  80%|  | 696909/870561 [02:41<00:32, 5366.47 examples/s]Running tokenizer on dataset (num_proc=64):  80%|  | 699909/870561 [02:42<00:38, 4461.73 examples/s]Running tokenizer on dataset (num_proc=64):  81%|  | 700909/870561 [02:42<00:35, 4728.12 examples/s]Running tokenizer on dataset (num_proc=64):  81%|  | 702909/870561 [02:42<00:28, 5800.48 examples/s]Running tokenizer on dataset (num_proc=64):  81%|  | 704909/870561 [02:43<00:25, 6409.83 examples/s]Running tokenizer on dataset (num_proc=64):  81%|  | 705909/870561 [02:43<00:34, 4718.56 examples/s]Running tokenizer on dataset (num_proc=64):  81%| | 707511/870561 [02:43<00:32, 5041.90 examples/s]Running tokenizer on dataset (num_proc=64):  81%| | 708511/870561 [02:44<00:37, 4340.57 examples/s]Running tokenizer on dataset (num_proc=64):  82%| | 709511/870561 [02:44<00:34, 4611.89 examples/s]Running tokenizer on dataset (num_proc=64):  82%| | 710511/870561 [02:44<00:30, 5168.83 examples/s]Running tokenizer on dataset (num_proc=64):  82%| | 712511/870561 [02:44<00:23, 6792.18 examples/s]Running tokenizer on dataset (num_proc=64):  82%| | 713511/870561 [02:44<00:22, 6856.33 examples/s]Running tokenizer on dataset (num_proc=64):  82%| | 714511/870561 [02:44<00:22, 6846.13 examples/s]Running tokenizer on dataset (num_proc=64):  82%| | 715511/870561 [02:44<00:21, 7202.44 examples/s]Running tokenizer on dataset (num_proc=64):  82%| | 717511/870561 [02:45<00:21, 7142.92 examples/s]Running tokenizer on dataset (num_proc=64):  83%| | 718511/870561 [02:45<00:21, 7205.16 examples/s]Running tokenizer on dataset (num_proc=64):  83%| | 719511/870561 [02:45<00:27, 5493.37 examples/s]Running tokenizer on dataset (num_proc=64):  83%| | 721113/870561 [02:46<00:29, 5015.01 examples/s]Running tokenizer on dataset (num_proc=64):  83%| | 723113/870561 [02:46<00:26, 5636.13 examples/s]Running tokenizer on dataset (num_proc=64):  83%| | 724113/870561 [02:46<00:23, 6150.78 examples/s]Running tokenizer on dataset (num_proc=64):  83%| | 725715/870561 [02:47<00:43, 3338.11 examples/s]Running tokenizer on dataset (num_proc=64):  84%| | 729715/870561 [02:47<00:21, 6639.68 examples/s]Running tokenizer on dataset (num_proc=64):  84%| | 731715/870561 [02:48<00:31, 4386.70 examples/s]Running tokenizer on dataset (num_proc=64):  84%| | 733317/870561 [02:48<00:35, 3815.91 examples/s]Running tokenizer on dataset (num_proc=64):  84%| | 734317/870561 [02:49<00:32, 4212.22 examples/s]Running tokenizer on dataset (num_proc=64):  85%| | 737317/870561 [02:49<00:21, 6167.33 examples/s]Running tokenizer on dataset (num_proc=64):  85%| | 738919/870561 [02:49<00:22, 5884.90 examples/s]Running tokenizer on dataset (num_proc=64):  85%| | 741919/870561 [02:49<00:15, 8469.45 examples/s]Running tokenizer on dataset (num_proc=64):  85%| | 743919/870561 [02:50<00:22, 5603.52 examples/s]Running tokenizer on dataset (num_proc=64):  86%| | 745919/870561 [02:50<00:21, 5916.60 examples/s]Running tokenizer on dataset (num_proc=64):  86%| | 747919/870561 [02:50<00:20, 6052.97 examples/s]Running tokenizer on dataset (num_proc=64):  86%| | 748919/870561 [02:51<00:35, 3413.98 examples/s]Running tokenizer on dataset (num_proc=64):  86%| | 749919/870561 [02:52<00:33, 3558.58 examples/s]Running tokenizer on dataset (num_proc=64):  86%| | 750919/870561 [02:52<00:33, 3571.60 examples/s]Running tokenizer on dataset (num_proc=64):  87%| | 753521/870561 [02:52<00:25, 4623.81 examples/s]Running tokenizer on dataset (num_proc=64):  87%| | 754521/870561 [02:53<00:31, 3664.70 examples/s]Running tokenizer on dataset (num_proc=64):  87%| | 755521/870561 [02:53<00:30, 3800.73 examples/s]Running tokenizer on dataset (num_proc=64):  87%| | 757521/870561 [02:53<00:24, 4650.83 examples/s]Running tokenizer on dataset (num_proc=64):  87%| | 758521/870561 [02:53<00:22, 4981.10 examples/s]Running tokenizer on dataset (num_proc=64):  87%| | 759521/870561 [02:54<00:22, 5011.99 examples/s]Running tokenizer on dataset (num_proc=64):  87%| | 760521/870561 [02:54<00:22, 4957.18 examples/s]Running tokenizer on dataset (num_proc=64):  87%| | 761521/870561 [02:54<00:20, 5419.69 examples/s]Running tokenizer on dataset (num_proc=64):  88%| | 762521/870561 [02:54<00:17, 6032.98 examples/s]Running tokenizer on dataset (num_proc=64):  88%| | 763521/870561 [02:55<00:30, 3481.50 examples/s]Running tokenizer on dataset (num_proc=64):  88%| | 765521/870561 [02:55<00:21, 4813.24 examples/s]Running tokenizer on dataset (num_proc=64):  88%| | 767521/870561 [02:55<00:15, 6570.94 examples/s]Running tokenizer on dataset (num_proc=64):  88%| | 768521/870561 [02:55<00:14, 6984.17 examples/s]Running tokenizer on dataset (num_proc=64):  88%| | 769521/870561 [02:56<00:27, 3695.16 examples/s]Running tokenizer on dataset (num_proc=64):  89%| | 770521/870561 [02:56<00:32, 3034.38 examples/s]Running tokenizer on dataset (num_proc=64):  89%| | 771521/870561 [02:57<00:30, 3240.52 examples/s]Running tokenizer on dataset (num_proc=64):  89%| | 773521/870561 [02:57<00:27, 3543.28 examples/s]Running tokenizer on dataset (num_proc=64):  89%| | 775123/870561 [02:58<00:29, 3192.82 examples/s]Running tokenizer on dataset (num_proc=64):  89%| | 777123/870561 [02:58<00:21, 4379.71 examples/s]Running tokenizer on dataset (num_proc=64):  89%| | 778123/870561 [02:58<00:20, 4429.42 examples/s]Running tokenizer on dataset (num_proc=64):  90%| | 780123/870561 [02:58<00:14, 6085.67 examples/s]Running tokenizer on dataset (num_proc=64):  90%| | 781123/870561 [02:58<00:15, 5674.18 examples/s]Running tokenizer on dataset (num_proc=64):  90%| | 782725/870561 [02:59<00:16, 5393.52 examples/s]Running tokenizer on dataset (num_proc=64):  90%| | 784725/870561 [02:59<00:21, 3911.67 examples/s]Running tokenizer on dataset (num_proc=64):  90%| | 787725/870561 [03:00<00:13, 6116.14 examples/s]Running tokenizer on dataset (num_proc=64):  91%| | 789327/870561 [03:00<00:19, 4275.12 examples/s]Running tokenizer on dataset (num_proc=64):  91%| | 790327/870561 [03:01<00:23, 3394.15 examples/s]Running tokenizer on dataset (num_proc=64):  91%| | 792327/870561 [03:01<00:22, 3524.01 examples/s]Running tokenizer on dataset (num_proc=64):  91%| | 793327/870561 [03:02<00:22, 3368.66 examples/s]Running tokenizer on dataset (num_proc=64):  91%|| 795327/870561 [03:02<00:21, 3463.15 examples/s]Running tokenizer on dataset (num_proc=64):  91%|| 795929/870561 [03:02<00:20, 3613.38 examples/s]Running tokenizer on dataset (num_proc=64):  92%|| 796929/870561 [03:03<00:20, 3583.13 examples/s]Running tokenizer on dataset (num_proc=64):  92%|| 798929/870561 [03:03<00:14, 4988.95 examples/s]Running tokenizer on dataset (num_proc=64):  92%|| 800929/870561 [03:03<00:16, 4325.86 examples/s]Running tokenizer on dataset (num_proc=64):  92%|| 802929/870561 [03:04<00:17, 3900.21 examples/s]Running tokenizer on dataset (num_proc=64):  92%|| 803929/870561 [03:04<00:15, 4356.32 examples/s]Running tokenizer on dataset (num_proc=64):  92%|| 804929/870561 [03:04<00:15, 4125.05 examples/s]Running tokenizer on dataset (num_proc=64):  93%|| 805929/870561 [03:05<00:14, 4499.17 examples/s]Running tokenizer on dataset (num_proc=64):  93%|| 806531/870561 [03:05<00:18, 3441.36 examples/s]Running tokenizer on dataset (num_proc=64):  93%|| 807531/870561 [03:06<00:25, 2459.72 examples/s]Running tokenizer on dataset (num_proc=64):  93%|| 810133/870561 [03:06<00:17, 3357.69 examples/s]Running tokenizer on dataset (num_proc=64):  93%|| 811133/870561 [03:06<00:16, 3602.42 examples/s]Running tokenizer on dataset (num_proc=64):  93%|| 813133/870561 [03:08<00:22, 2502.93 examples/s]Running tokenizer on dataset (num_proc=64):  94%|| 814133/870561 [03:08<00:20, 2774.82 examples/s]Running tokenizer on dataset (num_proc=64):  94%|| 815133/870561 [03:08<00:17, 3231.35 examples/s]Running tokenizer on dataset (num_proc=64):  94%|| 817133/870561 [03:09<00:16, 3247.94 examples/s]Running tokenizer on dataset (num_proc=64):  94%|| 818133/870561 [03:09<00:14, 3731.05 examples/s]Running tokenizer on dataset (num_proc=64):  94%|| 819133/870561 [03:09<00:12, 4151.45 examples/s]Running tokenizer on dataset (num_proc=64):  94%|| 820133/870561 [03:09<00:14, 3596.38 examples/s]Running tokenizer on dataset (num_proc=64):  94%|| 821133/870561 [03:10<00:16, 2977.41 examples/s]Running tokenizer on dataset (num_proc=64):  94%|| 822133/870561 [03:10<00:18, 2608.58 examples/s]Running tokenizer on dataset (num_proc=64):  95%|| 822735/870561 [03:11<00:19, 2415.58 examples/s]Running tokenizer on dataset (num_proc=64):  95%|| 824735/870561 [03:11<00:12, 3686.91 examples/s]Running tokenizer on dataset (num_proc=64):  95%|| 825735/870561 [03:11<00:11, 3792.80 examples/s]Running tokenizer on dataset (num_proc=64):  95%|| 826735/870561 [03:11<00:11, 3917.84 examples/s]Running tokenizer on dataset (num_proc=64):  95%|| 827337/870561 [03:12<00:17, 2529.18 examples/s]Running tokenizer on dataset (num_proc=64):  95%|| 828337/870561 [03:12<00:16, 2527.81 examples/s]Running tokenizer on dataset (num_proc=64):  95%|| 829939/870561 [03:13<00:15, 2660.60 examples/s]Running tokenizer on dataset (num_proc=64):  96%|| 831939/870561 [03:13<00:12, 3062.41 examples/s]Running tokenizer on dataset (num_proc=64):  96%|| 832939/870561 [03:14<00:10, 3474.88 examples/s]Running tokenizer on dataset (num_proc=64):  96%|| 833939/870561 [03:14<00:15, 2365.85 examples/s]Running tokenizer on dataset (num_proc=64):  96%|| 834939/870561 [03:15<00:12, 2760.53 examples/s]Running tokenizer on dataset (num_proc=64):  96%|| 835541/870561 [03:15<00:16, 2173.37 examples/s]Running tokenizer on dataset (num_proc=64):  96%|| 836541/870561 [03:15<00:12, 2619.07 examples/s]Running tokenizer on dataset (num_proc=64):  96%|| 837541/870561 [03:16<00:15, 2195.95 examples/s]Running tokenizer on dataset (num_proc=64):  96%|| 838541/870561 [03:16<00:11, 2852.37 examples/s]Running tokenizer on dataset (num_proc=64):  97%|| 840541/870561 [03:17<00:12, 2484.62 examples/s]Running tokenizer on dataset (num_proc=64):  97%|| 841143/870561 [03:17<00:11, 2660.43 examples/s]Running tokenizer on dataset (num_proc=64):  97%|| 842143/870561 [03:18<00:11, 2484.62 examples/s]Running tokenizer on dataset (num_proc=64):  97%|| 843143/870561 [03:18<00:12, 2166.27 examples/s]Running tokenizer on dataset (num_proc=64):  97%|| 844143/870561 [03:19<00:12, 2095.68 examples/s]Running tokenizer on dataset (num_proc=64):  97%|| 845143/870561 [03:19<00:13, 1856.51 examples/s]Running tokenizer on dataset (num_proc=64):  97%|| 846143/870561 [03:20<00:11, 2044.44 examples/s]Running tokenizer on dataset (num_proc=64):  97%|| 846745/870561 [03:20<00:14, 1634.53 examples/s]Running tokenizer on dataset (num_proc=64):  97%|| 848745/870561 [03:21<00:08, 2485.09 examples/s]Running tokenizer on dataset (num_proc=64):  98%|| 849745/870561 [03:21<00:08, 2394.56 examples/s]Running tokenizer on dataset (num_proc=64):  98%|| 850745/870561 [03:22<00:08, 2321.17 examples/s]Running tokenizer on dataset (num_proc=64):  98%|| 851745/870561 [03:23<00:11, 1585.68 examples/s]Running tokenizer on dataset (num_proc=64):  98%|| 852347/870561 [03:23<00:11, 1585.28 examples/s]Running tokenizer on dataset (num_proc=64):  98%|| 853347/870561 [03:24<00:10, 1711.73 examples/s]Running tokenizer on dataset (num_proc=64):  98%|| 854347/870561 [03:24<00:08, 1887.55 examples/s]Running tokenizer on dataset (num_proc=64):  98%|| 855347/870561 [03:24<00:06, 2236.82 examples/s]Running tokenizer on dataset (num_proc=64):  98%|| 855949/870561 [03:25<00:05, 2450.16 examples/s]Running tokenizer on dataset (num_proc=64):  98%|| 856949/870561 [03:26<00:08, 1545.00 examples/s]Running tokenizer on dataset (num_proc=64):  99%|| 857949/870561 [03:26<00:06, 1984.61 examples/s]Running tokenizer on dataset (num_proc=64):  99%|| 858551/870561 [03:27<00:10, 1124.73 examples/s]Running tokenizer on dataset (num_proc=64):  99%|| 859551/870561 [03:27<00:07, 1516.91 examples/s]Running tokenizer on dataset (num_proc=64):  99%|| 860551/870561 [03:28<00:06, 1434.61 examples/s]Running tokenizer on dataset (num_proc=64):  99%|| 861551/870561 [03:29<00:05, 1626.72 examples/s]Running tokenizer on dataset (num_proc=64):  99%|| 862551/870561 [03:30<00:07, 1077.48 examples/s]Running tokenizer on dataset (num_proc=64):  99%|| 864153/870561 [03:31<00:04, 1508.14 examples/s]Running tokenizer on dataset (num_proc=64):  99%|| 865153/870561 [03:33<00:06, 823.52 examples/s] Running tokenizer on dataset (num_proc=64): 100%|| 866755/870561 [03:34<00:02, 1288.24 examples/s]Running tokenizer on dataset (num_proc=64): 100%|| 867755/870561 [03:35<00:03, 928.15 examples/s] Running tokenizer on dataset (num_proc=64): 100%|| 868357/870561 [03:36<00:02, 905.63 examples/s]Running tokenizer on dataset (num_proc=64): 100%|| 869357/870561 [03:38<00:01, 741.70 examples/s]Running tokenizer on dataset (num_proc=64): 100%|| 869959/870561 [03:38<00:00, 866.39 examples/s]Running tokenizer on dataset (num_proc=64): 100%|| 870561/870561 [03:41<00:00, 540.62 examples/s]Running tokenizer on dataset (num_proc=64): 100%|| 870561/870561 [03:42<00:00, 3917.55 examples/s]
Concatenating 64 shards
input_ids:
[146775, 72258, 26927, 233, 86548, 41312, 35178, 106, 26927, 233, 146775, 49128, 105, 58908, 146227, 49128, 107, 11125, 120, 35178, 101, 80178, 250, 35178, 101, 80178, 250, 35178, 243, 72258, 52806, 106, 146711, 52806, 98, 146227, 58908, 35178, 107, 148015, 49128, 107, 148015, 148222, 49128, 105, 58908, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 146026, 80178, 100, 61356, 35178, 106, 58908, 86548, 58908, 35178, 248, 146227, 49128, 108, 35178, 228, 148291, 52806, 105, 49128, 101, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 72258, 760, 6299, 39394, 266, 41548, 5690, 198, 146838, 52806, 108, 148431, 52806, 249, 148156, 35178, 243, 26927, 225, 148481, 61356, 35178, 116, 11125, 224, 146026, 49128, 99, 35178, 243, 72258, 26927, 233, 86548, 41312, 35178, 106, 26927, 233, 146775, 49128, 105, 58908, 146227, 49128, 107, 11125, 120, 35178, 101, 80178, 250, 35178, 101, 80178, 250, 35178, 243, 72258, 52806, 106, 146711, 52806, 98, 146227, 58908, 35178, 107, 148015, 49128, 107, 148015, 148222, 49128, 105, 58908, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 146026, 80178, 100, 61356, 35178, 106, 58908, 86548, 58908, 35178, 248, 146227, 49128, 108, 35178, 228, 148291, 52806, 105, 49128, 101, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 72258, 198, 146775, 72258, 26927, 233, 86548, 41312, 35178, 106, 26927, 233, 146775, 49128, 105, 58908, 146227, 49128, 107, 11125, 120, 35178, 101, 80178, 250, 35178, 101, 80178, 250, 35178, 243, 72258, 52806, 106, 146711, 52806, 98, 146227, 58908, 35178, 107, 148015, 49128, 107, 148015, 148222, 49128, 105, 58908, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 146026, 80178, 100, 61356, 35178, 106, 58908, 86548, 58908, 35178, 248, 146227, 49128, 108, 35178, 228, 148291, 52806, 105, 49128, 101, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 72258, 198, 146775, 72258, 26927, 233, 86548, 41312, 35178, 106, 26927, 233, 146775, 49128, 105, 58908, 146227, 49128, 107, 11125, 120, 35178, 101, 80178, 250, 35178, 101, 80178, 250, 35178, 243, 72258, 52806, 106, 146711, 52806, 98, 146227, 58908, 35178, 107, 148015, 49128, 107, 148015, 148222, 49128, 105, 58908, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 146026, 80178, 100, 61356, 35178, 106, 58908, 86548, 58908, 35178, 248, 146227, 49128, 108, 35178, 228, 148291, 52806, 105, 49128, 101, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 72258, 146031, 35178, 249, 146026, 61356, 12, 146711, 11125, 224, 148787, 26927, 225, 148291, 26927, 222, 147645, 198, 146711, 26927, 223, 146838, 52806, 108, 148222, 49128, 97, 35178, 105, 148787, 26927, 223, 148124, 11125, 120, 41312, 320, 148204, 49128, 97, 26927, 222, 146834, 11125, 120, 1648, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 35178, 114, 58908, 149526, 35178, 117, 49128, 116, 80178, 101, 41312, 35178, 116, 146775, 146227, 146775, 58908, 35178, 243, 72258, 26927, 233, 86548, 35178, 255, 49128, 229, 72258, 49128, 116, 35178, 98, 58908, 146775, 58908, 35178, 101, 80178, 250, 58908, 148156, 58908, 72258, 35178, 116, 26927, 223, 72258, 146775, 52806, 115, 80178, 97, 35178, 108, 49128, 244, 147645, 58908, 35178, 101, 80178, 250, 35178, 101, 80178, 250, 35178, 243, 72258, 52806, 106, 146711, 52806, 98, 146227, 58908, 35178, 107, 148015, 49128, 107, 148015, 148222, 49128, 105, 58908, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 146026, 80178, 100, 61356, 35178, 106, 58908, 86548, 58908, 35178, 248, 146227, 49128, 108, 35178, 228, 148291, 52806, 105, 49128, 101, 35178, 250, 49128, 101, 80178, 107, 11125, 120, 58908, 35178, 105, 146227, 58908, 148972, 58908, 86548, 11, 35178, 250, 86548, 148787, 148194, 58908, 72258, 35178, 243, 146227, 52806, 107, 49128, 96, 58908, 72258, 35178, 243, 148015, 49128, 229, 35178, 97, 49128, 223, 72258, 35178, 116, 72258, 146775, 49128, 108, 35178, 116, 146026, 148431, 58908, 146834, 11125, 120, 58908, 35178, 105, 58908, 148125, 61356, 35178, 248, 80178, 101, 52806, 97, 41312, 35178, 243, 72258, 148972, 58908, 146031, 198, 147645, 80178, 101, 61356, 35178, 105, 146227, 58908, 86548, 11, 364, 146711, 146775, 146227, 146775, 58908, 35178, 116, 52806, 105, 12, 146711, 52806, 105, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 35178, 116, 26927, 223, 72258, 146775, 52806, 115, 80178, 97, 35178, 108, 58908, 149526, 58908, 148868, 35178, 116, 52806, 105, 12, 146711, 52806, 105, 35178, 243, 72258, 52806, 106, 146711, 52806, 98, 146227, 58908, 35178, 243, 49128, 250, 35178, 243, 72258, 58908, 35178, 107, 58908, 147645, 58908, 35178, 117, 146026, 58908, 146031, 35178, 99, 58908, 148125, 58908, 72258, 35178, 106, 49128, 101, 26927, 223, 148481, 35178, 107, 49128, 97, 58908, 35178, 243, 148481, 52806, 253, 35178, 101, 41312, 35178, 103, 49128, 107, 11125, 120, 35178, 243, 58908, 86548, 86548, 41312, 35178, 97, 49128, 223, 148156, 58908, 72258, 35178, 243, 148015, 49128, 229, 35178, 228, 146415, 72258, 41312, 35178, 105, 58908, 148125, 61356, 35178, 248, 80178, 101, 52806, 97, 41312, 35178, 243, 72258, 61356, 146031, 35178, 116, 146026, 49128, 229, 35178, 255, 49128, 110, 35178, 98, 49128, 243, 58908, 86548, 11, 35178, 116, 26927, 223, 146711, 52806, 98, 35178, 98, 49128, 243, 58908, 86548, 11, 35178, 116, 58908, 147338, 49128, 229, 35178, 243, 49128, 106, 86548, 41312, 35178, 243, 72258, 61356, 146031, 1248, 146415, 148571, 52806, 245, 146227, 146026, 49128, 108, 320, 26927, 102, 35178, 106, 58908, 8, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 35178, 114, 58908, 149526, 35178, 117, 49128, 116, 80178, 101, 41312, 35178, 250, 49128, 97, 26927, 222, 146834, 11125, 120, 35178, 227, 72258, 52806, 98, 86548, 26927, 230, 147645, 80178, 243, 35178, 103, 72258, 80178, 115, 148156, 58908, 72258, 35178, 101, 61356, 72258, 52806, 105, 49128, 117, 26927, 222, 35178, 243, 146415, 80178, 253, 61356, 72258, 320, 149525, 146775, 86548, 58908, 146775, 8, 35178, 116, 148222, 49128, 107, 11125, 120, 35178, 237, 146775, 148015, 41312, 35178, 105, 146227, 58908, 86548, 146031, 35178, 108, 49128, 250, 147997, 49128, 101, 26927, 222, 72258, 35178, 114, 58908, 72258, 58908, 146026, 49128, 224, 146227, 41312, 35178, 101, 148787, 72258, 58908, 72258, 35178, 237, 86548, 148868, 146711, 61356, 35178, 116, 146415, 52806, 106, 58908, 146227, 86548, 35178, 243, 146775, 52806, 115, 58908, 35178, 227, 86548, 26927, 223, 148481, 52806, 254, 80178, 97, 35178, 237, 148868, 35178, 116, 148222, 49128, 107, 11125, 120, 35178, 255, 80178, 94, 80178, 241, 35178, 243, 86548, 150262, 49128, 108, 58908, 86548, 52806, 116, 58908, 72258, 35178, 106, 49128, 100, 52806, 107, 146415, 58908, 35178, 245, 148194, 148222, 146026, 86548, 35178, 98, 58908, 146775, 58908, 35178, 116, 11125, 224, 146834, 26927, 223, 146775, 52806, 97, 35178, 117, 86548, 35178, 237, 146026, 11125, 224, 35178, 116, 148222, 49128, 103, 147645, 80178, 97, 52806, 105, 35178, 243, 72258, 58908, 86548, 220, 146031, 198, 149525, 148868, 35178, 255, 49128, 108, 52806, 248, 26927, 223, 146834, 11125, 120, 41312, 146227, 35178, 237, 146775, 86548, 58908, 146775, 35178, 116, 148222, 49128, 107, 11125, 120, 220, 26927, 100, 26927, 105, 35178, 117, 49128, 250, 49128, 108, 220, 26927, 101, 26927, 255, 26927, 105, 35178, 243, 26927, 233, 147338, 61356, 220, 26927, 102, 35178, 110, 49128, 244, 35178, 253, 49128, 243, 41312, 35178, 105, 52806, 107, 146834, 11125, 120, 58908, 220, 26927, 100, 26927, 99, 147338, 61356, 35178, 103, 52806, 108, 146775, 146227, 52806, 103, 35178, 227, 86548, 26927, 223, 146415, 26927, 233, 148156, 86548, 35178, 99, 58908, 146834, 11125, 120, 41312, 35178, 117, 146834, 11125, 120, 146031, 35178, 227, 86548, 26927, 223, 146415, 26927, 233, 148156, 80178, 97, 35178, 103, 52806, 108, 146775, 146227, 52806, 103, 58908, 72258, 35178, 250, 86548, 52806, 107, 35178, 105, 49128, 224, 146227, 49128, 99, 58908, 148125, 35178, 116, 72258, 146775, 49128, 108, 35178, 99, 58908, 146026, 58908, 220, 26927, 100, 26927, 103, 35178, 117, 49128, 250, 49128, 108, 220, 26927, 103, 26927, 99, 26927, 100, 35178, 243, 26927, 233, 147338, 61356, 220, 26927, 104, 26927, 101, 35178, 110, 49128, 244, 35178, 253, 49128, 243, 41312, 35178, 237, 146026, 11125, 224, 35178, 105, 26927, 230, 148156, 58908, 148125, 80178, 243, 35178, 233, 148194, 220, 26927, 100, 35178, 117, 49128, 250, 49128, 108, 220, 26927, 106, 26927, 106, 26927, 100, 35178, 243, 26927, 233, 147338, 61356, 220, 26927, 107, 26927, 255, 35178, 110, 49128, 244, 35178, 253, 49128, 243, 41312, 146031, 198, 146838, 72258, 58908, 35178, 103, 72258, 80178, 243, 146227, 52806, 103, 86548, 41312, 35178, 106, 86548, 52806, 97, 52806, 108, 26927, 222, 35178, 237, 146415, 149525, 35178, 106, 49128, 101, 52806, 101, 49128, 101, 35178, 116, 148222, 49128, 108, 35178, 105, 80178, 115, 146834, 11125, 120, 58908, 35178, 105, 80178, 116, 52806, 97, 49128, 108, 80178, 97, 35178, 116, 49128, 224, 146026, 49128, 99, 80178, 243, 148156, 58908, 72258, 35178, 227, 146026, 148291, 80178, 97, 35178, 243, 72258, 58908, 86548, 146031, 35178, 103, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 35178, 105, 146227, 58908, 86548, 11, 35178, 237, 72258, 35178, 228, 148787, 58908, 35178, 228, 146415, 72258, 41312, 35178, 250, 49128, 97, 26927, 222, 146834, 11125, 120, 35178, 227, 72258, 52806, 98, 86548, 26927, 230, 147645, 80178, 243, 35178, 243, 49128, 231, 86548, 52806, 116, 80178, 110, 58908, 72258, 35178, 116, 148222, 41312, 35178, 243, 72258, 58908, 35178, 105, 49128, 250, 58908, 147338, 35178, 103, 52806, 108, 148194, 146834, 11125, 120, 86548, 58908, 72258, 35178, 243, 49128, 250, 148787, 26927, 223, 146227, 26927, 233, 35178, 243, 72258, 58908, 148972, 61356, 146031, 198, 147645, 80178, 101, 61356, 35178, 105, 146227, 58908, 86548, 11, 35178, 243, 26927, 233, 148222, 80178, 94, 12, 26927, 100, 26927, 107, 35178, 255, 49128, 229, 72258, 49128, 116, 58908, 72258, 35178, 243, 49128, 108, 148194, 58908, 35178, 228, 148204, 35178, 114, 26927, 223, 147997, 26927, 223, 35178, 105, 49128, 224, 146227, 49128, 99, 58908, 148125, 35178, 101, 146834, 11125, 120, 35178, 116, 146415, 148787, 52806, 108, 35178, 105, 80178, 114, 52806, 105, 148868, 35178, 105, 146227, 147645, 58908, 35178, 245, 58908, 146227, 58908, 35178, 116, 52806, 98, 146026, 61356, 72258, 35178, 117, 146834, 11125, 120, 58908, 35178, 103, 148124, 11125, 120, 58908, 148972, 58908, 146031, 35178, 237, 72258, 146415, 147997, 52806, 107, 58908, 148873, 35178, 228, 146838, 86548, 49128, 108, 41312, 35178, 107, 49128, 108, 41312, 35178, 228, 148204, 146775, 58908, 35178, 103, 52806, 108, 146775, 146227, 52806, 103, 148787, 26927, 223, 146227, 26927, 233, 35178, 97, 26927, 230, 72258, 26927, 222, 35178, 243, 72258, 58908, 35178, 101, 80178, 107, 11125, 120, 58908, 35178, 237, 146711, 58908, 148972, 58908, 86548, 35178, 105, 41312, 35178, 94, 80178, 250, 80178, 253, 49128, 110, 35178, 103, 148156, 52806, 100, 147645, 80178, 97, 58908, 35178, 237, 148868, 35178, 106, 80178, 253, 80178, 224, 147338, 41312, 35178, 107, 58908, 35178, 243, 72258, 147645, 58908, 35178, 103, 49128, 108, 148972, 61356, 11, 35178, 116, 58908, 148204, 86548, 52806, 107, 35178, 228, 146838, 86548, 49128, 99, 58908, 72258, 35178, 228, 86548, 52806, 97, 72258, 80178, 243, 35178, 100, 86548, 52806, 107, 146026, 49128, 99, 35178, 250, 49128, 101, 49128, 229, 146031, 198, 146838, 52806, 108, 147997, 49128, 101, 146415, 86548, 52806, 97, 52806, 108, 26927, 222, 35178, 237, 146711, 146415, 146834, 11125, 120, 35178, 243, 72258, 58908, 86548, 41312, 35178, 255, 49128, 229, 72258, 49128, 116, 58908, 72258, 35178, 243, 49128, 108, 148194, 58908, 35178, 99, 58908, 148125, 58908, 35178, 237, 146026, 11125, 224, 35178, 105, 80178, 99, 58908, 148125, 58908, 35178, 106, 26927, 225, 147645, 52806, 107, 26927, 223, 146026, 72258, 86548, 146775, 49128, 108, 26927, 222, 35178, 105, 49128, 224, 146227, 49128, 99, 58908, 148125, 26927, 222, 148156, 58908, 72258, 35178, 250, 86548, 52806, 107, 35178, 114, 26927, 233, 146775, 35178, 241, 35178, 99, 26927, 223, 11125, 225, 149526, 35178, 103, 52806, 108, 146775, 49128, 114, 35178, 243, 72258, 58908, 35178, 97, 49128, 223, 148156, 58908, 72258, 35178, 228, 147645, 52806, 106, 49128, 108, 35178, 106, 49128, 245, 150262, 58908, 72258, 49128, 97, 35178, 243, 49128, 106, 86548, 41312, 35178, 243, 72258, 58908, 86548, 146031, 35178, 97, 80178, 101, 61356, 35178, 105, 146227, 58908, 86548, 11, 364, 149525, 35178, 105, 52806, 107, 49128, 103, 49128, 108, 58908, 35178, 107, 58908, 35178, 116, 52806, 105, 49128, 116, 52806, 98, 52806, 107, 146026, 80178, 100, 61356, 35178, 99, 58908, 148873, 146834, 11125, 120, 41312, 35178, 117, 146834, 11125, 120, 58908, 148972, 58908, 35178, 99, 58908, 148125, 146026, 49128, 116, 26927, 222, 35178, 116, 58908, 147338, 41312, 35178, 106, 58908, 86548, 58908, 35178, 248, 146227, 146026, 58908, 11, 35178, 237, 147338]
inputs:
           | Suprovat Bogura
             
          
           -
  ():                    ,         
 , ' -    -                     ,  ,   '
 ( )         ()                       
                                       
            ,            
 , -                              ,     
                      , '         , 
Caching indices mapping at /mnt/vol1/huangxin/nanda/dataset/CulturaX/cache/json/default-4e02b910cc3d648d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-05fe019f3d8af394.arrow
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Qwen2CrossAttnMergeModel(
  (small): Qwen2CrossAttnGeneratorModel(
    (embed_tokens): Embedding(151936, 1024)
    (layers): ModuleList(
      (0): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (1): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (2): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (3): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (4): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (5): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (6): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (7): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (8): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (9): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (10): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (11): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (12): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (13): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (14): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (15): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (16): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (17): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (18): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (19): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (20): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (21): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (22): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
      (23): Qwen2CrossAttnGeneratorDecoderLayer(
        (self_attn): Qwen2FlashAttention2(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm()
        (post_attention_layernorm): Qwen2RMSNorm()
      )
    )
    (norm): Qwen2RMSNorm()
  )
  (large): Qwen2CrossAttnCausalLM(
    (model): Qwen2CrossAttnModel(
      (embed_tokens): Embedding(151936, 4096)
      (layers): ModuleList(
        (0): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (1): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (2): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (3): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (4): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (5): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (6): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (7): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (8): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (9): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (10): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (11): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (12): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (13): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (14): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (15): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (16): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (17): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (18): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (19): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (20): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (21): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (22): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (23): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (24): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (25): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (26): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (27): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (28): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (29): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (30): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
        (31): Qwen2CrossAttnDecoderLayer(
          (self_attn): Qwen2Attention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=True)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): Qwen2RotaryEmbedding()
          )
          (mlp): Qwen2MLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): Qwen2RMSNorm()
          (post_attention_layernorm): Qwen2RMSNorm()
        )
      )
      (norm): Qwen2RMSNorm()
    )
    (lm_head): Linear(in_features=4096, out_features=151936, bias=False)
  )
  (align_modules): CrossAttn(
    (merge_modules): ModuleList(
      (0): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (1): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (2): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (3): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (4): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (5): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (6): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (7): ModuleDict(
        (projector): Projector(
          (fc): Linear(in_features=1024, out_features=4096, bias=True)
        )
        (q_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (k_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (v_weight): Linear(in_features=4096, out_features=4096, bias=True)
        (o_weight): Linear(in_features=4096, out_features=4096, bias=True)
      )
    )
  )
)
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:586] 2024-05-13 22:24:12,847 >> Using auto half precision backend
[2024-05-13 22:24:13,060] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.3, git-hash=unknown, git-branch=unknown
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1084187
})
[2024-05-13 22:24:55,353] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-05-13 22:24:55,355] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-05-13 22:24:55,356] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-05-13 22:24:55,361] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2024-05-13 22:24:55,361] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2024-05-13 22:24:55,362] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-05-13 22:24:55,362] [INFO] [stage_1_and_2.py:147:__init__] Reduce bucket size 500000000
[2024-05-13 22:24:55,362] [INFO] [stage_1_and_2.py:148:__init__] Allgather bucket size 500000000
[2024-05-13 22:24:55,362] [INFO] [stage_1_and_2.py:149:__init__] CPU Offload: False
[2024-05-13 22:24:55,362] [INFO] [stage_1_and_2.py:150:__init__] Round robin gradient partitioning: False
[2024-05-13 22:24:57,611] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states
[2024-05-13 22:24:57,612] [INFO] [utils.py:803:see_memory_usage] MA 17.29 GB         Max_MA 17.29 GB         CA 17.43 GB         Max_CA 17 GB 
[2024-05-13 22:24:57,612] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 154.52 GB, percent = 15.3%
[2024-05-13 22:24:57,794] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states
[2024-05-13 22:24:57,795] [INFO] [utils.py:803:see_memory_usage] MA 17.82 GB         Max_MA 18.62 GB         CA 18.76 GB         Max_CA 19 GB 
[2024-05-13 22:24:57,795] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 153.59 GB, percent = 15.2%
[2024-05-13 22:24:57,795] [INFO] [stage_1_and_2.py:514:__init__] optimizer state initialized
[2024-05-13 22:24:57,961] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer
[2024-05-13 22:24:57,962] [INFO] [utils.py:803:see_memory_usage] MA 17.82 GB         Max_MA 17.82 GB         CA 18.76 GB         Max_CA 19 GB 
[2024-05-13 22:24:57,962] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 151.9 GB, percent = 15.1%
[2024-05-13 22:24:57,963] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2024-05-13 22:24:57,963] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-05-13 22:24:57,963] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-05-13 22:24:57,963] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05, 5e-05], mom=[(0.9, 0.999), (0.9, 0.999)]
[2024-05-13 22:24:57,965] [INFO] [config.py:974:print] DeepSpeedEngine configuration:
[2024-05-13 22:24:57,965] [INFO] [config.py:978:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-05-13 22:24:57,965] [INFO] [config.py:978:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-05-13 22:24:57,965] [INFO] [config.py:978:print]   amp_enabled .................. False
[2024-05-13 22:24:57,965] [INFO] [config.py:978:print]   amp_params ................... False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   bfloat16_enabled ............. True
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   checkpoint_parallel_write_pipeline  False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   checkpoint_tag_validation_enabled  True
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   checkpoint_tag_validation_fail  False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7efdf935a5f0>
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   communication_data_type ...... None
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   curriculum_enabled_legacy .... False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   curriculum_params_legacy ..... False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   data_efficiency_enabled ...... False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   dataloader_drop_last ......... False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   disable_allgather ............ False
[2024-05-13 22:24:57,966] [INFO] [config.py:978:print]   dump_state ................... False
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   dynamic_loss_scale_args ...... None
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_enabled ........... False
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_gas_boundary_resolution  1
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_layer_num ......... 0
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_max_iter .......... 100
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_stability ......... 1e-06
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_tol ............... 0.01
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   eigenvalue_verbose ........... False
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   elasticity_enabled ........... False
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   fp16_auto_cast ............... None
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   fp16_enabled ................. False
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   fp16_master_weights_and_gradients  False
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   global_rank .................. 0
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   grad_accum_dtype ............. None
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   gradient_accumulation_steps .. 16
[2024-05-13 22:24:57,967] [INFO] [config.py:978:print]   gradient_clipping ............ 1.0
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   gradient_predivide_factor .... 1.0
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   initial_dynamic_scale ........ 1
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   load_universal_checkpoint .... False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   loss_scale ................... 1.0
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   memory_breakdown ............. False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   mics_hierarchial_params_gather  False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   mics_shard_size .............. -1
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   optimizer_legacy_fusion ...... False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   optimizer_name ............... None
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   optimizer_params ............. None
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   pld_enabled .................. False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   pld_params ................... False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   prescale_gradients ........... False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   scheduler_name ............... None
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   scheduler_params ............. None
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   seq_parallel_communication_data_type  torch.float32
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   sparse_attention ............. None
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   sparse_gradients_enabled ..... False
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   steps_per_print .............. inf
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   train_batch_size ............. 1024
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   train_micro_batch_size_per_gpu  8
[2024-05-13 22:24:57,968] [INFO] [config.py:978:print]   use_node_local_storage ....... False
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   wall_clock_breakdown ......... False
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   weight_quantization_config ... None
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   world_size ................... 8
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   zero_allow_untested_optimizer  True
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   zero_enabled ................. True
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   zero_force_ds_cpu_optimizer .. True
[2024-05-13 22:24:57,969] [INFO] [config.py:978:print]   zero_optimization_stage ...... 2
[2024-05-13 22:24:57,969] [INFO] [config.py:964:print_user_config]   json = {
    "train_batch_size": 1.024000e+03, 
    "train_micro_batch_size_per_gpu": 8, 
    "gradient_accumulation_steps": 16, 
    "gradient_clipping": 1.0, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "initial_scale_power": 16, 
        "loss_scale_window": 1000, 
        "hysteresis": 2, 
        "min_loss_scale": 1e-09
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 5.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 5.000000e+08, 
        "contiguous_gradients": true
    }, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }
}
[INFO|trainer.py:1747] 2024-05-13 22:24:57,969 >> ***** Running training *****
[INFO|trainer.py:1748] 2024-05-13 22:24:57,969 >>   Num examples = 1,084,187
[INFO|trainer.py:1749] 2024-05-13 22:24:57,969 >>   Num Epochs = 1
[INFO|trainer.py:1750] 2024-05-13 22:24:57,969 >>   Instantaneous batch size per device = 8
[INFO|trainer.py:1753] 2024-05-13 22:24:57,969 >>   Total train batch size (w. parallel, distributed & accumulation) = 1,024
[INFO|trainer.py:1754] 2024-05-13 22:24:57,969 >>   Gradient Accumulation steps = 16
[INFO|trainer.py:1755] 2024-05-13 22:24:57,969 >>   Total optimization steps = 1,058
[INFO|trainer.py:1756] 2024-05-13 22:24:57,971 >>   Number of trainable parameters = 570,589,184
  0%|          | 0/1058 [00:00<?, ?it/s]  0%|          | 1/1058 [02:09<38:04:30, 129.68s/it]  0%|          | 2/1058 [04:17<37:45:26, 128.72s/it]  0%|          | 3/1058 [06:25<37:34:31, 128.22s/it]  0%|          | 4/1058 [08:33<37:34:41, 128.35s/it]  0%|          | 5/1058 [10:42<37:32:57, 128.37s/it]  1%|          | 6/1058 [12:50<37:31:22, 128.41s/it]  1%|          | 7/1058 [14:58<37:24:45, 128.15s/it]  1%|          | 8/1058 [17:06<37:20:25, 128.02s/it]  1%|          | 9/1058 [19:13<37:16:31, 127.92s/it]  1%|          | 10/1058 [21:21<37:11:58, 127.78s/it]                                                     {'loss': 10.273, 'learning_rate': 4.9988979367702804e-05, 'epoch': 0.01}
  1%|          | 10/1058 [21:21<37:11:58, 127.78s/it]  1%|          | 11/1058 [23:29<37:14:30, 128.05s/it]  1%|          | 12/1058 [25:38<37:15:48, 128.25s/it]  1%|          | 13/1058 [27:47<37:15:00, 128.33s/it]  1%|         | 14/1058 [29:55<37:12:35, 128.31s/it]  1%|         | 15/1058 [32:03<37:07:45, 128.16s/it]  2%|         | 16/1058 [34:10<37:01:44, 127.93s/it]  2%|         | 17/1058 [36:18<37:01:30, 128.04s/it]  2%|         | 18/1058 [38:26<36:54:38, 127.77s/it]  2%|         | 19/1058 [40:33<36:53:05, 127.80s/it]  2%|         | 20/1058 [42:42<36:53:34, 127.95s/it]                                                     {'loss': 7.0916, 'learning_rate': 4.995592718715809e-05, 'epoch': 0.02}
  2%|         | 20/1058 [42:42<36:53:34, 127.95s/it]  2%|         | 21/1058 [44:50<36:53:15, 128.06s/it]  2%|         | 22/1058 [46:58<36:52:11, 128.12s/it]  2%|         | 23/1058 [49:07<36:50:31, 128.15s/it]  2%|         | 24/1058 [51:15<36:48:52, 128.17s/it]  2%|         | 25/1058 [53:23<36:46:59, 128.19s/it]  2%|         | 26/1058 [55:31<36:44:56, 128.19s/it]  3%|         | 27/1058 [57:39<36:42:43, 128.19s/it]  3%|         | 28/1058 [59:48<36:40:46, 128.20s/it]  3%|         | 29/1058 [1:01:56<36:38:31, 128.19s/it]  3%|         | 30/1058 [1:04:04<36:36:38, 128.21s/it]                                                       {'loss': 4.9599, 'learning_rate': 4.9900872598840156e-05, 'epoch': 0.03}
  3%|         | 30/1058 [1:04:04<36:36:38, 128.21s/it]  3%|         | 31/1058 [1:06:12<36:34:37, 128.22s/it]  3%|         | 32/1058 [1:08:20<36:29:23, 128.03s/it]  3%|         | 33/1058 [1:10:27<36:23:05, 127.79s/it]  3%|         | 34/1058 [1:12:35<36:22:37, 127.89s/it]  3%|         | 35/1058 [1:14:43<36:21:22, 127.94s/it]  3%|         | 36/1058 [1:16:51<36:19:32, 127.96s/it]  3%|         | 37/1058 [1:18:59<36:18:02, 127.99s/it]  4%|         | 38/1058 [1:21:08<36:16:43, 128.04s/it]  4%|         | 39/1058 [1:23:15<36:14:00, 128.01s/it]  4%|         | 40/1058 [1:25:22<36:06:36, 127.70s/it]                                                       {'loss': 4.4131, 'learning_rate': 4.9823864141658905e-05, 'epoch': 0.04}
  4%|         | 40/1058 [1:25:22<36:06:36, 127.70s/it]  4%|         | 41/1058 [1:27:30<36:06:06, 127.79s/it]  4%|         | 42/1058 [1:29:37<35:59:33, 127.53s/it]  4%|         | 43/1058 [1:31:45<35:58:08, 127.57s/it]  4%|         | 44/1058 [1:33:53<35:59:00, 127.75s/it]  4%|         | 45/1058 [1:36:00<35:53:54, 127.58s/it]  4%|         | 46/1058 [1:38:08<35:51:51, 127.58s/it]  4%|         | 47/1058 [1:40:15<35:46:20, 127.38s/it]  5%|         | 48/1058 [1:42:23<35:46:22, 127.51s/it]  5%|         | 49/1058 [1:44:30<35:41:10, 127.32s/it]  5%|         | 50/1058 [1:46:37<35:41:31, 127.47s/it]                                                       {'loss': 4.1544, 'learning_rate': 4.9724969710165594e-05, 'epoch': 0.05}
  5%|         | 50/1058 [1:46:37<35:41:31, 127.47s/it]  5%|         | 51/1058 [1:48:45<35:42:15, 127.64s/it]  5%|         | 52/1058 [1:50:53<35:37:17, 127.47s/it]  5%|         | 53/1058 [1:53:01<35:38:05, 127.65s/it]  5%|         | 54/1058 [1:55:09<35:37:25, 127.73s/it]  5%|         | 55/1058 [1:57:16<35:32:07, 127.54s/it]  5%|         | 56/1058 [1:59:24<35:33:27, 127.75s/it]  5%|         | 57/1058 [2:01:32<35:33:08, 127.86s/it]  5%|         | 58/1058 [2:03:40<35:32:48, 127.97s/it]  6%|         | 59/1058 [2:05:48<35:30:33, 127.96s/it]  6%|         | 60/1058 [2:07:55<35:23:33, 127.67s/it]                                                       {'loss': 4.0253, 'learning_rate': 4.9604276494693455e-05, 'epoch': 0.06}
  6%|         | 60/1058 [2:07:55<35:23:33, 127.67s/it]  6%|         | 61/1058 [2:10:03<35:23:18, 127.78s/it]  6%|         | 62/1058 [2:12:11<35:23:14, 127.91s/it]  6%|         | 63/1058 [2:14:20<35:22:25, 127.99s/it]  6%|         | 64/1058 [2:16:27<35:16:07, 127.73s/it]  6%|         | 65/1058 [2:18:35<35:14:42, 127.78s/it]  6%|         | 66/1058 [2:20:42<35:08:52, 127.55s/it]  6%|         | 67/1058 [2:22:49<35:07:37, 127.61s/it]  6%|         | 68/1058 [2:24:57<35:07:02, 127.70s/it]  7%|         | 69/1058 [2:27:04<35:02:29, 127.55s/it]  7%|         | 70/1058 [2:29:13<35:03:26, 127.74s/it]                                                       {'loss': 3.9819, 'learning_rate': 4.9461890904486387e-05, 'epoch': 0.07}
  7%|         | 70/1058 [2:29:13<35:03:26, 127.74s/it]  7%|         | 71/1058 [2:31:21<35:03:48, 127.89s/it]  7%|         | 72/1058 [2:33:28<34:58:53, 127.72s/it]  7%|         | 73/1058 [2:35:36<34:56:16, 127.69s/it]  7%|         | 74/1058 [2:37:44<34:57:19, 127.89s/it]  7%|         | 75/1058 [2:39:53<34:58:19, 128.08s/it]  7%|         | 76/1058 [2:42:01<34:58:06, 128.19s/it]  7%|         | 77/1058 [2:44:08<34:51:16, 127.91s/it]  7%|         | 78/1058 [2:46:16<34:50:08, 127.97s/it]  7%|         | 79/1058 [2:48:25<34:48:35, 128.00s/it]  8%|         | 80/1058 [2:50:32<34:44:15, 127.87s/it]                                                       {'loss': 3.9284, 'learning_rate': 4.9297938473883104e-05, 'epoch': 0.08}
  8%|         | 80/1058 [2:50:32<34:44:15, 127.87s/it]  8%|         | 81/1058 [2:52:41<34:46:21, 128.13s/it]  8%|         | 82/1058 [2:54:50<34:46:51, 128.29s/it]  8%|         | 83/1058 [2:56:58<34:45:58, 128.37s/it]  8%|         | 84/1058 [2:59:06<34:39:38, 128.11s/it]  8%|         | 85/1058 [3:01:14<34:38:47, 128.19s/it]  8%|         | 86/1058 [3:03:21<34:32:27, 127.93s/it]  8%|         | 87/1058 [3:05:30<34:33:25, 128.12s/it]  8%|         | 88/1058 [3:07:37<34:28:23, 127.94s/it]  8%|         | 89/1058 [3:09:46<34:29:02, 128.11s/it]  9%|         | 90/1058 [3:11:55<34:30:28, 128.34s/it]                                                       {'loss': 3.7096, 'learning_rate': 4.9112563751639765e-05, 'epoch': 0.09}
  9%|         | 90/1058 [3:11:55<34:30:28, 128.34s/it]  9%|         | 91/1058 [3:14:04<34:30:32, 128.47s/it]  9%|         | 92/1058 [3:16:12<34:29:31, 128.54s/it]  9%|         | 93/1058 [3:18:20<34:22:56, 128.27s/it]  9%|         | 94/1058 [3:20:28<34:20:45, 128.26s/it]  9%|         | 95/1058 [3:22:36<34:15:32, 128.07s/it]  9%|         | 96/1058 [3:24:45<34:17:25, 128.32s/it]  9%|         | 97/1058 [3:26:53<34:17:41, 128.47s/it]  9%|         | 98/1058 [3:29:02<34:17:33, 128.60s/it]  9%|         | 99/1058 [3:31:11<34:16:02, 128.64s/it]  9%|         | 100/1058 [3:33:20<34:14:58, 128.70s/it]                                                        {'loss': 3.3951, 'learning_rate': 4.890593017348846e-05, 'epoch': 0.09}
  9%|         | 100/1058 [3:33:20<34:14:58, 128.70s/it] 10%|         | 101/1058 [3:35:29<34:12:13, 128.67s/it] 10%|         | 102/1058 [3:37:37<34:10:32, 128.69s/it] 10%|         | 103/1058 [3:39:46<34:08:43, 128.72s/it] 10%|         | 104/1058 [3:41:54<34:03:54, 128.55s/it] 10%|         | 105/1058 [3:44:02<33:57:45, 128.30s/it] 10%|         | 106/1058 [3:46:10<33:55:08, 128.27s/it] 10%|         | 107/1058 [3:48:18<33:50:47, 128.13s/it] 10%|         | 108/1058 [3:50:27<33:51:59, 128.34s/it] 10%|         | 109/1058 [3:52:36<33:51:54, 128.47s/it] 10%|         | 110/1058 [3:54:44<33:51:16, 128.56s/it]                                                        {'loss': 3.2926, 'learning_rate': 4.8678219918043984e-05, 'epoch': 0.1}
 10%|         | 110/1058 [3:54:44<33:51:16, 128.56s/it] 10%|         | 111/1058 [3:56:52<33:45:47, 128.35s/it] 11%|         | 112/1058 [3:59:01<33:45:22, 128.46s/it] 11%|         | 113/1058 [4:01:10<33:46:40, 128.68s/it] 11%|         | 114/1058 [4:03:19<33:45:58, 128.77s/it] 11%|         | 115/1058 [4:05:28<33:44:28, 128.81s/it] 11%|         | 116/1058 [4:07:37<33:42:47, 128.84s/it] 11%|         | 117/1058 [4:09:46<33:41:19, 128.88s/it] 11%|         | 118/1058 [4:11:55<33:38:12, 128.82s/it] 11%|         | 119/1058 [4:14:03<33:35:27, 128.78s/it] 11%|        | 120/1058 [4:16:12<33:33:01, 128.76s/it]                                                        {'loss': 3.2662, 'learning_rate': 4.8429633746185975e-05, 'epoch': 0.11}
 11%|        | 120/1058 [4:16:12<33:33:01, 128.76s/it] 11%|        | 121/1058 [4:18:21<33:31:49, 128.83s/it] 12%|        | 122/1058 [4:20:29<33:26:06, 128.60s/it] 12%|        | 123/1058 [4:22:37<33:22:10, 128.48s/it] 12%|        | 124/1058 [4:24:45<33:16:33, 128.26s/it] 12%|        | 125/1058 [4:26:53<33:15:51, 128.35s/it] 12%|        | 126/1058 [4:29:02<33:16:06, 128.50s/it] 12%|        | 127/1058 [4:31:11<33:16:02, 128.64s/it] 12%|        | 128/1058 [4:33:20<33:15:19, 128.73s/it] 12%|        | 129/1058 [4:35:29<33:13:49, 128.77s/it] 12%|        | 130/1058 [4:37:38<33:12:11, 128.81s/it]                                                        {'loss': 3.2293, 'learning_rate': 4.816039082405799e-05, 'epoch': 0.12}
 12%|        | 130/1058 [4:37:38<33:12:11, 128.81s/it] 12%|        | 131/1058 [4:39:47<33:10:06, 128.81s/it] 12%|        | 132/1058 [4:41:56<33:08:07, 128.82s/it] 13%|        | 133/1058 [4:44:05<33:06:41, 128.87s/it] 13%|        | 134/1058 [4:46:14<33:04:43, 128.88s/it] 13%|        | 135/1058 [4:48:22<33:02:36, 128.88s/it] 13%|        | 136/1058 [4:50:31<33:00:54, 128.91s/it] 13%|        | 137/1058 [4:52:40<32:58:50, 128.91s/it] 13%|        | 138/1058 [4:54:49<32:56:07, 128.88s/it] 13%|        | 139/1058 [4:56:58<32:53:17, 128.83s/it] 13%|        | 140/1058 [4:59:06<32:47:15, 128.58s/it]                                                        {'loss': 3.216, 'learning_rate': 4.787072852983949e-05, 'epoch': 0.13}
 13%|        | 140/1058 [4:59:06<32:47:15, 128.58s/it] 13%|        | 141/1058 [5:01:15<32:46:33, 128.67s/it] 13%|        | 142/1058 [5:03:24<32:45:40, 128.76s/it] 14%|        | 143/1058 [5:05:33<32:43:51, 128.78s/it] 14%|        | 144/1058 [5:07:42<32:43:07, 128.87s/it] 14%|        | 145/1058 [5:09:50<32:38:14, 128.69s/it] 14%|        | 146/1058 [5:11:58<32:33:22, 128.51s/it] 14%|        | 147/1058 [5:14:06<32:29:54, 128.42s/it] 14%|        | 148/1058 [5:16:14<32:25:33, 128.28s/it] 14%|        | 149/1058 [5:18:23<32:26:16, 128.47s/it] 14%|        | 150/1058 [5:20:32<32:26:13, 128.61s/it]                                                        {'loss': 3.1565, 'learning_rate': 4.756090224446127e-05, 'epoch': 0.14}
 14%|        | 150/1058 [5:20:32<32:26:13, 128.61s/it] 14%|        | 151/1058 [5:22:41<32:26:13, 128.75s/it] 14%|        | 152/1058 [5:24:49<32:21:20, 128.57s/it] 14%|        | 153/1058 [5:26:57<32:18:05, 128.49s/it] 15%|        | 154/1058 [5:29:05<32:13:24, 128.32s/it] 15%|        | 155/1058 [5:31:14<32:12:45, 128.42s/it] 15%|        | 156/1058 [5:33:23<32:12:56, 128.58s/it] 15%|        | 157/1058 [5:35:32<32:12:20, 128.68s/it] 15%|        | 158/1058 [5:37:41<32:11:29, 128.77s/it] 15%|        | 159/1058 [5:39:50<32:10:08, 128.82s/it] 15%|        | 160/1058 [5:41:59<32:07:55, 128.81s/it]                                                        {'loss': 3.0934, 'learning_rate': 4.72311851264487e-05, 'epoch': 0.15}
 15%|        | 160/1058 [5:41:59<32:07:55, 128.81s/it] 15%|        | 161/1058 [5:44:08<32:05:58, 128.83s/it] 15%|        | 162/1058 [5:46:16<32:04:24, 128.87s/it] 15%|        | 163/1058 [5:48:25<32:02:16, 128.87s/it] 16%|        | 164/1058 [5:50:34<32:00:31, 128.89s/it] 16%|        | 165/1058 [5:52:43<31:58:58, 128.93s/it] 16%|        | 166/1058 [5:54:52<31:57:08, 128.96s/it] 16%|        | 167/1058 [5:57:01<31:54:53, 128.95s/it] 16%|        | 168/1058 [5:59:10<31:50:49, 128.82s/it] 16%|        | 169/1058 [6:01:18<31:47:43, 128.76s/it] 16%|        | 170/1058 [6:03:27<31:46:33, 128.82s/it]                                                        {'loss': 3.0117, 'learning_rate': 4.688186787109136e-05, 'epoch': 0.16}
 16%|        | 170/1058 [6:03:27<31:46:33, 128.82s/it] 16%|        | 171/1058 [6:05:36<31:45:07, 128.87s/it] 16%|        | 172/1058 [6:07:44<31:38:17, 128.55s/it] 16%|        | 173/1058 [6:09:53<31:36:35, 128.58s/it] 16%|        | 174/1058 [6:12:00<31:30:30, 128.31s/it] 17%|        | 175/1058 [6:14:09<31:31:00, 128.49s/it] 17%|        | 176/1058 [6:16:19<31:31:39, 128.68s/it] 17%|        | 177/1058 [6:18:28<31:31:23, 128.81s/it] 17%|        | 178/1058 [6:20:37<31:30:46, 128.92s/it] 17%|        | 179/1058 [6:22:46<31:29:33, 128.98s/it] 17%|        | 180/1058 [6:24:55<31:28:05, 129.03s/it]                                                        {'loss': 2.8987, 'learning_rate': 4.651325845415136e-05, 'epoch': 0.17}
 17%|        | 180/1058 [6:24:55<31:28:05, 129.03s/it] 17%|        | 181/1058 [6:27:03<31:21:49, 128.75s/it] 17%|        | 182/1058 [6:29:12<31:21:03, 128.84s/it] 17%|        | 183/1058 [6:31:21<31:20:20, 128.94s/it] 17%|        | 184/1058 [6:33:30<31:18:51, 128.98s/it] 17%|        | 185/1058 [6:35:39<31:16:02, 128.94s/it] 18%|        | 186/1058 [6:37:48<31:11:19, 128.76s/it] 18%|        | 187/1058 [6:39:56<31:08:23, 128.71s/it] 18%|        | 188/1058 [6:42:04<31:02:46, 128.47s/it] 18%|        | 189/1058 [6:44:13<31:03:43, 128.68s/it] 18%|        | 190/1058 [6:46:21<30:58:48, 128.49s/it]                                                        {'loss': 2.8021, 'learning_rate': 4.612568186033633e-05, 'epoch': 0.18}
 18%|        | 190/1058 [6:46:21<30:58:48, 128.49s/it] 18%|        | 191/1058 [6:48:30<30:57:37, 128.56s/it] 18%|        | 192/1058 [6:50:39<30:57:47, 128.72s/it] 18%|        | 193/1058 [6:52:48<30:57:15, 128.83s/it] 18%|        | 194/1058 [6:54:57<30:52:56, 128.68s/it] 18%|        | 195/1058 [6:57:05<30:49:50, 128.61s/it] 19%|        | 196/1058 [6:59:13<30:46:27, 128.52s/it] 19%|        | 197/1058 [7:01:22<30:43:27, 128.46s/it] 19%|        | 198/1058 [7:03:31<30:44:42, 128.70s/it] 19%|        | 199/1058 [7:05:40<30:44:14, 128.82s/it] 19%|        | 200/1058 [7:07:48<30:37:39, 128.51s/it]                                                        {'loss': 2.7433, 'learning_rate': 4.571947979677647e-05, 'epoch': 0.19}
 19%|        | 200/1058 [7:07:48<30:37:39, 128.51s/it][INFO|trainer.py:2979] 2024-05-14 05:32:54,746 >> Saving model checkpoint to /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200
[INFO|configuration_utils.py:473] 2024-05-14 05:32:54,751 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200/config.json
[INFO|configuration_utils.py:595] 2024-05-14 05:32:54,755 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200/generation_config.json
[INFO|modeling_utils.py:2540] 2024-05-14 05:33:11,606 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-05-14 05:33:11,611 >> tokenizer config file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-05-14 05:33:11,613 >> Special tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-05-14 05:33:11,615 >> added tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-200/added_tokens.json
 19%|        | 201/1058 [7:10:23<32:29:01, 136.45s/it] 19%|        | 202/1058 [7:12:32<31:55:52, 134.29s/it] 19%|        | 203/1058 [7:14:41<31:32:22, 132.80s/it] 19%|        | 204/1058 [7:16:51<31:14:57, 131.73s/it] 19%|        | 205/1058 [7:19:00<31:01:55, 130.97s/it] 19%|        | 206/1058 [7:21:09<30:50:56, 130.35s/it] 20%|        | 207/1058 [7:23:17<30:39:43, 129.71s/it] 20%|        | 208/1058 [7:25:26<30:35:08, 129.54s/it] 20%|        | 209/1058 [7:27:35<30:31:33, 129.44s/it] 20%|        | 210/1058 [7:29:44<30:28:01, 129.34s/it]                                                        {'loss': 2.6989, 'learning_rate': 4.529501039175824e-05, 'epoch': 0.2}
 20%|        | 210/1058 [7:29:44<30:28:01, 129.34s/it] 20%|        | 211/1058 [7:31:54<30:25:16, 129.30s/it] 20%|        | 212/1058 [7:34:03<30:22:25, 129.25s/it] 20%|        | 213/1058 [7:36:12<30:19:38, 129.21s/it] 20%|        | 214/1058 [7:38:21<30:17:21, 129.20s/it] 20%|        | 215/1058 [7:40:30<30:15:10, 129.19s/it] 20%|        | 216/1058 [7:42:39<30:12:36, 129.16s/it] 21%|        | 217/1058 [7:44:48<30:10:28, 129.17s/it] 21%|        | 218/1058 [7:46:58<30:08:04, 129.15s/it] 21%|        | 219/1058 [7:49:07<30:06:03, 129.16s/it] 21%|        | 220/1058 [7:51:15<29:59:04, 128.81s/it]                                                        {'loss': 2.67, 'learning_rate': 4.485264787898037e-05, 'epoch': 0.21}
 21%|        | 220/1058 [7:51:15<29:59:04, 128.81s/it] 21%|        | 221/1058 [7:53:24<29:57:08, 128.83s/it] 21%|        | 222/1058 [7:55:33<29:56:29, 128.93s/it] 21%|        | 223/1058 [7:57:42<29:56:05, 129.06s/it] 21%|        | 224/1058 [7:59:50<29:50:43, 128.83s/it] 21%|       | 225/1058 [8:01:59<29:49:29, 128.89s/it] 21%|       | 226/1058 [8:04:07<29:43:35, 128.62s/it] 21%|       | 227/1058 [8:06:16<29:42:50, 128.73s/it] 22%|       | 228/1058 [8:08:26<29:42:23, 128.85s/it] 22%|       | 229/1058 [8:10:35<29:41:43, 128.96s/it] 22%|       | 230/1058 [8:12:44<29:40:37, 129.03s/it]                                                        {'loss': 2.6368, 'learning_rate': 4.43927822676105e-05, 'epoch': 0.22}
 22%|       | 230/1058 [8:12:44<29:40:37, 129.03s/it] 22%|       | 231/1058 [8:14:53<29:39:00, 129.07s/it] 22%|       | 232/1058 [8:17:02<29:37:10, 129.09s/it] 22%|       | 233/1058 [8:19:10<29:30:44, 128.78s/it] 22%|       | 234/1058 [8:21:19<29:28:31, 128.78s/it] 22%|       | 235/1058 [8:23:27<29:23:26, 128.56s/it] 22%|       | 236/1058 [8:25:36<29:22:21, 128.64s/it] 22%|       | 237/1058 [8:27:44<29:17:06, 128.41s/it] 22%|       | 238/1058 [8:29:53<29:17:48, 128.62s/it] 23%|       | 239/1058 [8:32:01<29:13:09, 128.44s/it] 23%|       | 240/1058 [8:34:10<29:13:39, 128.63s/it]                                                        {'loss': 2.606, 'learning_rate': 4.3915818998433344e-05, 'epoch': 0.23}
 23%|       | 240/1058 [8:34:10<29:13:39, 128.63s/it] 23%|       | 241/1058 [8:36:19<29:13:41, 128.79s/it] 23%|       | 242/1058 [8:38:28<29:13:11, 128.91s/it] 23%|       | 243/1058 [8:40:38<29:12:26, 129.01s/it] 23%|       | 244/1058 [8:42:47<29:11:10, 129.08s/it] 23%|       | 245/1058 [8:44:56<29:09:59, 129.15s/it] 23%|       | 246/1058 [8:47:05<29:08:01, 129.16s/it] 23%|       | 247/1058 [8:49:15<29:06:04, 129.18s/it] 23%|       | 248/1058 [8:51:24<29:03:58, 129.18s/it] 24%|       | 249/1058 [8:53:33<29:02:19, 129.22s/it] 24%|       | 250/1058 [8:55:41<28:55:01, 128.84s/it]                                                        {'loss': 2.5764, 'learning_rate': 4.342217858639362e-05, 'epoch': 0.24}
 24%|       | 250/1058 [8:55:41<28:55:01, 128.84s/it] 24%|       | 251/1058 [8:57:50<28:53:06, 128.86s/it] 24%|       | 252/1058 [8:59:58<28:47:01, 128.56s/it] 24%|       | 253/1058 [9:02:07<28:46:48, 128.71s/it] 24%|       | 254/1058 [9:04:16<28:46:52, 128.87s/it] 24%|       | 255/1058 [9:06:24<28:41:58, 128.67s/it] 24%|       | 256/1058 [9:08:33<28:39:04, 128.61s/it] 24%|       | 257/1058 [9:10:42<28:39:08, 128.77s/it] 24%|       | 258/1058 [9:12:51<28:38:55, 128.92s/it] 24%|       | 259/1058 [9:14:59<28:32:37, 128.61s/it] 25%|       | 260/1058 [9:17:08<28:31:07, 128.66s/it]                                                        {'loss': 2.5395, 'learning_rate': 4.291229624984876e-05, 'epoch': 0.25}
 25%|       | 260/1058 [9:17:08<28:31:07, 128.66s/it] 25%|       | 261/1058 [9:19:17<28:30:58, 128.81s/it] 25%|       | 262/1058 [9:21:26<28:30:20, 128.92s/it] 25%|       | 263/1058 [9:23:35<28:28:43, 128.96s/it] 25%|       | 264/1058 [9:25:43<28:22:16, 128.63s/it] 25%|       | 265/1058 [9:27:52<28:21:25, 128.73s/it] 25%|       | 266/1058 [9:30:01<28:19:45, 128.77s/it] 25%|       | 267/1058 [9:32:09<28:15:16, 128.59s/it] 25%|       | 268/1058 [9:34:18<28:15:28, 128.77s/it] 25%|       | 269/1058 [9:36:28<28:15:59, 128.97s/it] 26%|       | 270/1058 [9:38:36<28:09:53, 128.67s/it]                                                        {'loss': 2.5124, 'learning_rate': 4.238662152685846e-05, 'epoch': 0.26}
 26%|       | 270/1058 [9:38:36<28:09:53, 128.67s/it] 26%|       | 271/1058 [9:40:44<28:07:49, 128.68s/it] 26%|       | 272/1058 [9:42:54<28:07:53, 128.85s/it] 26%|       | 273/1058 [9:45:02<28:02:53, 128.63s/it] 26%|       | 274/1058 [9:47:11<28:02:26, 128.76s/it] 26%|       | 275/1058 [9:49:20<28:02:02, 128.89s/it] 26%|       | 276/1058 [9:51:29<28:00:46, 128.96s/it] 26%|       | 277/1058 [9:53:38<27:59:16, 129.01s/it] 26%|       | 278/1058 [9:55:46<27:53:53, 128.76s/it] 26%|       | 279/1058 [9:57:55<27:51:26, 128.74s/it] 26%|       | 280/1058 [10:00:04<27:51:28, 128.90s/it]                                                         {'loss': 2.498, 'learning_rate': 4.184561787884911e-05, 'epoch': 0.26}
 26%|       | 280/1058 [10:00:04<27:51:28, 128.90s/it] 27%|       | 281/1058 [10:02:14<27:50:52, 129.02s/it] 27%|       | 282/1058 [10:04:23<27:49:14, 129.07s/it] 27%|       | 283/1058 [10:06:32<27:47:48, 129.12s/it] 27%|       | 284/1058 [10:08:41<27:45:40, 129.12s/it] 27%|       | 285/1058 [10:10:51<27:44:27, 129.19s/it] 27%|       | 286/1058 [10:13:00<27:42:31, 129.21s/it] 27%|       | 287/1058 [10:15:09<27:39:58, 129.18s/it] 27%|       | 288/1058 [10:17:18<27:38:02, 129.20s/it] 27%|       | 289/1058 [10:19:27<27:35:31, 129.17s/it] 27%|       | 290/1058 [10:21:37<27:33:30, 129.18s/it]                                                         {'loss': 2.4836, 'learning_rate': 4.1289762282002796e-05, 'epoch': 0.27}
 27%|       | 290/1058 [10:21:37<27:33:30, 129.18s/it] 28%|       | 291/1058 [10:23:45<27:29:43, 129.05s/it] 28%|       | 292/1058 [10:25:54<27:24:28, 128.81s/it] 28%|       | 293/1058 [10:28:02<27:20:55, 128.70s/it] 28%|       | 294/1058 [10:30:10<27:17:37, 128.61s/it] 28%|       | 295/1058 [10:32:19<27:14:37, 128.54s/it] 28%|       | 296/1058 [10:34:27<27:12:31, 128.55s/it] 28%|       | 297/1058 [10:36:37<27:13:10, 128.77s/it] 28%|       | 298/1058 [10:38:45<27:08:09, 128.54s/it] 28%|       | 299/1058 [10:40:54<27:07:32, 128.66s/it] 28%|       | 300/1058 [10:43:03<27:07:39, 128.84s/it]                                                         {'loss': 2.4515, 'learning_rate': 4.0719544806730987e-05, 'epoch': 0.28}
 28%|       | 300/1058 [10:43:03<27:07:39, 128.84s/it] 28%|       | 301/1058 [10:45:11<27:02:49, 128.63s/it] 29%|       | 302/1058 [10:47:20<27:02:09, 128.74s/it] 29%|       | 303/1058 [10:49:29<27:01:39, 128.87s/it] 29%|       | 304/1058 [10:51:38<27:00:28, 128.95s/it] 29%|       | 305/1058 [10:53:47<26:56:39, 128.82s/it] 29%|       | 306/1058 [10:55:56<26:55:52, 128.93s/it] 29%|       | 307/1058 [10:58:05<26:54:43, 129.01s/it] 29%|       | 308/1058 [11:00:14<26:53:32, 129.08s/it] 29%|       | 309/1058 [11:02:24<26:51:39, 129.10s/it] 29%|       | 310/1058 [11:04:33<26:49:48, 129.13s/it]                                                         {'loss': 2.4348, 'learning_rate': 4.013546818560362e-05, 'epoch': 0.29}
 29%|       | 310/1058 [11:04:33<26:49:48, 129.13s/it] 29%|       | 311/1058 [11:06:42<26:47:58, 129.16s/it] 29%|       | 312/1058 [11:08:51<26:46:03, 129.17s/it] 30%|       | 313/1058 [11:11:00<26:44:03, 129.19s/it] 30%|       | 314/1058 [11:13:10<26:42:10, 129.21s/it] 30%|       | 315/1058 [11:15:19<26:40:16, 129.23s/it] 30%|       | 316/1058 [11:17:28<26:37:57, 129.22s/it] 30%|       | 317/1058 [11:19:37<26:35:57, 129.23s/it] 30%|       | 318/1058 [11:21:47<26:33:28, 129.20s/it] 30%|       | 319/1058 [11:23:56<26:30:56, 129.17s/it] 30%|       | 320/1058 [11:26:05<26:28:55, 129.18s/it]                                                         {'loss': 2.4184, 'learning_rate': 3.9538047370114694e-05, 'epoch': 0.3}
 30%|       | 320/1058 [11:26:05<26:28:55, 129.18s/it] 30%|       | 321/1058 [11:28:14<26:26:54, 129.19s/it] 30%|       | 322/1058 [11:30:23<26:24:46, 129.19s/it] 31%|       | 323/1058 [11:32:32<26:19:30, 128.94s/it] 31%|       | 324/1058 [11:34:41<26:18:08, 129.00s/it] 31%|       | 325/1058 [11:36:50<26:16:41, 129.06s/it] 31%|       | 326/1058 [11:38:59<26:15:10, 129.11s/it] 31%|       | 327/1058 [11:41:09<26:13:51, 129.18s/it] 31%|       | 328/1058 [11:43:18<26:11:41, 129.18s/it] 31%|       | 329/1058 [11:45:26<26:06:46, 128.95s/it] 31%|       | 330/1058 [11:47:35<26:03:40, 128.87s/it]                                                         {'loss': 2.4029, 'learning_rate': 3.892780907667495e-05, 'epoch': 0.31}
 31%|       | 330/1058 [11:47:35<26:03:40, 128.87s/it] 31%|      | 331/1058 [11:49:44<26:02:15, 128.93s/it] 31%|      | 332/1058 [11:51:52<25:57:41, 128.74s/it] 31%|      | 333/1058 [11:54:01<25:56:52, 128.84s/it] 32%|      | 334/1058 [11:56:10<25:55:52, 128.94s/it] 32%|      | 335/1058 [11:58:19<25:52:20, 128.82s/it] 32%|      | 336/1058 [12:00:27<25:48:55, 128.72s/it] 32%|      | 337/1058 [12:02:37<25:48:19, 128.85s/it] 32%|      | 338/1058 [12:04:45<25:46:16, 128.86s/it] 32%|      | 339/1058 [12:06:54<25:41:17, 128.62s/it] 32%|      | 340/1058 [12:09:02<25:39:24, 128.64s/it]                                                         {'loss': 2.3778, 'learning_rate': 3.830529132223202e-05, 'epoch': 0.32}
 32%|      | 340/1058 [12:09:02<25:39:24, 128.64s/it] 32%|      | 341/1058 [12:11:10<25:35:47, 128.52s/it] 32%|      | 342/1058 [12:13:20<25:36:22, 128.75s/it] 32%|      | 343/1058 [12:15:28<25:31:04, 128.48s/it] 33%|      | 344/1058 [12:17:37<25:30:38, 128.63s/it] 33%|      | 345/1058 [12:19:45<25:26:44, 128.48s/it] 33%|      | 346/1058 [12:21:54<25:26:49, 128.67s/it] 33%|      | 347/1058 [12:24:03<25:26:25, 128.81s/it] 33%|      | 348/1058 [12:26:11<25:21:37, 128.59s/it] 33%|      | 349/1058 [12:28:20<25:20:37, 128.69s/it] 33%|      | 350/1058 [12:30:28<25:15:43, 128.45s/it]                                                         {'loss': 2.3647, 'learning_rate': 3.7671042949927535e-05, 'epoch': 0.33}
 33%|      | 350/1058 [12:30:28<25:15:43, 128.45s/it] 33%|      | 351/1058 [12:32:37<25:14:45, 128.55s/it] 33%|      | 352/1058 [12:34:45<25:10:23, 128.36s/it] 33%|      | 353/1058 [12:36:54<25:10:49, 128.58s/it] 33%|      | 354/1058 [12:39:03<25:11:11, 128.79s/it] 34%|      | 355/1058 [12:41:12<25:11:18, 128.99s/it] 34%|      | 356/1058 [12:43:22<25:10:15, 129.08s/it] 34%|      | 357/1058 [12:45:31<25:08:49, 129.14s/it] 34%|      | 358/1058 [12:47:40<25:07:13, 129.19s/it] 34%|      | 359/1058 [12:49:49<25:02:03, 128.93s/it] 34%|      | 360/1058 [12:51:58<25:00:54, 129.02s/it]                                                         {'loss': 2.3453, 'learning_rate': 3.702562314520919e-05, 'epoch': 0.34}
 34%|      | 360/1058 [12:51:58<25:00:54, 129.02s/it] 34%|      | 361/1058 [12:54:07<24:59:30, 129.08s/it] 34%|      | 362/1058 [12:56:16<24:57:53, 129.13s/it] 34%|      | 363/1058 [12:58:26<24:56:58, 129.23s/it] 34%|      | 364/1058 [13:00:35<24:55:26, 129.29s/it] 34%|      | 365/1058 [13:02:44<24:53:15, 129.29s/it] 35%|      | 366/1058 [13:04:53<24:47:28, 128.97s/it] 35%|      | 367/1058 [13:07:02<24:46:13, 129.05s/it] 35%|      | 368/1058 [13:09:11<24:45:02, 129.13s/it] 35%|      | 369/1058 [13:11:21<24:43:41, 129.20s/it] 35%|      | 370/1058 [13:13:29<24:40:03, 129.07s/it]                                                         {'loss': 2.3329, 'learning_rate': 3.6369600942824606e-05, 'epoch': 0.35}
 35%|      | 370/1058 [13:13:29<24:40:03, 129.07s/it] 35%|      | 371/1058 [13:15:38<24:35:39, 128.88s/it] 35%|      | 372/1058 [13:17:47<24:33:50, 128.91s/it] 35%|      | 373/1058 [13:19:55<24:29:01, 128.67s/it] 35%|      | 374/1058 [13:22:04<24:28:48, 128.84s/it] 35%|      | 375/1058 [13:24:12<24:24:02, 128.61s/it] 36%|      | 376/1058 [13:26:21<24:23:52, 128.79s/it] 36%|      | 377/1058 [13:28:31<24:23:26, 128.94s/it] 36%|      | 378/1058 [13:30:40<24:22:19, 129.03s/it] 36%|      | 379/1058 [13:32:49<24:20:39, 129.07s/it] 36%|      | 380/1058 [13:34:58<24:18:50, 129.10s/it]                                                         {'loss': 2.323, 'learning_rate': 3.570355472513148e-05, 'epoch': 0.36}
 36%|      | 380/1058 [13:34:58<24:18:50, 129.10s/it] 36%|      | 381/1058 [13:37:06<24:13:17, 128.80s/it] 36%|      | 382/1058 [13:39:15<24:12:13, 128.90s/it] 36%|      | 383/1058 [13:41:25<24:11:05, 128.99s/it] 36%|      | 384/1058 [13:43:34<24:10:03, 129.08s/it] 36%|      | 385/1058 [13:45:43<24:08:09, 129.11s/it] 36%|      | 386/1058 [13:47:52<24:03:26, 128.88s/it] 37%|      | 387/1058 [13:50:01<24:01:58, 128.94s/it] 37%|      | 388/1058 [13:52:10<24:01:34, 129.10s/it] 37%|      | 389/1058 [13:54:19<24:00:02, 129.15s/it] 37%|      | 390/1058 [13:56:28<23:55:16, 128.92s/it]                                                         {'loss': 2.3156, 'learning_rate': 3.5028071712166456e-05, 'epoch': 0.37}
 37%|      | 390/1058 [13:56:28<23:55:16, 128.92s/it] 37%|      | 391/1058 [13:58:36<23:51:53, 128.81s/it] 37%|      | 392/1058 [14:00:46<23:51:15, 128.94s/it] 37%|      | 393/1058 [14:02:55<23:50:05, 129.03s/it] 37%|      | 394/1058 [14:05:04<23:48:26, 129.08s/it] 37%|      | 395/1058 [14:07:13<23:45:57, 129.05s/it] 37%|      | 396/1058 [14:09:21<23:41:30, 128.84s/it] 38%|      | 397/1058 [14:11:30<23:39:14, 128.83s/it] 38%|      | 398/1058 [14:13:38<23:34:17, 128.57s/it] 38%|      | 399/1058 [14:15:47<23:34:43, 128.81s/it] 38%|      | 400/1058 [14:17:56<23:30:42, 128.64s/it]                                                         {'loss': 2.2843, 'learning_rate': 3.434374744392225e-05, 'epoch': 0.38}
 38%|      | 400/1058 [14:17:56<23:30:42, 128.64s/it][INFO|trainer.py:2979] 2024-05-14 12:43:02,357 >> Saving model checkpoint to /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400
[INFO|configuration_utils.py:473] 2024-05-14 12:43:02,364 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400/config.json
[INFO|configuration_utils.py:595] 2024-05-14 12:43:02,369 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400/generation_config.json
[INFO|modeling_utils.py:2540] 2024-05-14 12:43:24,202 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-05-14 12:43:24,212 >> tokenizer config file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-05-14 12:43:24,216 >> Special tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-05-14 12:43:24,219 >> added tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-400/added_tokens.json
[INFO|trainer.py:3071] 2024-05-14 12:43:25,159 >> Deleting older checkpoint [/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/checkpoint-200] due to args.save_total_limit
 38%|      | 401/1058 [14:20:35<25:10:37, 137.96s/it] 38%|      | 402/1058 [14:22:45<24:40:06, 135.38s/it] 38%|      | 403/1058 [14:24:54<24:18:14, 133.58s/it] 38%|      | 404/1058 [14:27:03<24:02:13, 132.31s/it] 38%|      | 405/1058 [14:29:13<23:49:49, 131.38s/it] 38%|      | 406/1058 [14:31:22<23:40:29, 130.72s/it] 38%|      | 407/1058 [14:33:31<23:33:29, 130.28s/it] 39%|      | 408/1058 [14:35:40<23:28:24, 130.01s/it] 39%|      | 409/1058 [14:37:50<23:23:44, 129.78s/it] 39%|      | 410/1058 [14:39:59<23:19:52, 129.62s/it]                                                         {'loss': 2.2928, 'learning_rate': 3.365118525528946e-05, 'epoch': 0.39}
 39%|      | 410/1058 [14:39:59<23:19:52, 129.62s/it] 39%|      | 411/1058 [14:42:08<23:16:29, 129.50s/it] 39%|      | 412/1058 [14:44:17<23:12:05, 129.30s/it] 39%|      | 413/1058 [14:46:25<23:06:57, 129.02s/it] 39%|      | 414/1058 [14:48:35<23:06:02, 129.13s/it] 39%|      | 415/1058 [14:50:44<23:04:15, 129.17s/it] 39%|      | 416/1058 [14:52:53<23:02:21, 129.19s/it] 39%|      | 417/1058 [14:55:03<23:00:44, 129.24s/it] 40%|      | 418/1058 [14:57:12<22:58:15, 129.21s/it] 40%|      | 419/1058 [14:59:21<22:56:22, 129.24s/it] 40%|      | 420/1058 [15:01:30<22:54:08, 129.23s/it]                                                         {'loss': 2.2685, 'learning_rate': 3.295099574412598e-05, 'epoch': 0.4}
 40%|      | 420/1058 [15:01:30<22:54:08, 129.23s/it] 40%|      | 421/1058 [15:03:40<22:52:11, 129.25s/it] 40%|      | 422/1058 [15:05:49<22:49:55, 129.24s/it] 40%|      | 423/1058 [15:07:58<22:47:46, 129.24s/it] 40%|      | 424/1058 [15:10:07<22:45:41, 129.24s/it] 40%|      | 425/1058 [15:12:17<22:43:35, 129.25s/it] 40%|      | 426/1058 [15:14:25<22:38:08, 128.94s/it] 40%|      | 427/1058 [15:16:34<22:36:11, 128.96s/it] 40%|      | 428/1058 [15:18:43<22:34:49, 129.03s/it] 41%|      | 429/1058 [15:20:52<22:33:22, 129.10s/it] 41%|      | 430/1058 [15:23:01<22:31:40, 129.14s/it]                                                         {'loss': 2.255, 'learning_rate': 3.22437962329231e-05, 'epoch': 0.41}
 41%|      | 430/1058 [15:23:01<22:31:40, 129.14s/it] 41%|      | 431/1058 [15:25:11<22:29:48, 129.17s/it] 41%|      | 432/1058 [15:27:20<22:27:50, 129.19s/it] 41%|      | 433/1058 [15:29:29<22:25:55, 129.21s/it] 41%|      | 434/1058 [15:31:38<22:23:46, 129.21s/it] 41%|      | 435/1058 [15:33:48<22:21:30, 129.20s/it] 41%|      | 436/1058 [15:35:57<22:19:30, 129.21s/it] 41%|     | 437/1058 [15:38:06<22:17:23, 129.22s/it] 41%|     | 438/1058 [15:40:15<22:13:06, 129.01s/it] 41%|     | 439/1058 [15:42:23<22:10:40, 128.98s/it] 42%|     | 440/1058 [15:44:32<22:07:05, 128.84s/it]                                                         {'loss': 2.2401, 'learning_rate': 3.15302102245427e-05, 'epoch': 0.42}
 42%|     | 440/1058 [15:44:32<22:07:05, 128.84s/it] 42%|     | 441/1058 [15:46:41<22:04:16, 128.78s/it] 42%|     | 442/1058 [15:48:50<22:03:27, 128.91s/it] 42%|     | 443/1058 [15:50:59<22:02:24, 129.02s/it] 42%|     | 444/1058 [15:53:08<22:00:56, 129.08s/it] 42%|     | 445/1058 [15:55:18<21:59:14, 129.13s/it] 42%|     | 446/1058 [15:57:27<21:57:21, 129.15s/it] 42%|     | 447/1058 [15:59:36<21:54:20, 129.07s/it] 42%|     | 448/1058 [16:01:44<21:50:04, 128.86s/it] 42%|     | 449/1058 [16:03:53<21:49:01, 128.97s/it] 43%|     | 450/1058 [16:06:03<21:47:57, 129.08s/it]                                                         {'loss': 2.2246, 'learning_rate': 3.081086685250565e-05, 'epoch': 0.43}
 43%|     | 450/1058 [16:06:03<21:47:57, 129.08s/it] 43%|     | 451/1058 [16:08:12<21:46:58, 129.19s/it] 43%|     | 452/1058 [16:10:21<21:45:03, 129.21s/it] 43%|     | 453/1058 [16:12:31<21:43:12, 129.24s/it] 43%|     | 454/1058 [16:14:40<21:40:59, 129.24s/it] 43%|     | 455/1058 [16:16:49<21:38:45, 129.23s/it] 43%|     | 456/1058 [16:18:58<21:36:41, 129.24s/it] 43%|     | 457/1058 [16:21:08<21:34:28, 129.23s/it] 43%|     | 458/1058 [16:23:17<21:32:30, 129.25s/it] 43%|     | 459/1058 [16:25:25<21:28:36, 129.08s/it] 43%|     | 460/1058 [16:27:34<21:25:29, 128.98s/it]                                                         {'loss': 2.2196, 'learning_rate': 3.008640032631585e-05, 'epoch': 0.43}
 43%|     | 460/1058 [16:27:34<21:25:29, 128.98s/it] 44%|     | 461/1058 [16:29:43<21:23:52, 129.03s/it] 44%|     | 462/1058 [16:31:53<21:22:16, 129.09s/it] 44%|     | 463/1058 [16:34:02<21:19:55, 129.07s/it] 44%|     | 464/1058 [16:36:10<21:15:17, 128.82s/it] 44%|     | 465/1058 [16:38:19<21:14:33, 128.96s/it] 44%|     | 466/1058 [16:40:28<21:13:32, 129.08s/it] 44%|     | 467/1058 [16:42:38<21:11:56, 129.13s/it] 44%|     | 468/1058 [16:44:47<21:10:25, 129.20s/it] 44%|     | 469/1058 [16:46:56<21:08:50, 129.25s/it] 44%|     | 470/1058 [16:49:06<21:06:54, 129.28s/it]                                                         {'loss': 2.2005, 'learning_rate': 2.9357449372309028e-05, 'epoch': 0.44}
 44%|     | 470/1058 [16:49:06<21:06:54, 129.28s/it] 45%|     | 471/1058 [16:51:15<21:04:38, 129.27s/it] 45%|     | 472/1058 [16:53:24<21:02:26, 129.26s/it] 45%|     | 473/1058 [16:55:33<20:59:59, 129.23s/it] 45%|     | 474/1058 [16:57:43<20:57:58, 129.24s/it] 45%|     | 475/1058 [16:59:52<20:55:43, 129.23s/it] 45%|     | 476/1058 [17:02:01<20:53:18, 129.21s/it] 45%|     | 477/1058 [17:04:10<20:50:09, 129.10s/it] 45%|     | 478/1058 [17:06:18<20:45:02, 128.80s/it] 45%|     | 479/1058 [17:08:27<20:44:09, 128.93s/it] 45%|     | 480/1058 [17:10:37<20:43:06, 129.04s/it]                                                         {'loss': 2.1854, 'learning_rate': 2.8624656670519335e-05, 'epoch': 0.45}
 45%|     | 480/1058 [17:10:37<20:43:06, 129.04s/it] 45%|     | 481/1058 [17:12:46<20:41:57, 129.15s/it] 46%|     | 482/1058 [17:14:55<20:40:18, 129.20s/it] 46%|     | 483/1058 [17:17:04<20:37:59, 129.18s/it] 46%|     | 484/1058 [17:19:14<20:36:14, 129.22s/it] 46%|     | 485/1058 [17:21:22<20:31:25, 128.95s/it] 46%|     | 486/1058 [17:23:31<20:28:54, 128.91s/it] 46%|     | 487/1058 [17:25:40<20:28:28, 129.09s/it] 46%|     | 488/1058 [17:27:50<20:27:22, 129.20s/it] 46%|     | 489/1058 [17:29:59<20:25:30, 129.23s/it] 46%|     | 490/1058 [17:32:08<20:21:25, 129.02s/it]                                                         {'loss': 2.1778, 'learning_rate': 2.7888668288060095e-05, 'epoch': 0.46}
 46%|     | 490/1058 [17:32:08<20:21:25, 129.02s/it] 46%|     | 491/1058 [17:34:17<20:18:58, 128.99s/it] 47%|     | 492/1058 [17:36:26<20:17:38, 129.08s/it] 47%|     | 493/1058 [17:38:35<20:16:08, 129.15s/it] 47%|     | 494/1058 [17:40:44<20:14:28, 129.20s/it] 47%|     | 495/1058 [17:42:54<20:12:37, 129.23s/it] 47%|     | 496/1058 [17:45:03<20:10:23, 129.22s/it] 47%|     | 497/1058 [17:47:12<20:08:46, 129.28s/it] 47%|     | 498/1058 [17:49:22<20:07:18, 129.36s/it] 47%|     | 499/1058 [17:51:31<20:05:05, 129.35s/it] 47%|     | 500/1058 [17:53:41<20:02:53, 129.34s/it]                                                         {'loss': 2.1648, 'learning_rate': 2.7150133109518344e-05, 'epoch': 0.47}
 47%|     | 500/1058 [17:53:41<20:02:53, 129.34s/it] 47%|     | 501/1058 [17:55:50<20:00:58, 129.37s/it] 47%|     | 502/1058 [17:57:59<19:58:33, 129.34s/it] 48%|     | 503/1058 [18:00:09<19:56:21, 129.34s/it] 48%|     | 504/1058 [18:02:18<19:53:58, 129.31s/it] 48%|     | 505/1058 [18:04:27<19:51:30, 129.28s/it] 48%|     | 506/1058 [18:06:36<19:46:59, 129.02s/it] 48%|     | 507/1058 [18:08:45<19:45:32, 129.10s/it] 48%|     | 508/1058 [18:10:54<19:43:47, 129.14s/it] 48%|     | 509/1058 [18:13:03<19:41:43, 129.15s/it] 48%|     | 510/1058 [18:15:12<19:39:53, 129.19s/it]                                                         {'loss': 2.1616, 'learning_rate': 2.6409702264865398e-05, 'epoch': 0.48}
 48%|     | 510/1058 [18:15:12<19:39:53, 129.19s/it] 48%|     | 511/1058 [18:17:22<19:38:10, 129.23s/it] 48%|     | 512/1058 [18:19:31<19:35:26, 129.17s/it] 48%|     | 513/1058 [18:21:39<19:30:52, 128.90s/it] 49%|     | 514/1058 [18:23:48<19:29:45, 129.02s/it] 49%|     | 515/1058 [18:25:58<19:28:16, 129.09s/it] 49%|     | 516/1058 [18:28:07<19:26:36, 129.15s/it] 49%|     | 517/1058 [18:30:16<19:24:32, 129.15s/it] 49%|     | 518/1058 [18:32:25<19:22:40, 129.19s/it] 49%|     | 519/1058 [18:34:35<19:20:34, 129.19s/it] 49%|     | 520/1058 [18:36:44<19:18:23, 129.19s/it]                                                         {'loss': 2.1453, 'learning_rate': 2.566802855538768e-05, 'epoch': 0.49}
 49%|     | 520/1058 [18:36:44<19:18:23, 129.19s/it] 49%|     | 521/1058 [18:38:53<19:16:34, 129.23s/it] 49%|     | 522/1058 [18:41:02<19:14:33, 129.24s/it] 49%|     | 523/1058 [18:43:11<19:10:27, 129.02s/it] 50%|     | 524/1058 [18:45:19<19:06:46, 128.85s/it] 50%|     | 525/1058 [18:47:28<19:04:33, 128.84s/it] 50%|     | 526/1058 [18:49:37<19:01:23, 128.73s/it] 50%|     | 527/1058 [18:51:46<19:01:10, 128.95s/it] 50%|     | 528/1058 [18:53:55<18:59:59, 129.06s/it] 50%|     | 529/1058 [18:56:05<18:58:20, 129.11s/it] 50%|     | 530/1058 [18:58:14<18:56:54, 129.19s/it]                                                         {'loss': 2.1357, 'learning_rate': 2.4925765878144117e-05, 'epoch': 0.5}
 50%|     | 530/1058 [18:58:14<18:56:54, 129.19s/it] 50%|     | 531/1058 [19:00:23<18:55:22, 129.27s/it] 50%|     | 532/1058 [19:02:33<18:53:16, 129.27s/it] 50%|     | 533/1058 [19:04:41<18:48:13, 128.94s/it] 50%|     | 534/1058 [19:06:50<18:46:23, 128.98s/it] 51%|     | 535/1058 [19:08:58<18:42:02, 128.72s/it] 51%|     | 536/1058 [19:11:07<18:39:58, 128.73s/it] 51%|     | 537/1058 [19:13:16<18:39:28, 128.92s/it] 51%|     | 538/1058 [19:15:25<18:37:04, 128.89s/it] 51%|     | 539/1058 [19:17:34<18:34:00, 128.79s/it] 51%|     | 540/1058 [19:19:43<18:33:05, 128.93s/it]                                                         {'loss': 2.1323, 'learning_rate': 2.4183568649457436e-05, 'epoch': 0.51}
 51%|     | 540/1058 [19:19:43<18:33:05, 128.93s/it] 51%|     | 541/1058 [19:21:52<18:32:05, 129.06s/it] 51%|     | 542/1058 [19:24:02<18:30:40, 129.15s/it] 51%|    | 543/1058 [19:26:11<18:28:58, 129.20s/it] 51%|    | 544/1058 [19:28:20<18:26:55, 129.21s/it] 52%|    | 545/1058 [19:30:29<18:24:55, 129.23s/it] 52%|    | 546/1058 [19:32:39<18:23:07, 129.27s/it] 52%|    | 547/1058 [19:34:48<18:21:18, 129.31s/it] 52%|    | 548/1058 [19:36:57<18:19:11, 129.32s/it] 52%|    | 549/1058 [19:39:07<18:17:08, 129.33s/it] 52%|    | 550/1058 [19:41:16<18:15:14, 129.36s/it]                                                         {'loss': 2.1164, 'learning_rate': 2.344209122794757e-05, 'epoch': 0.52}
 52%|    | 550/1058 [19:41:16<18:15:14, 129.36s/it] 52%|    | 551/1058 [19:43:25<18:10:45, 129.08s/it] 52%|    | 552/1058 [19:45:34<18:08:15, 129.04s/it] 52%|    | 553/1058 [19:47:43<18:06:35, 129.10s/it] 52%|    | 554/1058 [19:49:51<18:02:07, 128.82s/it] 52%|    | 555/1058 [19:52:00<17:59:49, 128.81s/it] 53%|    | 556/1058 [19:54:09<17:59:02, 128.97s/it] 53%|    | 557/1058 [19:56:19<17:57:47, 129.08s/it] 53%|    | 558/1058 [19:58:28<17:56:11, 129.14s/it] 53%|    | 559/1058 [20:00:37<17:54:24, 129.19s/it] 53%|    | 560/1058 [20:02:46<17:52:32, 129.22s/it]                                                         {'loss': 2.1088, 'learning_rate': 2.2701987337616052e-05, 'epoch': 0.53}
 53%|    | 560/1058 [20:02:46<17:52:32, 129.22s/it] 53%|    | 561/1058 [20:04:56<17:50:33, 129.24s/it] 53%|    | 562/1058 [20:07:05<17:47:46, 129.17s/it] 53%|    | 563/1058 [20:09:13<17:42:34, 128.80s/it] 53%|    | 564/1058 [20:11:22<17:41:09, 128.89s/it] 53%|    | 565/1058 [20:13:30<17:38:02, 128.77s/it] 53%|    | 566/1058 [20:15:38<17:34:37, 128.61s/it] 54%|    | 567/1058 [20:17:48<17:33:57, 128.79s/it] 54%|    | 568/1058 [20:19:57<17:33:08, 128.96s/it] 54%|    | 569/1058 [20:22:06<17:31:48, 129.06s/it] 54%|    | 570/1058 [20:24:15<17:27:52, 128.84s/it]                                                         {'loss': 2.0952, 'learning_rate': 2.1963909491489844e-05, 'epoch': 0.54}
 54%|    | 570/1058 [20:24:15<17:27:52, 128.84s/it] 54%|    | 571/1058 [20:26:24<17:26:40, 128.95s/it] 54%|    | 572/1058 [20:28:33<17:25:20, 129.05s/it] 54%|    | 573/1058 [20:30:41<17:21:05, 128.79s/it] 54%|    | 574/1058 [20:32:50<17:19:02, 128.81s/it] 54%|    | 575/1058 [20:34:59<17:15:52, 128.68s/it] 54%|    | 576/1058 [20:37:07<17:12:59, 128.59s/it] 55%|    | 577/1058 [20:39:16<17:12:46, 128.83s/it] 55%|    | 578/1058 [20:41:26<17:11:47, 128.97s/it] 55%|    | 579/1058 [20:43:35<17:10:19, 129.06s/it] 55%|    | 580/1058 [20:45:44<17:07:39, 129.00s/it]                                                         {'loss': 2.0879, 'learning_rate': 2.1228508416332876e-05, 'epoch': 0.55}
 55%|    | 580/1058 [20:45:44<17:07:39, 129.00s/it] 55%|    | 581/1058 [20:47:52<17:04:24, 128.86s/it] 55%|    | 582/1058 [20:50:02<17:03:23, 129.00s/it] 55%|    | 583/1058 [20:52:10<16:59:27, 128.77s/it] 55%|    | 584/1058 [20:54:19<16:57:52, 128.84s/it] 55%|    | 585/1058 [20:56:27<16:53:29, 128.56s/it] 55%|    | 586/1058 [20:58:36<16:52:03, 128.65s/it] 55%|    | 587/1058 [21:00:45<16:51:22, 128.84s/it] 56%|    | 588/1058 [21:02:54<16:50:25, 128.99s/it] 56%|    | 589/1058 [21:05:03<16:48:46, 129.05s/it] 56%|    | 590/1058 [21:07:12<16:45:33, 128.92s/it]                                                         {'loss': 2.0735, 'learning_rate': 2.0496432478932347e-05, 'epoch': 0.56}
 56%|    | 590/1058 [21:07:12<16:45:33, 128.92s/it] 56%|    | 591/1058 [21:09:21<16:42:24, 128.79s/it] 56%|    | 592/1058 [21:11:29<16:40:03, 128.76s/it] 56%|    | 593/1058 [21:13:38<16:36:59, 128.64s/it] 56%|    | 594/1058 [21:15:47<16:36:05, 128.80s/it] 56%|    | 595/1058 [21:17:55<16:31:54, 128.54s/it] 56%|    | 596/1058 [21:20:04<16:31:20, 128.75s/it] 56%|    | 597/1058 [21:22:12<16:28:16, 128.63s/it] 57%|    | 598/1058 [21:24:21<16:26:46, 128.71s/it] 57%|    | 599/1058 [21:26:29<16:22:45, 128.47s/it] 57%|    | 600/1058 [21:28:38<16:21:38, 128.60s/it]                                                         {'loss': 2.0647, 'learning_rate': 1.9768327114465843e-05, 'epoch': 0.57}
 57%|    | 600/1058 [21:28:38<16:21:38, 128.60s/it][INFO|trainer.py:2979] 2024-05-14 19:53:44,674 >> Saving model checkpoint to /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600
[INFO|configuration_utils.py:473] 2024-05-14 19:53:44,679 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600/config.json
[INFO|configuration_utils.py:595] 2024-05-14 19:53:44,683 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600/generation_config.json
[INFO|modeling_utils.py:2540] 2024-05-14 19:54:00,984 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-05-14 19:54:00,989 >> tokenizer config file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-05-14 19:54:00,992 >> Special tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-05-14 19:54:00,993 >> added tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-600/added_tokens.json
[INFO|trainer.py:3071] 2024-05-14 19:54:01,899 >> Deleting older checkpoint [/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/checkpoint-400] due to args.save_total_limit
 57%|    | 601/1058 [21:31:12<17:18:02, 136.29s/it] 57%|    | 602/1058 [21:33:21<16:59:50, 134.19s/it] 57%|    | 603/1058 [21:35:31<16:46:26, 132.72s/it] 57%|    | 604/1058 [21:37:40<16:36:37, 131.71s/it] 57%|    | 605/1058 [21:39:49<16:28:52, 130.98s/it] 57%|    | 606/1058 [21:41:59<16:23:04, 130.50s/it] 57%|    | 607/1058 [21:44:08<16:17:56, 130.10s/it] 57%|    | 608/1058 [21:46:17<16:13:25, 129.79s/it] 58%|    | 609/1058 [21:48:25<16:08:14, 129.39s/it] 58%|    | 610/1058 [21:50:35<16:05:39, 129.33s/it]                                                         {'loss': 2.0504, 'learning_rate': 1.9044834257452995e-05, 'epoch': 0.58}
 58%|    | 610/1058 [21:50:35<16:05:39, 129.33s/it] 58%|    | 611/1058 [21:52:44<16:03:31, 129.33s/it] 58%|    | 612/1058 [21:54:54<16:02:02, 129.42s/it] 58%|    | 613/1058 [21:57:03<15:59:34, 129.38s/it] 58%|    | 614/1058 [21:59:12<15:56:04, 129.20s/it] 58%|    | 615/1058 [22:01:20<15:52:40, 129.03s/it] 58%|    | 616/1058 [22:03:30<15:50:55, 129.08s/it] 58%|    | 617/1058 [22:05:39<15:49:04, 129.12s/it] 58%|    | 618/1058 [22:07:48<15:47:24, 129.19s/it] 59%|    | 619/1058 [22:09:57<15:45:19, 129.20s/it] 59%|    | 620/1058 [22:12:07<15:43:11, 129.20s/it]                                                         {'loss': 2.0383, 'learning_rate': 1.8326591775793543e-05, 'epoch': 0.59}
 59%|    | 620/1058 [22:12:07<15:43:11, 129.20s/it] 59%|    | 621/1058 [22:14:15<15:39:02, 128.93s/it] 59%|    | 622/1058 [22:16:24<15:37:24, 129.00s/it] 59%|    | 623/1058 [22:18:33<15:35:43, 129.06s/it] 59%|    | 624/1058 [22:20:42<15:33:59, 129.12s/it] 59%|    | 625/1058 [22:22:52<15:32:13, 129.18s/it] 59%|    | 626/1058 [22:25:01<15:30:08, 129.19s/it] 59%|    | 627/1058 [22:27:10<15:28:24, 129.25s/it] 59%|    | 628/1058 [22:29:19<15:25:40, 129.16s/it] 59%|    | 629/1058 [22:31:28<15:21:28, 128.88s/it] 60%|    | 630/1058 [22:33:36<15:19:16, 128.87s/it]                                                         {'loss': 2.0382, 'learning_rate': 1.761423290839075e-05, 'epoch': 0.6}
 60%|    | 630/1058 [22:33:36<15:19:16, 128.87s/it] 60%|    | 631/1058 [22:35:45<15:15:43, 128.67s/it] 60%|    | 632/1058 [22:37:54<15:14:34, 128.81s/it] 60%|    | 633/1058 [22:40:02<15:10:48, 128.59s/it] 60%|    | 634/1058 [22:42:11<15:09:43, 128.74s/it] 60%|    | 635/1058 [22:44:20<15:07:54, 128.78s/it] 60%|    | 636/1058 [22:46:28<15:04:29, 128.60s/it] 60%|    | 637/1058 [22:48:37<15:03:51, 128.82s/it] 60%|    | 638/1058 [22:50:47<15:03:05, 129.01s/it] 60%|    | 639/1058 [22:52:56<15:01:38, 129.11s/it] 60%|    | 640/1058 [22:55:05<14:59:57, 129.18s/it]                                                         {'loss': 2.0478, 'learning_rate': 1.6908385706855908e-05, 'epoch': 0.6}
 60%|    | 640/1058 [22:55:05<14:59:57, 129.18s/it] 61%|    | 641/1058 [22:57:15<14:58:05, 129.22s/it] 61%|    | 642/1058 [22:59:24<14:56:12, 129.26s/it] 61%|    | 643/1058 [23:01:33<14:54:07, 129.27s/it] 61%|    | 644/1058 [23:03:43<14:51:57, 129.27s/it] 61%|    | 645/1058 [23:05:52<14:50:01, 129.30s/it] 61%|    | 646/1058 [23:08:01<14:48:05, 129.33s/it] 61%|    | 647/1058 [23:10:11<14:46:06, 129.36s/it] 61%|    | 648/1058 [23:12:20<14:43:42, 129.32s/it] 61%|   | 649/1058 [23:14:29<14:41:24, 129.30s/it] 61%|   | 650/1058 [23:16:39<14:39:26, 129.33s/it]                                                         {'loss': 2.0404, 'learning_rate': 1.62096724817863e-05, 'epoch': 0.61}
 61%|   | 650/1058 [23:16:39<14:39:26, 129.33s/it] 62%|   | 651/1058 [23:18:48<14:37:12, 129.32s/it] 62%|   | 652/1058 [23:20:56<14:33:15, 129.05s/it] 62%|   | 653/1058 [23:23:06<14:31:11, 129.07s/it] 62%|   | 654/1058 [23:25:15<14:29:30, 129.13s/it] 62%|   | 655/1058 [23:27:24<14:27:31, 129.16s/it] 62%|   | 656/1058 [23:29:32<14:23:16, 128.85s/it] 62%|   | 657/1058 [23:31:41<14:21:43, 128.94s/it] 62%|   | 658/1058 [23:33:51<14:20:25, 129.06s/it] 62%|   | 659/1058 [23:36:00<14:17:53, 129.01s/it] 62%|   | 660/1058 [23:38:08<14:14:26, 128.81s/it]                                                         {'loss': 2.0242, 'learning_rate': 1.551870925410472e-05, 'epoch': 0.62}
 62%|   | 660/1058 [23:38:08<14:14:26, 128.81s/it] 62%|   | 661/1058 [23:40:17<14:13:06, 128.93s/it] 63%|   | 662/1058 [23:42:27<14:11:45, 129.05s/it] 63%|   | 663/1058 [23:44:36<14:09:43, 129.07s/it] 63%|   | 664/1058 [23:46:44<14:05:52, 128.81s/it] 63%|   | 665/1058 [23:48:53<14:03:58, 128.85s/it] 63%|   | 666/1058 [23:51:01<14:00:05, 128.59s/it] 63%|   | 667/1058 [23:53:10<13:59:15, 128.79s/it] 63%|   | 668/1058 [23:55:19<13:57:57, 128.92s/it] 63%|   | 669/1058 [23:57:27<13:54:18, 128.68s/it] 63%|   | 670/1058 [23:59:36<13:53:03, 128.82s/it]                                                         {'loss': 2.0144, 'learning_rate': 1.483610521194419e-05, 'epoch': 0.63}
 63%|   | 670/1058 [23:59:37<13:53:03, 128.82s/it] 63%|   | 671/1058 [24:01:46<13:51:53, 128.97s/it] 64%|   | 672/1058 [24:03:55<13:50:25, 129.08s/it] 64%|   | 673/1058 [24:06:04<13:48:40, 129.14s/it] 64%|   | 674/1058 [24:08:14<13:46:57, 129.21s/it] 64%|   | 675/1058 [24:10:23<13:44:46, 129.21s/it] 64%|   | 676/1058 [24:12:32<13:42:51, 129.25s/it] 64%|   | 677/1058 [24:14:42<13:40:56, 129.28s/it] 64%|   | 678/1058 [24:16:51<13:38:45, 129.28s/it] 64%|   | 679/1058 [24:18:59<13:34:13, 128.90s/it] 64%|   | 680/1058 [24:21:08<13:32:25, 128.96s/it]                                                         {'loss': 2.0088, 'learning_rate': 1.4162462173557007e-05, 'epoch': 0.64}
 64%|   | 680/1058 [24:21:08<13:32:25, 128.96s/it] 64%|   | 681/1058 [24:23:17<13:30:49, 129.04s/it] 64%|   | 682/1058 [24:25:27<13:29:35, 129.19s/it] 65%|   | 683/1058 [24:27:36<13:27:56, 129.27s/it] 65%|   | 684/1058 [24:29:45<13:23:45, 128.94s/it] 65%|   | 685/1058 [24:31:54<13:21:46, 128.97s/it] 65%|   | 686/1058 [24:34:03<13:20:05, 129.05s/it] 65%|   | 687/1058 [24:36:12<13:18:28, 129.13s/it] 65%|   | 688/1058 [24:38:22<13:16:51, 129.22s/it] 65%|   | 689/1058 [24:40:31<13:14:50, 129.24s/it] 65%|   | 690/1058 [24:42:40<13:12:56, 129.28s/it]                                                         {'loss': 2.004, 'learning_rate': 1.3498374056721197e-05, 'epoch': 0.65}
 65%|   | 690/1058 [24:42:40<13:12:56, 129.28s/it] 65%|   | 691/1058 [24:44:49<13:10:38, 129.26s/it] 65%|   | 692/1058 [24:46:59<13:08:36, 129.28s/it] 66%|   | 693/1058 [24:49:08<13:06:31, 129.29s/it] 66%|   | 694/1058 [24:51:17<13:04:29, 129.31s/it] 66%|   | 695/1058 [24:53:27<13:02:11, 129.29s/it] 66%|   | 696/1058 [24:55:36<13:00:02, 129.29s/it] 66%|   | 697/1058 [24:57:45<12:57:58, 129.30s/it] 66%|   | 698/1058 [24:59:54<12:55:09, 129.19s/it] 66%|   | 699/1058 [25:02:02<12:51:09, 128.89s/it] 66%|   | 700/1058 [25:04:12<12:49:49, 129.02s/it]                                                         {'loss': 1.9988, 'learning_rate': 1.2844426355112657e-05, 'epoch': 0.66}
 66%|   | 700/1058 [25:04:12<12:49:49, 129.02s/it] 66%|   | 701/1058 [25:06:21<12:48:11, 129.11s/it] 66%|   | 702/1058 [25:08:30<12:46:33, 129.20s/it] 66%|   | 703/1058 [25:10:39<12:42:31, 128.88s/it] 67%|   | 704/1058 [25:12:47<12:40:17, 128.86s/it] 67%|   | 705/1058 [25:14:57<12:39:01, 129.01s/it] 67%|   | 706/1058 [25:17:06<12:37:11, 129.07s/it] 67%|   | 707/1058 [25:19:15<12:35:40, 129.18s/it] 67%|   | 708/1058 [25:21:25<12:33:52, 129.24s/it] 67%|   | 709/1058 [25:23:34<12:31:24, 129.18s/it] 67%|   | 710/1058 [25:25:42<12:27:15, 128.84s/it]                                                         {'loss': 1.9897, 'learning_rate': 1.2201195622104264e-05, 'epoch': 0.67}
 67%|   | 710/1058 [25:25:42<12:27:15, 128.84s/it] 67%|   | 711/1058 [25:27:51<12:25:46, 128.95s/it] 67%|   | 712/1058 [25:30:00<12:23:58, 129.01s/it] 67%|   | 713/1058 [25:32:09<12:22:11, 129.08s/it] 67%|   | 714/1058 [25:34:19<12:20:23, 129.14s/it] 68%|   | 715/1058 [25:36:28<12:18:31, 129.19s/it] 68%|   | 716/1058 [25:38:37<12:16:45, 129.26s/it] 68%|   | 717/1058 [25:40:47<12:14:50, 129.30s/it] 68%|   | 718/1058 [25:42:55<12:11:09, 129.03s/it] 68%|   | 719/1058 [25:45:04<12:08:57, 129.02s/it] 68%|   | 720/1058 [25:47:14<12:07:26, 129.13s/it]                                                         {'loss': 1.9818, 'learning_rate': 1.1569248962447279e-05, 'epoch': 0.68}
 68%|   | 720/1058 [25:47:14<12:07:26, 129.13s/it] 68%|   | 721/1058 [25:49:23<12:05:26, 129.16s/it] 68%|   | 722/1058 [25:51:32<12:03:29, 129.20s/it] 68%|   | 723/1058 [25:53:41<12:01:34, 129.24s/it] 68%|   | 724/1058 [25:55:51<11:59:39, 129.28s/it] 69%|   | 725/1058 [25:58:00<11:57:42, 129.32s/it] 69%|   | 726/1058 [26:00:10<11:55:33, 129.32s/it] 69%|   | 727/1058 [26:02:19<11:53:22, 129.31s/it] 69%|   | 728/1058 [26:04:28<11:50:24, 129.17s/it] 69%|   | 729/1058 [26:06:36<11:47:35, 129.04s/it] 69%|   | 730/1058 [26:08:46<11:45:44, 129.10s/it]                                                         {'loss': 1.9812, 'learning_rate': 1.0949143532283108e-05, 'epoch': 0.69}
 69%|   | 730/1058 [26:08:46<11:45:44, 129.10s/it] 69%|   | 731/1058 [26:10:55<11:43:48, 129.14s/it] 69%|   | 732/1058 [26:13:04<11:41:45, 129.16s/it] 69%|   | 733/1058 [26:15:13<11:39:52, 129.21s/it] 69%|   | 734/1058 [26:17:23<11:37:38, 129.19s/it] 69%|   | 735/1058 [26:19:32<11:35:44, 129.24s/it] 70%|   | 736/1058 [26:21:41<11:33:54, 129.30s/it] 70%|   | 737/1058 [26:23:51<11:32:07, 129.37s/it] 70%|   | 738/1058 [26:26:00<11:30:06, 129.39s/it] 70%|   | 739/1058 [26:28:10<11:28:15, 129.45s/it] 70%|   | 740/1058 [26:30:19<11:25:48, 129.40s/it]                                                         {'loss': 1.9706, 'learning_rate': 1.0341426047926252e-05, 'epoch': 0.7}
 70%|   | 740/1058 [26:30:19<11:25:48, 129.40s/it] 70%|   | 741/1058 [26:32:29<11:23:28, 129.37s/it] 70%|   | 742/1058 [26:34:37<11:19:11, 128.96s/it] 70%|   | 743/1058 [26:36:46<11:17:19, 129.01s/it] 70%|   | 744/1058 [26:38:55<11:15:49, 129.14s/it] 70%|   | 745/1058 [26:41:04<11:12:37, 128.94s/it] 71%|   | 746/1058 [26:43:12<11:10:04, 128.86s/it] 71%|   | 747/1058 [26:45:22<11:08:57, 129.06s/it] 71%|   | 748/1058 [26:47:31<11:06:32, 129.01s/it] 71%|   | 749/1058 [26:49:39<11:02:54, 128.72s/it] 71%|   | 750/1058 [26:51:48<11:01:35, 128.88s/it]                                                         {'loss': 1.9707, 'learning_rate': 9.746632303851569e-06, 'epoch': 0.71}
 71%|   | 750/1058 [26:51:48<11:01:35, 128.88s/it] 71%|   | 751/1058 [26:53:57<11:00:12, 129.03s/it] 71%|   | 752/1058 [26:56:07<10:58:42, 129.16s/it] 71%|   | 753/1058 [26:58:16<10:56:45, 129.20s/it] 71%|  | 754/1058 [27:00:26<10:55:01, 129.28s/it] 71%|  | 755/1058 [27:02:35<10:52:58, 129.30s/it] 71%|  | 756/1058 [27:04:44<10:50:50, 129.31s/it] 72%|  | 757/1058 [27:06:54<10:48:47, 129.33s/it] 72%|  | 758/1058 [27:09:03<10:46:38, 129.33s/it] 72%|  | 759/1058 [27:11:12<10:44:29, 129.33s/it] 72%|  | 760/1058 [27:13:22<10:42:23, 129.34s/it]                                                         {'loss': 1.966, 'learning_rate': 9.165286700310746e-06, 'epoch': 0.72}
 72%|  | 760/1058 [27:13:22<10:42:23, 129.34s/it] 72%|  | 761/1058 [27:15:31<10:40:05, 129.31s/it] 72%|  | 762/1058 [27:17:40<10:38:04, 129.34s/it] 72%|  | 763/1058 [27:19:50<10:35:59, 129.35s/it] 72%|  | 764/1058 [27:21:59<10:33:54, 129.37s/it] 72%|  | 765/1058 [27:24:08<10:31:43, 129.36s/it] 72%|  | 766/1058 [27:26:18<10:29:38, 129.38s/it] 72%|  | 767/1058 [27:28:27<10:27:28, 129.38s/it] 73%|  | 768/1058 [27:30:37<10:25:35, 129.43s/it] 73%|  | 769/1058 [27:32:46<10:23:24, 129.43s/it] 73%|  | 770/1058 [27:34:55<10:21:01, 129.38s/it]                                                         {'loss': 1.9569, 'learning_rate': 8.597901780994524e-06, 'epoch': 0.73}
 73%|  | 770/1058 [27:34:55<10:21:01, 129.38s/it] 73%|  | 771/1058 [27:37:05<10:18:45, 129.36s/it] 73%|  | 772/1058 [27:39:13<10:15:10, 129.06s/it] 73%|  | 773/1058 [27:41:22<10:13:11, 129.09s/it] 73%|  | 774/1058 [27:43:31<10:11:01, 129.09s/it] 73%|  | 775/1058 [27:45:40<10:07:55, 128.89s/it] 73%|  | 776/1058 [27:47:49<10:06:24, 129.02s/it] 73%|  | 777/1058 [27:49:59<10:04:44, 129.13s/it] 74%|  | 778/1058 [27:52:08<10:02:56, 129.20s/it] 74%|  | 779/1058 [27:54:17<10:01:02, 129.26s/it] 74%|  | 780/1058 [27:56:27<9:59:09, 129.31s/it]                                                         {'loss': 1.9535, 'learning_rate': 8.044977781148242e-06, 'epoch': 0.74}
 74%|  | 780/1058 [27:56:27<9:59:09, 129.31s/it] 74%|  | 781/1058 [27:58:36<9:57:19, 129.39s/it] 74%|  | 782/1058 [28:00:46<9:55:25, 129.44s/it] 74%|  | 783/1058 [28:02:55<9:53:21, 129.46s/it] 74%|  | 784/1058 [28:05:05<9:51:14, 129.47s/it] 74%|  | 785/1058 [28:07:14<9:48:38, 129.37s/it] 74%|  | 786/1058 [28:09:22<9:44:55, 129.03s/it] 74%|  | 787/1058 [28:11:32<9:43:16, 129.14s/it] 74%|  | 788/1058 [28:13:41<9:41:29, 129.22s/it] 75%|  | 789/1058 [28:15:51<9:39:42, 129.30s/it] 75%|  | 790/1058 [28:18:00<9:37:47, 129.36s/it]                                                        {'loss': 1.9481, 'learning_rate': 7.507002186539147e-06, 'epoch': 0.75}
 75%|  | 790/1058 [28:18:00<9:37:47, 129.36s/it] 75%|  | 791/1058 [28:20:10<9:35:54, 129.42s/it] 75%|  | 792/1058 [28:22:18<9:32:11, 129.07s/it] 75%|  | 793/1058 [28:24:27<9:29:37, 128.97s/it] 75%|  | 794/1058 [28:26:35<9:26:45, 128.81s/it] 75%|  | 795/1058 [28:28:44<9:24:39, 128.82s/it] 75%|  | 796/1058 [28:30:53<9:23:05, 128.95s/it] 75%|  | 797/1058 [28:33:02<9:21:21, 129.05s/it] 75%|  | 798/1058 [28:35:12<9:19:28, 129.11s/it] 76%|  | 799/1058 [28:37:21<9:17:46, 129.22s/it] 76%|  | 800/1058 [28:39:30<9:15:53, 129.28s/it]                                                        {'loss': 1.9446, 'learning_rate': 6.984449303664287e-06, 'epoch': 0.76}
 76%|  | 800/1058 [28:39:30<9:15:53, 129.28s/it][INFO|trainer.py:2979] 2024-05-15 03:04:37,146 >> Saving model checkpoint to /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800
[INFO|configuration_utils.py:473] 2024-05-15 03:04:37,152 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800/config.json
[INFO|configuration_utils.py:595] 2024-05-15 03:04:37,157 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800/generation_config.json
[INFO|modeling_utils.py:2540] 2024-05-15 03:04:53,977 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-05-15 03:04:53,985 >> tokenizer config file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-05-15 03:04:53,989 >> Special tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-05-15 03:04:53,993 >> added tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-800/added_tokens.json
[INFO|trainer.py:3071] 2024-05-15 03:04:54,916 >> Deleting older checkpoint [/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/checkpoint-600] due to args.save_total_limit
 76%|  | 801/1058 [28:42:06<9:47:01, 137.05s/it] 76%|  | 802/1058 [28:44:15<9:35:02, 134.77s/it] 76%|  | 803/1058 [28:46:25<9:26:00, 133.18s/it] 76%|  | 804/1058 [28:48:34<9:19:11, 132.09s/it] 76%|  | 805/1058 [28:50:44<9:13:40, 131.31s/it] 76%|  | 806/1058 [28:52:53<9:09:11, 130.76s/it] 76%|  | 807/1058 [28:55:03<9:05:24, 130.38s/it] 76%|  | 808/1058 [28:57:12<9:02:14, 130.14s/it] 76%|  | 809/1058 [28:59:21<8:58:46, 129.83s/it] 77%|  | 810/1058 [29:01:30<8:55:02, 129.45s/it]                                                        {'loss': 1.9438, 'learning_rate': 6.477779841577899e-06, 'epoch': 0.77}
 77%|  | 810/1058 [29:01:30<8:55:02, 129.45s/it] 77%|  | 811/1058 [29:03:39<8:52:52, 129.44s/it] 77%|  | 812/1058 [29:05:49<8:50:48, 129.47s/it] 77%|  | 813/1058 [29:07:58<8:48:37, 129.46s/it] 77%|  | 814/1058 [29:10:08<8:46:25, 129.45s/it] 77%|  | 815/1058 [29:12:16<8:43:29, 129.26s/it] 77%|  | 816/1058 [29:14:25<8:40:30, 129.05s/it] 77%|  | 817/1058 [29:16:34<8:38:51, 129.18s/it] 77%|  | 818/1058 [29:18:44<8:36:56, 129.24s/it] 77%|  | 819/1058 [29:20:53<8:35:03, 129.30s/it] 78%|  | 820/1058 [29:23:03<8:33:01, 129.34s/it]                                                        {'loss': 1.9396, 'learning_rate': 5.987440505707023e-06, 'epoch': 0.77}
 78%|  | 820/1058 [29:23:03<8:33:01, 129.34s/it] 78%|  | 821/1058 [29:25:12<8:30:59, 129.36s/it] 78%|  | 822/1058 [29:27:22<8:28:59, 129.41s/it] 78%|  | 823/1058 [29:29:31<8:26:52, 129.41s/it] 78%|  | 824/1058 [29:31:41<8:24:44, 129.42s/it] 78%|  | 825/1058 [29:33:50<8:22:28, 129.39s/it] 78%|  | 826/1058 [29:35:59<8:20:20, 129.40s/it] 78%|  | 827/1058 [29:38:08<8:16:55, 129.07s/it] 78%|  | 828/1058 [29:40:17<8:14:59, 129.13s/it] 78%|  | 829/1058 [29:42:26<8:13:10, 129.21s/it] 78%|  | 830/1058 [29:44:36<8:11:23, 129.31s/it]                                                        {'loss': 1.9329, 'learning_rate': 5.5138636040133555e-06, 'epoch': 0.78}
 78%|  | 830/1058 [29:44:36<8:11:23, 129.31s/it] 79%|  | 831/1058 [29:46:45<8:09:33, 129.40s/it] 79%|  | 832/1058 [29:48:55<8:07:20, 129.38s/it] 79%|  | 833/1058 [29:51:04<8:05:17, 129.41s/it] 79%|  | 834/1058 [29:53:14<8:03:12, 129.43s/it] 79%|  | 835/1058 [29:55:23<8:01:02, 129.43s/it] 79%|  | 836/1058 [29:57:33<7:58:53, 129.43s/it] 79%|  | 837/1058 [29:59:42<7:56:46, 129.44s/it] 79%|  | 838/1058 [30:01:51<7:54:36, 129.44s/it] 79%|  | 839/1058 [30:04:01<7:52:29, 129.45s/it] 79%|  | 840/1058 [30:06:10<7:50:12, 129.41s/it]                                                        {'loss': 1.9323, 'learning_rate': 5.057466665848757e-06, 'epoch': 0.79}
 79%|  | 840/1058 [30:06:10<7:50:12, 129.41s/it] 79%|  | 841/1058 [30:08:19<7:47:16, 129.20s/it] 80%|  | 842/1058 [30:10:28<7:44:36, 129.06s/it] 80%|  | 843/1058 [30:12:37<7:42:16, 129.01s/it] 80%|  | 844/1058 [30:14:45<7:39:26, 128.82s/it] 80%|  | 845/1058 [30:16:54<7:37:51, 128.97s/it] 80%|  | 846/1058 [30:19:03<7:35:08, 128.81s/it] 80%|  | 847/1058 [30:21:12<7:33:09, 128.86s/it] 80%|  | 848/1058 [30:23:21<7:31:30, 129.00s/it] 80%|  | 849/1058 [30:25:30<7:29:39, 129.09s/it] 80%|  | 850/1058 [30:27:39<7:27:08, 128.98s/it]                                                        {'loss': 1.9289, 'learning_rate': 4.618652073840188e-06, 'epoch': 0.8}
 80%|  | 850/1058 [30:27:39<7:27:08, 128.98s/it] 80%|  | 851/1058 [30:29:47<7:24:24, 128.81s/it] 81%|  | 852/1058 [30:31:56<7:22:24, 128.86s/it] 81%|  | 853/1058 [30:34:05<7:19:29, 128.63s/it] 81%|  | 854/1058 [30:36:14<7:17:55, 128.80s/it] 81%|  | 855/1058 [30:38:22<7:15:01, 128.58s/it] 81%|  | 856/1058 [30:40:31<7:13:28, 128.75s/it] 81%|  | 857/1058 [30:42:39<7:10:47, 128.59s/it] 81%|  | 858/1058 [30:44:48<7:08:57, 128.69s/it] 81%|  | 859/1058 [30:46:57<7:06:42, 128.66s/it] 81%| | 860/1058 [30:49:06<7:04:47, 128.73s/it]                                                        {'loss': 1.9222, 'learning_rate': 4.197806709128865e-06, 'epoch': 0.81}
 81%| | 860/1058 [30:49:06<7:04:47, 128.73s/it] 81%| | 861/1058 [30:51:14<7:02:17, 128.61s/it] 81%| | 862/1058 [30:53:23<7:00:42, 128.79s/it] 82%| | 863/1058 [30:55:33<6:59:13, 128.99s/it] 82%| | 864/1058 [30:57:42<6:57:17, 129.06s/it] 82%| | 865/1058 [30:59:50<6:54:25, 128.84s/it] 82%| | 866/1058 [31:01:59<6:52:42, 128.97s/it] 82%| | 867/1058 [31:04:08<6:50:19, 128.90s/it] 82%| | 868/1058 [31:06:17<6:47:47, 128.78s/it] 82%| | 869/1058 [31:08:26<6:45:59, 128.89s/it] 82%| | 870/1058 [31:10:34<6:43:06, 128.65s/it]                                                        {'loss': 1.9245, 'learning_rate': 3.7953016102762696e-06, 'epoch': 0.82}
 82%| | 870/1058 [31:10:34<6:43:06, 128.65s/it] 82%| | 871/1058 [31:12:43<6:41:26, 128.81s/it] 82%| | 872/1058 [31:14:53<6:39:58, 129.03s/it] 83%| | 873/1058 [31:17:02<6:38:20, 129.19s/it] 83%| | 874/1058 [31:19:12<6:36:21, 129.25s/it] 83%| | 875/1058 [31:21:20<6:33:09, 128.90s/it] 83%| | 876/1058 [31:23:29<6:31:03, 128.92s/it] 83%| | 877/1058 [31:25:38<6:29:26, 129.09s/it] 83%| | 878/1058 [31:27:47<6:26:43, 128.91s/it] 83%| | 879/1058 [31:29:55<6:24:28, 128.88s/it] 83%| | 880/1058 [31:32:05<6:22:50, 129.05s/it]                                                        {'loss': 1.9252, 'learning_rate': 3.4114916461377625e-06, 'epoch': 0.83}
 83%| | 880/1058 [31:32:05<6:22:50, 129.05s/it] 83%| | 881/1058 [31:34:14<6:21:01, 129.16s/it] 83%| | 882/1058 [31:36:23<6:18:56, 129.18s/it] 83%| | 883/1058 [31:38:33<6:16:53, 129.22s/it] 84%| | 884/1058 [31:40:42<6:14:50, 129.25s/it] 84%| | 885/1058 [31:42:51<6:12:47, 129.29s/it] 84%| | 886/1058 [31:45:01<6:10:43, 129.32s/it] 84%| | 887/1058 [31:47:10<6:08:34, 129.33s/it] 84%| | 888/1058 [31:49:20<6:06:27, 129.34s/it] 84%| | 889/1058 [31:51:29<6:04:20, 129.35s/it] 84%| | 890/1058 [31:53:38<6:02:16, 129.38s/it]                                                        {'loss': 1.9178, 'learning_rate': 3.0467152029922926e-06, 'epoch': 0.84}
 84%| | 890/1058 [31:53:38<6:02:16, 129.38s/it] 84%| | 891/1058 [31:55:48<6:00:07, 129.39s/it] 84%| | 892/1058 [31:57:57<5:57:58, 129.39s/it] 84%| | 893/1058 [32:00:07<5:55:48, 129.39s/it] 84%| | 894/1058 [32:02:16<5:53:38, 129.38s/it] 85%| | 895/1058 [32:04:25<5:51:31, 129.40s/it] 85%| | 896/1058 [32:06:34<5:49:04, 129.29s/it] 85%| | 897/1058 [32:08:43<5:46:22, 129.08s/it] 85%| | 898/1058 [32:10:52<5:44:26, 129.16s/it] 85%| | 899/1058 [32:13:02<5:42:28, 129.23s/it] 85%| | 900/1058 [32:15:11<5:40:26, 129.28s/it]                                                        {'loss': 1.924, 'learning_rate': 2.701293886203912e-06, 'epoch': 0.85}
 85%| | 900/1058 [32:15:11<5:40:26, 129.28s/it] 85%| | 901/1058 [32:17:21<5:38:22, 129.32s/it] 85%| | 902/1058 [32:19:30<5:36:18, 129.35s/it] 85%| | 903/1058 [32:21:39<5:34:11, 129.37s/it] 85%| | 904/1058 [32:23:49<5:32:01, 129.36s/it] 86%| | 905/1058 [32:25:58<5:29:52, 129.36s/it] 86%| | 906/1058 [32:28:08<5:27:44, 129.37s/it] 86%| | 907/1058 [32:30:17<5:25:38, 129.40s/it] 86%| | 908/1058 [32:32:26<5:23:32, 129.42s/it] 86%| | 909/1058 [32:34:36<5:21:19, 129.39s/it] 86%| | 910/1058 [32:36:45<5:19:10, 129.39s/it]                                                        {'loss': 1.9157, 'learning_rate': 2.3755322366782155e-06, 'epoch': 0.86}
 86%| | 910/1058 [32:36:45<5:19:10, 129.39s/it] 86%| | 911/1058 [32:38:54<5:16:58, 129.38s/it] 86%| | 912/1058 [32:41:04<5:14:48, 129.37s/it] 86%| | 913/1058 [32:43:13<5:12:42, 129.40s/it] 86%| | 914/1058 [32:45:23<5:10:34, 129.41s/it] 86%| | 915/1058 [32:47:32<5:08:23, 129.40s/it] 87%| | 916/1058 [32:49:42<5:06:15, 129.41s/it] 87%| | 917/1058 [32:51:51<5:04:09, 129.43s/it] 87%| | 918/1058 [32:54:00<5:01:57, 129.41s/it] 87%| | 919/1058 [32:56:09<4:59:27, 129.26s/it] 87%| | 920/1058 [32:58:17<4:56:31, 128.92s/it]                                                        {'loss': 1.9178, 'learning_rate': 2.0697174623636794e-06, 'epoch': 0.87}
 87%| | 920/1058 [32:58:17<4:56:31, 128.92s/it] 87%| | 921/1058 [33:00:27<4:54:37, 129.04s/it] 87%| | 922/1058 [33:02:36<4:52:42, 129.13s/it] 87%| | 923/1058 [33:04:45<4:50:40, 129.19s/it] 87%| | 924/1058 [33:06:55<4:48:37, 129.24s/it] 87%| | 925/1058 [33:09:04<4:46:33, 129.27s/it] 88%| | 926/1058 [33:11:12<4:43:45, 128.98s/it] 88%| | 927/1058 [33:13:21<4:41:35, 128.97s/it] 88%| | 928/1058 [33:15:31<4:39:38, 129.07s/it] 88%| | 929/1058 [33:17:40<4:37:41, 129.16s/it] 88%| | 930/1058 [33:19:49<4:35:38, 129.21s/it]                                                        {'loss': 1.9139, 'learning_rate': 1.7841191850345967e-06, 'epoch': 0.88}
 88%| | 930/1058 [33:19:49<4:35:38, 129.21s/it] 88%| | 931/1058 [33:21:59<4:33:36, 129.26s/it] 88%| | 932/1058 [33:24:08<4:31:34, 129.32s/it] 88%| | 933/1058 [33:26:18<4:29:28, 129.34s/it] 88%| | 934/1058 [33:28:27<4:27:20, 129.36s/it] 88%| | 935/1058 [33:30:36<4:25:13, 129.37s/it] 88%| | 936/1058 [33:32:46<4:23:05, 129.39s/it] 89%| | 937/1058 [33:34:55<4:20:53, 129.37s/it] 89%| | 938/1058 [33:37:04<4:18:40, 129.34s/it] 89%| | 939/1058 [33:39:14<4:16:32, 129.35s/it] 89%| | 940/1058 [33:41:22<4:13:44, 129.02s/it]                                                        {'loss': 1.9169, 'learning_rate': 1.5189892025789049e-06, 'epoch': 0.89}
 89%| | 940/1058 [33:41:22<4:13:44, 129.02s/it] 89%| | 941/1058 [33:43:31<4:11:31, 128.99s/it] 89%| | 942/1058 [33:45:39<4:08:49, 128.70s/it] 89%| | 943/1058 [33:47:48<4:07:00, 128.88s/it] 89%| | 944/1058 [33:49:58<4:05:11, 129.05s/it] 89%| | 945/1058 [33:52:07<4:03:12, 129.14s/it] 89%| | 946/1058 [33:54:16<4:01:11, 129.21s/it] 90%| | 947/1058 [33:56:26<3:59:10, 129.28s/it] 90%| | 948/1058 [33:58:35<3:57:03, 129.30s/it] 90%| | 949/1058 [34:00:45<3:54:56, 129.32s/it] 90%| | 950/1058 [34:02:54<3:52:42, 129.28s/it]                                                        {'loss': 1.9118, 'learning_rate': 1.2745612670004153e-06, 'epoch': 0.9}
 90%| | 950/1058 [34:02:54<3:52:42, 129.28s/it] 90%| | 951/1058 [34:05:02<3:50:11, 129.08s/it] 90%| | 952/1058 [34:07:12<3:48:09, 129.15s/it] 90%| | 953/1058 [34:09:21<3:46:09, 129.23s/it] 90%| | 954/1058 [34:11:31<3:44:05, 129.29s/it] 90%| | 955/1058 [34:13:40<3:41:59, 129.31s/it] 90%| | 956/1058 [34:15:49<3:39:51, 129.33s/it] 90%| | 957/1058 [34:17:59<3:37:43, 129.35s/it] 91%| | 958/1058 [34:20:08<3:35:34, 129.35s/it] 91%| | 959/1058 [34:22:17<3:33:26, 129.36s/it] 91%| | 960/1058 [34:24:27<3:31:17, 129.36s/it]                                                        {'loss': 1.9092, 'learning_rate': 1.0510508783312224e-06, 'epoch': 0.91}
 91%| | 960/1058 [34:24:27<3:31:17, 129.36s/it] 91%| | 961/1058 [34:26:36<3:29:09, 129.38s/it] 91%| | 962/1058 [34:28:46<3:27:00, 129.38s/it] 91%| | 963/1058 [34:30:55<3:24:52, 129.39s/it] 91%| | 964/1058 [34:33:04<3:22:42, 129.39s/it] 91%| | 965/1058 [34:35:14<3:20:32, 129.38s/it] 91%|| 966/1058 [34:37:23<3:18:22, 129.38s/it] 91%|| 967/1058 [34:39:33<3:16:12, 129.37s/it] 91%|| 968/1058 [34:41:42<3:14:02, 129.36s/it] 92%|| 969/1058 [34:43:51<3:11:53, 129.37s/it] 92%|| 970/1058 [34:46:01<3:09:42, 129.35s/it]                                                        {'loss': 1.9094, 'learning_rate': 8.486550946359778e-07, 'epoch': 0.92}
 92%|| 970/1058 [34:46:01<3:09:42, 129.35s/it] 92%|| 971/1058 [34:48:10<3:07:35, 129.37s/it] 92%|| 972/1058 [34:50:19<3:05:25, 129.36s/it] 92%|| 973/1058 [34:52:29<3:03:16, 129.37s/it] 92%|| 974/1058 [34:54:38<3:01:07, 129.38s/it] 92%|| 975/1058 [34:56:48<2:59:00, 129.41s/it] 92%|| 976/1058 [34:58:57<2:56:51, 129.41s/it] 92%|| 977/1058 [35:01:06<2:54:41, 129.41s/it] 92%|| 978/1058 [35:03:16<2:52:33, 129.42s/it] 93%|| 979/1058 [35:05:25<2:50:20, 129.37s/it] 93%|| 980/1058 [35:07:35<2:48:12, 129.39s/it]                                                        {'loss': 1.9101, 'learning_rate': 6.675523582755222e-07, 'epoch': 0.93}
 93%|| 980/1058 [35:07:35<2:48:12, 129.39s/it] 93%|| 981/1058 [35:09:44<2:46:03, 129.39s/it] 93%|| 982/1058 [35:11:53<2:43:55, 129.42s/it] 93%|| 983/1058 [35:14:03<2:41:45, 129.41s/it] 93%|| 984/1058 [35:16:12<2:39:32, 129.36s/it] 93%|| 985/1058 [35:18:21<2:37:22, 129.35s/it] 93%|| 986/1058 [35:20:31<2:35:13, 129.35s/it] 93%|| 987/1058 [35:22:40<2:33:06, 129.39s/it] 93%|| 988/1058 [35:24:50<2:30:58, 129.41s/it] 93%|| 989/1058 [35:26:59<2:28:46, 129.36s/it] 94%|| 990/1058 [35:29:08<2:26:25, 129.20s/it]                                                        {'loss': 1.9082, 'learning_rate': 5.079023385830939e-07, 'epoch': 0.94}
 94%|| 990/1058 [35:29:08<2:26:25, 129.20s/it] 94%|| 991/1058 [35:31:16<2:23:57, 128.92s/it] 94%|| 992/1058 [35:33:25<2:21:56, 129.04s/it] 94%|| 993/1058 [35:35:35<2:19:53, 129.13s/it] 94%|| 994/1058 [35:37:44<2:17:48, 129.20s/it] 94%|| 995/1058 [35:39:53<2:15:44, 129.29s/it] 94%|| 996/1058 [35:42:03<2:13:38, 129.33s/it] 94%|| 997/1058 [35:44:12<2:11:29, 129.34s/it] 94%|| 998/1058 [35:46:22<2:09:19, 129.33s/it] 94%|| 999/1058 [35:48:31<2:07:08, 129.30s/it] 95%|| 1000/1058 [35:50:40<2:04:58, 129.29s/it]                                                         {'loss': 1.9109, 'learning_rate': 3.6984579109176074e-07, 'epoch': 0.94}
 95%|| 1000/1058 [35:50:40<2:04:58, 129.29s/it][INFO|trainer.py:2979] 2024-05-15 10:15:46,883 >> Saving model checkpoint to /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000
[INFO|configuration_utils.py:473] 2024-05-15 10:15:46,888 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000/config.json
[INFO|configuration_utils.py:595] 2024-05-15 10:15:46,892 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000/generation_config.json
[INFO|modeling_utils.py:2540] 2024-05-15 10:16:03,756 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-05-15 10:16:03,774 >> tokenizer config file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-05-15 10:16:03,778 >> Special tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-05-15 10:16:03,781 >> added tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tmp-checkpoint-1000/added_tokens.json
[INFO|trainer.py:3071] 2024-05-15 10:16:04,702 >> Deleting older checkpoint [/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/checkpoint-600] due to args.save_total_limit
[INFO|trainer.py:3071] 2024-05-15 10:16:04,706 >> Deleting older checkpoint [/root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/checkpoint-800] due to args.save_total_limit
 95%|| 1001/1058 [35:53:15<2:10:12, 137.06s/it] 95%|| 1002/1058 [35:55:25<2:05:49, 134.81s/it] 95%|| 1003/1058 [35:57:34<2:02:01, 133.11s/it] 95%|| 1004/1058 [35:59:42<1:58:26, 131.61s/it] 95%|| 1005/1058 [36:01:51<1:55:34, 130.83s/it] 95%|| 1006/1058 [36:03:59<1:52:39, 129.99s/it] 95%|| 1007/1058 [36:06:08<1:50:16, 129.74s/it] 95%|| 1008/1058 [36:08:18<1:48:01, 129.62s/it] 95%|| 1009/1058 [36:10:27<1:45:48, 129.56s/it] 95%|| 1010/1058 [36:12:36<1:43:35, 129.48s/it]                                                         {'loss': 1.9112, 'learning_rate': 2.535044334372072e-07, 'epoch': 0.95}
 95%|| 1010/1058 [36:12:36<1:43:35, 129.48s/it] 96%|| 1011/1058 [36:14:44<1:41:05, 129.06s/it] 96%|| 1012/1058 [36:16:54<1:38:58, 129.09s/it] 96%|| 1013/1058 [36:19:03<1:36:53, 129.20s/it] 96%|| 1014/1058 [36:21:12<1:34:47, 129.25s/it] 96%|| 1015/1058 [36:23:21<1:32:23, 128.93s/it] 96%|| 1016/1058 [36:25:30<1:30:17, 128.98s/it] 96%|| 1017/1058 [36:27:39<1:28:13, 129.11s/it] 96%|| 1018/1058 [36:29:48<1:26:07, 129.20s/it] 96%|| 1019/1058 [36:31:57<1:23:51, 129.00s/it] 96%|| 1020/1058 [36:34:06<1:21:41, 129.00s/it]                                                         {'loss': 1.9091, 'learning_rate': 1.589808380453306e-07, 'epoch': 0.96}
 96%|| 1020/1058 [36:34:06<1:21:41, 129.00s/it] 97%|| 1021/1058 [36:36:16<1:19:38, 129.15s/it] 97%|| 1022/1058 [36:38:25<1:17:31, 129.22s/it] 97%|| 1023/1058 [36:40:34<1:15:23, 129.25s/it] 97%|| 1024/1058 [36:42:44<1:13:15, 129.28s/it] 97%|| 1025/1058 [36:44:53<1:11:06, 129.30s/it] 97%|| 1026/1058 [36:47:02<1:08:57, 129.31s/it] 97%|| 1027/1058 [36:49:12<1:06:48, 129.30s/it] 97%|| 1028/1058 [36:51:21<1:04:38, 129.29s/it] 97%|| 1029/1058 [36:53:29<1:02:20, 128.97s/it] 97%|| 1030/1058 [36:55:38<1:00:13, 129.06s/it]                                                         {'loss': 1.908, 'learning_rate': 8.635834169918311e-08, 'epoch': 0.97}
 97%|| 1030/1058 [36:55:38<1:00:13, 129.06s/it] 97%|| 1031/1058 [36:57:48<58:07, 129.16s/it]   98%|| 1032/1058 [36:59:57<56:00, 129.23s/it] 98%|| 1033/1058 [37:02:06<53:51, 129.25s/it] 98%|| 1034/1058 [37:04:16<51:42, 129.29s/it] 98%|| 1035/1058 [37:06:25<49:34, 129.34s/it] 98%|| 1036/1058 [37:08:35<47:25, 129.35s/it] 98%|| 1037/1058 [37:10:44<45:16, 129.37s/it] 98%|| 1038/1058 [37:12:52<43:01, 129.07s/it] 98%|| 1039/1058 [37:15:02<40:52, 129.09s/it] 98%|| 1040/1058 [37:17:11<38:44, 129.15s/it]                                                       {'loss': 1.9094, 'learning_rate': 3.5700972065066954e-08, 'epoch': 0.98}
 98%|| 1040/1058 [37:17:11<38:44, 129.15s/it] 98%|| 1041/1058 [37:19:20<36:36, 129.20s/it] 98%|| 1042/1058 [37:21:29<34:23, 128.96s/it] 99%|| 1043/1058 [37:23:37<32:13, 128.92s/it] 99%|| 1044/1058 [37:25:47<30:06, 129.07s/it] 99%|| 1045/1058 [37:27:56<27:58, 129.15s/it] 99%|| 1046/1058 [37:30:05<25:50, 129.20s/it] 99%|| 1047/1058 [37:32:15<23:41, 129.26s/it] 99%|| 1048/1058 [37:34:24<21:33, 129.31s/it] 99%|| 1049/1058 [37:36:34<19:24, 129.34s/it] 99%|| 1050/1058 [37:38:43<17:14, 129.37s/it]                                                       {'loss': 1.9048, 'learning_rate': 7.053391242492491e-09, 'epoch': 0.99}
 99%|| 1050/1058 [37:38:43<17:14, 129.37s/it] 99%|| 1051/1058 [37:40:53<15:05, 129.39s/it] 99%|| 1052/1058 [37:43:01<12:54, 129.09s/it]100%|| 1053/1058 [37:45:10<10:45, 129.03s/it]100%|| 1054/1058 [37:47:19<08:36, 129.15s/it]100%|| 1055/1058 [37:49:29<06:27, 129.21s/it]100%|| 1056/1058 [37:51:38<04:18, 129.22s/it]100%|| 1057/1058 [37:53:47<02:09, 129.27s/it]100%|| 1058/1058 [37:55:57<00:00, 129.31s/it][INFO|trainer.py:1988] 2024-05-15 12:20:55,124 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                       {'train_runtime': 136557.154, 'train_samples_per_second': 7.939, 'train_steps_per_second': 0.008, 'train_loss': 2.482775608848759, 'epoch': 1.0}
100%|| 1058/1058 [37:55:57<00:00, 129.31s/it]100%|| 1058/1058 [37:55:57<00:00, 129.07s/it]
[INFO|trainer.py:2979] 2024-05-15 12:21:03,320 >> Saving model checkpoint to /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07
[INFO|configuration_utils.py:473] 2024-05-15 12:21:03,323 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/config.json
[INFO|configuration_utils.py:595] 2024-05-15 12:21:03,328 >> Configuration saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/generation_config.json
[2024-05-15 12:21:06,709] [INFO] [launch.py:347:main] Process 279774 exits successfully.
[2024-05-15 12:21:06,712] [INFO] [launch.py:347:main] Process 279772 exits successfully.
[2024-05-15 12:21:06,714] [INFO] [launch.py:347:main] Process 279778 exits successfully.
[2024-05-15 12:21:06,722] [INFO] [launch.py:347:main] Process 279777 exits successfully.
[2024-05-15 12:21:07,730] [INFO] [launch.py:347:main] Process 279776 exits successfully.
[2024-05-15 12:21:07,731] [INFO] [launch.py:347:main] Process 279775 exits successfully.
[2024-05-15 12:21:07,732] [INFO] [launch.py:347:main] Process 279773 exits successfully.
[INFO|modeling_utils.py:2540] 2024-05-15 12:21:23,527 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-05-15 12:21:23,533 >> tokenizer config file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-05-15 12:21:23,535 >> Special tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-05-15 12:21:23,537 >> added tokens file saved in /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/added_tokens.json
***** train metrics *****
  epoch                    =                1.0
  train_loss               =             2.4828
  train_runtime            = 1 day, 13:55:57.15
  train_samples_per_second =              7.939
  train_steps_per_second   =              0.008
Figure saved: /root/huangxin/nanda/checkpoints/merge/0.5b-bn-7b-ca-0.07/training_loss.png
05/15/2024 12:21:25 - WARNING - llmtuner.extras.ploting - No metric eval_loss to plot.
[INFO|modelcard.py:452] 2024-05-15 12:21:25,250 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
[2024-05-15 12:21:27,832] [INFO] [launch.py:347:main] Process 279771 exits successfully.
