[2024-03-25 15:54:44,253] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-25 15:54:46,964] [WARNING] [runner.py:203:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-03-25 15:54:47,005] [INFO] [runner.py:570:main] cmd = /home/nfs02/anaconda3/envs/wzjsz/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMiwgMywgNSwgNl19 --master_addr=127.0.0.1 --master_port=9901 --enable_each_rank_log=None src/train_bash.py --deepspeed /home/wangzj/LLaMA-Factory/llama-pt/config/ds_config.json --stage pt --flash_attn --model_name_or_path /home/nfs02/model/phi-2 --do_train --dataset ar_1b --preprocessing_num_workers 16 --cutoff_len 1024 --finetuning_type full --output_dir /home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b --overwrite_output_dir --per_device_train_batch_size 4 --gradient_accumulation_steps 16 --lr_scheduler_type cosine --logging_steps 10 --save_total_limit 1 --save_only_model --save_steps 100000 --learning_rate 5e-5 --num_train_epochs 1.0 --plot_loss --bf16
[2024-03-25 15:54:48,443] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-25 15:54:50,336] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 2, 3, 5, 6]}
[2024-03-25 15:54:50,336] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=5, node_rank=0
[2024-03-25 15:54:50,336] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4]})
[2024-03-25 15:54:50,336] [INFO] [launch.py:163:main] dist_world_size=5
[2024-03-25 15:54:50,336] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,2,3,5,6
[2024-03-25 15:54:54,503] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-25 15:54:54,510] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-25 15:54:54,513] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-25 15:54:54,514] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-25 15:54:54,518] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-25 15:55:00,956] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-25 15:55:00,956] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-25 15:55:00,956] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-03-25 15:55:00,956] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-25 15:55:00,957] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-25 15:55:00,969] [INFO] [comm.py:637:init_distributed] cdb=None
03/25/2024 15:55:01 - INFO - llmtuner.hparams.parser - Process rank: 2, device: cuda:2, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
03/25/2024 15:55:01 - INFO - llmtuner.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
03/25/2024 15:55:01 - INFO - llmtuner.hparams.parser - Process rank: 3, device: cuda:3, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
03/25/2024 15:55:01 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=2,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b/runs/Mar25_15-55-00_3090ti-1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=4,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=100000,
save_strategy=steps,
save_total_limit=1,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
03/25/2024 15:55:01 - INFO - llmtuner.hparams.parser - Process rank: 4, device: cuda:4, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
03/25/2024 15:55:01 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b/runs/Mar25_15-55-00_3090ti-1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=4,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=100000,
save_strategy=steps,
save_total_limit=1,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
03/25/2024 15:55:01 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=3,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b/runs/Mar25_15-55-00_3090ti-1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=4,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=100000,
save_strategy=steps,
save_total_limit=1,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
03/25/2024 15:55:01 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=4,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b/runs/Mar25_15-55-00_3090ti-1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=4,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=100000,
save_strategy=steps,
save_total_limit=1,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[INFO|tokenization_utils_base.py:2027] 2024-03-25 15:55:01,018 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2027] 2024-03-25 15:55:01,018 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2027] 2024-03-25 15:55:01,018 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2027] 2024-03-25 15:55:01,018 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2027] 2024-03-25 15:55:01,018 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2027] 2024-03-25 15:55:01,018 >> loading file tokenizer.json
03/25/2024 15:55:01 - INFO - llmtuner.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1
  distributed training: True, compute dtype: torch.bfloat16
03/25/2024 15:55:01 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=/home/wangzj/LLaMA-Factory/llama-pt/config/ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=1,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b/runs/Mar25_15-55-00_3090ti-1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=4,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b,
save_on_each_node=False,
save_only_model=True,
save_safetensors=True,
save_steps=100000,
save_strategy=steps,
save_total_limit=1,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:314] 2024-03-25 15:55:01,119 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:727] 2024-03-25 15:55:01,120 >> loading configuration file /home/nfs02/model/phi-2/config.json
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:727] 2024-03-25 15:55:01,138 >> loading configuration file /home/nfs02/model/phi-2/config.json
[INFO|configuration_utils.py:792] 2024-03-25 15:55:01,140 >> Model config PhiConfig {
  "_name_or_path": "/home/nfs02/model/phi-2",
  "architectures": [
    "PhiForCausalLM"
  ],
  "attention_dropout": 0.0,
  "auto_map": {
    "AutoConfig": "configuration_phi.PhiConfig",
    "AutoModelForCausalLM": "modeling_phi.PhiForCausalLM"
  },
  "bos_token_id": 50256,
  "embd_pdrop": 0.0,
  "eos_token_id": 50256,
  "hidden_act": "gelu_new",
  "hidden_size": 2560,
  "initializer_range": 0.02,
  "intermediate_size": 10240,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "phi",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "partial_rotary_factor": 0.4,
  "qk_layernorm": false,
  "resid_pdrop": 0.1,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.38.0.dev0",
  "use_cache": true,
  "vocab_size": 51200
}

03/25/2024 15:55:01 - INFO - llmtuner.model.patcher - Using FlashAttention-2 for faster training and inference.
03/25/2024 15:55:01 - INFO - llmtuner.model.patcher - Using FlashAttention-2 for faster training and inference.
03/25/2024 15:55:01 - INFO - llmtuner.model.patcher - Using FlashAttention-2 for faster training and inference.
03/25/2024 15:55:01 - INFO - llmtuner.model.patcher - Using FlashAttention-2 for faster training and inference.
03/25/2024 15:55:01 - INFO - llmtuner.model.patcher - Using FlashAttention-2 for faster training and inference.
[INFO|modeling_utils.py:3334] 2024-03-25 15:55:01,238 >> loading weights file /home/nfs02/model/phi-2/model.safetensors.index.json
[INFO|modeling_utils.py:1459] 2024-03-25 15:55:01,239 >> Instantiating PhiForCausalLM model under default dtype torch.bfloat16.
The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
[WARNING|logging.py:329] 2024-03-25 15:55:01,239 >> The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[WARNING|logging.py:329] 2024-03-25 15:55:01,241 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[INFO|configuration_utils.py:827] 2024-03-25 15:55:01,243 >> Generate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.50s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.52s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.49s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.51s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.02s/it]
[INFO|modeling_utils.py:4070] 2024-03-25 15:55:09,776 >> All model checkpoint weights were used when initializing PhiForCausalLM.

[INFO|modeling_utils.py:4078] 2024-03-25 15:55:09,776 >> All the weights of PhiForCausalLM were initialized from the model checkpoint at /home/nfs02/model/phi-2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use PhiForCausalLM for predictions without further training.
[INFO|configuration_utils.py:780] 2024-03-25 15:55:09,779 >> loading configuration file /home/nfs02/model/phi-2/generation_config.json
[INFO|configuration_utils.py:827] 2024-03-25 15:55:09,780 >> Generate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}

03/25/2024 15:55:09 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
03/25/2024 15:55:09 - INFO - llmtuner.model.adapter - Fine-tuning method: Full
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.01s/it]
03/25/2024 15:55:09 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
03/25/2024 15:55:09 - INFO - llmtuner.model.adapter - Fine-tuning method: Full
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.04s/it]
03/25/2024 15:55:09 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
03/25/2024 15:55:09 - INFO - llmtuner.model.adapter - Fine-tuning method: Full
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.09s/it]
03/25/2024 15:55:09 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
03/25/2024 15:55:09 - INFO - llmtuner.model.adapter - Fine-tuning method: Full
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]
03/25/2024 15:55:09 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
03/25/2024 15:55:09 - INFO - llmtuner.model.adapter - Fine-tuning method: Full
03/25/2024 15:55:18 - INFO - llmtuner.model.loader - trainable params: 2779683840 || all params: 2779683840 || trainable%: 100.0000
03/25/2024 15:55:18 - INFO - llmtuner.data.template - Add pad token: <|endoftext|>
03/25/2024 15:55:18 - INFO - llmtuner.model.loader - trainable params: 2779683840 || all params: 2779683840 || trainable%: 100.0000
03/25/2024 15:55:18 - INFO - llmtuner.data.template - Add pad token: <|endoftext|>
03/25/2024 15:55:18 - INFO - llmtuner.model.loader - trainable params: 2779683840 || all params: 2779683840 || trainable%: 100.0000
03/25/2024 15:55:18 - INFO - llmtuner.data.template - Add pad token: <|endoftext|>
03/25/2024 15:55:18 - INFO - llmtuner.model.loader - trainable params: 2779683840 || all params: 2779683840 || trainable%: 100.0000
03/25/2024 15:55:18 - INFO - llmtuner.data.template - Add pad token: <|endoftext|>
03/25/2024 15:55:18 - INFO - llmtuner.model.loader - trainable params: 2779683840 || all params: 2779683840 || trainable%: 100.0000
03/25/2024 15:55:18 - INFO - llmtuner.data.template - Add pad token: <|endoftext|>
03/25/2024 15:55:22 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ar_1b.jsonl.
Using custom data configuration default-59cb3ddd10a01018
Loading Dataset Infos from /home/nfs02/anaconda3/envs/wzjsz/lib/python3.10/site-packages/datasets/packaged_modules/json
Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
Found cached dataset json (/home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)
Loading Dataset info from /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96
Dataset({
    features: ['text'],
    num_rows: 369160
})
{'text': 'قال وزير تونسي إن الوفد اليهودي الفرنسي، غادر ملتقى "سفراء الحوار بين الأديان"، الذي انطلق بتونس يوم الأحد، "تجنبًا لأي لبس".\nوأوضح وزير الشؤون الدينية، أحمد عظوم، في تصريحات إعلاميّة، أن الوفد اليهودي الفرنسي "غير معني" بقرار قضائي تونسي يقضي بمنع منظمة الكشافة التونسية من قبول مشاركين إسرائيليين في هذا الملتقى.\nوقال عظوم، في كلمته أمام الملتقى، إنّ الملتقى الكشفي العالمي "سفراء الحوار بين الأديان"، يُساهم في التعايش السلمي ونبذ التطرف والعنف.\nوأشار إلى أنّ "وحدة الصف بين الشعوب في هذه اللحظة الفارقة، هي الضامن للتعايش السلمي بعيدًا عن الكراهية والتعصب على أساس الدين".\nمن جانبه، اعتبر القائد العام للكشافة التونسية، وحيد العبيدي، في كلمته، أن "الملتقى مناسبة لدفع مسار الحوار بين الأديان والثقافات ولتوفير الأمن والسلم".\nوأشار إلى أن 24 جنسية موزعين على 6 ديانات، يشاركون في هذا الملتقى العالمي الأول من نوعه، والذّي يتواصل حتى 8 نوفمبر/تشرين الثاني الجاري.\nويختتم الملتقى أعماله بإصدار "وثيقة تونس" لسفراء الحوار بين الأديان التي ستشكل لبنة أولى، لخلق منابر حوار داخل المنظمات الكشفية خلال المؤتمرات العالمية المقبلة.\nوانطلقت في مدينة الحمامات التونسية، مساء الأحد، أعمال الملتقى الكشفي العالمي "سفراء الحوار بين الأديان"، بمشاركة أكثر 150 شخصًا من 24 دولة.\nويهدف الملتقى، الذي يستمر 4 أيام، للعمل على تبني الحوار في المناهج الكشفية، وترسيخ ثقافة الحوار والتعايش بين الأديان.\nأصيب، اليوم الاثنين، مواطن، بالرصاص الحي عقب اقتحام قوات الاحتلال منزله واعتقال نجله في بلدة حلحول شمال الخليل، جنوب الضفة الغربية.'}
Process #0 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00000_of_00016.arrow
Process #1 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00001_of_00016.arrow
Process #2 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00002_of_00016.arrow
Process #3 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00003_of_00016.arrow
Process #4 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00004_of_00016.arrow
Process #5 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00005_of_00016.arrow
Process #6 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00006_of_00016.arrow
Process #7 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00007_of_00016.arrow
Process #8 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00008_of_00016.arrow
Process #9 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00009_of_00016.arrow
Process #10 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00010_of_00016.arrow
Process #11 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00011_of_00016.arrow
Process #12 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00012_of_00016.arrow
Process #13 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00013_of_00016.arrow
Process #14 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00014_of_00016.arrow
Process #15 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_00015_of_00016.arrow
Loading cached processed dataset at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6129162dd7223443_*_of_00016.arrow
Concatenating 16 shards
Process #0 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00000_of_00016.arrow
Process #1 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00001_of_00016.arrow
Process #2 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00002_of_00016.arrow
Process #3 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00003_of_00016.arrow
Process #4 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00004_of_00016.arrow
Process #5 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00005_of_00016.arrow
Process #6 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00006_of_00016.arrow
Process #7 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00007_of_00016.arrow
Process #8 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00008_of_00016.arrow
Process #9 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00009_of_00016.arrow
Process #10 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00010_of_00016.arrow
Process #11 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00011_of_00016.arrow
Process #12 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00012_of_00016.arrow
Process #13 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00013_of_00016.arrow
Process #14 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00014_of_00016.arrow
Process #15 will write at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_00015_of_00016.arrow
Loading cached processed dataset at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-01d88b9db3733f12_*_of_00016.arrow
Concatenating 16 shards
input_ids:
[149, 224, 23525, 42092, 148, 110, 22654, 26897, 17550, 103, 30335, 23338, 45692, 22654, 17550, 98, 23338, 28981, 30335, 149, 223, 38843, 28981, 22654, 29519, 30335, 38843, 22654, 28981, 149, 223, 26897, 23338, 45692, 22654, 148, 234, 17550, 118, 34247, 107, 26897, 47048, 13862, 41486, 149, 224, 149, 231, 366, 45692, 149, 223, 26897, 34247, 94, 28981, 148, 255, 30335, 12919, 26897, 17550, 101, 22654, 23338, 28981, 148, 96, 38843, 22654, 12919, 23338, 1, 148, 234, 28981, 148, 108, 22654, 220, 12919, 23338, 148, 115, 13862, 149, 224, 17550, 101, 41486, 30335, 23338, 45692, 18923, 232, 30335, 25405, 28981, 148, 96, 148, 255, 38843, 148, 234, 366, 41486, 148, 105, 23338, 39848, 149, 233, 12919, 220, 13862, 148, 96, 22654, 220, 13862, 39848, 45692, 1911, 198, 30335, 148, 96, 30335, 148, 114, 148, 255, 42092, 148, 110, 22654, 26897, 28981, 148, 112, 148, 97, 30335, 23338, 28981, 38843, 22654, 23338, 22654, 45632, 148, 234, 17550, 96, 148, 255, 25405, 38843, 17550, 117, 148, 116, 30335, 25405, 148, 234, 18923, 223, 22654, 17550, 103, 148, 113, 26897, 22654, 148, 255, 34247, 103, 17550, 98, 44690, 13862, 12919, 25405, 22654, 149, 239, 45632, 148, 234, 17550, 96, 23338, 28981, 30335, 149, 223, 38843, 28981, 22654, 29519, 30335, 38843, 22654, 28981, 149, 223, 26897, 23338, 45692, 22654, 366, 148, 118, 22654, 26897, 47048, 44690, 23338, 22654, 1, 17550, 101, 149, 224, 26897, 12919, 26897, 18923, 224, 148, 114, 34247, 99, 22654, 17550, 103, 30335, 23338, 45692, 22654, 18923, 232, 149, 224, 148, 114, 22654, 17550, 101, 25405, 23338, 44690, 47048, 23338, 148, 116, 25405, 45632, 28981, 149, 225, 148, 112, 12919, 149, 223, 45632, 28981, 41486, 30335, 23338, 45692, 22654, 45632, 47048, 23338, 18923, 224, 39848, 30335, 13862, 47048, 148, 112, 12919, 26897, 149, 225, 22654, 23338, 17550, 98, 45692, 26897, 34247, 99, 22654, 13862, 22654, 22654, 23338, 18923, 223, 22654, 18923, 229, 148, 108, 12919, 28981, 25405, 13862, 41486, 149, 224, 149, 231, 13, 198, 30335, 149, 224, 23525, 17550, 117, 148, 116, 30335, 25405, 148, 234, 18923, 223, 22654, 18923, 225, 13862, 25405, 41486, 29519, 17550, 96, 25405, 12919, 25405, 28981, 25405, 13862, 41486, 149, 224, 149, 231, 148, 234, 17550, 98, 23338, 149, 239, 28981, 25405, 13862, 41486, 149, 224, 149, 231, 28981, 149, 225, 148, 112, 149, 223, 22654, 28981, 44690, 23525, 25405, 22654, 366, 45692, 149, 223, 26897, 34247, 94, 28981, 148, 255, 30335, 12919, 26897, 17550, 101, 22654, 23338, 28981, 148, 96, 38843, 22654, 12919, 23338, 1, 148, 234, 18923, 232, 149, 237, 45692, 12919, 29519, 25405, 18923, 223, 22654, 28981, 41486, 44690, 12919, 22654, 148, 112, 28981, 45692, 13862, 25405, 22654, 42092, 23338, 39848, 148, 108, 28981, 41486, 148, 115, 26897, 149, 223, 42092, 23525, 44690, 23338, 149, 223, 13, 198, 30335, 148, 96, 148, 112, 12919, 26897, 17550, 98, 13862, 149, 231, 17550, 96, 23338, 149, 239, 366, 30335, 148, 255, 38843, 45632, 28981, 148, 113, 149, 223, 17550, 101, 22654, 23338, 28981, 148, 112, 44690, 30335, 39848, 18923, 223, 22654, 18923, 229, 148, 108, 29519, 28981, 13862, 148, 255, 148, 116, 45632, 28981, 149, 223, 12919, 26897, 149, 224, 45632, 148, 234, 18923, 229, 22654, 28981, 148, 114, 12919, 25405, 23338, 220, 13862, 13862, 41486, 44690, 12919, 22654, 148, 112, 28981, 45692, 13862, 25405, 22654, 17550, 101, 44690, 22654, 38843, 149, 233, 12919, 17550, 117, 23338, 28981, 149, 225, 26897, 12919, 29519, 22654, 45632, 42092, 23525, 41486, 44690, 148, 113, 39848, 17550, 117, 13862, 149, 231, 17550, 96, 45692, 34247, 111, 28981, 38843, 22654, 23338, 1911, 198, 25405, 23338, 17550, 105, 12919, 23338, 39848, 29519, 148, 234, 220, 34247, 117, 41486, 39848, 26897, 28981, 149, 224, 34247, 99, 38843, 28981, 44690, 12919, 25405, 220, 13862, 13862, 149, 225, 148, 112, 12919, 149, 223, 45632, 28981, 41486, 30335, 23338, 45692, 22654, 45632, 148, 234, 42092, 148, 255, 22654, 38843, 28981, 44690, 39848, 22654, 38843, 22654, 148, 234, 18923, 223, 22654, 18923, 225, 13862, 25405, 41486, 29519, 148, 234, 17550, 96, 23338, 366, 23525, 25405, 13862, 41486, 149, 224, 149, 231, 47048, 23338, 34247, 111, 39848, 45632, 220, 13862, 38843, 149, 223, 44690, 47048, 45692, 12919, 26897, 28981, 148, 255, 30335, 12919, 26897, 17550, 101, 22654, 23338, 28981, 148, 96, 38843, 22654, 12919, 23338, 42092, 23525, 148, 104, 149, 224, 12919, 149, 223, 34247, 103, 42092, 13862, 41486, 30335, 149, 223, 22654, 26897, 28981, 148, 96, 25405, 23338, 42092, 23525, 45692, 13862, 25405, 1911, 198, 30335, 148, 96, 148, 112, 12919, 26897, 17550, 98, 13862, 149, 231, 17550, 96, 23338, 1987, 17550, 105, 23338, 45692, 22654, 45632, 47048, 30335, 148, 110, 44690, 22654, 23338, 17550, 117, 13862, 149, 231, 718, 17550, 107, 22654, 12919, 23338, 34247, 103, 148, 234, 18923, 232, 148, 112, 12919, 26897, 149, 225, 30335, 23338, 18923, 223, 22654, 18923, 229, 148, 108, 12919, 28981, 25405, 13862, 41486, 149, 224, 149, 231, 28981, 44690, 23525, 25405, 22654, 28981, 148, 96, 30335, 13862, 47048, 23338, 18923, 228, 30335, 44690, 29519, 148, 234, 42092, 23525, 148, 108, 149, 239, 22654, 18923, 232, 41486, 30335, 34247, 113, 13862, 17550, 255, 41486, 149, 231, 807, 18923, 228, 30335, 149, 223, 25405, 39848, 26897, 14, 41486, 148, 112, 26897, 22654, 23338, 28981, 148, 104, 12919, 23338, 22654, 28981, 148, 105, 12919, 26897, 22654, 13, 198, 30335, 22654, 148, 106, 41486, 41486, 25405, 28981, 25405, 13862, 41486, 149, 224, 149, 231, 17550, 96, 44690, 25405, 23525, 29519, 17550, 101, 148, 98, 148, 113, 38843, 12919, 26897, 366, 30335, 148, 104, 22654, 149, 224, 45632, 17550, 103, 30335, 23338, 45692, 1, 220, 13862, 45692, 149, 223, 26897, 34247, 94, 28981, 148, 255, 30335, 12919, 26897, 17550, 101, 22654, 23338, 28981, 148, 96, 38843, 22654, 12919, 23338, 28981, 41486, 22654, 17550, 111, 41486, 148, 112, 149, 225, 13862, 220, 13862, 39848, 23338, 45632, 17550, 96, 30335, 13862, 149, 231, 148, 234, 220, 13862, 148, 106, 13862, 149, 224, 47048, 23338, 34247, 101, 26897, 17550, 255, 30335, 12919, 26897, 17550, 107, 34247, 106, 13862, 28981, 25405, 23338, 148, 116, 25405, 34247, 103, 28981, 149, 225, 148, 112, 149, 223, 22654, 45632, 17550, 106, 13862, 23525, 28981, 25405, 148, 97, 41486, 25405, 26897, 34247, 103, 28981, 44690, 23525, 25405, 22654, 45632, 28981, 25405, 149, 224, 39848, 13862]
inputs:
قال وزير تونسي إن الوفد اليهودي الفرنسي، غادر ملتقى "سفراء الحوار بين الأديان"، الذي انطلق بتونس يوم الأحد، "تجنبًا لأي لبس".
وأوضح وزير الشؤون الدينية، أحمد عظوم، في تصريحات إعلاميّة، أن الوفد اليهودي الفرنسي "غير معني" بقرار قضائي تونسي يقضي بمنع منظمة الكشافة التونسية من قبول مشاركين إسرائيليين في هذا الملتقى.
وقال عظوم، في كلمته أمام الملتقى، إنّ الملتقى الكشفي العالمي "سفراء الحوار بين الأديان"، يُساهم في التعايش السلمي ونبذ التطرف والعنف.
وأشار إلى أنّ "وحدة الصف بين الشعوب في هذه اللحظة الفارقة، هي الضامن للتعايش السلمي بعيدًا عن الكراهية والتعصب على أساس الدين".
من جانبه، اعتبر القائد العام للكشافة التونسية، وحيد العبيدي، في كلمته، أن "الملتقى مناسبة لدفع مسار الحوار بين الأديان والثقافات ولتوفير الأمن والسلم".
وأشار إلى أن 24 جنسية موزعين على 6 ديانات، يشاركون في هذا الملتقى العالمي الأول من نوعه، والذّي يتواصل حتى 8 نوفمبر/تشرين الثاني الجاري.
ويختتم الملتقى أعماله بإصدار "وثيقة تونس" لسفراء الحوار بين الأديان التي ستشكل لبنة أولى، لخلق منابر حوار داخل المنظمات الكشفية خلال المؤتمرات العالمية المقبل
03/25/2024 15:55:37 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ar_1b.jsonl.
03/25/2024 15:55:37 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ar_1b.jsonl.
03/25/2024 15:55:38 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ar_1b.jsonl.
03/25/2024 15:55:38 - WARNING - llmtuner.data.utils - Checksum failed: mismatched SHA-1 hash value at data/ar_1b.jsonl.
Dataset({
    features: ['text'],
    num_rows: 369160
})
{'text': 'قال وزير تونسي إن الوفد اليهودي الفرنسي، غادر ملتقى "سفراء الحوار بين الأديان"، الذي انطلق بتونس يوم الأحد، "تجنبًا لأي لبس".\nوأوضح وزير الشؤون الدينية، أحمد عظوم، في تصريحات إعلاميّة، أن الوفد اليهودي الفرنسي "غير معني" بقرار قضائي تونسي يقضي بمنع منظمة الكشافة التونسية من قبول مشاركين إسرائيليين في هذا الملتقى.\nوقال عظوم، في كلمته أمام الملتقى، إنّ الملتقى الكشفي العالمي "سفراء الحوار بين الأديان"، يُساهم في التعايش السلمي ونبذ التطرف والعنف.\nوأشار إلى أنّ "وحدة الصف بين الشعوب في هذه اللحظة الفارقة، هي الضامن للتعايش السلمي بعيدًا عن الكراهية والتعصب على أساس الدين".\nمن جانبه، اعتبر القائد العام للكشافة التونسية، وحيد العبيدي، في كلمته، أن "الملتقى مناسبة لدفع مسار الحوار بين الأديان والثقافات ولتوفير الأمن والسلم".\nوأشار إلى أن 24 جنسية موزعين على 6 ديانات، يشاركون في هذا الملتقى العالمي الأول من نوعه، والذّي يتواصل حتى 8 نوفمبر/تشرين الثاني الجاري.\nويختتم الملتقى أعماله بإصدار "وثيقة تونس" لسفراء الحوار بين الأديان التي ستشكل لبنة أولى، لخلق منابر حوار داخل المنظمات الكشفية خلال المؤتمرات العالمية المقبلة.\nوانطلقت في مدينة الحمامات التونسية، مساء الأحد، أعمال الملتقى الكشفي العالمي "سفراء الحوار بين الأديان"، بمشاركة أكثر 150 شخصًا من 24 دولة.\nويهدف الملتقى، الذي يستمر 4 أيام، للعمل على تبني الحوار في المناهج الكشفية، وترسيخ ثقافة الحوار والتعايش بين الأديان.\nأصيب، اليوم الاثنين، مواطن، بالرصاص الحي عقب اقتحام قوات الاحتلال منزله واعتقال نجله في بلدة حلحول شمال الخليل، جنوب الضفة الغربية.'}
Dataset({
    features: ['text'],
    num_rows: 369160
})
{'text': 'قال وزير تونسي إن الوفد اليهودي الفرنسي، غادر ملتقى "سفراء الحوار بين الأديان"، الذي انطلق بتونس يوم الأحد، "تجنبًا لأي لبس".\nوأوضح وزير الشؤون الدينية، أحمد عظوم، في تصريحات إعلاميّة، أن الوفد اليهودي الفرنسي "غير معني" بقرار قضائي تونسي يقضي بمنع منظمة الكشافة التونسية من قبول مشاركين إسرائيليين في هذا الملتقى.\nوقال عظوم، في كلمته أمام الملتقى، إنّ الملتقى الكشفي العالمي "سفراء الحوار بين الأديان"، يُساهم في التعايش السلمي ونبذ التطرف والعنف.\nوأشار إلى أنّ "وحدة الصف بين الشعوب في هذه اللحظة الفارقة، هي الضامن للتعايش السلمي بعيدًا عن الكراهية والتعصب على أساس الدين".\nمن جانبه، اعتبر القائد العام للكشافة التونسية، وحيد العبيدي، في كلمته، أن "الملتقى مناسبة لدفع مسار الحوار بين الأديان والثقافات ولتوفير الأمن والسلم".\nوأشار إلى أن 24 جنسية موزعين على 6 ديانات، يشاركون في هذا الملتقى العالمي الأول من نوعه، والذّي يتواصل حتى 8 نوفمبر/تشرين الثاني الجاري.\nويختتم الملتقى أعماله بإصدار "وثيقة تونس" لسفراء الحوار بين الأديان التي ستشكل لبنة أولى، لخلق منابر حوار داخل المنظمات الكشفية خلال المؤتمرات العالمية المقبلة.\nوانطلقت في مدينة الحمامات التونسية، مساء الأحد، أعمال الملتقى الكشفي العالمي "سفراء الحوار بين الأديان"، بمشاركة أكثر 150 شخصًا من 24 دولة.\nويهدف الملتقى، الذي يستمر 4 أيام، للعمل على تبني الحوار في المناهج الكشفية، وترسيخ ثقافة الحوار والتعايش بين الأديان.\nأصيب، اليوم الاثنين، مواطن، بالرصاص الحي عقب اقتحام قوات الاحتلال منزله واعتقال نجله في بلدة حلحول شمال الخليل، جنوب الضفة الغربية.'}
Dataset({
    features: ['text'],
    num_rows: 369160
})
{'text': 'قال وزير تونسي إن الوفد اليهودي الفرنسي، غادر ملتقى "سفراء الحوار بين الأديان"، الذي انطلق بتونس يوم الأحد، "تجنبًا لأي لبس".\nوأوضح وزير الشؤون الدينية، أحمد عظوم، في تصريحات إعلاميّة، أن الوفد اليهودي الفرنسي "غير معني" بقرار قضائي تونسي يقضي بمنع منظمة الكشافة التونسية من قبول مشاركين إسرائيليين في هذا الملتقى.\nوقال عظوم، في كلمته أمام الملتقى، إنّ الملتقى الكشفي العالمي "سفراء الحوار بين الأديان"، يُساهم في التعايش السلمي ونبذ التطرف والعنف.\nوأشار إلى أنّ "وحدة الصف بين الشعوب في هذه اللحظة الفارقة، هي الضامن للتعايش السلمي بعيدًا عن الكراهية والتعصب على أساس الدين".\nمن جانبه، اعتبر القائد العام للكشافة التونسية، وحيد العبيدي، في كلمته، أن "الملتقى مناسبة لدفع مسار الحوار بين الأديان والثقافات ولتوفير الأمن والسلم".\nوأشار إلى أن 24 جنسية موزعين على 6 ديانات، يشاركون في هذا الملتقى العالمي الأول من نوعه، والذّي يتواصل حتى 8 نوفمبر/تشرين الثاني الجاري.\nويختتم الملتقى أعماله بإصدار "وثيقة تونس" لسفراء الحوار بين الأديان التي ستشكل لبنة أولى، لخلق منابر حوار داخل المنظمات الكشفية خلال المؤتمرات العالمية المقبلة.\nوانطلقت في مدينة الحمامات التونسية، مساء الأحد، أعمال الملتقى الكشفي العالمي "سفراء الحوار بين الأديان"، بمشاركة أكثر 150 شخصًا من 24 دولة.\nويهدف الملتقى، الذي يستمر 4 أيام، للعمل على تبني الحوار في المناهج الكشفية، وترسيخ ثقافة الحوار والتعايش بين الأديان.\nأصيب، اليوم الاثنين، مواطن، بالرصاص الحي عقب اقتحام قوات الاحتلال منزله واعتقال نجله في بلدة حلحول شمال الخليل، جنوب الضفة الغربية.'}
Dataset({
    features: ['text'],
    num_rows: 369160
})
{'text': 'قال وزير تونسي إن الوفد اليهودي الفرنسي، غادر ملتقى "سفراء الحوار بين الأديان"، الذي انطلق بتونس يوم الأحد، "تجنبًا لأي لبس".\nوأوضح وزير الشؤون الدينية، أحمد عظوم، في تصريحات إعلاميّة، أن الوفد اليهودي الفرنسي "غير معني" بقرار قضائي تونسي يقضي بمنع منظمة الكشافة التونسية من قبول مشاركين إسرائيليين في هذا الملتقى.\nوقال عظوم، في كلمته أمام الملتقى، إنّ الملتقى الكشفي العالمي "سفراء الحوار بين الأديان"، يُساهم في التعايش السلمي ونبذ التطرف والعنف.\nوأشار إلى أنّ "وحدة الصف بين الشعوب في هذه اللحظة الفارقة، هي الضامن للتعايش السلمي بعيدًا عن الكراهية والتعصب على أساس الدين".\nمن جانبه، اعتبر القائد العام للكشافة التونسية، وحيد العبيدي، في كلمته، أن "الملتقى مناسبة لدفع مسار الحوار بين الأديان والثقافات ولتوفير الأمن والسلم".\nوأشار إلى أن 24 جنسية موزعين على 6 ديانات، يشاركون في هذا الملتقى العالمي الأول من نوعه، والذّي يتواصل حتى 8 نوفمبر/تشرين الثاني الجاري.\nويختتم الملتقى أعماله بإصدار "وثيقة تونس" لسفراء الحوار بين الأديان التي ستشكل لبنة أولى، لخلق منابر حوار داخل المنظمات الكشفية خلال المؤتمرات العالمية المقبلة.\nوانطلقت في مدينة الحمامات التونسية، مساء الأحد، أعمال الملتقى الكشفي العالمي "سفراء الحوار بين الأديان"، بمشاركة أكثر 150 شخصًا من 24 دولة.\nويهدف الملتقى، الذي يستمر 4 أيام، للعمل على تبني الحوار في المناهج الكشفية، وترسيخ ثقافة الحوار والتعايش بين الأديان.\nأصيب، اليوم الاثنين، مواطن، بالرصاص الحي عقب اقتحام قوات الاحتلال منزله واعتقال نجله في بلدة حلحول شمال الخليل، جنوب الضفة الغربية.'}
Loading cached shuffled indices for dataset at /home/wangzj/.cache/huggingface/datasets/json/default-59cb3ddd10a01018/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-d59fe843553f11d0.arrow
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1072999
})
PhiForCausalLM(
  (model): PhiModel(
    (embed_tokens): Embedding(51200, 2560)
    (embed_dropout): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (1): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (2): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (3): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (4): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (5): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (6): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (7): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (8): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (9): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (10): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (11): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (12): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (13): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (14): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (15): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (16): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (17): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (18): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (19): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (20): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (21): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (22): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (23): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (24): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (25): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (26): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (27): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (28): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (29): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (30): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (31): PhiDecoderLayer(
        (self_attn): PhiFlashAttention2(
          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)
          (dense): Linear(in_features=2560, out_features=2560, bias=True)
          (rotary_emb): PhiRotaryEmbedding()
        )
        (mlp): PhiMLP(
          (activation_fn): NewGELUActivation()
          (fc1): Linear(in_features=2560, out_features=10240, bias=True)
          (fc2): Linear(in_features=10240, out_features=2560, bias=True)
        )
        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)
  )
  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)
)
[INFO|trainer.py:586] 2024-03-25 15:55:49,293 >> Using auto half precision backend
[2024-03-25 15:55:49,524] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.3, git-hash=unknown, git-branch=unknown
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1072999
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1072999
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1072999
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 1072999
})
[2024-03-25 15:56:04,336] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-03-25 15:56:04,339] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-03-25 15:56:04,339] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-03-25 15:56:04,377] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2024-03-25 15:56:04,377] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2024-03-25 15:56:04,377] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-03-25 15:56:04,377] [INFO] [stage_1_and_2.py:147:__init__] Reduce bucket size 500000000
[2024-03-25 15:56:04,377] [INFO] [stage_1_and_2.py:148:__init__] Allgather bucket size 500000000
[2024-03-25 15:56:04,378] [INFO] [stage_1_and_2.py:149:__init__] CPU Offload: False
[2024-03-25 15:56:04,378] [INFO] [stage_1_and_2.py:150:__init__] Round robin gradient partitioning: False
[2024-03-25 15:56:17,948] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states
[2024-03-25 15:56:17,949] [INFO] [utils.py:803:see_memory_usage] MA 7.26 GB         Max_MA 7.26 GB         CA 7.28 GB         Max_CA 7 GB 
[2024-03-25 15:56:17,949] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 74.01 GB, percent = 29.4%
[2024-03-25 15:56:18,137] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states
[2024-03-25 15:56:18,137] [INFO] [utils.py:803:see_memory_usage] MA 11.4 GB         Max_MA 17.61 GB         CA 17.63 GB         Max_CA 18 GB 
[2024-03-25 15:56:18,138] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 69.78 GB, percent = 27.7%
[2024-03-25 15:56:18,138] [INFO] [stage_1_and_2.py:514:__init__] optimizer state initialized
[2024-03-25 15:56:18,313] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer
[2024-03-25 15:56:18,314] [INFO] [utils.py:803:see_memory_usage] MA 11.4 GB         Max_MA 11.4 GB         CA 17.63 GB         Max_CA 18 GB 
[2024-03-25 15:56:18,314] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 64.05 GB, percent = 25.5%
[2024-03-25 15:56:18,318] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2024-03-25 15:56:18,318] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-03-25 15:56:18,318] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-03-25 15:56:18,318] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05, 5e-05], mom=[(0.9, 0.999), (0.9, 0.999)]
[2024-03-25 15:56:18,319] [INFO] [config.py:974:print] DeepSpeedEngine configuration:
[2024-03-25 15:56:18,319] [INFO] [config.py:978:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-03-25 15:56:18,319] [INFO] [config.py:978:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-03-25 15:56:18,319] [INFO] [config.py:978:print]   amp_enabled .................. False
[2024-03-25 15:56:18,319] [INFO] [config.py:978:print]   amp_params ................... False
[2024-03-25 15:56:18,319] [INFO] [config.py:978:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-03-25 15:56:18,319] [INFO] [config.py:978:print]   bfloat16_enabled ............. True
[2024-03-25 15:56:18,319] [INFO] [config.py:978:print]   checkpoint_parallel_write_pipeline  False
[2024-03-25 15:56:18,319] [INFO] [config.py:978:print]   checkpoint_tag_validation_enabled  True
[2024-03-25 15:56:18,319] [INFO] [config.py:978:print]   checkpoint_tag_validation_fail  False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fdd4687c910>
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   communication_data_type ...... None
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   curriculum_enabled_legacy .... False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   curriculum_params_legacy ..... False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   data_efficiency_enabled ...... False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   dataloader_drop_last ......... False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   disable_allgather ............ False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   dump_state ................... False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   dynamic_loss_scale_args ...... None
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   eigenvalue_enabled ........... False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   eigenvalue_gas_boundary_resolution  1
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   eigenvalue_layer_num ......... 0
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   eigenvalue_max_iter .......... 100
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   eigenvalue_stability ......... 1e-06
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   eigenvalue_tol ............... 0.01
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   eigenvalue_verbose ........... False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   elasticity_enabled ........... False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   fp16_auto_cast ............... None
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   fp16_enabled ................. False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   fp16_master_weights_and_gradients  False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   global_rank .................. 0
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   grad_accum_dtype ............. None
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   gradient_accumulation_steps .. 16
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   gradient_clipping ............ 1.0
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   gradient_predivide_factor .... 1.0
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   initial_dynamic_scale ........ 1
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   load_universal_checkpoint .... False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   loss_scale ................... 1.0
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   memory_breakdown ............. False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   mics_hierarchial_params_gather  False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   mics_shard_size .............. -1
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-03-25 15:56:18,320] [INFO] [config.py:978:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   optimizer_legacy_fusion ...... False
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   optimizer_name ............... None
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   optimizer_params ............. None
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   pld_enabled .................. False
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   pld_params ................... False
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   prescale_gradients ........... False
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   scheduler_name ............... None
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   scheduler_params ............. None
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   seq_parallel_communication_data_type  torch.float32
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   sparse_attention ............. None
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   sparse_gradients_enabled ..... False
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   steps_per_print .............. inf
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   train_batch_size ............. 320
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   train_micro_batch_size_per_gpu  4
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   use_node_local_storage ....... False
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   wall_clock_breakdown ......... False
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   weight_quantization_config ... None
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   world_size ................... 5
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   zero_allow_untested_optimizer  True
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   zero_enabled ................. True
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   zero_force_ds_cpu_optimizer .. True
[2024-03-25 15:56:18,321] [INFO] [config.py:978:print]   zero_optimization_stage ...... 2
[2024-03-25 15:56:18,321] [INFO] [config.py:964:print_user_config]   json = {
    "train_batch_size": 320, 
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 16, 
    "gradient_clipping": 1.0, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": false, 
        "loss_scale": 0, 
        "initial_scale_power": 16, 
        "loss_scale_window": 1000, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 5.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 5.000000e+08, 
        "contiguous_gradients": true
    }, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }
}
[INFO|trainer.py:1747] 2024-03-25 15:56:18,321 >> ***** Running training *****
[INFO|trainer.py:1748] 2024-03-25 15:56:18,321 >>   Num examples = 1,072,999
[INFO|trainer.py:1749] 2024-03-25 15:56:18,321 >>   Num Epochs = 1
[INFO|trainer.py:1750] 2024-03-25 15:56:18,321 >>   Instantaneous batch size per device = 4
[INFO|trainer.py:1753] 2024-03-25 15:56:18,321 >>   Total train batch size (w. parallel, distributed & accumulation) = 320
[INFO|trainer.py:1754] 2024-03-25 15:56:18,321 >>   Gradient Accumulation steps = 16
[INFO|trainer.py:1755] 2024-03-25 15:56:18,321 >>   Total optimization steps = 3,353
[INFO|trainer.py:1756] 2024-03-25 15:56:18,323 >>   Number of trainable parameters = 2,779,683,840
03/25/2024 15:56:18 - WARNING - llmtuner.extras.callbacks - Previous log file in this folder will be deleted.
  0%|          | 0/3353 [00:00<?, ?it/s]  0%|          | 1/3353 [00:34<32:03:32, 34.43s/it]  0%|          | 2/3353 [01:07<31:25:17, 33.76s/it]  0%|          | 3/3353 [01:41<31:15:06, 33.58s/it]  0%|          | 4/3353 [02:14<31:11:39, 33.53s/it]  0%|          | 5/3353 [02:48<31:09:30, 33.50s/it]  0%|          | 6/3353 [03:21<31:07:19, 33.47s/it]  0%|          | 7/3353 [03:55<31:12:59, 33.59s/it]  0%|          | 8/3353 [04:28<31:15:07, 33.63s/it]  0%|          | 9/3353 [05:02<31:10:44, 33.57s/it]  0%|          | 10/3353 [05:35<31:07:42, 33.52s/it]                                                    {'loss': 2.4753, 'learning_rate': 4.9998902664386114e-05, 'epoch': 0.0}
  0%|          | 10/3353 [05:35<31:07:42, 33.52s/it]  0%|          | 11/3353 [06:09<31:06:08, 33.50s/it]  0%|          | 12/3353 [06:42<31:04:20, 33.48s/it]  0%|          | 13/3353 [07:16<31:02:35, 33.46s/it]  0%|          | 14/3353 [07:49<31:01:28, 33.45s/it]  0%|          | 15/3353 [08:22<31:00:32, 33.44s/it]  0%|          | 16/3353 [08:56<31:06:54, 33.57s/it]  1%|          | 17/3353 [09:30<31:04:05, 33.53s/it]  1%|          | 18/3353 [10:03<31:02:07, 33.50s/it]  1%|          | 19/3353 [10:37<31:00:21, 33.48s/it]  1%|          | 20/3353 [11:10<30:58:50, 33.46s/it]                                                    {'loss': 1.9915, 'learning_rate': 4.999561075387608e-05, 'epoch': 0.01}
  1%|          | 20/3353 [11:10<30:58:50, 33.46s/it]  1%|          | 21/3353 [11:44<31:02:04, 33.53s/it]  1%|          | 22/3353 [12:17<30:59:59, 33.50s/it]  1%|          | 23/3353 [12:51<31:02:38, 33.56s/it]  1%|          | 24/3353 [13:25<31:06:23, 33.64s/it]  1%|          | 25/3353 [13:58<31:03:06, 33.59s/it]  1%|          | 26/3353 [14:32<31:00:11, 33.55s/it]  1%|          | 27/3353 [15:05<30:58:04, 33.52s/it]  1%|          | 28/3353 [15:39<30:56:10, 33.49s/it]  1%|          | 29/3353 [16:12<30:54:55, 33.48s/it]  1%|          | 30/3353 [16:45<30:53:45, 33.47s/it]                                                    {'loss': 1.8373, 'learning_rate': 4.9990124557456364e-05, 'epoch': 0.01}
  1%|          | 30/3353 [16:45<30:53:45, 33.47s/it]  1%|          | 31/3353 [17:19<30:54:36, 33.50s/it]  1%|          | 32/3353 [17:53<30:54:41, 33.51s/it]  1%|          | 33/3353 [18:26<30:53:05, 33.49s/it]  1%|          | 34/3353 [18:59<30:51:45, 33.48s/it]  1%|          | 35/3353 [19:33<30:51:03, 33.47s/it]  1%|          | 36/3353 [20:06<30:50:11, 33.47s/it]  1%|          | 37/3353 [20:40<30:49:48, 33.47s/it]  1%|          | 38/3353 [21:13<30:49:09, 33.47s/it]  1%|          | 39/3353 [21:47<30:51:15, 33.52s/it]  1%|          | 40/3353 [22:21<30:54:01, 33.58s/it]                                                    {'loss': 1.7628, 'learning_rate': 4.998244455674285e-05, 'epoch': 0.01}
  1%|          | 40/3353 [22:21<30:54:01, 33.58s/it]  1%|          | 41/3353 [22:54<30:53:37, 33.58s/it]  1%|▏         | 42/3353 [23:28<30:51:12, 33.55s/it]  1%|▏         | 43/3353 [24:01<30:49:26, 33.52s/it]  1%|▏         | 44/3353 [24:35<30:48:17, 33.51s/it]  1%|▏         | 45/3353 [25:08<30:47:23, 33.51s/it]  1%|▏         | 46/3353 [25:42<30:45:57, 33.49s/it]  1%|▏         | 47/3353 [26:15<30:48:21, 33.55s/it]  1%|▏         | 48/3353 [26:49<30:50:04, 33.59s/it]  1%|▏         | 49/3353 [27:23<30:52:40, 33.64s/it]  1%|▏         | 50/3353 [27:56<30:51:43, 33.64s/it]                                                    {'loss': 1.7289, 'learning_rate': 4.99725714259386e-05, 'epoch': 0.01}
  1%|▏         | 50/3353 [27:56<30:51:43, 33.64s/it]  2%|▏         | 51/3353 [28:30<30:49:29, 33.61s/it]  2%|▏         | 52/3353 [29:03<30:47:56, 33.59s/it]  2%|▏         | 53/3353 [29:37<30:48:14, 33.60s/it]  2%|▏         | 54/3353 [30:11<30:49:23, 33.64s/it]  2%|▏         | 55/3353 [30:45<30:51:02, 33.68s/it]  2%|▏         | 56/3353 [31:18<30:49:06, 33.65s/it]  2%|▏         | 57/3353 [31:52<30:50:28, 33.69s/it]  2%|▏         | 58/3353 [32:26<30:49:05, 33.67s/it]  2%|▏         | 59/3353 [32:59<30:45:18, 33.61s/it]  2%|▏         | 60/3353 [33:33<30:43:36, 33.59s/it]                                                    {'loss': 1.7156, 'learning_rate': 4.9960506031774666e-05, 'epoch': 0.02}
  2%|▏         | 60/3353 [33:33<30:43:36, 33.59s/it]  2%|▏         | 61/3353 [34:06<30:44:06, 33.61s/it]  2%|▏         | 62/3353 [34:40<30:42:44, 33.60s/it]  2%|▏         | 63/3353 [35:13<30:42:28, 33.60s/it]  2%|▏         | 64/3353 [35:47<30:41:45, 33.60s/it]  2%|▏         | 65/3353 [36:21<30:45:49, 33.68s/it]  2%|▏         | 66/3353 [36:54<30:42:23, 33.63s/it]  2%|▏         | 67/3353 [37:28<30:39:06, 33.58s/it]  2%|▏         | 68/3353 [38:01<30:37:19, 33.56s/it]  2%|▏         | 69/3353 [38:35<30:35:30, 33.54s/it]  2%|▏         | 70/3353 [39:08<30:34:26, 33.53s/it]                                                    {'loss': 1.7049, 'learning_rate': 4.994624943343399e-05, 'epoch': 0.02}
  2%|▏         | 70/3353 [39:08<30:34:26, 33.53s/it]  2%|▏         | 71/3353 [39:42<30:36:26, 33.57s/it]  2%|▏         | 72/3353 [40:15<30:34:45, 33.55s/it]  2%|▏         | 73/3353 [40:49<30:35:57, 33.58s/it]  2%|▏         | 74/3353 [41:23<30:33:25, 33.55s/it]  2%|▏         | 75/3353 [41:56<30:32:27, 33.54s/it]  2%|▏         | 76/3353 [42:30<30:32:29, 33.55s/it]  2%|▏         | 77/3353 [43:03<30:30:40, 33.53s/it]  2%|▏         | 78/3353 [43:37<30:29:26, 33.52s/it]  2%|▏         | 79/3353 [44:10<30:28:23, 33.51s/it]  2%|▏         | 80/3353 [44:44<30:31:35, 33.58s/it]                                                    {'loss': 1.681, 'learning_rate': 4.992980288245841e-05, 'epoch': 0.02}
  2%|▏         | 80/3353 [44:44<30:31:35, 33.58s/it]  2%|▏         | 81/3353 [45:18<30:37:46, 33.70s/it]  2%|▏         | 82/3353 [45:51<30:34:54, 33.66s/it]  2%|▏         | 83/3353 [46:25<30:31:37, 33.61s/it]  3%|▎         | 84/3353 [46:58<30:29:31, 33.58s/it]  3%|▎         | 85/3353 [47:32<30:28:44, 33.58s/it]  3%|▎         | 86/3353 [48:06<30:28:15, 33.58s/it]  3%|▎         | 87/3353 [48:39<30:27:36, 33.58s/it]  3%|▎         | 88/3353 [49:13<30:26:00, 33.56s/it]  3%|▎         | 89/3353 [49:46<30:28:39, 33.62s/it]  3%|▎         | 90/3353 [50:20<30:28:33, 33.62s/it]                                                    {'loss': 1.6593, 'learning_rate': 4.991116782263882e-05, 'epoch': 0.03}
  3%|▎         | 90/3353 [50:20<30:28:33, 33.62s/it]  3%|▎         | 91/3353 [50:54<30:29:37, 33.65s/it]  3%|▎         | 92/3353 [51:27<30:26:52, 33.61s/it]  3%|▎         | 93/3353 [52:01<30:24:23, 33.58s/it]  3%|▎         | 94/3353 [52:34<30:23:09, 33.57s/it]  3%|▎         | 95/3353 [53:08<30:22:50, 33.57s/it]  3%|▎         | 96/3353 [53:42<30:24:31, 33.61s/it]  3%|▎         | 97/3353 [54:15<30:23:41, 33.61s/it]  3%|▎         | 98/3353 [54:49<30:21:33, 33.58s/it]  3%|▎         | 99/3353 [55:22<30:21:11, 33.58s/it]  3%|▎         | 100/3353 [55:56<30:21:09, 33.59s/it]                                                     {'loss': 1.6404, 'learning_rate': 4.98903458898884e-05, 'epoch': 0.03}
  3%|▎         | 100/3353 [55:56<30:21:09, 33.59s/it]  3%|▎         | 101/3353 [56:30<30:21:40, 33.61s/it]  3%|▎         | 102/3353 [57:03<30:19:07, 33.57s/it]  3%|▎         | 103/3353 [57:37<30:17:10, 33.55s/it]  3%|▎         | 104/3353 [58:10<30:18:54, 33.59s/it]  3%|▎         | 105/3353 [58:44<30:19:36, 33.61s/it]  3%|▎         | 106/3353 [59:18<30:20:41, 33.64s/it]  3%|▎         | 107/3353 [59:51<30:17:57, 33.60s/it]  3%|▎         | 108/3353 [1:00:25<30:15:44, 33.57s/it]  3%|▎         | 109/3353 [1:00:58<30:13:45, 33.55s/it]  3%|▎         | 110/3353 [1:01:32<30:11:38, 33.52s/it]                                                       {'loss': 1.6432, 'learning_rate': 4.9867338912099016e-05, 'epoch': 0.03}
  3%|▎         | 110/3353 [1:01:32<30:11:38, 33.52s/it]  3%|▎         | 111/3353 [1:02:05<30:10:37, 33.51s/it]  3%|▎         | 112/3353 [1:02:39<30:12:34, 33.56s/it]  3%|▎         | 113/3353 [1:03:12<30:13:49, 33.59s/it]  3%|▎         | 114/3353 [1:03:46<30:11:36, 33.56s/it]  3%|▎         | 115/3353 [1:04:19<30:09:52, 33.54s/it]  3%|▎         | 116/3353 [1:04:53<30:08:29, 33.52s/it]  3%|▎         | 117/3353 [1:05:26<30:08:03, 33.52s/it]  4%|▎         | 118/3353 [1:06:00<30:07:30, 33.52s/it]  4%|▎         | 119/3353 [1:06:33<30:06:06, 33.51s/it]  4%|▎         | 120/3353 [1:07:07<30:05:38, 33.51s/it]                                                       {'loss': 1.6483, 'learning_rate': 4.984214890898077e-05, 'epoch': 0.04}
  4%|▎         | 120/3353 [1:07:07<30:05:38, 33.51s/it]  4%|▎         | 121/3353 [1:07:40<30:05:31, 33.52s/it]  4%|▎         | 122/3353 [1:08:14<30:08:25, 33.58s/it]  4%|▎         | 123/3353 [1:08:48<30:06:19, 33.55s/it]  4%|▎         | 124/3353 [1:09:21<30:04:41, 33.53s/it]  4%|▎         | 125/3353 [1:09:55<30:03:06, 33.51s/it]  4%|▍         | 126/3353 [1:10:28<30:01:40, 33.50s/it]  4%|▍         | 127/3353 [1:11:02<30:00:31, 33.49s/it]  4%|▍         | 128/3353 [1:11:35<30:01:34, 33.52s/it]  4%|▍         | 129/3353 [1:12:09<30:00:48, 33.51s/it]  4%|▍         | 130/3353 [1:12:43<30:05:47, 33.62s/it]                                                       {'loss': 1.6208, 'learning_rate': 4.981477809188465e-05, 'epoch': 0.04}
  4%|▍         | 130/3353 [1:12:43<30:05:47, 33.62s/it]  4%|▍         | 131/3353 [1:13:16<30:03:54, 33.59s/it]  4%|▍         | 132/3353 [1:13:50<30:01:31, 33.56s/it]  4%|▍         | 133/3353 [1:14:23<30:00:17, 33.55s/it]  4%|▍         | 134/3353 [1:14:57<29:58:47, 33.53s/it]  4%|▍         | 135/3353 [1:15:30<29:57:52, 33.52s/it]  4%|▍         | 136/3353 [1:16:04<29:56:37, 33.51s/it]  4%|▍         | 137/3353 [1:16:37<29:58:56, 33.56s/it]  4%|▍         | 138/3353 [1:17:11<29:59:57, 33.59s/it]  4%|▍         | 139/3353 [1:17:44<29:57:40, 33.56s/it]  4%|▍         | 140/3353 [1:18:18<29:55:43, 33.53s/it]                                                       {'loss': 1.5913, 'learning_rate': 4.978522886360845e-05, 'epoch': 0.04}
  4%|▍         | 140/3353 [1:18:18<29:55:43, 33.53s/it]  4%|▍         | 141/3353 [1:18:51<29:55:20, 33.54s/it]  4%|▍         | 142/3353 [1:19:25<29:53:29, 33.51s/it]  4%|▍         | 143/3353 [1:19:58<29:51:58, 33.50s/it]  4%|▍         | 144/3353 [1:20:32<29:50:58, 33.49s/it]  4%|▍         | 145/3353 [1:21:05<29:50:34, 33.49s/it]  4%|▍         | 146/3353 [1:21:39<29:52:09, 33.53s/it]  4%|▍         | 147/3353 [1:22:12<29:50:04, 33.50s/it]  4%|▍         | 148/3353 [1:22:46<29:48:37, 33.48s/it]  4%|▍         | 149/3353 [1:23:19<29:47:13, 33.47s/it]  4%|▍         | 150/3353 [1:23:53<29:46:01, 33.46s/it]                                                       {'loss': 1.5729, 'learning_rate': 4.975350381818582e-05, 'epoch': 0.04}
  4%|▍         | 150/3353 [1:23:53<29:46:01, 33.46s/it]  5%|▍         | 151/3353 [1:24:26<29:46:13, 33.47s/it]  5%|▍         | 152/3353 [1:25:00<29:45:25, 33.47s/it]  5%|▍         | 153/3353 [1:25:33<29:47:27, 33.51s/it]  5%|▍         | 154/3353 [1:26:07<29:50:19, 33.58s/it]  5%|▍         | 155/3353 [1:26:40<29:48:14, 33.55s/it]  5%|▍         | 156/3353 [1:27:14<29:46:32, 33.53s/it]  5%|▍         | 157/3353 [1:27:47<29:45:03, 33.51s/it]  5%|▍         | 158/3353 [1:28:21<29:44:02, 33.50s/it]  5%|▍         | 159/3353 [1:28:54<29:43:20, 33.50s/it]  5%|▍         | 160/3353 [1:29:28<29:41:57, 33.49s/it]                                                       {'loss': 1.55, 'learning_rate': 4.971960574065853e-05, 'epoch': 0.05}
  5%|▍         | 160/3353 [1:29:28<29:41:57, 33.49s/it]  5%|▍         | 161/3353 [1:30:02<29:45:29, 33.56s/it]  5%|▍         | 162/3353 [1:30:35<29:43:07, 33.53s/it]  5%|▍         | 163/3353 [1:31:09<29:44:16, 33.56s/it]  5%|▍         | 164/3353 [1:31:42<29:42:10, 33.53s/it]  5%|▍         | 165/3353 [1:32:15<29:39:56, 33.50s/it]  5%|▍         | 166/3353 [1:32:49<29:38:50, 33.49s/it]  5%|▍         | 167/3353 [1:33:22<29:37:59, 33.48s/it]  5%|▌         | 168/3353 [1:33:56<29:37:28, 33.48s/it]  5%|▌         | 169/3353 [1:34:30<29:40:18, 33.55s/it]  5%|▌         | 170/3353 [1:35:03<29:41:28, 33.58s/it]                                                       {'loss': 1.5381, 'learning_rate': 4.9683537606831995e-05, 'epoch': 0.05}
  5%|▌         | 170/3353 [1:35:03<29:41:28, 33.58s/it]  5%|▌         | 171/3353 [1:35:37<29:40:04, 33.57s/it]  5%|▌         | 172/3353 [1:36:10<29:38:24, 33.54s/it]  5%|▌         | 173/3353 [1:36:44<29:36:35, 33.52s/it]  5%|▌         | 174/3353 [1:37:17<29:35:32, 33.51s/it]  5%|▌         | 175/3353 [1:37:51<29:34:19, 33.50s/it]  5%|▌         | 176/3353 [1:38:24<29:32:38, 33.48s/it]  5%|▌         | 177/3353 [1:38:58<29:31:39, 33.47s/it]  5%|▌         | 178/3353 [1:39:31<29:33:35, 33.52s/it]  5%|▌         | 179/3353 [1:40:05<29:34:35, 33.55s/it]  5%|▌         | 180/3353 [1:40:38<29:32:08, 33.51s/it]                                                       {'loss': 1.5224, 'learning_rate': 4.964530258301404e-05, 'epoch': 0.05}
  5%|▌         | 180/3353 [1:40:38<29:32:08, 33.51s/it]  5%|▌         | 181/3353 [1:41:12<29:31:36, 33.51s/it]  5%|▌         | 182/3353 [1:41:45<29:29:54, 33.49s/it]  5%|▌         | 183/3353 [1:42:19<29:28:30, 33.47s/it]  5%|▌         | 184/3353 [1:42:52<29:27:56, 33.47s/it]  6%|▌         | 185/3353 [1:43:26<29:28:45, 33.50s/it]  6%|▌         | 186/3353 [1:43:59<29:27:45, 33.49s/it]  6%|▌         | 187/3353 [1:44:33<29:31:16, 33.57s/it]  6%|▌         | 188/3353 [1:45:06<29:28:43, 33.53s/it]  6%|▌         | 189/3353 [1:45:40<29:26:31, 33.50s/it]  6%|▌         | 190/3353 [1:46:13<29:24:51, 33.48s/it]                                                       {'loss': 1.5102, 'learning_rate': 4.960490402573694e-05, 'epoch': 0.06}
  6%|▌         | 190/3353 [1:46:13<29:24:51, 33.48s/it]  6%|▌         | 191/3353 [1:46:47<29:25:11, 33.50s/it]  6%|▌         | 192/3353 [1:47:20<29:23:50, 33.48s/it]  6%|▌         | 193/3353 [1:47:54<29:22:42, 33.47s/it]  6%|▌         | 194/3353 [1:48:27<29:25:04, 33.52s/it]  6%|▌         | 195/3353 [1:49:01<29:29:01, 33.61s/it]  6%|▌         | 196/3353 [1:49:35<29:25:53, 33.56s/it]  6%|▌         | 197/3353 [1:50:08<29:23:15, 33.52s/it]  6%|▌         | 198/3353 [1:50:41<29:21:09, 33.49s/it]  6%|▌         | 199/3353 [1:51:15<29:19:31, 33.47s/it]  6%|▌         | 200/3353 [1:51:48<29:18:24, 33.46s/it]                                                       {'loss': 1.5187, 'learning_rate': 4.956234548146274e-05, 'epoch': 0.06}
  6%|▌         | 200/3353 [1:51:48<29:18:24, 33.46s/it]  6%|▌         | 201/3353 [1:52:22<29:18:02, 33.47s/it]  6%|▌         | 202/3353 [1:52:55<29:17:44, 33.47s/it]  6%|▌         | 203/3353 [1:53:29<29:17:08, 33.47s/it]  6%|▌         | 204/3353 [1:54:02<29:16:14, 33.46s/it]  6%|▌         | 205/3353 [1:54:36<29:15:20, 33.46s/it]  6%|▌         | 206/3353 [1:55:09<29:15:01, 33.46s/it]  6%|▌         | 207/3353 [1:55:42<29:13:57, 33.45s/it]  6%|▌         | 208/3353 [1:56:16<29:13:23, 33.45s/it]  6%|▌         | 209/3353 [1:56:49<29:12:40, 33.45s/it]  6%|▋         | 210/3353 [1:57:23<29:14:35, 33.50s/it]                                                       {'loss': 1.5129, 'learning_rate': 4.951763068627193e-05, 'epoch': 0.06}
  6%|▋         | 210/3353 [1:57:23<29:14:35, 33.50s/it]  6%|▋         | 211/3353 [1:57:57<29:17:05, 33.55s/it]  6%|▋         | 212/3353 [1:58:30<29:14:17, 33.51s/it]  6%|▋         | 213/3353 [1:59:03<29:12:37, 33.49s/it]  6%|▋         | 214/3353 [1:59:37<29:11:06, 33.47s/it]  6%|▋         | 215/3353 [2:00:10<29:10:13, 33.46s/it]  6%|▋         | 216/3353 [2:00:44<29:09:33, 33.46s/it]  6%|▋         | 217/3353 [2:01:17<29:08:41, 33.46s/it]  7%|▋         | 218/3353 [2:01:51<29:11:28, 33.52s/it]  7%|▋         | 219/3353 [2:02:25<29:12:47, 33.56s/it]  7%|▋         | 220/3353 [2:02:58<29:13:52, 33.59s/it]                                                       {'loss': 1.4995, 'learning_rate': 4.947076356553551e-05, 'epoch': 0.07}
  7%|▋         | 220/3353 [2:02:58<29:13:52, 33.59s/it]  7%|▋         | 221/3353 [2:03:32<29:12:55, 33.58s/it]  7%|▋         | 222/3353 [2:04:05<29:10:18, 33.54s/it]  7%|▋         | 223/3353 [2:04:39<29:08:49, 33.52s/it]  7%|▋         | 224/3353 [2:05:12<29:07:58, 33.52s/it]  7%|▋         | 225/3353 [2:05:46<29:07:00, 33.51s/it]  7%|▋         | 226/3353 [2:06:19<29:08:54, 33.56s/it]  7%|▋         | 227/3353 [2:06:53<29:06:30, 33.52s/it]  7%|▋         | 228/3353 [2:07:26<29:05:20, 33.51s/it]  7%|▋         | 229/3353 [2:08:00<29:03:56, 33.49s/it]  7%|▋         | 230/3353 [2:08:33<29:03:00, 33.49s/it]                                                       {'loss': 1.4976, 'learning_rate': 4.942174823357033e-05, 'epoch': 0.07}
  7%|▋         | 230/3353 [2:08:33<29:03:00, 33.49s/it]  7%|▋         | 231/3353 [2:09:07<29:02:14, 33.48s/it]  7%|▋         | 232/3353 [2:09:40<29:01:29, 33.48s/it]  7%|▋         | 233/3353 [2:10:14<29:00:12, 33.47s/it]  7%|▋         | 234/3353 [2:10:47<28:59:38, 33.47s/it]  7%|▋         | 235/3353 [2:11:21<29:01:22, 33.51s/it]  7%|▋         | 236/3353 [2:11:54<29:02:04, 33.53s/it]  7%|▋         | 237/3353 [2:12:28<28:59:57, 33.50s/it]  7%|▋         | 238/3353 [2:13:01<28:58:22, 33.48s/it]  7%|▋         | 239/3353 [2:13:35<28:57:47, 33.48s/it]  7%|▋         | 240/3353 [2:14:08<28:57:06, 33.48s/it]                                                       {'loss': 1.4789, 'learning_rate': 4.937058899327794e-05, 'epoch': 0.07}
  7%|▋         | 240/3353 [2:14:08<28:57:06, 33.48s/it]  7%|▋         | 241/3353 [2:14:42<28:57:02, 33.49s/it]  7%|▋         | 242/3353 [2:15:15<28:57:15, 33.51s/it]  7%|▋         | 243/3353 [2:15:49<28:58:31, 33.54s/it]  7%|▋         | 244/3353 [2:16:22<28:59:37, 33.57s/it]  7%|▋         | 245/3353 [2:16:56<28:56:44, 33.53s/it]  7%|▋         | 246/3353 [2:17:29<28:54:55, 33.50s/it]  7%|▋         | 247/3353 [2:18:03<28:53:49, 33.49s/it]  7%|▋         | 248/3353 [2:18:36<28:52:37, 33.48s/it]  7%|▋         | 249/3353 [2:19:10<28:51:13, 33.46s/it]  7%|▋         | 250/3353 [2:19:43<28:50:28, 33.46s/it]                                                       {'loss': 1.4694, 'learning_rate': 4.9317290335766844e-05, 'epoch': 0.07}
  7%|▋         | 250/3353 [2:19:43<28:50:28, 33.46s/it]  7%|▋         | 251/3353 [2:20:17<28:53:57, 33.54s/it]  8%|▊         | 252/3353 [2:20:51<28:56:02, 33.59s/it]  8%|▊         | 253/3353 [2:21:24<28:52:55, 33.54s/it]  8%|▊         | 254/3353 [2:21:57<28:50:58, 33.51s/it]  8%|▊         | 255/3353 [2:22:31<28:49:29, 33.50s/it]  8%|▊         | 256/3353 [2:23:04<28:48:08, 33.48s/it]  8%|▊         | 257/3353 [2:23:38<28:47:02, 33.47s/it]  8%|▊         | 258/3353 [2:24:11<28:46:14, 33.46s/it]  8%|▊         | 259/3353 [2:24:45<28:45:32, 33.46s/it]  8%|▊         | 260/3353 [2:25:18<28:47:21, 33.51s/it]                                                       {'loss': 1.4774, 'learning_rate': 4.926185693995826e-05, 'epoch': 0.08}
  8%|▊         | 260/3353 [2:25:18<28:47:21, 33.51s/it]  8%|▊         | 261/3353 [2:25:52<28:46:15, 33.50s/it]  8%|▊         | 262/3353 [2:26:25<28:45:00, 33.48s/it]  8%|▊         | 263/3353 [2:26:59<28:43:38, 33.47s/it]  8%|▊         | 264/3353 [2:27:32<28:42:39, 33.46s/it]  8%|▊         | 265/3353 [2:28:06<28:41:31, 33.45s/it]  8%|▊         | 266/3353 [2:28:39<28:40:46, 33.45s/it]  8%|▊         | 267/3353 [2:29:13<28:43:13, 33.50s/it]  8%|▊         | 268/3353 [2:29:46<28:43:14, 33.52s/it]  8%|▊         | 269/3353 [2:30:20<28:41:46, 33.50s/it]  8%|▊         | 270/3353 [2:30:53<28:40:22, 33.48s/it]                                                       {'loss': 1.4926, 'learning_rate': 4.9204293672175315e-05, 'epoch': 0.08}
  8%|▊         | 270/3353 [2:30:53<28:40:22, 33.48s/it]  8%|▊         | 271/3353 [2:31:27<28:39:58, 33.48s/it]  8%|▊         | 272/3353 [2:32:00<28:38:57, 33.48s/it]  8%|▊         | 273/3353 [2:32:33<28:37:45, 33.46s/it]  8%|▊         | 274/3353 [2:33:07<28:36:55, 33.46s/it]  8%|▊         | 275/3353 [2:33:41<28:39:11, 33.51s/it]  8%|▊         | 276/3353 [2:34:14<28:39:34, 33.53s/it]  8%|▊         | 277/3353 [2:34:48<28:40:53, 33.57s/it]  8%|▊         | 278/3353 [2:35:21<28:38:25, 33.53s/it]  8%|▊         | 279/3353 [2:35:55<28:36:38, 33.51s/it]  8%|▊         | 280/3353 [2:36:28<28:35:07, 33.49s/it]                                                       {'loss': 1.4769, 'learning_rate': 4.914460558571595e-05, 'epoch': 0.08}
  8%|▊         | 280/3353 [2:36:28<28:35:07, 33.49s/it]  8%|▊         | 281/3353 [2:37:02<28:34:58, 33.50s/it]  8%|▊         | 282/3353 [2:37:35<28:33:43, 33.48s/it]  8%|▊         | 283/3353 [2:38:09<28:35:56, 33.54s/it]  8%|▊         | 284/3353 [2:38:42<28:37:00, 33.57s/it]  8%|▊         | 285/3353 [2:39:16<28:35:12, 33.54s/it]  9%|▊         | 286/3353 [2:39:49<28:32:42, 33.51s/it]  9%|▊         | 287/3353 [2:40:23<28:31:26, 33.49s/it]  9%|▊         | 288/3353 [2:40:56<28:30:39, 33.49s/it]  9%|▊         | 289/3353 [2:41:30<28:30:05, 33.49s/it]  9%|▊         | 290/3353 [2:42:03<28:29:35, 33.49s/it]                                                       {'loss': 1.4596, 'learning_rate': 4.908279792040917e-05, 'epoch': 0.09}
  9%|▊         | 290/3353 [2:42:03<28:29:35, 33.49s/it]  9%|▊         | 291/3353 [2:42:37<28:31:39, 33.54s/it]  9%|▊         | 292/3353 [2:43:10<28:29:52, 33.52s/it]  9%|▊         | 293/3353 [2:43:44<28:30:49, 33.55s/it]  9%|▉         | 294/3353 [2:44:17<28:29:01, 33.52s/it]  9%|▉         | 295/3353 [2:44:51<28:27:37, 33.50s/it]  9%|▉         | 296/3353 [2:45:24<28:26:28, 33.49s/it]  9%|▉         | 297/3353 [2:45:58<28:25:14, 33.48s/it]  9%|▉         | 298/3353 [2:46:31<28:24:19, 33.47s/it]  9%|▉         | 299/3353 [2:47:05<28:25:00, 33.50s/it]  9%|▉         | 300/3353 [2:47:38<28:26:30, 33.54s/it]                                                       {'loss': 1.4465, 'learning_rate': 4.901887610215518e-05, 'epoch': 0.09}
  9%|▉         | 300/3353 [2:47:38<28:26:30, 33.54s/it]  9%|▉         | 301/3353 [2:48:12<28:29:01, 33.60s/it]  9%|▉         | 302/3353 [2:48:46<28:26:45, 33.56s/it]  9%|▉         | 303/3353 [2:49:19<28:24:55, 33.54s/it]  9%|▉         | 304/3353 [2:49:53<28:23:27, 33.52s/it]  9%|▉         | 305/3353 [2:50:26<28:22:31, 33.51s/it]  9%|▉         | 306/3353 [2:51:00<28:20:59, 33.49s/it]  9%|▉         | 307/3353 [2:51:33<28:19:57, 33.49s/it]  9%|▉         | 308/3353 [2:52:07<28:24:47, 33.59s/it]  9%|▉         | 309/3353 [2:52:40<28:25:07, 33.61s/it]  9%|▉         | 310/3353 [2:53:14<28:22:10, 33.56s/it]                                                       {'loss': 1.4401, 'learning_rate': 4.8952845742448996e-05, 'epoch': 0.09}
  9%|▉         | 310/3353 [2:53:14<28:22:10, 33.56s/it]  9%|▉         | 311/3353 [2:53:47<28:20:29, 33.54s/it]  9%|▉         | 312/3353 [2:54:21<28:18:31, 33.51s/it]  9%|▉         | 313/3353 [2:54:54<28:17:13, 33.50s/it]  9%|▉         | 314/3353 [2:55:28<28:15:47, 33.48s/it]  9%|▉         | 315/3353 [2:56:01<28:14:59, 33.48s/it]  9%|▉         | 316/3353 [2:56:35<28:14:57, 33.49s/it]  9%|▉         | 317/3353 [2:57:08<28:16:03, 33.52s/it]  9%|▉         | 318/3353 [2:57:42<28:14:40, 33.50s/it] 10%|▉         | 319/3353 [2:58:15<28:13:12, 33.48s/it] 10%|▉         | 320/3353 [2:58:49<28:12:14, 33.48s/it]                                                       {'loss': 1.4324, 'learning_rate': 4.888471263788784e-05, 'epoch': 0.1}
 10%|▉         | 320/3353 [2:58:49<28:12:14, 33.48s/it] 10%|▉         | 321/3353 [2:59:22<28:12:02, 33.48s/it] 10%|▉         | 322/3353 [2:59:56<28:11:08, 33.48s/it] 10%|▉         | 323/3353 [3:00:29<28:10:03, 33.47s/it] 10%|▉         | 324/3353 [3:01:03<28:12:42, 33.53s/it] 10%|▉         | 325/3353 [3:01:37<28:15:01, 33.59s/it] 10%|▉         | 326/3353 [3:02:10<28:12:01, 33.54s/it] 10%|▉         | 327/3353 [3:02:43<28:10:26, 33.52s/it] 10%|▉         | 328/3353 [3:03:17<28:09:33, 33.51s/it] 10%|▉         | 329/3353 [3:03:50<28:07:43, 33.49s/it] 10%|▉         | 330/3353 [3:04:24<28:06:25, 33.47s/it]                                                       {'loss': 1.4205, 'learning_rate': 4.881448276966227e-05, 'epoch': 0.1}
 10%|▉         | 330/3353 [3:04:24<28:06:25, 33.47s/it] 10%|▉         | 331/3353 [3:04:57<28:06:43, 33.49s/it] 10%|▉         | 332/3353 [3:05:31<28:08:43, 33.54s/it] 10%|▉         | 333/3353 [3:06:04<28:07:37, 33.53s/it] 10%|▉         | 334/3353 [3:06:38<28:08:45, 33.56s/it] 10%|▉         | 335/3353 [3:07:12<28:06:09, 33.52s/it] 10%|█         | 336/3353 [3:07:45<28:04:08, 33.49s/it] 10%|█         | 337/3353 [3:08:18<28:03:17, 33.49s/it] 10%|█         | 338/3353 [3:08:52<28:01:59, 33.47s/it] 10%|█         | 339/3353 [3:09:25<28:00:58, 33.46s/it] 10%|█         | 340/3353 [3:09:59<28:03:12, 33.52s/it]                                                       {'loss': 1.4161, 'learning_rate': 4.8742162303031145e-05, 'epoch': 0.1}
 10%|█         | 340/3353 [3:09:59<28:03:12, 33.52s/it] 10%|█         | 341/3353 [3:10:33<28:04:29, 33.56s/it] 10%|█         | 342/3353 [3:11:06<28:02:02, 33.52s/it] 10%|█         | 343/3353 [3:11:39<28:00:06, 33.49s/it] 10%|█         | 344/3353 [3:12:13<27:59:10, 33.48s/it] 10%|█         | 345/3353 [3:12:46<27:57:42, 33.46s/it] 10%|█         | 346/3353 [3:13:20<27:56:36, 33.45s/it] 10%|█         | 347/3353 [3:13:53<27:55:31, 33.44s/it] 10%|█         | 348/3353 [3:14:27<27:55:24, 33.45s/it] 10%|█         | 349/3353 [3:15:00<27:57:47, 33.51s/it] 10%|█         | 350/3353 [3:15:34<27:58:23, 33.53s/it]                                                       {'loss': 1.4034, 'learning_rate': 4.866775758678035e-05, 'epoch': 0.1}
 10%|█         | 350/3353 [3:15:34<27:58:23, 33.53s/it] 10%|█         | 351/3353 [3:16:07<27:57:32, 33.53s/it] 10%|█         | 352/3353 [3:16:41<27:55:40, 33.50s/it] 11%|█         | 353/3353 [3:17:14<27:54:25, 33.49s/it] 11%|█         | 354/3353 [3:17:48<27:52:56, 33.47s/it] 11%|█         | 355/3353 [3:18:21<27:51:56, 33.46s/it] 11%|█         | 356/3353 [3:18:55<27:52:40, 33.49s/it] 11%|█         | 357/3353 [3:19:28<27:51:20, 33.47s/it] 11%|█         | 358/3353 [3:20:02<27:53:15, 33.52s/it] 11%|█         | 359/3353 [3:20:35<27:51:17, 33.49s/it] 11%|█         | 360/3353 [3:21:09<27:49:31, 33.47s/it]                                                       {'loss': 1.4011, 'learning_rate': 4.8591275152665486e-05, 'epoch': 0.11}
 11%|█         | 360/3353 [3:21:09<27:49:31, 33.47s/it] 11%|█         | 361/3353 [3:21:42<27:49:04, 33.47s/it] 11%|█         | 362/3353 [3:22:16<27:47:42, 33.45s/it] 11%|█         | 363/3353 [3:22:49<27:46:54, 33.45s/it] 11%|█         | 364/3353 [3:23:22<27:46:35, 33.45s/it] 11%|█         | 365/3353 [3:23:56<27:51:03, 33.56s/it] 11%|█         | 366/3353 [3:24:30<27:51:31, 33.58s/it] 11%|█         | 367/3353 [3:25:03<27:48:53, 33.53s/it] 11%|█         | 368/3353 [3:25:37<27:46:50, 33.50s/it] 11%|█         | 369/3353 [3:26:10<27:45:36, 33.49s/it] 11%|█         | 370/3353 [3:26:44<27:44:06, 33.47s/it]                                                       {'loss': 1.3984, 'learning_rate': 4.851272171483846e-05, 'epoch': 0.11}
 11%|█         | 370/3353 [3:26:45<27:44:06, 33.47s/it] 11%|█         | 371/3353 [3:27:18<28:00:30, 33.81s/it] 11%|█         | 372/3353 [3:27:52<27:54:34, 33.70s/it] 11%|█         | 373/3353 [3:28:25<27:53:37, 33.70s/it] 11%|█         | 374/3353 [3:28:59<27:49:47, 33.63s/it] 11%|█         | 375/3353 [3:29:32<27:47:02, 33.59s/it] 11%|█         | 376/3353 [3:30:06<27:44:57, 33.56s/it] 11%|█         | 377/3353 [3:30:39<27:43:06, 33.53s/it] 11%|█▏        | 378/3353 [3:31:13<27:42:18, 33.53s/it] 11%|█▏        | 379/3353 [3:31:46<27:40:34, 33.50s/it] 11%|█▏        | 380/3353 [3:32:20<27:41:25, 33.53s/it]                                                       {'loss': 1.4027, 'learning_rate': 4.8432104169258065e-05, 'epoch': 0.11}
 11%|█▏        | 380/3353 [3:32:20<27:41:25, 33.53s/it] 11%|█▏        | 381/3353 [3:32:54<27:44:13, 33.60s/it] 11%|█▏        | 382/3353 [3:33:27<27:43:33, 33.60s/it] 11%|█▏        | 383/3353 [3:34:01<27:40:54, 33.55s/it] 11%|█▏        | 384/3353 [3:34:34<27:38:48, 33.52s/it] 11%|█▏        | 385/3353 [3:35:08<27:37:22, 33.51s/it] 12%|█▏        | 386/3353 [3:35:41<27:35:51, 33.49s/it] 12%|█▏        | 387/3353 [3:36:14<27:34:36, 33.47s/it] 12%|█▏        | 388/3353 [3:36:48<27:33:32, 33.46s/it] 12%|█▏        | 389/3353 [3:37:21<27:35:17, 33.51s/it] 12%|█▏        | 390/3353 [3:37:55<27:36:31, 33.54s/it]                                                       {'loss': 1.4027, 'learning_rate': 4.8349429593084597e-05, 'epoch': 0.12}
 12%|█▏        | 390/3353 [3:37:55<27:36:31, 33.54s/it] 12%|█▏        | 391/3353 [3:38:29<27:38:29, 33.60s/it] 12%|█▏        | 392/3353 [3:39:02<27:35:35, 33.55s/it] 12%|█▏        | 393/3353 [3:39:36<27:33:34, 33.52s/it] 12%|█▏        | 394/3353 [3:40:09<27:31:40, 33.49s/it] 12%|█▏        | 395/3353 [3:40:43<27:30:16, 33.47s/it] 12%|█▏        | 396/3353 [3:41:16<27:28:59, 33.46s/it] 12%|█▏        | 397/3353 [3:41:50<27:31:31, 33.52s/it] 12%|█▏        | 398/3353 [3:42:23<27:29:46, 33.50s/it] 12%|█▏        | 399/3353 [3:42:57<27:28:13, 33.48s/it] 12%|█▏        | 400/3353 [3:43:30<27:27:12, 33.47s/it]                                                       {'loss': 1.3883, 'learning_rate': 4.826470524405862e-05, 'epoch': 0.12}
 12%|█▏        | 400/3353 [3:43:30<27:27:12, 33.47s/it] 12%|█▏        | 401/3353 [3:44:04<27:27:46, 33.49s/it] 12%|█▏        | 402/3353 [3:44:37<27:26:16, 33.47s/it] 12%|█▏        | 403/3353 [3:45:10<27:25:27, 33.47s/it] 12%|█▏        | 404/3353 [3:45:44<27:24:22, 33.46s/it] 12%|█▏        | 405/3353 [3:46:17<27:26:40, 33.51s/it] 12%|█▏        | 406/3353 [3:46:51<27:26:49, 33.53s/it] 12%|█▏        | 407/3353 [3:47:25<27:27:16, 33.55s/it] 12%|█▏        | 408/3353 [3:47:58<27:25:18, 33.52s/it] 12%|█▏        | 409/3353 [3:48:32<27:23:16, 33.49s/it] 12%|█▏        | 410/3353 [3:49:05<27:22:00, 33.48s/it]                                                       {'loss': 1.3861, 'learning_rate': 4.8177938559863756e-05, 'epoch': 0.12}
 12%|█▏        | 410/3353 [3:49:05<27:22:00, 33.48s/it] 12%|█▏        | 411/3353 [3:49:38<27:21:19, 33.47s/it] 12%|█▏        | 412/3353 [3:50:12<27:20:11, 33.46s/it] 12%|█▏        | 413/3353 [3:50:46<27:22:27, 33.52s/it] 12%|█▏        | 414/3353 [3:51:19<27:24:09, 33.57s/it] 12%|█▏        | 415/3353 [3:51:53<27:24:21, 33.58s/it] 12%|█▏        | 416/3353 [3:52:26<27:21:42, 33.54s/it] 12%|█▏        | 417/3353 [3:53:00<27:19:41, 33.51s/it] 12%|█▏        | 418/3353 [3:53:33<27:18:04, 33.49s/it] 12%|█▏        | 419/3353 [3:54:07<27:16:41, 33.47s/it] 13%|█▎        | 420/3353 [3:54:40<27:15:36, 33.46s/it]                                                       {'loss': 1.3819, 'learning_rate': 4.808913715747384e-05, 'epoch': 0.13}
 13%|█▎        | 420/3353 [3:54:40<27:15:36, 33.46s/it] 13%|█▎        | 421/3353 [3:55:13<27:15:27, 33.47s/it] 13%|█▎        | 422/3353 [3:55:47<27:17:30, 33.52s/it] 13%|█▎        | 423/3353 [3:56:21<27:18:39, 33.56s/it] 13%|█▎        | 424/3353 [3:56:54<27:16:47, 33.53s/it] 13%|█▎        | 425/3353 [3:57:28<27:15:00, 33.50s/it] 13%|█▎        | 426/3353 [3:58:01<27:13:30, 33.48s/it] 13%|█▎        | 427/3353 [3:58:35<27:12:14, 33.47s/it] 13%|█▎        | 428/3353 [3:59:08<27:11:06, 33.46s/it] 13%|█▎        | 429/3353 [3:59:41<27:10:19, 33.45s/it] 13%|█▎        | 430/3353 [4:00:15<27:13:54, 33.54s/it]                                                       {'loss': 1.3802, 'learning_rate': 4.799830883248417e-05, 'epoch': 0.13}
 13%|█▎        | 430/3353 [4:00:15<27:13:54, 33.54s/it] 13%|█▎        | 431/3353 [4:00:49<27:13:22, 33.54s/it] 13%|█▎        | 432/3353 [4:01:22<27:11:23, 33.51s/it] 13%|█▎        | 433/3353 [4:01:56<27:10:00, 33.49s/it] 13%|█▎        | 434/3353 [4:02:29<27:08:36, 33.48s/it] 13%|█▎        | 435/3353 [4:03:03<27:08:00, 33.48s/it] 13%|█▎        | 436/3353 [4:03:36<27:07:37, 33.48s/it] 13%|█▎        | 437/3353 [4:04:09<27:06:45, 33.47s/it] 13%|█▎        | 438/3353 [4:04:43<27:11:16, 33.58s/it] 13%|█▎        | 439/3353 [4:05:17<27:10:20, 33.57s/it] 13%|█▎        | 440/3353 [4:05:50<27:08:08, 33.54s/it]                                                       {'loss': 1.3865, 'learning_rate': 4.790546155842721e-05, 'epoch': 0.13}
 13%|█▎        | 440/3353 [4:05:50<27:08:08, 33.54s/it] 13%|█▎        | 441/3353 [4:06:24<27:07:08, 33.53s/it] 13%|█▎        | 442/3353 [4:06:57<27:05:45, 33.51s/it] 13%|█▎        | 443/3353 [4:07:31<27:04:16, 33.49s/it] 13%|█▎        | 444/3353 [4:08:04<27:03:07, 33.48s/it] 13%|█▎        | 445/3353 [4:08:38<27:01:59, 33.47s/it] 13%|█▎        | 446/3353 [4:09:11<27:04:13, 33.52s/it] 13%|█▎        | 447/3353 [4:09:45<27:03:16, 33.52s/it] 13%|█▎        | 448/3353 [4:10:18<27:04:41, 33.56s/it] 13%|█▎        | 449/3353 [4:10:52<27:01:52, 33.51s/it] 13%|█▎        | 450/3353 [4:11:25<27:00:41, 33.50s/it]                                                       {'loss': 1.3866, 'learning_rate': 4.7810603486072616e-05, 'epoch': 0.13}
 13%|█▎        | 450/3353 [4:11:25<27:00:41, 33.50s/it] 13%|█▎        | 451/3353 [4:11:59<27:00:04, 33.50s/it] 13%|█▎        | 452/3353 [4:12:32<26:58:41, 33.48s/it] 14%|█▎        | 453/3353 [4:13:06<26:57:35, 33.47s/it] 14%|█▎        | 454/3353 [4:13:39<26:59:38, 33.52s/it] 14%|█▎        | 455/3353 [4:14:13<27:01:17, 33.57s/it] 14%|█▎        | 456/3353 [4:14:46<26:59:15, 33.54s/it] 14%|█▎        | 457/3353 [4:15:20<26:57:01, 33.50s/it] 14%|█▎        | 458/3353 [4:15:53<26:55:43, 33.49s/it] 14%|█▎        | 459/3353 [4:16:27<26:54:45, 33.48s/it] 14%|█▎        | 460/3353 [4:17:00<26:53:42, 33.47s/it]                                                       {'loss': 1.3716, 'learning_rate': 4.771374294271164e-05, 'epoch': 0.14}
 14%|█▎        | 460/3353 [4:17:00<26:53:42, 33.47s/it] 14%|█▎        | 461/3353 [4:17:34<26:53:10, 33.47s/it] 14%|█▍        | 462/3353 [4:18:07<26:52:47, 33.47s/it] 14%|█▍        | 463/3353 [4:18:41<26:51:28, 33.46s/it] 14%|█▍        | 464/3353 [4:19:14<26:53:05, 33.50s/it] 14%|█▍        | 465/3353 [4:19:48<26:51:41, 33.48s/it] 14%|█▍        | 466/3353 [4:20:21<26:50:33, 33.47s/it] 14%|█▍        | 467/3353 [4:20:55<26:50:03, 33.47s/it] 14%|█▍        | 468/3353 [4:21:28<26:49:07, 33.47s/it] 14%|█▍        | 469/3353 [4:22:01<26:47:54, 33.45s/it] 14%|█▍        | 470/3353 [4:22:35<26:48:51, 33.48s/it]                                                       {'loss': 1.3619, 'learning_rate': 4.761488843142621e-05, 'epoch': 0.14}
 14%|█▍        | 470/3353 [4:22:35<26:48:51, 33.48s/it] 14%|█▍        | 471/3353 [4:23:09<26:50:10, 33.52s/it] 14%|█▍        | 472/3353 [4:23:42<26:51:29, 33.56s/it] 14%|█▍        | 473/3353 [4:24:16<26:49:55, 33.54s/it] 14%|█▍        | 474/3353 [4:24:49<26:49:16, 33.54s/it] 14%|█▍        | 475/3353 [4:25:23<26:48:07, 33.53s/it] 14%|█▍        | 476/3353 [4:25:56<26:48:07, 33.54s/it] 14%|█▍        | 477/3353 [4:26:30<26:47:03, 33.53s/it] 14%|█▍        | 478/3353 [4:27:03<26:45:57, 33.52s/it] 14%|█▍        | 479/3353 [4:27:37<26:51:25, 33.64s/it] 14%|█▍        | 480/3353 [4:28:11<26:51:09, 33.65s/it]                                                       {'loss': 1.3569, 'learning_rate': 4.751404863034238e-05, 'epoch': 0.14}
 14%|█▍        | 480/3353 [4:28:11<26:51:09, 33.65s/it] 14%|█▍        | 481/3353 [4:28:44<26:48:26, 33.60s/it] 14%|█▍        | 482/3353 [4:29:18<26:46:24, 33.57s/it] 14%|█▍        | 483/3353 [4:29:51<26:45:02, 33.56s/it] 14%|█▍        | 484/3353 [4:30:25<26:42:56, 33.52s/it] 14%|█▍        | 485/3353 [4:30:58<26:41:04, 33.50s/it] 14%|█▍        | 486/3353 [4:31:32<26:39:54, 33.48s/it] 15%|█▍        | 487/3353 [4:32:05<26:39:10, 33.48s/it] 15%|█▍        | 488/3353 [4:32:39<26:37:41, 33.46s/it] 15%|█▍        | 489/3353 [4:33:12<26:36:36, 33.45s/it] 15%|█▍        | 490/3353 [4:33:45<26:35:47, 33.44s/it]                                                       {'loss': 1.3511, 'learning_rate': 4.741123239186856e-05, 'epoch': 0.15}
 15%|█▍        | 490/3353 [4:33:46<26:35:47, 33.44s/it] 15%|█▍        | 491/3353 [4:34:19<26:35:59, 33.46s/it] 15%|█▍        | 492/3353 [4:34:52<26:35:02, 33.45s/it] 15%|█▍        | 493/3353 [4:35:26<26:34:13, 33.45s/it] 15%|█▍        | 494/3353 [4:35:59<26:33:25, 33.44s/it] 15%|█▍        | 495/3353 [4:36:33<26:37:45, 33.54s/it] 15%|█▍        | 496/3353 [4:37:07<26:37:01, 33.54s/it] 15%|█▍        | 497/3353 [4:37:40<26:35:01, 33.51s/it] 15%|█▍        | 498/3353 [4:38:13<26:33:13, 33.48s/it] 15%|█▍        | 499/3353 [4:38:47<26:31:55, 33.47s/it] 15%|█▍        | 500/3353 [4:39:20<26:30:44, 33.45s/it]                                                       {'loss': 1.3467, 'learning_rate': 4.7306448741918364e-05, 'epoch': 0.15}
 15%|█▍        | 500/3353 [4:39:20<26:30:44, 33.45s/it] 15%|█▍        | 501/3353 [4:39:54<26:30:32, 33.46s/it] 15%|█▍        | 502/3353 [4:40:27<26:29:48, 33.46s/it] 15%|█▌        | 503/3353 [4:41:01<26:34:33, 33.57s/it] 15%|█▌        | 504/3353 [4:41:34<26:31:47, 33.52s/it] 15%|█▌        | 505/3353 [4:42:08<26:32:24, 33.55s/it] 15%|█▌        | 506/3353 [4:42:41<26:29:43, 33.50s/it] 15%|█▌        | 507/3353 [4:43:15<26:28:00, 33.48s/it] 15%|█▌        | 508/3353 [4:43:48<26:26:38, 33.46s/it] 15%|█▌        | 509/3353 [4:44:22<26:25:08, 33.44s/it] 15%|█▌        | 510/3353 [4:44:55<26:24:24, 33.44s/it]                                                       {'loss': 1.337, 'learning_rate': 4.7199706879118255e-05, 'epoch': 0.15}
 15%|█▌        | 510/3353 [4:44:55<26:24:24, 33.44s/it] 15%|█▌        | 511/3353 [4:45:29<26:27:47, 33.52s/it] 15%|█▌        | 512/3353 [4:46:02<26:27:06, 33.52s/it] 15%|█▌        | 513/3353 [4:46:36<26:28:26, 33.56s/it] 15%|█▌        | 514/3353 [4:47:09<26:25:41, 33.51s/it] 15%|█▌        | 515/3353 [4:47:43<26:23:50, 33.49s/it] 15%|█▌        | 516/3353 [4:48:16<26:22:12, 33.46s/it] 15%|█▌        | 517/3353 [4:48:50<26:21:23, 33.46s/it] 15%|█▌        | 518/3353 [4:49:23<26:20:04, 33.44s/it] 15%|█▌        | 519/3353 [4:49:57<26:19:36, 33.44s/it] 16%|█▌        | 520/3353 [4:50:30<26:21:08, 33.49s/it]                                                       {'loss': 1.3315, 'learning_rate': 4.709101617400003e-05, 'epoch': 0.16}
 16%|█▌        | 520/3353 [4:50:30<26:21:08, 33.49s/it] 16%|█▌        | 521/3353 [4:51:04<26:20:19, 33.48s/it] 16%|█▌        | 522/3353 [4:51:37<26:18:58, 33.46s/it] 16%|█▌        | 523/3353 [4:52:10<26:17:50, 33.45s/it] 16%|█▌        | 524/3353 [4:52:44<26:16:57, 33.45s/it] 16%|█▌        | 525/3353 [4:53:17<26:16:11, 33.44s/it] 16%|█▌        | 526/3353 [4:53:51<26:15:37, 33.44s/it] 16%|█▌        | 527/3353 [4:54:24<26:16:28, 33.47s/it] 16%|█▌        | 528/3353 [4:54:58<26:15:35, 33.46s/it] 16%|█▌        | 529/3353 [4:55:31<26:15:39, 33.48s/it] 16%|█▌        | 530/3353 [4:56:05<26:14:20, 33.46s/it]                                                       {'loss': 1.3269, 'learning_rate': 4.698038616817824e-05, 'epoch': 0.16}
 16%|█▌        | 530/3353 [4:56:05<26:14:20, 33.46s/it] 16%|█▌        | 531/3353 [4:56:38<26:13:48, 33.46s/it] 16%|█▌        | 532/3353 [4:57:12<26:12:56, 33.45s/it] 16%|█▌        | 533/3353 [4:57:45<26:12:06, 33.45s/it] 16%|█▌        | 534/3353 [4:58:18<26:11:16, 33.44s/it] 16%|█▌        | 535/3353 [4:58:52<26:10:41, 33.44s/it] 16%|█▌        | 536/3353 [4:59:26<26:15:02, 33.55s/it] 16%|█▌        | 537/3353 [4:59:59<26:12:54, 33.51s/it] 16%|█▌        | 538/3353 [5:00:33<26:14:21, 33.56s/it] 16%|█▌        | 539/3353 [5:01:06<26:12:22, 33.53s/it] 16%|█▌        | 540/3353 [5:01:40<26:10:41, 33.50s/it]                                                       {'loss': 1.3292, 'learning_rate': 4.68678265735125e-05, 'epoch': 0.16}
 16%|█▌        | 540/3353 [5:01:40<26:10:41, 33.50s/it] 16%|█▌        | 541/3353 [5:02:13<26:10:32, 33.51s/it] 16%|█▌        | 542/3353 [5:02:47<26:08:33, 33.48s/it] 16%|█▌        | 543/3353 [5:03:20<26:07:12, 33.46s/it] 16%|█▌        | 544/3353 [5:03:54<26:09:14, 33.52s/it] 16%|█▋        | 545/3353 [5:04:27<26:07:26, 33.49s/it] 16%|█▋        | 546/3353 [5:05:01<26:05:57, 33.47s/it] 16%|█▋        | 547/3353 [5:05:34<26:05:02, 33.46s/it] 16%|█▋        | 548/3353 [5:06:07<26:03:39, 33.45s/it] 16%|█▋        | 549/3353 [5:06:41<26:03:02, 33.45s/it] 16%|█▋        | 550/3353 [5:07:14<26:01:58, 33.44s/it]                                                       {'loss': 1.3241, 'learning_rate': 4.6753347271254956e-05, 'epoch': 0.16}
 16%|█▋        | 550/3353 [5:07:14<26:01:58, 33.44s/it] 16%|█▋        | 551/3353 [5:07:48<26:01:53, 33.45s/it] 16%|█▋        | 552/3353 [5:08:21<26:03:31, 33.49s/it] 16%|█▋        | 553/3353 [5:08:55<26:01:32, 33.46s/it] 17%|█▋        | 554/3353 [5:09:28<26:02:59, 33.50s/it] 17%|█▋        | 555/3353 [5:10:02<26:00:58, 33.47s/it] 17%|█▋        | 556/3353 [5:10:35<25:59:30, 33.45s/it] 17%|█▋        | 557/3353 [5:11:09<25:58:15, 33.44s/it] 17%|█▋        | 558/3353 [5:11:42<25:57:01, 33.42s/it] 17%|█▋        | 559/3353 [5:12:15<25:56:23, 33.42s/it] 17%|█▋        | 560/3353 [5:12:49<26:00:47, 33.53s/it]                                                       {'loss': 1.3192, 'learning_rate': 4.663695831118284e-05, 'epoch': 0.17}
 17%|█▋        | 560/3353 [5:12:49<26:00:47, 33.53s/it] 17%|█▋        | 561/3353 [5:13:23<25:59:00, 33.50s/it] 17%|█▋        | 562/3353 [5:13:56<25:59:59, 33.54s/it] 17%|█▋        | 563/3353 [5:14:30<25:57:41, 33.50s/it] 17%|█▋        | 564/3353 [5:15:03<25:56:00, 33.47s/it] 17%|█▋        | 565/3353 [5:15:36<25:54:28, 33.45s/it] 17%|█▋        | 566/3353 [5:16:10<25:53:37, 33.45s/it] 17%|█▋        | 567/3353 [5:16:43<25:52:09, 33.43s/it] 17%|█▋        | 568/3353 [5:17:17<25:56:31, 33.53s/it] 17%|█▋        | 569/3353 [5:17:50<25:54:09, 33.49s/it] 17%|█▋        | 570/3353 [5:18:24<25:55:09, 33.53s/it]                                                       {'loss': 1.3213, 'learning_rate': 4.651866991071625e-05, 'epoch': 0.17}
 17%|█▋        | 570/3353 [5:18:24<25:55:09, 33.53s/it] 17%|█▋        | 571/3353 [5:18:57<25:53:47, 33.51s/it] 17%|█▋        | 572/3353 [5:19:31<25:51:46, 33.48s/it] 17%|█▋        | 573/3353 [5:20:04<25:50:32, 33.46s/it] 17%|█▋        | 574/3353 [5:20:38<25:49:02, 33.44s/it] 17%|█▋        | 575/3353 [5:21:11<25:48:12, 33.44s/it] 17%|█▋        | 576/3353 [5:21:45<25:47:49, 33.44s/it] 17%|█▋        | 577/3353 [5:22:18<25:47:28, 33.45s/it] 17%|█▋        | 578/3353 [5:22:51<25:46:25, 33.44s/it] 17%|█▋        | 579/3353 [5:23:25<25:45:49, 33.44s/it] 17%|█▋        | 580/3353 [5:23:58<25:45:19, 33.44s/it]                                                       {'loss': 1.3191, 'learning_rate': 4.6398492454021136e-05, 'epoch': 0.17}
 17%|█▋        | 580/3353 [5:23:58<25:45:19, 33.44s/it] 17%|█▋        | 581/3353 [5:24:32<25:45:42, 33.46s/it] 17%|█▋        | 582/3353 [5:25:05<25:44:45, 33.45s/it] 17%|█▋        | 583/3353 [5:25:39<25:43:23, 33.43s/it] 17%|█▋        | 584/3353 [5:26:12<25:44:26, 33.47s/it] 17%|█▋        | 585/3353 [5:26:46<25:45:44, 33.51s/it] 17%|█▋        | 586/3353 [5:27:19<25:45:22, 33.51s/it] 18%|█▊        | 587/3353 [5:27:53<25:43:44, 33.49s/it] 18%|█▊        | 588/3353 [5:28:26<25:42:22, 33.47s/it] 18%|█▊        | 589/3353 [5:29:00<25:41:27, 33.46s/it] 18%|█▊        | 590/3353 [5:29:33<25:40:36, 33.46s/it]                                                       {'loss': 1.3117, 'learning_rate': 4.627643649109775e-05, 'epoch': 0.18}
 18%|█▊        | 590/3353 [5:29:33<25:40:36, 33.46s/it] 18%|█▊        | 591/3353 [5:30:07<25:40:39, 33.47s/it] 18%|█▊        | 592/3353 [5:30:40<25:39:27, 33.45s/it] 18%|█▊        | 593/3353 [5:31:14<25:41:09, 33.50s/it] 18%|█▊        | 594/3353 [5:31:47<25:39:27, 33.48s/it] 18%|█▊        | 595/3353 [5:32:21<25:41:19, 33.53s/it] 18%|█▊        | 596/3353 [5:32:54<25:38:59, 33.49s/it] 18%|█▊        | 597/3353 [5:33:27<25:37:24, 33.47s/it] 18%|█▊        | 598/3353 [5:34:01<25:36:21, 33.46s/it] 18%|█▊        | 599/3353 [5:34:34<25:35:18, 33.45s/it] 18%|█▊        | 600/3353 [5:35:08<25:34:10, 33.44s/it]                                                       {'loss': 1.3179, 'learning_rate': 4.61525127368545e-05, 'epoch': 0.18}
 18%|█▊        | 600/3353 [5:35:08<25:34:10, 33.44s/it] 18%|█▊        | 601/3353 [5:35:41<25:37:06, 33.51s/it] 18%|█▊        | 602/3353 [5:36:15<25:35:22, 33.49s/it] 18%|█▊        | 603/3353 [5:36:48<25:35:01, 33.49s/it] 18%|█▊        | 604/3353 [5:37:22<25:33:27, 33.47s/it] 18%|█▊        | 605/3353 [5:37:55<25:32:40, 33.46s/it] 18%|█▊        | 606/3353 [5:38:29<25:32:07, 33.46s/it] 18%|█▊        | 607/3353 [5:39:02<25:30:40, 33.45s/it] 18%|█▊        | 608/3353 [5:39:36<25:29:40, 33.44s/it] 18%|█▊        | 609/3353 [5:40:09<25:34:37, 33.56s/it] 18%|█▊        | 610/3353 [5:40:43<25:32:19, 33.52s/it]                                                       {'loss': 1.3047, 'learning_rate': 4.60267320701673e-05, 'epoch': 0.18}
 18%|█▊        | 610/3353 [5:40:43<25:32:19, 33.52s/it] 18%|█▊        | 611/3353 [5:41:16<25:33:23, 33.55s/it] 18%|█▊        | 612/3353 [5:41:50<25:31:04, 33.51s/it] 18%|█▊        | 613/3353 [5:42:23<25:29:26, 33.49s/it] 18%|█▊        | 614/3353 [5:42:57<25:28:06, 33.47s/it] 18%|█▊        | 615/3353 [5:43:30<25:26:41, 33.46s/it] 18%|█▊        | 616/3353 [5:44:04<25:25:55, 33.45s/it] 18%|█▊        | 617/3353 [5:44:37<25:28:14, 33.51s/it] 18%|█▊        | 618/3353 [5:45:11<25:26:25, 33.49s/it] 18%|█▊        | 619/3353 [5:45:44<25:28:20, 33.54s/it] 18%|█▊        | 620/3353 [5:46:18<25:26:26, 33.51s/it]                                                       {'loss': 1.3032, 'learning_rate': 4.589910553292455e-05, 'epoch': 0.18}
 18%|█▊        | 620/3353 [5:46:18<25:26:26, 33.51s/it] 19%|█▊        | 621/3353 [5:46:51<25:25:28, 33.50s/it] 19%|█▊        | 622/3353 [5:47:25<25:24:00, 33.48s/it] 19%|█▊        | 623/3353 [5:47:58<25:22:48, 33.47s/it] 19%|█▊        | 624/3353 [5:48:32<25:21:49, 33.46s/it] 19%|█▊        | 625/3353 [5:49:05<25:26:35, 33.58s/it] 19%|█▊        | 626/3353 [5:49:39<25:24:07, 33.53s/it] 19%|█▊        | 627/3353 [5:50:12<25:25:01, 33.57s/it] 19%|█▊        | 628/3353 [5:50:46<25:23:05, 33.54s/it] 19%|█▉        | 629/3353 [5:51:19<25:21:12, 33.51s/it] 19%|█▉        | 630/3353 [5:51:53<25:19:38, 33.48s/it]                                                       {'loss': 1.3036, 'learning_rate': 4.576964432905783e-05, 'epoch': 0.19}
 19%|█▉        | 630/3353 [5:51:53<25:19:38, 33.48s/it] 19%|█▉        | 631/3353 [5:52:26<25:19:53, 33.50s/it] 19%|█▉        | 632/3353 [5:53:00<25:18:53, 33.49s/it] 19%|█▉        | 633/3353 [5:53:34<25:20:45, 33.55s/it] 19%|█▉        | 634/3353 [5:54:07<25:18:44, 33.51s/it] 19%|█▉        | 635/3353 [5:54:40<25:17:01, 33.49s/it] 19%|█▉        | 636/3353 [5:55:14<25:15:57, 33.48s/it] 19%|█▉        | 637/3353 [5:55:47<25:15:11, 33.47s/it] 19%|█▉        | 638/3353 [5:56:21<25:14:20, 33.47s/it] 19%|█▉        | 639/3353 [5:56:54<25:13:01, 33.45s/it] 19%|█▉        | 640/3353 [5:57:28<25:12:07, 33.44s/it]                                                       {'loss': 1.3108, 'learning_rate': 4.5638359823558304e-05, 'epoch': 0.19}
 19%|█▉        | 640/3353 [5:57:28<25:12:07, 33.44s/it] 19%|█▉        | 641/3353 [5:58:01<25:13:36, 33.49s/it] 19%|█▉        | 642/3353 [5:58:35<25:13:42, 33.50s/it] 19%|█▉        | 643/3353 [5:59:08<25:13:33, 33.51s/it] 19%|█▉        | 644/3353 [5:59:42<25:12:05, 33.49s/it] 19%|█▉        | 645/3353 [6:00:15<25:10:54, 33.48s/it] 19%|█▉        | 646/3353 [6:00:49<25:09:48, 33.46s/it] 19%|█▉        | 647/3353 [6:01:22<25:08:58, 33.46s/it] 19%|█▉        | 648/3353 [6:01:55<25:08:13, 33.45s/it] 19%|█▉        | 649/3353 [6:02:29<25:07:09, 33.44s/it] 19%|█▉        | 650/3353 [6:03:03<25:11:47, 33.56s/it]                                                       {'loss': 1.3029, 'learning_rate': 4.550526354147904e-05, 'epoch': 0.19}
 19%|█▉        | 650/3353 [6:03:03<25:11:47, 33.56s/it] 19%|█▉        | 651/3353 [6:03:36<25:11:00, 33.55s/it] 19%|█▉        | 652/3353 [6:04:10<25:11:35, 33.58s/it] 19%|█▉        | 653/3353 [6:04:43<25:09:03, 33.53s/it] 20%|█▉        | 654/3353 [6:05:17<25:07:30, 33.51s/it] 20%|█▉        | 655/3353 [6:05:50<25:06:11, 33.50s/it] 20%|█▉        | 656/3353 [6:06:24<25:05:03, 33.48s/it] 20%|█▉        | 657/3353 [6:06:57<25:04:05, 33.47s/it] 20%|█▉        | 658/3353 [6:07:31<25:03:01, 33.46s/it] 20%|█▉        | 659/3353 [6:08:04<25:02:09, 33.46s/it] 20%|█▉        | 660/3353 [6:08:37<25:01:15, 33.45s/it]                                                       {'loss': 1.2986, 'learning_rate': 4.537036716692328e-05, 'epoch': 0.2}
 20%|█▉        | 660/3353 [6:08:37<25:01:15, 33.45s/it] 20%|█▉        | 661/3353 [6:09:11<25:01:11, 33.46s/it] 20%|█▉        | 662/3353 [6:09:44<25:00:16, 33.45s/it] 20%|█▉        | 663/3353 [6:10:18<24:59:46, 33.45s/it] 20%|█▉        | 664/3353 [6:10:51<24:58:52, 33.44s/it] 20%|█▉        | 665/3353 [6:11:25<24:58:05, 33.44s/it] 20%|█▉        | 666/3353 [6:11:58<25:02:03, 33.54s/it] 20%|█▉        | 667/3353 [6:12:32<25:00:05, 33.51s/it] 20%|█▉        | 668/3353 [6:13:05<25:00:41, 33.54s/it] 20%|█▉        | 669/3353 [6:13:39<24:58:59, 33.51s/it] 20%|█▉        | 670/3353 [6:14:12<24:57:30, 33.49s/it]                                                       {'loss': 1.3024, 'learning_rate': 4.5233682542018705e-05, 'epoch': 0.2}
 20%|█▉        | 670/3353 [6:14:12<24:57:30, 33.49s/it] 20%|██        | 671/3353 [6:14:46<24:57:04, 33.49s/it] 20%|██        | 672/3353 [6:15:19<24:55:37, 33.47s/it] 20%|██        | 673/3353 [6:15:53<24:54:34, 33.46s/it] 20%|██        | 674/3353 [6:16:27<24:59:06, 33.57s/it] 20%|██        | 675/3353 [6:17:00<24:57:24, 33.55s/it] 20%|██        | 676/3353 [6:17:34<24:58:17, 33.58s/it] 20%|██        | 677/3353 [6:18:07<24:55:46, 33.54s/it] 20%|██        | 678/3353 [6:18:41<24:53:50, 33.51s/it] 20%|██        | 679/3353 [6:19:14<24:53:43, 33.52s/it] 20%|██        | 680/3353 [6:19:48<24:52:11, 33.49s/it]                                                       {'loss': 1.2985, 'learning_rate': 4.509522166587784e-05, 'epoch': 0.2}
 20%|██        | 680/3353 [6:19:48<24:52:11, 33.49s/it] 20%|██        | 681/3353 [6:20:21<24:51:20, 33.49s/it] 20%|██        | 682/3353 [6:20:55<24:54:04, 33.56s/it] 20%|██        | 683/3353 [6:21:28<24:53:16, 33.56s/it] 20%|██        | 684/3353 [6:22:02<24:55:14, 33.61s/it] 20%|██        | 685/3353 [6:22:36<24:54:34, 33.61s/it] 20%|██        | 686/3353 [6:23:09<24:54:28, 33.62s/it] 20%|██        | 687/3353 [6:23:43<24:54:04, 33.63s/it] 21%|██        | 688/3353 [6:24:17<24:54:15, 33.64s/it] 21%|██        | 689/3353 [6:24:50<24:54:08, 33.65s/it] 21%|██        | 690/3353 [6:25:24<24:56:45, 33.72s/it]                                                       {'loss': 1.3008, 'learning_rate': 4.495499669354475e-05, 'epoch': 0.21}
 21%|██        | 690/3353 [6:25:24<24:56:45, 33.72s/it] 21%|██        | 691/3353 [6:25:58<24:56:10, 33.72s/it] 21%|██        | 692/3353 [6:26:32<24:53:56, 33.69s/it] 21%|██        | 693/3353 [6:27:05<24:52:11, 33.66s/it] 21%|██        | 694/3353 [6:27:39<24:52:01, 33.67s/it] 21%|██        | 695/3353 [6:28:12<24:52:00, 33.68s/it] 21%|██        | 696/3353 [6:28:46<24:51:28, 33.68s/it] 21%|██        | 697/3353 [6:29:20<24:50:26, 33.67s/it] 21%|██        | 698/3353 [6:29:54<24:52:30, 33.73s/it] 21%|██        | 699/3353 [6:30:27<24:51:20, 33.72s/it] 21%|██        | 700/3353 [6:31:01<24:51:42, 33.74s/it]                                                       {'loss': 1.3016, 'learning_rate': 4.48130199349279e-05, 'epoch': 0.21}
 21%|██        | 700/3353 [6:31:01<24:51:42, 33.74s/it] 21%|██        | 701/3353 [6:31:35<24:51:23, 33.74s/it] 21%|██        | 702/3353 [6:32:09<24:49:31, 33.71s/it] 21%|██        | 703/3353 [6:32:42<24:47:21, 33.68s/it] 21%|██        | 704/3353 [6:33:16<24:45:44, 33.65s/it] 21%|██        | 705/3353 [6:33:49<24:46:06, 33.67s/it] 21%|██        | 706/3353 [6:34:23<24:45:34, 33.67s/it] 21%|██        | 707/3353 [6:34:57<24:49:18, 33.77s/it] 21%|██        | 708/3353 [6:35:31<24:47:22, 33.74s/it] 21%|██        | 709/3353 [6:36:05<24:48:45, 33.78s/it] 21%|██        | 710/3353 [6:36:38<24:46:01, 33.73s/it]                                                       {'loss': 1.3001, 'learning_rate': 4.466930385371959e-05, 'epoch': 0.21}
 21%|██        | 710/3353 [6:36:38<24:46:01, 33.73s/it] 21%|██        | 711/3353 [6:37:12<24:45:23, 33.73s/it] 21%|██        | 712/3353 [6:37:46<24:43:58, 33.71s/it] 21%|██▏       | 713/3353 [6:38:19<24:43:02, 33.71s/it] 21%|██▏       | 714/3353 [6:38:53<24:43:00, 33.72s/it] 21%|██▏       | 715/3353 [6:39:27<24:45:06, 33.78s/it] 21%|██▏       | 716/3353 [6:40:01<24:43:31, 33.75s/it] 21%|██▏       | 717/3353 [6:40:34<24:41:44, 33.73s/it] 21%|██▏       | 718/3353 [6:41:08<24:39:21, 33.69s/it] 21%|██▏       | 719/3353 [6:41:42<24:38:55, 33.69s/it] 21%|██▏       | 720/3353 [6:42:15<24:38:00, 33.68s/it]                                                       {'loss': 1.2861, 'learning_rate': 4.452386106630176e-05, 'epoch': 0.21}
 21%|██▏       | 720/3353 [6:42:15<24:38:00, 33.68s/it] 22%|██▏       | 721/3353 [6:42:49<24:38:31, 33.71s/it] 22%|██▏       | 722/3353 [6:43:23<24:36:47, 33.68s/it] 22%|██▏       | 723/3353 [6:43:57<24:37:36, 33.71s/it] 22%|██▏       | 724/3353 [6:44:30<24:36:14, 33.69s/it] 22%|██▏       | 725/3353 [6:45:04<24:38:16, 33.75s/it] 22%|██▏       | 726/3353 [6:45:38<24:36:56, 33.73s/it] 22%|██▏       | 727/3353 [6:46:11<24:36:06, 33.73s/it] 22%|██▏       | 728/3353 [6:46:45<24:34:39, 33.71s/it] 22%|██▏       | 729/3353 [6:47:19<24:32:38, 33.67s/it] 22%|██▏       | 730/3353 [6:47:52<24:31:23, 33.66s/it]                                                       {'loss': 1.2849, 'learning_rate': 4.437670434063843e-05, 'epoch': 0.22}
 22%|██▏       | 730/3353 [6:47:53<24:31:23, 33.66s/it] 22%|██▏       | 731/3353 [6:48:27<24:37:55, 33.82s/it] 22%|██▏       | 732/3353 [6:49:00<24:35:56, 33.79s/it] 22%|██▏       | 733/3353 [6:49:34<24:36:43, 33.82s/it] 22%|██▏       | 734/3353 [6:50:08<24:34:52, 33.79s/it] 22%|██▏       | 735/3353 [6:50:42<24:33:08, 33.76s/it] 22%|██▏       | 736/3353 [6:51:15<24:30:34, 33.72s/it] 22%|██▏       | 737/3353 [6:51:49<24:29:13, 33.70s/it] 22%|██▏       | 738/3353 [6:52:22<24:27:50, 33.68s/it] 22%|██▏       | 739/3353 [6:52:57<24:33:01, 33.81s/it] 22%|██▏       | 740/3353 [6:53:30<24:30:42, 33.77s/it]                                                       {'loss': 1.2799, 'learning_rate': 4.4227846595154876e-05, 'epoch': 0.22}
 22%|██▏       | 740/3353 [6:53:31<24:30:42, 33.77s/it] 22%|██▏       | 741/3353 [6:54:04<24:34:59, 33.88s/it] 22%|██▏       | 742/3353 [6:54:38<24:31:59, 33.83s/it] 22%|██▏       | 743/3353 [6:55:12<24:29:19, 33.78s/it] 22%|██▏       | 744/3353 [6:55:45<24:26:25, 33.72s/it] 22%|██▏       | 745/3353 [6:56:19<24:24:38, 33.70s/it] 22%|██▏       | 746/3353 [6:56:53<24:23:11, 33.68s/it] 22%|██▏       | 747/3353 [6:57:26<24:24:36, 33.72s/it] 22%|██▏       | 748/3353 [6:58:00<24:23:02, 33.70s/it] 22%|██▏       | 749/3353 [6:58:34<24:21:47, 33.68s/it] 22%|██▏       | 750/3353 [6:59:07<24:19:57, 33.65s/it]                                                       {'loss': 1.2741, 'learning_rate': 4.4077300897603544e-05, 'epoch': 0.22}
 22%|██▏       | 750/3353 [6:59:07<24:19:57, 33.65s/it] 22%|██▏       | 751/3353 [6:59:41<24:20:57, 33.69s/it] 22%|██▏       | 752/3353 [7:00:15<24:19:20, 33.66s/it] 22%|██▏       | 753/3353 [7:00:48<24:17:35, 33.64s/it] 22%|██▏       | 754/3353 [7:01:22<24:16:35, 33.63s/it] 23%|██▎       | 755/3353 [7:01:56<24:20:06, 33.72s/it] 23%|██▎       | 756/3353 [7:02:29<24:18:46, 33.70s/it] 23%|██▎       | 757/3353 [7:03:03<24:18:56, 33.72s/it] 23%|██▎       | 758/3353 [7:03:37<24:16:37, 33.68s/it] 23%|██▎       | 759/3353 [7:04:10<24:14:58, 33.65s/it] 23%|██▎       | 760/3353 [7:04:44<24:13:33, 33.63s/it]                                                       {'loss': 1.2731, 'learning_rate': 4.3925080463916865e-05, 'epoch': 0.23}
 23%|██▎       | 760/3353 [7:04:44<24:13:33, 33.63s/it] 23%|██▎       | 761/3353 [7:05:18<24:15:55, 33.70s/it] 23%|██▎       | 762/3353 [7:05:51<24:14:14, 33.68s/it] 23%|██▎       | 763/3353 [7:06:25<24:15:25, 33.72s/it] 23%|██▎       | 764/3353 [7:06:59<24:16:07, 33.75s/it] 23%|██▎       | 765/3353 [7:07:33<24:13:03, 33.69s/it] 23%|██▎       | 766/3353 [7:08:06<24:14:16, 33.73s/it] 23%|██▎       | 767/3353 [7:08:40<24:11:00, 33.67s/it] 23%|██▎       | 768/3353 [7:09:14<24:09:14, 33.64s/it] 23%|██▎       | 769/3353 [7:09:47<24:08:23, 33.63s/it] 23%|██▎       | 770/3353 [7:10:21<24:07:46, 33.63s/it]                                                       {'loss': 1.2667, 'learning_rate': 4.377119865704708e-05, 'epoch': 0.23}
 23%|██▎       | 770/3353 [7:10:21<24:07:46, 33.63s/it] 23%|██▎       | 771/3353 [7:10:55<24:09:36, 33.69s/it] 23%|██▎       | 772/3353 [7:11:28<24:07:49, 33.66s/it] 23%|██▎       | 773/3353 [7:12:02<24:05:39, 33.62s/it] 23%|██▎       | 774/3353 [7:12:35<24:03:30, 33.58s/it] 23%|██▎       | 775/3353 [7:13:09<24:01:51, 33.56s/it] 23%|██▎       | 776/3353 [7:13:42<24:00:56, 33.55s/it] 23%|██▎       | 777/3353 [7:14:16<24:00:13, 33.55s/it] 23%|██▎       | 778/3353 [7:14:49<23:59:50, 33.55s/it] 23%|██▎       | 779/3353 [7:15:23<23:59:03, 33.54s/it] 23%|██▎       | 780/3353 [7:15:57<24:02:51, 33.65s/it]                                                       {'loss': 1.2662, 'learning_rate': 4.361566898579317e-05, 'epoch': 0.23}
 23%|██▎       | 780/3353 [7:15:57<24:02:51, 33.65s/it] 23%|██▎       | 781/3353 [7:16:31<24:03:07, 33.67s/it] 23%|██▎       | 782/3353 [7:17:04<24:02:58, 33.67s/it] 23%|██▎       | 783/3353 [7:17:38<24:00:38, 33.63s/it] 23%|██▎       | 784/3353 [7:18:11<23:59:11, 33.61s/it] 23%|██▎       | 785/3353 [7:18:45<23:57:15, 33.58s/it] 23%|██▎       | 786/3353 [7:19:18<23:55:57, 33.56s/it] 23%|██▎       | 787/3353 [7:19:52<23:54:29, 33.54s/it] 24%|██▎       | 788/3353 [7:20:26<23:57:03, 33.62s/it] 24%|██▎       | 789/3353 [7:20:59<23:55:36, 33.59s/it] 24%|██▎       | 790/3353 [7:21:33<23:57:25, 33.65s/it]                                                       {'loss': 1.2586, 'learning_rate': 4.345850510361489e-05, 'epoch': 0.24}
 24%|██▎       | 790/3353 [7:21:33<23:57:25, 33.65s/it] 24%|██▎       | 791/3353 [7:22:07<23:57:01, 33.65s/it] 24%|██▎       | 792/3353 [7:22:40<23:55:11, 33.62s/it] 24%|██▎       | 793/3353 [7:23:14<23:53:22, 33.59s/it] 24%|██▎       | 794/3353 [7:23:47<23:52:02, 33.58s/it] 24%|██▎       | 795/3353 [7:24:21<23:50:39, 33.56s/it] 24%|██▎       | 796/3353 [7:24:55<23:54:29, 33.66s/it] 24%|██▍       | 797/3353 [7:25:28<23:52:49, 33.63s/it] 24%|██▍       | 798/3353 [7:26:02<23:54:04, 33.68s/it] 24%|██▍       | 799/3353 [7:26:35<23:51:20, 33.63s/it] 24%|██▍       | 800/3353 [7:27:09<23:49:28, 33.60s/it]                                                       {'loss': 1.2636, 'learning_rate': 4.329972080743426e-05, 'epoch': 0.24}
 24%|██▍       | 800/3353 [7:27:09<23:49:28, 33.60s/it] 24%|██▍       | 801/3353 [7:27:43<23:49:56, 33.62s/it] 24%|██▍       | 802/3353 [7:28:16<23:48:26, 33.60s/it] 24%|██▍       | 803/3353 [7:28:50<23:46:56, 33.58s/it] 24%|██▍       | 804/3353 [7:29:23<23:48:13, 33.62s/it] 24%|██▍       | 805/3353 [7:29:57<23:46:40, 33.60s/it] 24%|██▍       | 806/3353 [7:30:31<23:45:47, 33.59s/it] 24%|██▍       | 807/3353 [7:31:04<23:44:18, 33.57s/it] 24%|██▍       | 808/3353 [7:31:38<23:42:48, 33.54s/it] 24%|██▍       | 809/3353 [7:32:11<23:41:37, 33.53s/it] 24%|██▍       | 810/3353 [7:32:45<23:40:45, 33.52s/it]                                                       {'loss': 1.2675, 'learning_rate': 4.313933003642434e-05, 'epoch': 0.24}
 24%|██▍       | 810/3353 [7:32:45<23:40:45, 33.52s/it] 24%|██▍       | 811/3353 [7:33:18<23:43:24, 33.60s/it] 24%|██▍       | 812/3353 [7:33:52<23:43:14, 33.61s/it] 24%|██▍       | 813/3353 [7:34:26<23:41:42, 33.58s/it] 24%|██▍       | 814/3353 [7:34:59<23:40:47, 33.58s/it] 24%|██▍       | 815/3353 [7:35:33<23:39:07, 33.55s/it] 24%|██▍       | 816/3353 [7:36:06<23:38:06, 33.54s/it] 24%|██▍       | 817/3353 [7:36:40<23:37:34, 33.54s/it] 24%|██▍       | 818/3353 [7:37:13<23:36:35, 33.53s/it] 24%|██▍       | 819/3353 [7:37:47<23:35:37, 33.52s/it] 24%|██▍       | 820/3353 [7:38:20<23:37:23, 33.57s/it]                                                       {'loss': 1.2684, 'learning_rate': 4.297734687078553e-05, 'epoch': 0.24}
 24%|██▍       | 820/3353 [7:38:20<23:37:23, 33.57s/it] 24%|██▍       | 821/3353 [7:38:54<23:40:02, 33.65s/it] 25%|██▍       | 822/3353 [7:39:28<23:37:37, 33.61s/it] 25%|██▍       | 823/3353 [7:40:01<23:37:58, 33.63s/it] 25%|██▍       | 824/3353 [7:40:35<23:35:59, 33.59s/it] 25%|██▍       | 825/3353 [7:41:08<23:34:22, 33.57s/it] 25%|██▍       | 826/3353 [7:41:42<23:33:45, 33.57s/it] 25%|██▍       | 827/3353 [7:42:16<23:33:31, 33.58s/it] 25%|██▍       | 828/3353 [7:42:49<23:34:56, 33.62s/it] 25%|██▍       | 829/3353 [7:43:23<23:33:35, 33.60s/it] 25%|██▍       | 830/3353 [7:43:56<23:32:19, 33.59s/it]                                                       {'loss': 1.2963, 'learning_rate': 4.281378553050956e-05, 'epoch': 0.25}
 25%|██▍       | 830/3353 [7:43:57<23:32:19, 33.59s/it] 25%|██▍       | 831/3353 [7:44:30<23:34:47, 33.66s/it] 25%|██▍       | 832/3353 [7:45:04<23:33:13, 33.63s/it] 25%|██▍       | 833/3353 [7:45:37<23:31:23, 33.60s/it] 25%|██▍       | 834/3353 [7:46:11<23:30:04, 33.59s/it] 25%|██▍       | 835/3353 [7:46:44<23:29:57, 33.60s/it] 25%|██▍       | 836/3353 [7:47:18<23:28:47, 33.58s/it] 25%|██▍       | 837/3353 [7:47:52<23:30:47, 33.64s/it] 25%|██▍       | 838/3353 [7:48:25<23:28:59, 33.61s/it] 25%|██▌       | 839/3353 [7:48:59<23:29:40, 33.64s/it] 25%|██▌       | 840/3353 [7:49:33<23:28:39, 33.63s/it]                                                       {'loss': 1.2809, 'learning_rate': 4.264866037413112e-05, 'epoch': 0.25}
 25%|██▌       | 840/3353 [7:49:33<23:28:39, 33.63s/it] 25%|██▌       | 841/3353 [7:50:06<23:27:04, 33.61s/it] 25%|██▌       | 842/3353 [7:50:40<23:26:42, 33.61s/it] 25%|██▌       | 843/3353 [7:51:13<23:25:05, 33.59s/it] 25%|██▌       | 844/3353 [7:51:47<23:24:29, 33.59s/it] 25%|██▌       | 845/3353 [7:52:21<23:28:56, 33.71s/it] 25%|██▌       | 846/3353 [7:52:55<23:27:02, 33.67s/it] 25%|██▌       | 847/3353 [7:53:28<23:27:45, 33.71s/it] 25%|██▌       | 848/3353 [7:54:02<23:25:08, 33.66s/it] 25%|██▌       | 849/3353 [7:54:35<23:24:00, 33.64s/it] 25%|██▌       | 850/3353 [7:55:09<23:22:11, 33.61s/it]                                                       {'loss': 1.2715, 'learning_rate': 4.2481985897467406e-05, 'epoch': 0.25}
 25%|██▌       | 850/3353 [7:55:09<23:22:11, 33.61s/it] 25%|██▌       | 851/3353 [7:55:43<23:22:10, 33.63s/it] 25%|██▌       | 852/3353 [7:56:16<23:20:38, 33.60s/it] 25%|██▌       | 853/3353 [7:56:50<23:22:59, 33.67s/it] 25%|██▌       | 854/3353 [7:57:24<23:21:36, 33.65s/it] 25%|██▌       | 855/3353 [7:57:57<23:23:23, 33.71s/it] 26%|██▌       | 856/3353 [7:58:31<23:21:20, 33.67s/it] 26%|██▌       | 857/3353 [7:59:05<23:19:08, 33.63s/it] 26%|██▌       | 858/3353 [7:59:38<23:17:45, 33.61s/it] 26%|██▌       | 859/3353 [8:00:12<23:17:04, 33.61s/it] 26%|██▌       | 860/3353 [8:00:45<23:15:26, 33.58s/it]                                                       {'loss': 1.2711, 'learning_rate': 4.231377673234555e-05, 'epoch': 0.26}
 26%|██▌       | 860/3353 [8:00:45<23:15:26, 33.58s/it] 26%|██▌       | 861/3353 [8:01:19<23:17:30, 33.65s/it] 26%|██▌       | 862/3353 [8:01:53<23:16:03, 33.63s/it] 26%|██▌       | 863/3353 [8:02:26<23:15:16, 33.62s/it] 26%|██▌       | 864/3353 [8:03:00<23:13:46, 33.60s/it] 26%|██▌       | 865/3353 [8:03:33<23:12:45, 33.59s/it] 26%|██▌       | 866/3353 [8:04:07<23:11:30, 33.57s/it] 26%|██▌       | 867/3353 [8:04:41<23:11:37, 33.59s/it] 26%|██▌       | 868/3353 [8:05:14<23:12:06, 33.61s/it] 26%|██▌       | 869/3353 [8:05:48<23:15:14, 33.70s/it] 26%|██▌       | 870/3353 [8:06:22<23:12:52, 33.66s/it]                                                       {'loss': 1.277, 'learning_rate': 4.2144047645318146e-05, 'epoch': 0.26}
 26%|██▌       | 870/3353 [8:06:22<23:12:52, 33.66s/it] 26%|██▌       | 871/3353 [8:06:55<23:13:43, 33.69s/it] 26%|██▌       | 872/3353 [8:07:29<23:10:48, 33.63s/it] 26%|██▌       | 873/3353 [8:08:02<23:08:45, 33.60s/it] 26%|██▌       | 874/3353 [8:08:36<23:07:53, 33.59s/it] 26%|██▌       | 875/3353 [8:09:10<23:06:15, 33.57s/it] 26%|██▌       | 876/3353 [8:09:43<23:05:18, 33.56s/it] 26%|██▌       | 877/3353 [8:10:17<23:05:37, 33.58s/it] 26%|██▌       | 878/3353 [8:10:51<23:07:33, 33.64s/it] 26%|██▌       | 879/3353 [8:11:24<23:05:52, 33.61s/it] 26%|██▌       | 880/3353 [8:11:58<23:07:17, 33.66s/it]                                                       {'loss': 1.2731, 'learning_rate': 4.197281353636695e-05, 'epoch': 0.26}
 26%|██▌       | 880/3353 [8:11:58<23:07:17, 33.66s/it] 26%|██▋       | 881/3353 [8:12:31<23:05:25, 33.63s/it] 26%|██▋       | 882/3353 [8:13:05<23:03:44, 33.60s/it] 26%|██▋       | 883/3353 [8:13:39<23:02:59, 33.59s/it] 26%|██▋       | 884/3353 [8:14:12<23:02:33, 33.60s/it] 26%|██▋       | 885/3353 [8:14:46<23:04:14, 33.65s/it] 26%|██▋       | 886/3353 [8:15:20<23:03:13, 33.64s/it] 26%|██▋       | 887/3353 [8:15:53<23:01:32, 33.61s/it] 26%|██▋       | 888/3353 [8:16:27<23:01:22, 33.62s/it] 27%|██▋       | 889/3353 [8:17:00<23:00:08, 33.61s/it] 27%|██▋       | 890/3353 [8:17:34<23:00:02, 33.62s/it]                                                       {'loss': 1.259, 'learning_rate': 4.180008943759484e-05, 'epoch': 0.27}
 27%|██▋       | 890/3353 [8:17:34<23:00:02, 33.62s/it] 27%|██▋       | 891/3353 [8:18:08<23:00:01, 33.63s/it] 27%|██▋       | 892/3353 [8:18:41<22:58:40, 33.61s/it] 27%|██▋       | 893/3353 [8:19:15<22:59:41, 33.65s/it] 27%|██▋       | 894/3353 [8:19:49<23:01:19, 33.70s/it] 27%|██▋       | 895/3353 [8:20:22<22:59:11, 33.67s/it] 27%|██▋       | 896/3353 [8:20:56<23:00:46, 33.72s/it] 27%|██▋       | 897/3353 [8:21:30<22:58:29, 33.68s/it] 27%|██▋       | 898/3353 [8:22:03<22:57:31, 33.67s/it] 27%|██▋       | 899/3353 [8:22:37<22:56:36, 33.66s/it] 27%|██▋       | 900/3353 [8:23:11<22:55:17, 33.64s/it]                                                       {'loss': 1.2516, 'learning_rate': 4.162589051190623e-05, 'epoch': 0.27}
 27%|██▋       | 900/3353 [8:23:11<22:55:17, 33.64s/it] 27%|██▋       | 901/3353 [8:23:44<22:56:20, 33.68s/it] 27%|██▋       | 902/3353 [8:24:18<22:57:26, 33.72s/it] 27%|██▋       | 903/3353 [8:24:52<22:54:55, 33.67s/it] 27%|██▋       | 904/3353 [8:25:26<22:55:59, 33.71s/it] 27%|██▋       | 905/3353 [8:25:59<22:53:44, 33.67s/it] 27%|██▋       | 906/3353 [8:26:33<22:51:49, 33.64s/it] 27%|██▋       | 907/3353 [8:27:06<22:50:22, 33.62s/it] 27%|██▋       | 908/3353 [8:27:40<22:49:01, 33.60s/it] 27%|██▋       | 909/3353 [8:28:13<22:48:17, 33.59s/it] 27%|██▋       | 910/3353 [8:28:47<22:52:04, 33.70s/it]                                                       {'loss': 1.2514, 'learning_rate': 4.14502320516759e-05, 'epoch': 0.27}
 27%|██▋       | 910/3353 [8:28:47<22:52:04, 33.70s/it] 27%|██▋       | 911/3353 [8:29:21<22:50:14, 33.67s/it] 27%|██▋       | 912/3353 [8:29:55<22:51:30, 33.71s/it] 27%|██▋       | 913/3353 [8:30:28<22:49:24, 33.67s/it] 27%|██▋       | 914/3353 [8:31:02<22:47:47, 33.65s/it] 27%|██▋       | 915/3353 [8:31:36<22:47:14, 33.65s/it] 27%|██▋       | 916/3353 [8:32:09<22:45:45, 33.63s/it] 27%|██▋       | 917/3353 [8:32:43<22:45:12, 33.63s/it] 27%|██▋       | 918/3353 [8:33:16<22:45:05, 33.64s/it] 27%|██▋       | 919/3353 [8:33:50<22:44:52, 33.65s/it] 27%|██▋       | 920/3353 [8:34:24<22:44:20, 33.65s/it]                                                       {'loss': 1.2476, 'learning_rate': 4.1273129477406616e-05, 'epoch': 0.27}
 27%|██▋       | 920/3353 [8:34:24<22:44:20, 33.65s/it] 27%|██▋       | 921/3353 [8:34:57<22:44:04, 33.65s/it] 27%|██▋       | 922/3353 [8:35:31<22:42:59, 33.64s/it] 28%|██▊       | 923/3353 [8:36:05<22:42:23, 33.64s/it] 28%|██▊       | 924/3353 [8:36:38<22:42:10, 33.65s/it] 28%|██▊       | 925/3353 [8:37:12<22:40:50, 33.63s/it] 28%|██▊       | 926/3353 [8:37:46<22:42:52, 33.69s/it] 28%|██▊       | 927/3353 [8:38:19<22:41:02, 33.66s/it] 28%|██▊       | 928/3353 [8:38:53<22:40:34, 33.66s/it] 28%|██▊       | 929/3353 [8:39:27<22:39:38, 33.65s/it] 28%|██▊       | 930/3353 [8:40:00<22:38:37, 33.64s/it]                                                       {'loss': 1.2386, 'learning_rate': 4.109459833637533e-05, 'epoch': 0.28}
 28%|██▊       | 930/3353 [8:40:00<22:38:37, 33.64s/it] 28%|██▊       | 931/3353 [8:40:34<22:38:17, 33.65s/it] 28%|██▊       | 932/3353 [8:41:08<22:38:32, 33.67s/it] 28%|██▊       | 933/3353 [8:41:41<22:37:31, 33.66s/it] 28%|██▊       | 934/3353 [8:42:15<22:38:24, 33.69s/it] 28%|██▊       | 935/3353 [8:42:49<22:39:35, 33.74s/it] 28%|██▊       | 936/3353 [8:43:22<22:37:43, 33.70s/it] 28%|██▊       | 937/3353 [8:43:56<22:38:34, 33.74s/it] 28%|██▊       | 938/3353 [8:44:30<22:37:23, 33.72s/it] 28%|██▊       | 939/3353 [8:45:04<22:36:11, 33.71s/it] 28%|██▊       | 940/3353 [8:45:37<22:34:56, 33.69s/it]                                                       {'loss': 1.2378, 'learning_rate': 4.0914654301268387e-05, 'epoch': 0.28}
 28%|██▊       | 940/3353 [8:45:37<22:34:56, 33.69s/it] 28%|██▊       | 941/3353 [8:46:11<22:35:36, 33.72s/it] 28%|██▊       | 942/3353 [8:46:45<22:35:19, 33.73s/it] 28%|██▊       | 943/3353 [8:47:19<22:34:42, 33.73s/it] 28%|██▊       | 944/3353 [8:47:52<22:34:19, 33.73s/it] 28%|██▊       | 945/3353 [8:48:26<22:34:16, 33.74s/it] 28%|██▊       | 946/3353 [8:49:00<22:32:29, 33.71s/it] 28%|██▊       | 947/3353 [8:49:33<22:31:29, 33.70s/it] 28%|██▊       | 948/3353 [8:50:07<22:31:35, 33.72s/it] 28%|██▊       | 949/3353 [8:50:41<22:31:20, 33.73s/it] 28%|██▊       | 950/3353 [8:51:15<22:34:09, 33.81s/it]                                                       {'loss': 1.2359, 'learning_rate': 4.073331316880564e-05, 'epoch': 0.28}
 28%|██▊       | 950/3353 [8:51:15<22:34:09, 33.81s/it] 28%|██▊       | 951/3353 [8:51:49<22:37:28, 33.91s/it] 28%|██▊       | 952/3353 [8:52:23<22:34:27, 33.85s/it] 28%|██▊       | 953/3353 [8:52:57<22:33:30, 33.84s/it] 28%|██▊       | 954/3353 [8:53:30<22:30:30, 33.78s/it] 28%|██▊       | 955/3353 [8:54:04<22:28:46, 33.75s/it] 29%|██▊       | 956/3353 [8:54:38<22:28:12, 33.75s/it] 29%|██▊       | 957/3353 [8:55:11<22:27:41, 33.75s/it] 29%|██▊       | 958/3353 [8:55:45<22:28:30, 33.78s/it] 29%|██▊       | 959/3353 [8:56:19<22:31:29, 33.87s/it] 29%|██▊       | 960/3353 [8:56:53<22:29:34, 33.84s/it]                                                       {'loss': 1.2353, 'learning_rate': 4.055059085835372e-05, 'epoch': 0.29}
 29%|██▊       | 960/3353 [8:56:53<22:29:34, 33.84s/it] 29%|██▊       | 961/3353 [8:57:27<22:31:49, 33.91s/it] 29%|██▊       | 962/3353 [8:58:01<22:29:39, 33.87s/it] 29%|██▊       | 963/3353 [8:58:35<22:27:07, 33.82s/it] 29%|██▉       | 964/3353 [8:59:08<22:25:51, 33.80s/it] 29%|██▉       | 965/3353 [8:59:42<22:24:41, 33.79s/it] 29%|██▉       | 966/3353 [9:00:16<22:23:53, 33.78s/it] 29%|██▉       | 967/3353 [9:00:50<22:28:59, 33.92s/it] 29%|██▉       | 968/3353 [9:01:24<22:26:35, 33.88s/it] 29%|██▉       | 969/3353 [9:01:58<22:28:07, 33.93s/it] 29%|██▉       | 970/3353 [9:02:32<22:25:49, 33.89s/it]                                                       {'loss': 1.2384, 'learning_rate': 4.036650341052853e-05, 'epoch': 0.29}
 29%|██▉       | 970/3353 [9:02:32<22:25:49, 33.89s/it] 29%|██▉       | 971/3353 [9:03:06<22:24:21, 33.86s/it] 29%|██▉       | 972/3353 [9:03:39<22:21:53, 33.82s/it] 29%|██▉       | 973/3353 [9:04:13<22:20:33, 33.80s/it] 29%|██▉       | 974/3353 [9:04:47<22:19:02, 33.77s/it] 29%|██▉       | 975/3353 [9:05:21<22:22:41, 33.88s/it] 29%|██▉       | 976/3353 [9:05:55<22:20:31, 33.84s/it] 29%|██▉       | 977/3353 [9:06:28<22:19:48, 33.83s/it] 29%|██▉       | 978/3353 [9:07:02<22:18:09, 33.81s/it] 29%|██▉       | 979/3353 [9:07:36<22:15:55, 33.76s/it] 29%|██▉       | 980/3353 [9:08:10<22:13:54, 33.73s/it]                                                       {'loss': 1.2339, 'learning_rate': 4.018106698578709e-05, 'epoch': 0.29}
 29%|██▉       | 980/3353 [9:08:10<22:13:54, 33.73s/it] 29%|██▉       | 981/3353 [9:08:43<22:14:14, 33.75s/it] 29%|██▉       | 982/3353 [9:09:17<22:13:24, 33.74s/it] 29%|██▉       | 983/3353 [9:09:51<22:14:31, 33.79s/it] 29%|██▉       | 984/3353 [9:10:25<22:12:18, 33.74s/it] 29%|██▉       | 985/3353 [9:10:58<22:12:27, 33.76s/it] 29%|██▉       | 986/3353 [9:11:32<22:11:53, 33.76s/it] 29%|██▉       | 987/3353 [9:12:06<22:11:42, 33.77s/it] 29%|██▉       | 988/3353 [9:12:40<22:10:33, 33.76s/it] 29%|██▉       | 989/3353 [9:13:13<22:08:11, 33.71s/it] 30%|██▉       | 990/3353 [9:13:47<22:06:26, 33.68s/it]                                                       {'loss': 1.2267, 'learning_rate': 3.9994297863008805e-05, 'epoch': 0.3}
 30%|██▉       | 990/3353 [9:13:47<22:06:26, 33.68s/it] 30%|██▉       | 991/3353 [9:14:21<22:07:08, 33.71s/it] 30%|██▉       | 992/3353 [9:14:55<22:08:15, 33.76s/it] 30%|██▉       | 993/3353 [9:15:28<22:06:45, 33.73s/it] 30%|██▉       | 994/3353 [9:16:02<22:07:18, 33.76s/it] 30%|██▉       | 995/3353 [9:16:36<22:05:04, 33.72s/it] 30%|██▉       | 996/3353 [9:17:09<22:03:14, 33.68s/it] 30%|██▉       | 997/3353 [9:17:43<22:00:56, 33.64s/it] 30%|██▉       | 998/3353 [9:18:16<22:00:09, 33.63s/it] 30%|██▉       | 999/3353 [9:18:50<22:02:38, 33.71s/it] 30%|██▉       | 1000/3353 [9:19:24<22:01:35, 33.70s/it]                                                        {'loss': 1.2349, 'learning_rate': 3.9806212438066505e-05, 'epoch': 0.3}
 30%|██▉       | 1000/3353 [9:19:24<22:01:35, 33.70s/it] 30%|██▉       | 1001/3353 [9:19:58<22:01:23, 33.71s/it] 30%|██▉       | 1002/3353 [9:20:31<21:59:43, 33.68s/it] 30%|██▉       | 1003/3353 [9:21:05<21:58:35, 33.67s/it] 30%|██▉       | 1004/3353 [9:21:39<21:57:12, 33.65s/it] 30%|██▉       | 1005/3353 [9:22:12<21:57:05, 33.66s/it] 30%|███       | 1006/3353 [9:22:46<21:57:15, 33.67s/it] 30%|███       | 1007/3353 [9:23:20<21:56:08, 33.66s/it] 30%|███       | 1008/3353 [9:23:53<21:57:23, 33.71s/it] 30%|███       | 1009/3353 [9:24:27<21:56:43, 33.70s/it] 30%|███       | 1010/3353 [9:25:01<21:57:14, 33.73s/it]                                                        {'loss': 1.2405, 'learning_rate': 3.9616827222386986e-05, 'epoch': 0.3}
 30%|███       | 1010/3353 [9:25:01<21:57:14, 33.73s/it] 30%|███       | 1011/3353 [9:25:35<21:56:32, 33.73s/it] 30%|███       | 1012/3353 [9:26:08<21:54:15, 33.68s/it] 30%|███       | 1013/3353 [9:26:42<21:52:35, 33.66s/it] 30%|███       | 1014/3353 [9:27:15<21:50:45, 33.62s/it] 30%|███       | 1015/3353 [9:27:49<21:51:47, 33.66s/it] 30%|███       | 1016/3353 [9:28:23<21:52:03, 33.69s/it] 30%|███       | 1017/3353 [9:28:56<21:50:57, 33.67s/it] 30%|███       | 1018/3353 [9:29:30<21:51:37, 33.70s/it] 30%|███       | 1019/3353 [9:30:04<21:50:40, 33.69s/it] 30%|███       | 1020/3353 [9:30:38<21:49:36, 33.68s/it]                                                        {'loss': 1.2314, 'learning_rate': 3.942615884150162e-05, 'epoch': 0.3}
 30%|███       | 1020/3353 [9:30:38<21:49:36, 33.68s/it] 30%|███       | 1021/3353 [9:31:11<21:49:19, 33.69s/it] 30%|███       | 1022/3353 [9:31:45<21:48:19, 33.68s/it] 31%|███       | 1023/3353 [9:32:19<21:49:59, 33.73s/it] 31%|███       | 1024/3353 [9:32:53<21:51:12, 33.78s/it] 31%|███       | 1025/3353 [9:33:26<21:48:46, 33.73s/it] 31%|███       | 1026/3353 [9:34:00<21:49:58, 33.78s/it] 31%|███       | 1027/3353 [9:34:34<21:47:42, 33.73s/it] 31%|███       | 1028/3353 [9:35:07<21:45:24, 33.69s/it] 31%|███       | 1029/3353 [9:35:41<21:43:58, 33.67s/it] 31%|███       | 1030/3353 [9:36:15<21:42:27, 33.64s/it]                                                        {'loss': 1.236, 'learning_rate': 3.9234224033586784e-05, 'epoch': 0.31}
 31%|███       | 1030/3353 [9:36:15<21:42:27, 33.64s/it] 31%|███       | 1031/3353 [9:36:48<21:41:29, 33.63s/it] 31%|███       | 1032/3353 [9:37:22<21:40:37, 33.62s/it] 31%|███       | 1033/3353 [9:37:55<21:39:19, 33.60s/it] 31%|███       | 1034/3353 [9:38:29<21:37:52, 33.58s/it] 31%|███       | 1035/3353 [9:39:02<21:36:53, 33.57s/it] 31%|███       | 1036/3353 [9:39:36<21:35:58, 33.56s/it] 31%|███       | 1037/3353 [9:40:09<21:35:00, 33.55s/it] 31%|███       | 1038/3353 [9:40:43<21:33:36, 33.53s/it] 31%|███       | 1039/3353 [9:41:16<21:33:11, 33.53s/it] 31%|███       | 1040/3353 [9:41:50<21:36:00, 33.62s/it]                                                        {'loss': 1.2266, 'learning_rate': 3.904103964799449e-05, 'epoch': 0.31}
 31%|███       | 1040/3353 [9:41:50<21:36:00, 33.62s/it] 31%|███       | 1041/3353 [9:42:24<21:34:50, 33.60s/it] 31%|███       | 1042/3353 [9:42:57<21:33:55, 33.59s/it] 31%|███       | 1043/3353 [9:43:31<21:32:28, 33.57s/it] 31%|███       | 1044/3353 [9:44:04<21:30:49, 33.54s/it] 31%|███       | 1045/3353 [9:44:38<21:29:29, 33.52s/it] 31%|███       | 1046/3353 [9:45:11<21:28:17, 33.51s/it] 31%|███       | 1047/3353 [9:45:45<21:27:47, 33.51s/it] 31%|███▏      | 1048/3353 [9:46:18<21:27:04, 33.50s/it] 31%|███▏      | 1049/3353 [9:46:52<21:29:07, 33.57s/it] 31%|███▏      | 1050/3353 [9:47:26<21:27:13, 33.54s/it]                                                        {'loss': 1.2271, 'learning_rate': 3.8846622643773265e-05, 'epoch': 0.31}
 31%|███▏      | 1050/3353 [9:47:26<21:27:13, 33.54s/it] 31%|███▏      | 1051/3353 [9:47:59<21:29:09, 33.60s/it] 31%|███▏      | 1052/3353 [9:48:33<21:26:34, 33.55s/it] 31%|███▏      | 1053/3353 [9:49:06<21:25:12, 33.53s/it] 31%|███▏      | 1054/3353 [9:49:40<21:23:42, 33.50s/it] 31%|███▏      | 1055/3353 [9:50:13<21:22:50, 33.49s/it] 31%|███▏      | 1056/3353 [9:50:47<21:23:15, 33.52s/it] 32%|███▏      | 1057/3353 [9:51:20<21:23:07, 33.53s/it] 32%|███▏      | 1058/3353 [9:51:54<21:22:16, 33.52s/it] 32%|███▏      | 1059/3353 [9:52:27<21:21:19, 33.51s/it] 32%|███▏      | 1060/3353 [9:53:01<21:20:10, 33.50s/it]                                                        {'loss': 1.2331, 'learning_rate': 3.86509900881793e-05, 'epoch': 0.32}
 32%|███▏      | 1060/3353 [9:53:01<21:20:10, 33.50s/it] 32%|███▏      | 1061/3353 [9:53:34<21:19:32, 33.50s/it] 32%|███▏      | 1062/3353 [9:54:08<21:19:09, 33.50s/it] 32%|███▏      | 1063/3353 [9:54:41<21:19:04, 33.51s/it] 32%|███▏      | 1064/3353 [9:55:15<21:20:09, 33.56s/it] 32%|███▏      | 1065/3353 [9:55:49<21:20:26, 33.58s/it] 32%|███▏      | 1066/3353 [9:56:22<21:18:51, 33.55s/it] 32%|███▏      | 1067/3353 [9:56:56<21:19:07, 33.57s/it] 32%|███▏      | 1068/3353 [9:57:29<21:18:01, 33.56s/it] 32%|███▏      | 1069/3353 [9:58:03<21:16:33, 33.53s/it] 32%|███▏      | 1070/3353 [9:58:36<21:15:16, 33.52s/it]                                                        {'loss': 1.2311, 'learning_rate': 3.8454159155178255e-05, 'epoch': 0.32}
 32%|███▏      | 1070/3353 [9:58:36<21:15:16, 33.52s/it] 32%|███▏      | 1071/3353 [9:59:10<21:14:54, 33.52s/it] 32%|███▏      | 1072/3353 [9:59:43<21:13:39, 33.50s/it] 32%|███▏      | 1073/3353 [10:00:17<21:15:49, 33.57s/it] 32%|███▏      | 1074/3353 [10:00:50<21:13:47, 33.54s/it] 32%|███▏      | 1075/3353 [10:01:24<21:15:11, 33.59s/it] 32%|███▏      | 1076/3353 [10:01:58<21:13:25, 33.56s/it] 32%|███▏      | 1077/3353 [10:02:31<21:13:16, 33.57s/it] 32%|███▏      | 1078/3353 [10:03:05<21:11:18, 33.53s/it] 32%|███▏      | 1079/3353 [10:03:38<21:10:41, 33.53s/it] 32%|███▏      | 1080/3353 [10:04:12<21:11:22, 33.56s/it]                                                         {'loss': 1.2333, 'learning_rate': 3.825614712393754e-05, 'epoch': 0.32}
 32%|███▏      | 1080/3353 [10:04:12<21:11:22, 33.56s/it] 32%|███▏      | 1081/3353 [10:04:45<21:12:35, 33.61s/it] 32%|███▏      | 1082/3353 [10:05:19<21:10:53, 33.58s/it] 32%|███▏      | 1083/3353 [10:05:53<21:11:08, 33.60s/it] 32%|███▏      | 1084/3353 [10:06:26<21:09:13, 33.56s/it] 32%|███▏      | 1085/3353 [10:07:00<21:07:36, 33.53s/it] 32%|███▏      | 1086/3353 [10:07:33<21:06:32, 33.52s/it] 32%|███▏      | 1087/3353 [10:08:07<21:05:34, 33.51s/it] 32%|███▏      | 1088/3353 [10:08:40<21:06:26, 33.55s/it] 32%|███▏      | 1089/3353 [10:09:14<21:06:08, 33.56s/it] 33%|███▎      | 1090/3353 [10:09:47<21:04:42, 33.53s/it]                                                         {'loss': 1.2252, 'learning_rate': 3.805697137730945e-05, 'epoch': 0.33}
 33%|███▎      | 1090/3353 [10:09:47<21:04:42, 33.53s/it] 33%|███▎      | 1091/3353 [10:10:21<21:03:38, 33.52s/it] 33%|███▎      | 1092/3353 [10:10:54<21:02:38, 33.51s/it] 33%|███▎      | 1093/3353 [10:11:28<21:01:55, 33.50s/it] 33%|███▎      | 1094/3353 [10:12:01<21:00:57, 33.49s/it] 33%|███▎      | 1095/3353 [10:12:35<21:00:12, 33.49s/it] 33%|███▎      | 1096/3353 [10:13:08<20:59:15, 33.48s/it] 33%|███▎      | 1097/3353 [10:13:42<21:00:20, 33.52s/it] 33%|███▎      | 1098/3353 [10:14:15<20:59:12, 33.50s/it] 33%|███▎      | 1099/3353 [10:14:49<20:58:54, 33.51s/it] 33%|███▎      | 1100/3353 [10:15:22<20:57:45, 33.50s/it]                                                         {'loss': 1.2267, 'learning_rate': 3.7856649400305216e-05, 'epoch': 0.33}
 33%|███▎      | 1100/3353 [10:15:22<20:57:45, 33.50s/it] 33%|███▎      | 1101/3353 [10:15:56<20:57:24, 33.50s/it] 33%|███▎      | 1102/3353 [10:16:29<20:57:25, 33.52s/it] 33%|███▎      | 1103/3353 [10:17:03<20:56:59, 33.52s/it] 33%|███▎      | 1104/3353 [10:17:36<20:56:04, 33.51s/it] 33%|███▎      | 1105/3353 [10:18:10<20:57:05, 33.55s/it] 33%|███▎      | 1106/3353 [10:18:44<20:58:09, 33.60s/it] 33%|███▎      | 1107/3353 [10:19:17<20:55:59, 33.55s/it] 33%|███▎      | 1108/3353 [10:19:51<20:56:41, 33.59s/it] 33%|███▎      | 1109/3353 [10:20:24<20:54:54, 33.55s/it] 33%|███▎      | 1110/3353 [10:20:58<20:53:33, 33.53s/it]                                                         {'loss': 1.2307, 'learning_rate': 3.765519877856001e-05, 'epoch': 0.33}
 33%|███▎      | 1110/3353 [10:20:58<20:53:33, 33.53s/it] 33%|███▎      | 1111/3353 [10:21:31<20:52:48, 33.53s/it] 33%|███▎      | 1112/3353 [10:22:05<20:51:00, 33.49s/it] 33%|███▎      | 1113/3353 [10:22:38<20:50:11, 33.49s/it] 33%|███▎      | 1114/3353 [10:23:11<20:49:21, 33.48s/it] 33%|███▎      | 1115/3353 [10:23:45<20:48:34, 33.47s/it] 33%|███▎      | 1116/3353 [10:24:18<20:47:40, 33.46s/it] 33%|███▎      | 1117/3353 [10:24:52<20:47:18, 33.47s/it] 33%|███▎      | 1118/3353 [10:25:25<20:46:49, 33.47s/it] 33%|███▎      | 1119/3353 [10:25:59<20:46:12, 33.47s/it] 33%|███▎      | 1120/3353 [10:26:32<20:45:48, 33.47s/it]                                                         {'loss': 1.2648, 'learning_rate': 3.745263719678915e-05, 'epoch': 0.33}
 33%|███▎      | 1120/3353 [10:26:32<20:45:48, 33.47s/it] 33%|███▎      | 1121/3353 [10:27:06<20:47:10, 33.53s/it] 33%|███▎      | 1122/3353 [10:27:40<20:47:22, 33.55s/it] 33%|███▎      | 1123/3353 [10:28:13<20:45:44, 33.52s/it] 34%|███▎      | 1124/3353 [10:28:47<20:46:29, 33.55s/it] 34%|███▎      | 1125/3353 [10:29:20<20:44:51, 33.52s/it] 34%|███▎      | 1126/3353 [10:29:54<20:43:07, 33.49s/it] 34%|███▎      | 1127/3353 [10:30:27<20:42:18, 33.49s/it] 34%|███▎      | 1128/3353 [10:31:00<20:41:31, 33.48s/it] 34%|███▎      | 1129/3353 [10:31:34<20:43:01, 33.53s/it] 34%|███▎      | 1130/3353 [10:32:08<20:44:06, 33.58s/it]                                                         {'loss': 1.2908, 'learning_rate': 3.724898243723566e-05, 'epoch': 0.34}
 34%|███▎      | 1130/3353 [10:32:08<20:44:06, 33.58s/it] 34%|███▎      | 1131/3353 [10:32:41<20:42:30, 33.55s/it] 34%|███▍      | 1132/3353 [10:33:15<20:43:09, 33.58s/it] 34%|███▍      | 1133/3353 [10:33:48<20:41:57, 33.57s/it] 34%|███▍      | 1134/3353 [10:34:22<20:40:14, 33.54s/it] 34%|███▍      | 1135/3353 [10:34:55<20:39:04, 33.52s/it] 34%|███▍      | 1136/3353 [10:35:29<20:37:55, 33.50s/it] 34%|███▍      | 1137/3353 [10:36:02<20:37:29, 33.51s/it] 34%|███▍      | 1138/3353 [10:36:36<20:38:58, 33.56s/it] 34%|███▍      | 1139/3353 [10:37:10<20:37:07, 33.53s/it] 34%|███▍      | 1140/3353 [10:37:43<20:38:04, 33.57s/it]                                                         {'loss': 1.2975, 'learning_rate': 3.704425237810919e-05, 'epoch': 0.34}
 34%|███▍      | 1140/3353 [10:37:43<20:38:04, 33.57s/it] 34%|███▍      | 1141/3353 [10:38:17<20:36:23, 33.54s/it] 34%|███▍      | 1142/3353 [10:38:50<20:35:07, 33.52s/it] 34%|███▍      | 1143/3353 [10:39:24<20:34:08, 33.51s/it] 34%|███▍      | 1144/3353 [10:39:57<20:32:51, 33.49s/it] 34%|███▍      | 1145/3353 [10:40:31<20:33:56, 33.53s/it] 34%|███▍      | 1146/3353 [10:41:04<20:32:16, 33.50s/it] 34%|███▍      | 1147/3353 [10:41:38<20:31:33, 33.50s/it] 34%|███▍      | 1148/3353 [10:42:11<20:31:16, 33.50s/it] 34%|███▍      | 1149/3353 [10:42:45<20:30:45, 33.51s/it] 34%|███▍      | 1150/3353 [10:43:18<20:29:52, 33.50s/it]                                                         {'loss': 1.309, 'learning_rate': 3.683846499201655e-05, 'epoch': 0.34}
 34%|███▍      | 1150/3353 [10:43:18<20:29:52, 33.50s/it] 34%|███▍      | 1151/3353 [10:43:52<20:29:45, 33.51s/it] 34%|███▍      | 1152/3353 [10:44:25<20:28:50, 33.50s/it] 34%|███▍      | 1153/3353 [10:44:59<20:30:06, 33.55s/it] 34%|███▍      | 1154/3353 [10:45:32<20:30:21, 33.57s/it] 34%|███▍      | 1155/3353 [10:46:06<20:29:23, 33.56s/it] 34%|███▍      | 1156/3353 [10:46:39<20:28:23, 33.55s/it] 35%|███▍      | 1157/3353 [10:47:13<20:26:32, 33.51s/it] 35%|███▍      | 1158/3353 [10:47:46<20:25:20, 33.49s/it] 35%|███▍      | 1159/3353 [10:48:20<20:24:28, 33.49s/it] 35%|███▍      | 1160/3353 [10:48:53<20:24:30, 33.50s/it]                                                         {'loss': 1.3286, 'learning_rate': 3.663163834438395e-05, 'epoch': 0.35}
 35%|███▍      | 1160/3353 [10:48:53<20:24:30, 33.50s/it] 35%|███▍      | 1161/3353 [10:49:27<20:24:19, 33.51s/it] 35%|███▍      | 1162/3353 [10:50:00<20:24:09, 33.52s/it] 35%|███▍      | 1163/3353 [10:50:34<20:25:01, 33.56s/it] 35%|███▍      | 1164/3353 [10:51:08<20:23:10, 33.53s/it] 35%|███▍      | 1165/3353 [10:51:41<20:24:11, 33.57s/it] 35%|███▍      | 1166/3353 [10:52:15<20:22:27, 33.54s/it] 35%|███▍      | 1167/3353 [10:52:48<20:20:45, 33.51s/it] 35%|███▍      | 1168/3353 [10:53:22<20:19:39, 33.49s/it] 35%|███▍      | 1169/3353 [10:53:55<20:19:09, 33.49s/it] 35%|███▍      | 1170/3353 [10:54:29<20:20:12, 33.54s/it]                                                         {'loss': 1.3287, 'learning_rate': 3.642379059187109e-05, 'epoch': 0.35}
 35%|███▍      | 1170/3353 [10:54:29<20:20:12, 33.54s/it] 35%|███▍      | 1171/3353 [10:55:02<20:19:03, 33.52s/it] 35%|███▍      | 1172/3353 [10:55:36<20:17:44, 33.50s/it] 35%|███▍      | 1173/3353 [10:56:09<20:16:58, 33.49s/it] 35%|███▌      | 1174/3353 [10:56:43<20:16:33, 33.50s/it] 35%|███▌      | 1175/3353 [10:57:16<20:15:38, 33.49s/it] 35%|███▌      | 1176/3353 [10:57:50<20:15:18, 33.50s/it] 35%|███▌      | 1177/3353 [10:58:23<20:14:49, 33.50s/it] 35%|███▌      | 1178/3353 [10:58:57<20:14:03, 33.49s/it] 35%|███▌      | 1179/3353 [10:59:30<20:15:01, 33.53s/it] 35%|███▌      | 1180/3353 [11:00:04<20:13:32, 33.51s/it]                                                         {'loss': 1.3007, 'learning_rate': 3.621493998077727e-05, 'epoch': 0.35}
 35%|███▌      | 1180/3353 [11:00:04<20:13:32, 33.51s/it] 35%|███▌      | 1181/3353 [11:00:37<20:14:55, 33.56s/it] 35%|███▌      | 1182/3353 [11:01:11<20:13:14, 33.53s/it] 35%|███▌      | 1183/3353 [11:01:44<20:12:04, 33.51s/it] 35%|███▌      | 1184/3353 [11:02:18<20:11:04, 33.50s/it] 35%|███▌      | 1185/3353 [11:02:51<20:10:06, 33.49s/it] 35%|███▌      | 1186/3353 [11:03:25<20:10:26, 33.51s/it] 35%|███▌      | 1187/3353 [11:03:58<20:11:26, 33.56s/it] 35%|███▌      | 1188/3353 [11:04:32<20:09:44, 33.53s/it] 35%|███▌      | 1189/3353 [11:05:06<20:10:45, 33.57s/it] 35%|███▌      | 1190/3353 [11:05:39<20:08:45, 33.53s/it]                                                         {'loss': 1.2959, 'learning_rate': 3.6005104845439566e-05, 'epoch': 0.35}
 35%|███▌      | 1190/3353 [11:05:39<20:08:45, 33.53s/it] 36%|███▌      | 1191/3353 [11:06:13<20:07:59, 33.52s/it] 36%|███▌      | 1192/3353 [11:06:46<20:06:33, 33.50s/it] 36%|███▌      | 1193/3353 [11:07:19<20:06:09, 33.50s/it] 36%|███▌      | 1194/3353 [11:07:53<20:07:09, 33.55s/it] 36%|███▌      | 1195/3353 [11:08:27<20:07:44, 33.58s/it] 36%|███▌      | 1196/3353 [11:09:00<20:05:38, 33.54s/it] 36%|███▌      | 1197/3353 [11:09:34<20:06:41, 33.58s/it] 36%|███▌      | 1198/3353 [11:10:07<20:04:24, 33.53s/it] 36%|███▌      | 1199/3353 [11:10:41<20:03:04, 33.51s/it] 36%|███▌      | 1200/3353 [11:11:14<20:02:32, 33.51s/it]                                                         {'loss': 1.306, 'learning_rate': 3.579430360662334e-05, 'epoch': 0.36}
 36%|███▌      | 1200/3353 [11:11:15<20:02:32, 33.51s/it] 36%|███▌      | 1201/3353 [11:11:49<20:13:17, 33.83s/it] 36%|███▌      | 1202/3353 [11:12:22<20:08:29, 33.71s/it] 36%|███▌      | 1203/3353 [11:12:56<20:05:33, 33.64s/it] 36%|███▌      | 1204/3353 [11:13:29<20:03:18, 33.60s/it] 36%|███▌      | 1205/3353 [11:14:03<20:01:21, 33.56s/it] 36%|███▌      | 1206/3353 [11:14:36<19:59:22, 33.52s/it] 36%|███▌      | 1207/3353 [11:15:10<19:57:56, 33.49s/it] 36%|███▌      | 1208/3353 [11:15:43<19:57:07, 33.49s/it] 36%|███▌      | 1209/3353 [11:16:17<19:56:42, 33.49s/it] 36%|███▌      | 1210/3353 [11:16:50<19:57:36, 33.53s/it]                                                         {'loss': 1.3119, 'learning_rate': 3.5582554769905144e-05, 'epoch': 0.36}
 36%|███▌      | 1210/3353 [11:16:50<19:57:36, 33.53s/it] 36%|███▌      | 1211/3353 [11:17:24<19:58:40, 33.58s/it] 36%|███▌      | 1212/3353 [11:17:57<19:57:16, 33.55s/it] 36%|███▌      | 1213/3353 [11:18:31<19:57:07, 33.56s/it] 36%|███▌      | 1214/3353 [11:19:04<19:55:26, 33.53s/it] 36%|███▌      | 1215/3353 [11:19:38<19:54:31, 33.52s/it] 36%|███▋      | 1216/3353 [11:20:11<19:53:05, 33.50s/it] 36%|███▋      | 1217/3353 [11:20:45<19:51:50, 33.48s/it] 36%|███▋      | 1218/3353 [11:21:18<19:52:48, 33.52s/it] 36%|███▋      | 1219/3353 [11:21:52<19:51:27, 33.50s/it] 36%|███▋      | 1220/3353 [11:22:26<19:53:03, 33.56s/it]                                                         {'loss': 1.3098, 'learning_rate': 3.5369876924048153e-05, 'epoch': 0.36}
 36%|███▋      | 1220/3353 [11:22:26<19:53:03, 33.56s/it] 36%|███▋      | 1221/3353 [11:22:59<19:54:00, 33.60s/it] 36%|███▋      | 1222/3353 [11:23:33<19:54:04, 33.62s/it] 36%|███▋      | 1223/3353 [11:24:06<19:51:34, 33.57s/it] 37%|███▋      | 1224/3353 [11:24:40<19:49:44, 33.53s/it] 37%|███▋      | 1225/3353 [11:25:13<19:48:56, 33.52s/it] 37%|███▋      | 1226/3353 [11:25:47<19:47:45, 33.50s/it] 37%|███▋      | 1227/3353 [11:26:20<19:47:36, 33.52s/it] 37%|███▋      | 1228/3353 [11:26:54<19:47:06, 33.52s/it] 37%|███▋      | 1229/3353 [11:27:27<19:45:56, 33.50s/it] 37%|███▋      | 1230/3353 [11:28:01<19:45:01, 33.49s/it]                                                         {'loss': 1.3122, 'learning_rate': 3.515628873937032e-05, 'epoch': 0.37}
 37%|███▋      | 1230/3353 [11:28:02<19:45:01, 33.49s/it] 37%|███▋      | 1231/3353 [11:28:35<19:54:36, 33.78s/it] 37%|███▋      | 1232/3353 [11:29:09<19:50:50, 33.69s/it] 37%|███▋      | 1233/3353 [11:29:42<19:47:39, 33.61s/it] 37%|███▋      | 1234/3353 [11:30:16<19:45:51, 33.58s/it] 37%|███▋      | 1235/3353 [11:30:49<19:45:51, 33.59s/it] 37%|███▋      | 1236/3353 [11:31:23<19:45:54, 33.61s/it] 37%|███▋      | 1237/3353 [11:31:56<19:43:48, 33.57s/it] 37%|███▋      | 1238/3353 [11:32:30<19:43:42, 33.58s/it] 37%|███▋      | 1239/3353 [11:33:03<19:42:15, 33.56s/it] 37%|███▋      | 1240/3353 [11:33:37<19:40:50, 33.53s/it]                                                         {'loss': 1.2971, 'learning_rate': 3.4941808966105403e-05, 'epoch': 0.37}
 37%|███▋      | 1240/3353 [11:33:37<19:40:50, 33.53s/it] 37%|███▋      | 1241/3353 [11:34:10<19:40:03, 33.52s/it] 37%|███▋      | 1242/3353 [11:34:44<19:38:59, 33.51s/it] 37%|███▋      | 1243/3353 [11:35:17<19:38:32, 33.51s/it] 37%|███▋      | 1244/3353 [11:35:51<19:39:55, 33.57s/it] 37%|███▋      | 1245/3353 [11:36:25<19:38:19, 33.54s/it] 37%|███▋      | 1246/3353 [11:36:58<19:39:00, 33.57s/it] 37%|███▋      | 1247/3353 [11:37:32<19:37:16, 33.54s/it] 37%|███▋      | 1248/3353 [11:38:05<19:35:44, 33.51s/it] 37%|███▋      | 1249/3353 [11:38:39<19:34:38, 33.50s/it] 37%|███▋      | 1250/3353 [11:39:12<19:33:59, 33.49s/it]                                                         {'loss': 1.2886, 'learning_rate': 3.4726456432756885e-05, 'epoch': 0.37}
 37%|███▋      | 1250/3353 [11:39:12<19:33:59, 33.49s/it] 37%|███▋      | 1251/3353 [11:39:46<19:34:56, 33.54s/it] 37%|███▋      | 1252/3353 [11:40:19<19:35:48, 33.58s/it] 37%|███▋      | 1253/3353 [11:40:53<19:33:57, 33.54s/it] 37%|███▋      | 1254/3353 [11:41:27<19:34:37, 33.58s/it] 37%|███▋      | 1255/3353 [11:42:00<19:33:06, 33.55s/it] 37%|███▋      | 1256/3353 [11:42:34<19:31:32, 33.52s/it] 37%|███▋      | 1257/3353 [11:43:07<19:30:23, 33.50s/it] 38%|███▊      | 1258/3353 [11:43:40<19:29:39, 33.50s/it] 38%|███▊      | 1259/3353 [11:44:14<19:31:04, 33.56s/it] 38%|███▊      | 1260/3353 [11:44:48<19:30:17, 33.55s/it]                                                         {'loss': 1.295, 'learning_rate': 3.451025004444512e-05, 'epoch': 0.38}
 38%|███▊      | 1260/3353 [11:44:48<19:30:17, 33.55s/it] 38%|███▊      | 1261/3353 [11:45:21<19:29:41, 33.55s/it] 38%|███▊      | 1262/3353 [11:45:55<19:28:27, 33.53s/it] 38%|███▊      | 1263/3353 [11:46:28<19:27:29, 33.52s/it] 38%|███▊      | 1264/3353 [11:47:02<19:26:25, 33.50s/it] 38%|███▊      | 1265/3353 [11:47:35<19:25:45, 33.50s/it] 38%|███▊      | 1266/3353 [11:48:09<19:24:59, 33.49s/it] 38%|███▊      | 1267/3353 [11:48:42<19:24:06, 33.48s/it] 38%|███▊      | 1268/3353 [11:49:16<19:24:25, 33.51s/it] 38%|███▊      | 1269/3353 [11:49:49<19:23:50, 33.51s/it] 38%|███▊      | 1270/3353 [11:50:23<19:24:01, 33.53s/it]                                                         {'loss': 1.2874, 'learning_rate': 3.42932087812477e-05, 'epoch': 0.38}
 38%|███▊      | 1270/3353 [11:50:23<19:24:01, 33.53s/it] 38%|███▊      | 1271/3353 [11:50:56<19:23:12, 33.52s/it] 38%|███▊      | 1272/3353 [11:51:30<19:21:50, 33.50s/it] 38%|███▊      | 1273/3353 [11:52:03<19:20:49, 33.49s/it] 38%|███▊      | 1274/3353 [11:52:37<19:19:41, 33.47s/it] 38%|███▊      | 1275/3353 [11:53:10<19:20:56, 33.52s/it] 38%|███▊      | 1276/3353 [11:53:44<19:20:09, 33.51s/it] 38%|███▊      | 1277/3353 [11:54:17<19:21:25, 33.57s/it] 38%|███▊      | 1278/3353 [11:54:51<19:19:55, 33.54s/it] 38%|███▊      | 1279/3353 [11:55:25<19:20:24, 33.57s/it] 38%|███▊      | 1280/3353 [11:55:58<19:18:59, 33.55s/it]                                                         {'loss': 1.2666, 'learning_rate': 3.407535169653323e-05, 'epoch': 0.38}
 38%|███▊      | 1280/3353 [11:55:58<19:18:59, 33.55s/it] 38%|███▊      | 1281/3353 [11:56:32<19:18:25, 33.55s/it] 38%|███▊      | 1282/3353 [11:57:05<19:17:30, 33.53s/it] 38%|███▊      | 1283/3353 [11:57:39<19:18:02, 33.57s/it] 38%|███▊      | 1284/3353 [11:58:12<19:16:38, 33.54s/it] 38%|███▊      | 1285/3353 [11:58:46<19:15:48, 33.53s/it] 38%|███▊      | 1286/3353 [11:59:19<19:14:41, 33.52s/it] 38%|███▊      | 1287/3353 [11:59:53<19:13:32, 33.50s/it] 38%|███▊      | 1288/3353 [12:00:26<19:12:37, 33.49s/it] 38%|███▊      | 1289/3353 [12:01:00<19:11:32, 33.48s/it] 38%|███▊      | 1290/3353 [12:01:33<19:10:52, 33.47s/it]                                                         {'loss': 1.2598, 'learning_rate': 3.3856697915288755e-05, 'epoch': 0.38}
 38%|███▊      | 1290/3353 [12:01:33<19:10:52, 33.47s/it] 39%|███▊      | 1291/3353 [12:02:07<19:10:21, 33.47s/it] 39%|███▊      | 1292/3353 [12:02:40<19:09:54, 33.48s/it] 39%|███▊      | 1293/3353 [12:03:14<19:10:54, 33.52s/it] 39%|███▊      | 1294/3353 [12:03:47<19:09:37, 33.50s/it] 39%|███▊      | 1295/3353 [12:04:21<19:10:40, 33.55s/it] 39%|███▊      | 1296/3353 [12:04:54<19:09:03, 33.52s/it] 39%|███▊      | 1297/3353 [12:05:28<19:07:58, 33.50s/it] 39%|███▊      | 1298/3353 [12:06:01<19:06:49, 33.48s/it] 39%|███▊      | 1299/3353 [12:06:35<19:05:57, 33.47s/it] 39%|███▉      | 1300/3353 [12:07:08<19:06:55, 33.52s/it]                                                         {'loss': 1.2431, 'learning_rate': 3.363726663244076e-05, 'epoch': 0.39}
 39%|███▉      | 1300/3353 [12:07:08<19:06:55, 33.52s/it] 39%|███▉      | 1301/3353 [12:07:42<19:08:13, 33.57s/it] 39%|███▉      | 1302/3353 [12:08:15<19:06:10, 33.53s/it] 39%|███▉      | 1303/3353 [12:08:49<19:07:34, 33.59s/it] 39%|███▉      | 1304/3353 [12:09:22<19:05:58, 33.56s/it] 39%|███▉      | 1305/3353 [12:09:56<19:04:24, 33.53s/it] 39%|███▉      | 1306/3353 [12:10:29<19:02:50, 33.50s/it] 39%|███▉      | 1307/3353 [12:11:03<19:01:54, 33.49s/it] 39%|███▉      | 1308/3353 [12:11:36<19:01:26, 33.49s/it] 39%|███▉      | 1309/3353 [12:12:10<19:02:21, 33.53s/it] 39%|███▉      | 1310/3353 [12:12:43<19:01:29, 33.52s/it]                                                         {'loss': 1.2426, 'learning_rate': 3.341707711117018e-05, 'epoch': 0.39}
 39%|███▉      | 1310/3353 [12:12:44<19:01:29, 33.52s/it] 39%|███▉      | 1311/3353 [12:13:17<19:02:15, 33.56s/it] 39%|███▉      | 1312/3353 [12:13:51<19:00:25, 33.53s/it] 39%|███▉      | 1313/3353 [12:14:24<18:59:35, 33.52s/it] 39%|███▉      | 1314/3353 [12:14:58<18:58:42, 33.51s/it] 39%|███▉      | 1315/3353 [12:15:31<18:58:08, 33.51s/it] 39%|███▉      | 1316/3353 [12:16:05<18:58:23, 33.53s/it] 39%|███▉      | 1317/3353 [12:16:38<18:57:41, 33.53s/it] 39%|███▉      | 1318/3353 [12:17:12<18:56:37, 33.51s/it] 39%|███▉      | 1319/3353 [12:17:45<18:55:32, 33.50s/it] 39%|███▉      | 1320/3353 [12:18:19<18:55:00, 33.50s/it]                                                         {'loss': 1.2345, 'learning_rate': 3.319614868122128e-05, 'epoch': 0.39}
 39%|███▉      | 1320/3353 [12:18:19<18:55:00, 33.50s/it] 39%|███▉      | 1321/3353 [12:18:52<18:54:12, 33.49s/it] 39%|███▉      | 1322/3353 [12:19:26<18:53:30, 33.49s/it] 39%|███▉      | 1323/3353 [12:19:59<18:52:36, 33.48s/it] 39%|███▉      | 1324/3353 [12:20:33<18:53:27, 33.52s/it] 40%|███▉      | 1325/3353 [12:21:06<18:53:16, 33.53s/it] 40%|███▉      | 1326/3353 [12:21:40<18:51:50, 33.50s/it] 40%|███▉      | 1327/3353 [12:22:13<18:51:43, 33.52s/it] 40%|███▉      | 1328/3353 [12:22:47<18:51:01, 33.51s/it] 40%|███▉      | 1329/3353 [12:23:20<18:49:44, 33.49s/it] 40%|███▉      | 1330/3353 [12:23:54<18:48:39, 33.47s/it]                                                         {'loss': 1.2373, 'learning_rate': 3.297450073720481e-05, 'epoch': 0.4}
 40%|███▉      | 1330/3353 [12:23:54<18:48:39, 33.47s/it] 40%|███▉      | 1331/3353 [12:24:27<18:48:18, 33.48s/it] 40%|███▉      | 1332/3353 [12:25:00<18:47:17, 33.47s/it] 40%|███▉      | 1333/3353 [12:25:34<18:46:06, 33.45s/it] 40%|███▉      | 1334/3353 [12:26:08<18:47:29, 33.51s/it] 40%|███▉      | 1335/3353 [12:26:41<18:46:19, 33.49s/it] 40%|███▉      | 1336/3353 [12:27:15<18:47:09, 33.53s/it] 40%|███▉      | 1337/3353 [12:27:48<18:46:23, 33.52s/it] 40%|███▉      | 1338/3353 [12:28:22<18:45:36, 33.52s/it] 40%|███▉      | 1339/3353 [12:28:55<18:44:18, 33.49s/it] 40%|███▉      | 1340/3353 [12:29:29<18:45:01, 33.53s/it]                                                         {'loss': 1.232, 'learning_rate': 3.275215273689538e-05, 'epoch': 0.4}
 40%|███▉      | 1340/3353 [12:29:29<18:45:01, 33.53s/it] 40%|███▉      | 1341/3353 [12:30:02<18:44:03, 33.52s/it] 40%|████      | 1342/3353 [12:30:36<18:43:04, 33.51s/it] 40%|████      | 1343/3353 [12:31:09<18:41:49, 33.49s/it] 40%|████      | 1344/3353 [12:31:43<18:40:57, 33.48s/it] 40%|████      | 1345/3353 [12:32:16<18:40:34, 33.48s/it] 40%|████      | 1346/3353 [12:32:50<18:40:05, 33.49s/it] 40%|████      | 1347/3353 [12:33:23<18:39:02, 33.47s/it] 40%|████      | 1348/3353 [12:33:57<18:40:14, 33.52s/it] 40%|████      | 1349/3353 [12:34:30<18:38:44, 33.50s/it] 40%|████      | 1350/3353 [12:35:04<18:39:22, 33.53s/it]                                                         {'loss': 1.2216, 'learning_rate': 3.2529124199523367e-05, 'epoch': 0.4}
 40%|████      | 1350/3353 [12:35:04<18:39:22, 33.53s/it] 40%|████      | 1351/3353 [12:35:37<18:38:57, 33.54s/it] 40%|████      | 1352/3353 [12:36:11<18:39:00, 33.55s/it] 40%|████      | 1353/3353 [12:36:44<18:37:18, 33.52s/it] 40%|████      | 1354/3353 [12:37:18<18:36:12, 33.50s/it] 40%|████      | 1355/3353 [12:37:51<18:35:08, 33.49s/it] 40%|████      | 1356/3353 [12:38:25<18:34:38, 33.49s/it] 40%|████      | 1357/3353 [12:38:58<18:34:08, 33.49s/it] 41%|████      | 1358/3353 [12:39:32<18:34:50, 33.53s/it] 41%|████      | 1359/3353 [12:40:05<18:33:15, 33.50s/it] 41%|████      | 1360/3353 [12:40:39<18:34:09, 33.54s/it]                                                         {'loss': 1.2237, 'learning_rate': 3.230543470406129e-05, 'epoch': 0.41}
 41%|████      | 1360/3353 [12:40:39<18:34:09, 33.54s/it] 41%|████      | 1361/3353 [12:41:12<18:33:11, 33.53s/it] 41%|████      | 1362/3353 [12:41:46<18:31:40, 33.50s/it] 41%|████      | 1363/3353 [12:42:19<18:30:50, 33.49s/it] 41%|████      | 1364/3353 [12:42:53<18:29:55, 33.48s/it] 41%|████      | 1365/3353 [12:43:26<18:30:41, 33.52s/it] 41%|████      | 1366/3353 [12:44:00<18:31:19, 33.56s/it] 41%|████      | 1367/3353 [12:44:33<18:29:39, 33.52s/it] 41%|████      | 1368/3353 [12:45:07<18:30:32, 33.57s/it] 41%|████      | 1369/3353 [12:45:41<18:28:47, 33.53s/it] 41%|████      | 1370/3353 [12:46:14<18:27:50, 33.52s/it]                                                         {'loss': 1.2156, 'learning_rate': 3.208110388750517e-05, 'epoch': 0.41}
 41%|████      | 1370/3353 [12:46:14<18:27:50, 33.52s/it] 41%|████      | 1371/3353 [12:46:47<18:27:04, 33.51s/it] 41%|████      | 1372/3353 [12:47:21<18:25:54, 33.50s/it] 41%|████      | 1373/3353 [12:47:54<18:25:18, 33.49s/it] 41%|████      | 1374/3353 [12:48:28<18:24:32, 33.49s/it] 41%|████      | 1375/3353 [12:49:01<18:23:29, 33.47s/it] 41%|████      | 1376/3353 [12:49:35<18:22:36, 33.46s/it] 41%|████      | 1377/3353 [12:50:08<18:21:49, 33.46s/it] 41%|████      | 1378/3353 [12:50:42<18:21:10, 33.45s/it] 41%|████      | 1379/3353 [12:51:15<18:20:22, 33.45s/it] 41%|████      | 1380/3353 [12:51:49<18:19:44, 33.44s/it]                                                         {'loss': 1.2151, 'learning_rate': 3.185615144315054e-05, 'epoch': 0.41}
 41%|████      | 1380/3353 [12:51:49<18:19:44, 33.44s/it] 41%|████      | 1381/3353 [12:52:22<18:21:12, 33.51s/it] 41%|████      | 1382/3353 [12:52:56<18:21:28, 33.53s/it] 41%|████      | 1383/3353 [12:53:29<18:20:01, 33.50s/it] 41%|████▏     | 1384/3353 [12:54:03<18:19:44, 33.51s/it] 41%|████▏     | 1385/3353 [12:54:36<18:18:35, 33.49s/it] 41%|████▏     | 1386/3353 [12:55:10<18:17:36, 33.48s/it] 41%|████▏     | 1387/3353 [12:55:43<18:16:51, 33.47s/it] 41%|████▏     | 1388/3353 [12:56:17<18:16:08, 33.47s/it] 41%|████▏     | 1389/3353 [12:56:50<18:17:39, 33.53s/it] 41%|████▏     | 1390/3353 [12:57:24<18:15:54, 33.50s/it]                                                         {'loss': 1.2232, 'learning_rate': 3.163059711886368e-05, 'epoch': 0.41}
 41%|████▏     | 1390/3353 [12:57:24<18:15:54, 33.50s/it] 41%|████▏     | 1391/3353 [12:57:57<18:17:19, 33.56s/it] 42%|████▏     | 1392/3353 [12:58:31<18:15:43, 33.53s/it] 42%|████▏     | 1393/3353 [12:59:04<18:16:07, 33.56s/it] 42%|████▏     | 1394/3353 [12:59:38<18:14:31, 33.52s/it] 42%|████▏     | 1395/3353 [13:00:11<18:13:16, 33.50s/it] 42%|████▏     | 1396/3353 [13:00:45<18:12:23, 33.49s/it] 42%|████▏     | 1397/3353 [13:01:18<18:11:03, 33.47s/it] 42%|████▏     | 1398/3353 [13:01:52<18:10:28, 33.47s/it] 42%|████▏     | 1399/3353 [13:02:25<18:10:00, 33.47s/it] 42%|████▏     | 1400/3353 [13:02:59<18:09:01, 33.46s/it]                                                         {'loss': 1.208, 'learning_rate': 3.140446071534803e-05, 'epoch': 0.42}
 42%|████▏     | 1400/3353 [13:02:59<18:09:01, 33.46s/it] 42%|████▏     | 1401/3353 [13:03:32<18:08:50, 33.47s/it] 42%|████▏     | 1402/3353 [13:04:06<18:08:17, 33.47s/it] 42%|████▏     | 1403/3353 [13:04:39<18:07:18, 33.46s/it] 42%|████▏     | 1404/3353 [13:05:12<18:06:39, 33.45s/it] 42%|████▏     | 1405/3353 [13:05:46<18:08:01, 33.51s/it] 42%|████▏     | 1406/3353 [13:06:20<18:06:59, 33.50s/it] 42%|████▏     | 1407/3353 [13:06:53<18:08:00, 33.55s/it] 42%|████▏     | 1408/3353 [13:07:27<18:06:35, 33.52s/it] 42%|████▏     | 1409/3353 [13:08:00<18:07:12, 33.56s/it] 42%|████▏     | 1410/3353 [13:08:34<18:05:40, 33.53s/it]                                                         {'loss': 1.2163, 'learning_rate': 3.1177762084405926e-05, 'epoch': 0.42}
 42%|████▏     | 1410/3353 [13:08:34<18:05:40, 33.53s/it] 42%|████▏     | 1411/3353 [13:09:07<18:04:55, 33.52s/it] 42%|████▏     | 1412/3353 [13:09:41<18:04:10, 33.51s/it] 42%|████▏     | 1413/3353 [13:10:14<18:05:06, 33.56s/it] 42%|████▏     | 1414/3353 [13:10:48<18:03:55, 33.54s/it] 42%|████▏     | 1415/3353 [13:11:22<18:04:12, 33.57s/it] 42%|████▏     | 1416/3353 [13:11:55<18:02:20, 33.53s/it] 42%|████▏     | 1417/3353 [13:12:29<18:03:01, 33.56s/it] 42%|████▏     | 1418/3353 [13:13:02<18:01:19, 33.53s/it] 42%|████▏     | 1419/3353 [13:13:36<18:00:20, 33.52s/it] 42%|████▏     | 1420/3353 [13:14:09<17:59:19, 33.50s/it]                                                         {'loss': 1.2079, 'learning_rate': 3.0950521127195873e-05, 'epoch': 0.42}
 42%|████▏     | 1420/3353 [13:14:09<17:59:19, 33.50s/it] 42%|████▏     | 1421/3353 [13:14:43<17:58:36, 33.50s/it] 42%|████▏     | 1422/3353 [13:15:16<17:58:04, 33.50s/it] 42%|████▏     | 1423/3353 [13:15:50<17:58:39, 33.53s/it] 42%|████▏     | 1424/3353 [13:16:23<17:57:20, 33.51s/it] 42%|████▏     | 1425/3353 [13:16:57<17:58:15, 33.56s/it] 43%|████▎     | 1426/3353 [13:17:30<17:56:52, 33.53s/it] 43%|████▎     | 1427/3353 [13:18:04<17:55:31, 33.51s/it] 43%|████▎     | 1428/3353 [13:18:37<17:54:39, 33.50s/it] 43%|████▎     | 1429/3353 [13:19:11<17:53:31, 33.48s/it] 43%|████▎     | 1430/3353 [13:19:44<17:54:47, 33.54s/it]                                                         {'loss': 1.2164, 'learning_rate': 3.072275779248549e-05, 'epoch': 0.43}
 43%|████▎     | 1430/3353 [13:19:44<17:54:47, 33.54s/it] 43%|████▎     | 1431/3353 [13:20:18<17:53:55, 33.53s/it] 43%|████▎     | 1432/3353 [13:20:51<17:52:24, 33.50s/it] 43%|████▎     | 1433/3353 [13:21:25<17:51:21, 33.48s/it] 43%|████▎     | 1434/3353 [13:21:58<17:50:31, 33.47s/it] 43%|████▎     | 1435/3353 [13:22:31<17:49:20, 33.45s/it] 43%|████▎     | 1436/3353 [13:23:05<17:48:37, 33.45s/it] 43%|████▎     | 1437/3353 [13:23:38<17:47:53, 33.44s/it] 43%|████▎     | 1438/3353 [13:24:12<17:47:44, 33.45s/it] 43%|████▎     | 1439/3353 [13:24:45<17:48:04, 33.48s/it] 43%|████▎     | 1440/3353 [13:25:19<17:47:00, 33.47s/it]                                                         {'loss': 1.2259, 'learning_rate': 3.0494492074900287e-05, 'epoch': 0.43}
 43%|████▎     | 1440/3353 [13:25:19<17:47:00, 33.47s/it] 43%|████▎     | 1441/3353 [13:25:52<17:47:13, 33.49s/it] 43%|████▎     | 1442/3353 [13:26:26<17:46:06, 33.47s/it] 43%|████▎     | 1443/3353 [13:26:59<17:45:10, 33.46s/it] 43%|████▎     | 1444/3353 [13:27:33<17:44:28, 33.46s/it] 43%|████▎     | 1445/3353 [13:28:06<17:44:04, 33.46s/it] 43%|████▎     | 1446/3353 [13:28:40<17:44:58, 33.51s/it] 43%|████▎     | 1447/3353 [13:29:13<17:43:51, 33.49s/it] 43%|████▎     | 1448/3353 [13:29:47<17:44:51, 33.54s/it] 43%|████▎     | 1449/3353 [13:30:20<17:43:08, 33.50s/it] 43%|████▎     | 1450/3353 [13:30:54<17:43:52, 33.54s/it]                                                         {'loss': 1.2245, 'learning_rate': 3.0265744013168358e-05, 'epoch': 0.43}
 43%|████▎     | 1450/3353 [13:30:54<17:43:52, 33.54s/it] 43%|████▎     | 1451/3353 [13:31:27<17:42:24, 33.51s/it] 43%|████▎     | 1452/3353 [13:32:01<17:41:01, 33.49s/it] 43%|████▎     | 1453/3353 [13:32:34<17:39:55, 33.47s/it] 43%|████▎     | 1454/3353 [13:33:08<17:40:55, 33.52s/it] 43%|████▎     | 1455/3353 [13:33:41<17:39:40, 33.50s/it] 43%|████▎     | 1456/3353 [13:34:15<17:38:47, 33.49s/it] 43%|████▎     | 1457/3353 [13:34:48<17:38:00, 33.48s/it] 43%|████▎     | 1458/3353 [13:35:22<17:36:50, 33.46s/it] 44%|████▎     | 1459/3353 [13:35:55<17:36:02, 33.45s/it] 44%|████▎     | 1460/3353 [13:36:29<17:35:10, 33.44s/it]                                                         {'loss': 1.2253, 'learning_rate': 3.003653368836129e-05, 'epoch': 0.44}
 44%|████▎     | 1460/3353 [13:36:29<17:35:10, 33.44s/it] 44%|████▎     | 1461/3353 [13:37:02<17:34:59, 33.46s/it] 44%|████▎     | 1462/3353 [13:37:35<17:34:18, 33.45s/it] 44%|████▎     | 1463/3353 [13:38:09<17:33:34, 33.45s/it] 44%|████▎     | 1464/3353 [13:38:42<17:34:24, 33.49s/it] 44%|████▎     | 1465/3353 [13:39:16<17:33:40, 33.49s/it] 44%|████▎     | 1466/3353 [13:39:50<17:34:05, 33.52s/it] 44%|████▍     | 1467/3353 [13:40:23<17:32:59, 33.50s/it] 44%|████▍     | 1468/3353 [13:40:56<17:31:45, 33.48s/it] 44%|████▍     | 1469/3353 [13:41:30<17:30:43, 33.46s/it] 44%|████▍     | 1470/3353 [13:42:03<17:31:28, 33.50s/it]                                                         {'loss': 1.2166, 'learning_rate': 2.980688122213128e-05, 'epoch': 0.44}
 44%|████▍     | 1470/3353 [13:42:03<17:31:28, 33.50s/it] 44%|████▍     | 1471/3353 [13:42:37<17:30:48, 33.50s/it] 44%|████▍     | 1472/3353 [13:43:11<17:31:49, 33.55s/it] 44%|████▍     | 1473/3353 [13:43:44<17:30:07, 33.51s/it] 44%|████▍     | 1474/3353 [13:44:18<17:31:15, 33.57s/it] 44%|████▍     | 1475/3353 [13:44:51<17:29:28, 33.53s/it] 44%|████▍     | 1476/3353 [13:45:25<17:28:13, 33.51s/it] 44%|████▍     | 1477/3353 [13:45:58<17:27:19, 33.50s/it] 44%|████▍     | 1478/3353 [13:46:32<17:27:55, 33.53s/it] 44%|████▍     | 1479/3353 [13:47:05<17:26:43, 33.51s/it] 44%|████▍     | 1480/3353 [13:47:39<17:27:12, 33.55s/it]                                                         {'loss': 1.2138, 'learning_rate': 2.9576806774944722e-05, 'epoch': 0.44}
 44%|████▍     | 1480/3353 [13:47:39<17:27:12, 33.55s/it] 44%|████▍     | 1481/3353 [13:48:12<17:26:24, 33.54s/it] 44%|████▍     | 1482/3353 [13:48:46<17:26:46, 33.57s/it] 44%|████▍     | 1483/3353 [13:49:19<17:25:02, 33.53s/it] 44%|████▍     | 1484/3353 [13:49:53<17:23:47, 33.51s/it] 44%|████▍     | 1485/3353 [13:50:26<17:22:33, 33.49s/it] 44%|████▍     | 1486/3353 [13:51:00<17:21:32, 33.47s/it] 44%|████▍     | 1487/3353 [13:51:33<17:21:09, 33.48s/it] 44%|████▍     | 1488/3353 [13:52:07<17:20:30, 33.47s/it] 44%|████▍     | 1489/3353 [13:52:40<17:19:59, 33.48s/it] 44%|████▍     | 1490/3353 [13:53:14<17:19:27, 33.48s/it]                                                         {'loss': 1.206, 'learning_rate': 2.93463305443124e-05, 'epoch': 0.44}
 44%|████▍     | 1490/3353 [13:53:14<17:19:27, 33.48s/it] 44%|████▍     | 1491/3353 [13:53:47<17:19:05, 33.48s/it] 44%|████▍     | 1492/3353 [13:54:21<17:18:22, 33.48s/it] 45%|████▍     | 1493/3353 [13:54:54<17:17:46, 33.48s/it] 45%|████▍     | 1494/3353 [13:55:28<17:16:45, 33.46s/it] 45%|████▍     | 1495/3353 [13:56:01<17:17:42, 33.51s/it] 45%|████▍     | 1496/3353 [13:56:35<17:17:26, 33.52s/it] 45%|████▍     | 1497/3353 [13:57:08<17:15:55, 33.49s/it] 45%|████▍     | 1498/3353 [13:57:42<17:15:46, 33.50s/it] 45%|████▍     | 1499/3353 [13:58:15<17:14:27, 33.48s/it] 45%|████▍     | 1500/3353 [13:58:48<17:13:29, 33.46s/it]                                                         {'loss': 1.2066, 'learning_rate': 2.91154727630164e-05, 'epoch': 0.45}
 45%|████▍     | 1500/3353 [13:58:49<17:13:29, 33.46s/it] 45%|████▍     | 1501/3353 [13:59:22<17:13:02, 33.47s/it] 45%|████▍     | 1502/3353 [13:59:55<17:11:58, 33.45s/it] 45%|████▍     | 1503/3353 [14:00:29<17:11:24, 33.45s/it] 45%|████▍     | 1504/3353 [14:01:02<17:10:55, 33.45s/it] 45%|████▍     | 1505/3353 [14:01:36<17:12:10, 33.51s/it] 45%|████▍     | 1506/3353 [14:02:09<17:11:15, 33.50s/it] 45%|████▍     | 1507/3353 [14:02:43<17:11:43, 33.53s/it] 45%|████▍     | 1508/3353 [14:03:16<17:10:05, 33.50s/it] 45%|████▌     | 1509/3353 [14:03:50<17:09:03, 33.48s/it] 45%|████▌     | 1510/3353 [14:04:23<17:07:46, 33.46s/it]                                                         {'loss': 1.2067, 'learning_rate': 2.8884253697333937e-05, 'epoch': 0.45}
 45%|████▌     | 1510/3353 [14:04:23<17:07:46, 33.46s/it] 45%|████▌     | 1511/3353 [14:04:57<17:08:23, 33.50s/it] 45%|████▌     | 1512/3353 [14:05:30<17:07:23, 33.48s/it] 45%|████▌     | 1513/3353 [14:06:04<17:06:40, 33.48s/it] 45%|████▌     | 1514/3353 [14:06:37<17:05:58, 33.47s/it] 45%|████▌     | 1515/3353 [14:07:11<17:05:29, 33.48s/it] 45%|████▌     | 1516/3353 [14:07:44<17:04:26, 33.46s/it] 45%|████▌     | 1517/3353 [14:08:18<17:03:59, 33.46s/it] 45%|████▌     | 1518/3353 [14:08:51<17:03:04, 33.45s/it] 45%|████▌     | 1519/3353 [14:09:25<17:04:17, 33.51s/it] 45%|████▌     | 1520/3353 [14:09:58<17:03:12, 33.49s/it]                                                         {'loss': 1.2002, 'learning_rate': 2.865269364525823e-05, 'epoch': 0.45}
 45%|████▌     | 1520/3353 [14:09:58<17:03:12, 33.49s/it] 45%|████▌     | 1521/3353 [14:10:32<17:04:13, 33.54s/it] 45%|████▌     | 1522/3353 [14:11:05<17:02:47, 33.52s/it] 45%|████▌     | 1523/3353 [14:11:39<17:03:47, 33.57s/it] 45%|████▌     | 1524/3353 [14:12:12<17:02:25, 33.54s/it] 45%|████▌     | 1525/3353 [14:12:46<17:01:07, 33.52s/it] 46%|████▌     | 1526/3353 [14:13:19<17:00:30, 33.51s/it] 46%|████▌     | 1527/3353 [14:13:53<16:59:26, 33.50s/it] 46%|████▌     | 1528/3353 [14:14:26<16:58:23, 33.48s/it] 46%|████▌     | 1529/3353 [14:15:00<16:58:52, 33.52s/it] 46%|████▌     | 1530/3353 [14:15:33<16:57:46, 33.50s/it]                                                         {'loss': 1.2137, 'learning_rate': 2.842081293471664e-05, 'epoch': 0.46}
 46%|████▌     | 1530/3353 [14:15:33<16:57:46, 33.50s/it] 46%|████▌     | 1531/3353 [14:16:07<16:58:58, 33.56s/it] 46%|████▌     | 1532/3353 [14:16:40<16:57:18, 33.52s/it] 46%|████▌     | 1533/3353 [14:17:14<16:56:22, 33.51s/it] 46%|████▌     | 1534/3353 [14:17:47<16:55:15, 33.49s/it] 46%|████▌     | 1535/3353 [14:18:21<16:55:54, 33.53s/it] 46%|████▌     | 1536/3353 [14:18:54<16:54:42, 33.51s/it] 46%|████▌     | 1537/3353 [14:19:28<16:55:22, 33.55s/it] 46%|████▌     | 1538/3353 [14:20:02<16:54:34, 33.54s/it] 46%|████▌     | 1539/3353 [14:20:35<16:54:55, 33.57s/it] 46%|████▌     | 1540/3353 [14:21:09<16:53:01, 33.53s/it]                                                         {'loss': 1.2198, 'learning_rate': 2.8188631921786107e-05, 'epoch': 0.46}
 46%|████▌     | 1540/3353 [14:21:09<16:53:01, 33.53s/it] 46%|████▌     | 1541/3353 [14:21:42<16:52:20, 33.52s/it] 46%|████▌     | 1542/3353 [14:22:16<16:50:59, 33.50s/it] 46%|████▌     | 1543/3353 [14:22:49<16:51:53, 33.54s/it] 46%|████▌     | 1544/3353 [14:23:23<16:50:24, 33.51s/it] 46%|████▌     | 1545/3353 [14:23:56<16:49:45, 33.51s/it] 46%|████▌     | 1546/3353 [14:24:30<16:48:23, 33.48s/it] 46%|████▌     | 1547/3353 [14:25:03<16:47:29, 33.47s/it] 46%|████▌     | 1548/3353 [14:25:37<16:46:42, 33.46s/it] 46%|████▌     | 1549/3353 [14:26:10<16:46:04, 33.46s/it] 46%|████▌     | 1550/3353 [14:26:43<16:45:19, 33.45s/it]                                                         {'loss': 1.2086, 'learning_rate': 2.7956170988906195e-05, 'epoch': 0.46}
 46%|████▌     | 1550/3353 [14:26:44<16:45:19, 33.45s/it] 46%|████▋     | 1551/3353 [14:27:17<16:45:25, 33.48s/it] 46%|████▋     | 1552/3353 [14:27:51<16:45:20, 33.49s/it] 46%|████▋     | 1553/3353 [14:28:24<16:45:19, 33.51s/it] 46%|████▋     | 1554/3353 [14:28:58<16:44:06, 33.49s/it] 46%|████▋     | 1555/3353 [14:29:31<16:43:34, 33.49s/it] 46%|████▋     | 1556/3353 [14:30:04<16:42:22, 33.47s/it] 46%|████▋     | 1557/3353 [14:30:38<16:41:40, 33.46s/it] 46%|████▋     | 1558/3353 [14:31:11<16:40:52, 33.46s/it] 46%|████▋     | 1559/3353 [14:31:45<16:40:20, 33.46s/it] 47%|████▋     | 1560/3353 [14:32:18<16:41:34, 33.52s/it]                                                         {'loss': 1.2113, 'learning_rate': 2.772345054308973e-05, 'epoch': 0.47}
 47%|████▋     | 1560/3353 [14:32:18<16:41:34, 33.52s/it] 47%|████▋     | 1561/3353 [14:32:52<16:40:38, 33.50s/it] 47%|████▋     | 1562/3353 [14:33:26<16:41:16, 33.54s/it] 47%|████▋     | 1563/3353 [14:33:59<16:40:02, 33.52s/it] 47%|████▋     | 1564/3353 [14:34:33<16:40:40, 33.56s/it] 47%|████▋     | 1565/3353 [14:35:06<16:39:14, 33.53s/it] 47%|████▋     | 1566/3353 [14:35:40<16:38:01, 33.51s/it] 47%|████▋     | 1567/3353 [14:36:13<16:37:20, 33.51s/it] 47%|████▋     | 1568/3353 [14:36:47<16:36:35, 33.50s/it] 47%|████▋     | 1569/3353 [14:37:20<16:35:39, 33.49s/it] 47%|████▋     | 1570/3353 [14:37:54<16:35:12, 33.49s/it]                                                         {'loss': 1.2069, 'learning_rate': 2.7490491014131375e-05, 'epoch': 0.47}
 47%|████▋     | 1570/3353 [14:37:54<16:35:12, 33.49s/it] 47%|████▋     | 1571/3353 [14:38:27<16:34:56, 33.50s/it] 47%|████▋     | 1572/3353 [14:39:01<16:34:12, 33.49s/it] 47%|████▋     | 1573/3353 [14:39:34<16:33:30, 33.49s/it] 47%|████▋     | 1574/3353 [14:40:07<16:32:58, 33.49s/it] 47%|████▋     | 1575/3353 [14:40:41<16:32:14, 33.48s/it] 47%|████▋     | 1576/3353 [14:41:15<16:32:51, 33.52s/it] 47%|████▋     | 1577/3353 [14:41:48<16:31:39, 33.50s/it] 47%|████▋     | 1578/3353 [14:42:22<16:32:22, 33.55s/it] 47%|████▋     | 1579/3353 [14:42:55<16:31:06, 33.52s/it] 47%|████▋     | 1580/3353 [14:43:29<16:31:21, 33.55s/it]                                                         {'loss': 1.2045, 'learning_rate': 2.7257312852814154e-05, 'epoch': 0.47}
 47%|████▋     | 1580/3353 [14:43:29<16:31:21, 33.55s/it] 47%|████▋     | 1581/3353 [14:44:02<16:30:39, 33.54s/it] 47%|████▋     | 1582/3353 [14:44:36<16:29:34, 33.53s/it] 47%|████▋     | 1583/3353 [14:45:09<16:28:36, 33.51s/it] 47%|████▋     | 1584/3353 [14:45:43<16:29:32, 33.56s/it] 47%|████▋     | 1585/3353 [14:46:16<16:28:05, 33.53s/it] 47%|████▋     | 1586/3353 [14:46:50<16:28:47, 33.58s/it] 47%|████▋     | 1587/3353 [14:47:24<16:27:19, 33.54s/it] 47%|████▋     | 1588/3353 [14:47:57<16:27:45, 33.58s/it] 47%|████▋     | 1589/3353 [14:48:31<16:26:00, 33.54s/it] 47%|████▋     | 1590/3353 [14:49:04<16:25:08, 33.53s/it]                                                         {'loss': 1.1964, 'learning_rate': 2.7023936529114125e-05, 'epoch': 0.47}
 47%|████▋     | 1590/3353 [14:49:04<16:25:08, 33.53s/it] 47%|████▋     | 1591/3353 [14:49:38<16:25:02, 33.54s/it] 47%|████▋     | 1592/3353 [14:50:11<16:24:03, 33.53s/it] 48%|████▊     | 1593/3353 [14:50:45<16:23:11, 33.52s/it] 48%|████▊     | 1594/3353 [14:51:18<16:24:08, 33.57s/it] 48%|████▊     | 1595/3353 [14:51:52<16:23:12, 33.56s/it] 48%|████▊     | 1596/3353 [14:52:26<16:24:16, 33.61s/it] 48%|████▊     | 1597/3353 [14:52:59<16:22:16, 33.56s/it] 48%|████▊     | 1598/3353 [14:53:33<16:20:57, 33.54s/it] 48%|████▊     | 1599/3353 [14:54:06<16:20:02, 33.52s/it] 48%|████▊     | 1600/3353 [14:54:40<16:20:43, 33.57s/it]                                                         {'loss': 1.1946, 'learning_rate': 2.6790382530403403e-05, 'epoch': 0.48}
 48%|████▊     | 1600/3353 [14:54:40<16:20:43, 33.57s/it] 48%|████▊     | 1601/3353 [14:55:13<16:19:54, 33.56s/it] 48%|████▊     | 1602/3353 [14:55:47<16:18:56, 33.54s/it] 48%|████▊     | 1603/3353 [14:56:20<16:18:34, 33.55s/it] 48%|████▊     | 1604/3353 [14:56:54<16:17:32, 33.53s/it] 48%|████▊     | 1605/3353 [14:57:27<16:16:48, 33.53s/it] 48%|████▊     | 1606/3353 [14:58:01<16:16:19, 33.53s/it] 48%|████▊     | 1607/3353 [14:58:34<16:15:26, 33.52s/it] 48%|████▊     | 1608/3353 [14:59:08<16:16:07, 33.56s/it] 48%|████▊     | 1609/3353 [14:59:42<16:14:49, 33.54s/it] 48%|████▊     | 1610/3353 [15:00:15<16:14:39, 33.55s/it]                                                         {'loss': 1.197, 'learning_rate': 2.655667135965163e-05, 'epoch': 0.48}
 48%|████▊     | 1610/3353 [15:00:15<16:14:39, 33.55s/it] 48%|████▊     | 1611/3353 [15:00:49<16:14:07, 33.55s/it] 48%|████▊     | 1612/3353 [15:01:22<16:13:48, 33.56s/it] 48%|████▊     | 1613/3353 [15:01:56<16:12:23, 33.53s/it] 48%|████▊     | 1614/3353 [15:02:29<16:11:07, 33.51s/it] 48%|████▊     | 1615/3353 [15:03:03<16:10:14, 33.50s/it] 48%|████▊     | 1616/3353 [15:03:36<16:08:58, 33.47s/it] 48%|████▊     | 1617/3353 [15:04:10<16:08:55, 33.49s/it] 48%|████▊     | 1618/3353 [15:04:43<16:07:50, 33.47s/it] 48%|████▊     | 1619/3353 [15:05:17<16:09:08, 33.53s/it] 48%|████▊     | 1620/3353 [15:05:50<16:08:03, 33.52s/it]                                                         {'loss': 1.1944, 'learning_rate': 2.6322823533626096e-05, 'epoch': 0.48}
 48%|████▊     | 1620/3353 [15:05:50<16:08:03, 33.52s/it] 48%|████▊     | 1621/3353 [15:06:24<16:09:13, 33.58s/it] 48%|████▊     | 1622/3353 [15:06:57<16:07:29, 33.53s/it] 48%|████▊     | 1623/3353 [15:07:31<16:06:09, 33.51s/it] 48%|████▊     | 1624/3353 [15:08:04<16:04:45, 33.48s/it] 48%|████▊     | 1625/3353 [15:08:38<16:05:21, 33.52s/it] 48%|████▊     | 1626/3353 [15:09:11<16:03:58, 33.49s/it] 49%|████▊     | 1627/3353 [15:09:45<16:03:16, 33.49s/it] 49%|████▊     | 1628/3353 [15:10:18<16:02:36, 33.48s/it] 49%|████▊     | 1629/3353 [15:10:52<16:01:41, 33.47s/it] 49%|████▊     | 1630/3353 [15:11:25<16:00:50, 33.46s/it]                                                         {'loss': 1.2021, 'learning_rate': 2.6088859581090614e-05, 'epoch': 0.49}
 49%|████▊     | 1630/3353 [15:11:25<16:00:50, 33.46s/it] 49%|████▊     | 1631/3353 [15:11:59<16:00:43, 33.47s/it] 49%|████▊     | 1632/3353 [15:12:32<15:59:59, 33.47s/it] 49%|████▊     | 1633/3353 [15:13:05<15:59:20, 33.47s/it] 49%|████▊     | 1634/3353 [15:13:39<15:58:24, 33.45s/it] 49%|████▉     | 1635/3353 [15:14:13<15:59:13, 33.50s/it] 49%|████▉     | 1636/3353 [15:14:46<15:58:09, 33.48s/it] 49%|████▉     | 1637/3353 [15:15:20<15:58:49, 33.53s/it] 49%|████▉     | 1638/3353 [15:15:53<15:57:39, 33.50s/it] 49%|████▉     | 1639/3353 [15:16:26<15:56:39, 33.49s/it] 49%|████▉     | 1640/3353 [15:17:00<15:55:25, 33.46s/it]                                                         {'loss': 1.1896, 'learning_rate': 2.5854800041003386e-05, 'epoch': 0.49}
 49%|████▉     | 1640/3353 [15:17:00<15:55:25, 33.46s/it] 49%|████▉     | 1641/3353 [15:17:33<15:56:01, 33.51s/it] 49%|████▉     | 1642/3353 [15:18:07<15:55:05, 33.49s/it] 49%|████▉     | 1643/3353 [15:18:41<15:55:56, 33.54s/it] 49%|████▉     | 1644/3353 [15:19:14<15:54:39, 33.52s/it] 49%|████▉     | 1645/3353 [15:19:48<15:55:05, 33.55s/it] 49%|████▉     | 1646/3353 [15:20:21<15:53:28, 33.51s/it] 49%|████▉     | 1647/3353 [15:20:55<15:52:32, 33.50s/it] 49%|████▉     | 1648/3353 [15:21:28<15:51:36, 33.49s/it] 49%|████▉     | 1649/3353 [15:22:02<15:52:10, 33.53s/it] 49%|████▉     | 1650/3353 [15:22:35<15:50:49, 33.50s/it]                                                         {'loss': 1.1847, 'learning_rate': 2.5620665460713933e-05, 'epoch': 0.49}
 49%|████▉     | 1650/3353 [15:22:35<15:50:49, 33.50s/it] 49%|████▉     | 1651/3353 [15:23:09<15:52:10, 33.57s/it] 49%|████▉     | 1652/3353 [15:23:42<15:50:39, 33.53s/it] 49%|████▉     | 1653/3353 [15:24:16<15:51:12, 33.57s/it] 49%|████▉     | 1654/3353 [15:24:49<15:49:36, 33.54s/it] 49%|████▉     | 1655/3353 [15:25:23<15:48:24, 33.51s/it] 49%|████▉     | 1656/3353 [15:25:56<15:47:27, 33.50s/it] 49%|████▉     | 1657/3353 [15:26:30<15:46:19, 33.48s/it] 49%|████▉     | 1658/3353 [15:27:03<15:45:34, 33.47s/it] 49%|████▉     | 1659/3353 [15:27:37<15:44:57, 33.47s/it] 50%|████▉     | 1660/3353 [15:28:10<15:44:07, 33.46s/it]                                                         {'loss': 1.1845, 'learning_rate': 2.5386476394159338e-05, 'epoch': 0.5}
 50%|████▉     | 1660/3353 [15:28:10<15:44:07, 33.46s/it] 50%|████▉     | 1661/3353 [15:28:44<15:43:50, 33.47s/it] 50%|████▉     | 1662/3353 [15:29:17<15:43:05, 33.46s/it] 50%|████▉     | 1663/3353 [15:29:50<15:42:20, 33.46s/it] 50%|████▉     | 1664/3353 [15:30:24<15:41:43, 33.45s/it] 50%|████▉     | 1665/3353 [15:30:58<15:42:47, 33.51s/it] 50%|████▉     | 1666/3353 [15:31:31<15:41:50, 33.50s/it] 50%|████▉     | 1667/3353 [15:32:05<15:41:51, 33.52s/it] 50%|████▉     | 1668/3353 [15:32:38<15:40:58, 33.51s/it] 50%|████▉     | 1669/3353 [15:33:12<15:40:36, 33.51s/it] 50%|████▉     | 1670/3353 [15:33:45<15:39:46, 33.50s/it]                                                         {'loss': 1.1875, 'learning_rate': 2.5152253400059832e-05, 'epoch': 0.5}
 50%|████▉     | 1670/3353 [15:33:45<15:39:46, 33.50s/it] 50%|████▉     | 1671/3353 [15:34:19<15:39:33, 33.52s/it] 50%|████▉     | 1672/3353 [15:34:52<15:38:26, 33.50s/it] 50%|████▉     | 1673/3353 [15:35:26<15:39:05, 33.54s/it] 50%|████▉     | 1674/3353 [15:35:59<15:37:55, 33.52s/it] 50%|████▉     | 1675/3353 [15:36:33<15:36:36, 33.49s/it] 50%|████▉     | 1676/3353 [15:37:06<15:37:18, 33.54s/it] 50%|█████     | 1677/3353 [15:37:40<15:36:04, 33.51s/it] 50%|█████     | 1678/3353 [15:38:13<15:36:27, 33.54s/it] 50%|█████     | 1679/3353 [15:38:47<15:35:12, 33.52s/it] 50%|█████     | 1680/3353 [15:39:20<15:33:48, 33.49s/it]                                                         {'loss': 1.1852, 'learning_rate': 2.4918017040114082e-05, 'epoch': 0.5}
 50%|█████     | 1680/3353 [15:39:20<15:33:48, 33.49s/it] 50%|█████     | 1681/3353 [15:39:54<15:32:51, 33.48s/it] 50%|█████     | 1682/3353 [15:40:27<15:32:24, 33.48s/it] 50%|█████     | 1683/3353 [15:41:01<15:31:38, 33.47s/it] 50%|█████     | 1684/3353 [15:41:34<15:31:02, 33.47s/it] 50%|█████     | 1685/3353 [15:42:07<15:29:59, 33.45s/it] 50%|█████     | 1686/3353 [15:42:41<15:29:10, 33.44s/it] 50%|█████     | 1687/3353 [15:43:14<15:28:30, 33.44s/it] 50%|█████     | 1688/3353 [15:43:48<15:27:54, 33.44s/it] 50%|█████     | 1689/3353 [15:44:21<15:27:23, 33.44s/it] 50%|█████     | 1690/3353 [15:44:55<15:28:07, 33.49s/it]                                                         {'loss': 1.1857, 'learning_rate': 2.4683787877194053e-05, 'epoch': 0.5}
 50%|█████     | 1690/3353 [15:44:55<15:28:07, 33.49s/it] 50%|█████     | 1691/3353 [15:45:28<15:27:43, 33.49s/it] 50%|█████     | 1692/3353 [15:46:02<15:28:02, 33.52s/it] 50%|█████     | 1693/3353 [15:46:35<15:27:02, 33.51s/it] 51%|█████     | 1694/3353 [15:47:09<15:27:08, 33.53s/it] 51%|█████     | 1695/3353 [15:47:42<15:25:35, 33.50s/it] 51%|█████     | 1696/3353 [15:48:16<15:24:33, 33.48s/it] 51%|█████     | 1697/3353 [15:48:49<15:23:30, 33.46s/it] 51%|█████     | 1698/3353 [15:49:23<15:22:50, 33.46s/it] 51%|█████     | 1699/3353 [15:49:56<15:22:12, 33.45s/it] 51%|█████     | 1700/3353 [15:50:30<15:23:02, 33.50s/it]                                                         {'loss': 1.187, 'learning_rate': 2.444958647353994e-05, 'epoch': 0.51}
 51%|█████     | 1700/3353 [15:50:30<15:23:02, 33.50s/it] 51%|█████     | 1701/3353 [15:51:03<15:22:21, 33.50s/it] 51%|█████     | 1702/3353 [15:51:37<15:23:18, 33.55s/it] 51%|█████     | 1703/3353 [15:52:10<15:21:42, 33.52s/it] 51%|█████     | 1704/3353 [15:52:44<15:20:40, 33.50s/it] 51%|█████     | 1705/3353 [15:53:17<15:19:44, 33.49s/it] 51%|█████     | 1706/3353 [15:53:51<15:20:00, 33.52s/it] 51%|█████     | 1707/3353 [15:54:24<15:18:49, 33.49s/it] 51%|█████     | 1708/3353 [15:54:58<15:19:39, 33.54s/it] 51%|█████     | 1709/3353 [15:55:31<15:18:15, 33.51s/it] 51%|█████     | 1710/3353 [15:56:05<15:18:43, 33.55s/it]                                                         {'loss': 1.1828, 'learning_rate': 2.421543338895502e-05, 'epoch': 0.51}
 51%|█████     | 1710/3353 [15:56:05<15:18:43, 33.55s/it] 51%|█████     | 1711/3353 [15:56:39<15:17:53, 33.54s/it] 51%|█████     | 1712/3353 [15:57:12<15:16:25, 33.51s/it] 51%|█████     | 1713/3353 [15:57:45<15:15:21, 33.49s/it] 51%|█████     | 1714/3353 [15:58:19<15:16:19, 33.54s/it] 51%|█████     | 1715/3353 [15:58:53<15:15:06, 33.52s/it] 51%|█████     | 1716/3353 [15:59:26<15:14:18, 33.51s/it] 51%|█████     | 1717/3353 [16:00:00<15:13:16, 33.49s/it] 51%|█████     | 1718/3353 [16:00:33<15:12:28, 33.49s/it] 51%|█████▏    | 1719/3353 [16:01:06<15:11:51, 33.48s/it] 51%|█████▏    | 1720/3353 [16:01:40<15:11:04, 33.48s/it]                                                         {'loss': 1.1795, 'learning_rate': 2.3981349179000807e-05, 'epoch': 0.51}
 51%|█████▏    | 1720/3353 [16:01:40<15:11:04, 33.48s/it] 51%|█████▏    | 1721/3353 [16:02:13<15:10:48, 33.49s/it] 51%|█████▏    | 1722/3353 [16:02:47<15:10:07, 33.48s/it] 51%|█████▏    | 1723/3353 [16:03:20<15:09:28, 33.48s/it] 51%|█████▏    | 1724/3353 [16:03:54<15:09:54, 33.51s/it] 51%|█████▏    | 1725/3353 [16:04:27<15:08:49, 33.50s/it] 51%|█████▏    | 1726/3353 [16:05:01<15:08:28, 33.50s/it] 52%|█████▏    | 1727/3353 [16:05:34<15:07:26, 33.49s/it] 52%|█████▏    | 1728/3353 [16:06:08<15:06:30, 33.47s/it] 52%|█████▏    | 1729/3353 [16:06:41<15:05:40, 33.46s/it] 52%|█████▏    | 1730/3353 [16:07:15<15:06:29, 33.51s/it]                                                         {'loss': 1.1809, 'learning_rate': 2.3747354393192504e-05, 'epoch': 0.52}
 52%|█████▏    | 1730/3353 [16:07:15<15:06:29, 33.51s/it] 52%|█████▏    | 1731/3353 [16:07:48<15:05:54, 33.51s/it] 52%|█████▏    | 1732/3353 [16:08:22<15:04:59, 33.50s/it] 52%|█████▏    | 1733/3353 [16:08:56<15:05:33, 33.54s/it] 52%|█████▏    | 1734/3353 [16:09:29<15:04:14, 33.51s/it] 52%|█████▏    | 1735/3353 [16:10:03<15:04:48, 33.55s/it] 52%|█████▏    | 1736/3353 [16:10:36<15:03:19, 33.52s/it] 52%|█████▏    | 1737/3353 [16:11:09<15:02:10, 33.50s/it] 52%|█████▏    | 1738/3353 [16:11:43<15:02:30, 33.53s/it] 52%|█████▏    | 1739/3353 [16:12:17<15:01:00, 33.49s/it] 52%|█████▏    | 1740/3353 [16:12:50<14:59:44, 33.47s/it]                                                         {'loss': 1.1804, 'learning_rate': 2.351346957319509e-05, 'epoch': 0.52}
 52%|█████▏    | 1740/3353 [16:12:50<14:59:44, 33.47s/it] 52%|█████▏    | 1741/3353 [16:13:23<14:59:44, 33.49s/it] 52%|█████▏    | 1742/3353 [16:13:57<14:58:43, 33.47s/it] 52%|█████▏    | 1743/3353 [16:14:30<14:57:42, 33.45s/it] 52%|█████▏    | 1744/3353 [16:15:04<14:57:07, 33.45s/it] 52%|█████▏    | 1745/3353 [16:15:37<14:56:13, 33.44s/it] 52%|█████▏    | 1746/3353 [16:16:11<14:55:43, 33.44s/it] 52%|█████▏    | 1747/3353 [16:16:44<14:55:26, 33.45s/it] 52%|█████▏    | 1748/3353 [16:17:18<14:54:34, 33.44s/it] 52%|█████▏    | 1749/3353 [16:17:51<14:55:15, 33.49s/it] 52%|█████▏    | 1750/3353 [16:18:25<14:54:22, 33.48s/it]                                                         {'loss': 1.1777, 'learning_rate': 2.3279715251019936e-05, 'epoch': 0.52}
 52%|█████▏    | 1750/3353 [16:18:25<14:54:22, 33.48s/it] 52%|█████▏    | 1751/3353 [16:18:58<14:54:48, 33.51s/it] 52%|█████▏    | 1752/3353 [16:19:32<14:53:30, 33.49s/it] 52%|█████▏    | 1753/3353 [16:20:05<14:52:46, 33.48s/it] 52%|█████▏    | 1754/3353 [16:20:38<14:51:47, 33.46s/it] 52%|█████▏    | 1755/3353 [16:21:12<14:52:41, 33.52s/it] 52%|█████▏    | 1756/3353 [16:21:46<14:51:12, 33.48s/it] 52%|█████▏    | 1757/3353 [16:22:19<14:51:55, 33.53s/it] 52%|█████▏    | 1758/3353 [16:22:53<14:50:35, 33.50s/it] 52%|█████▏    | 1759/3353 [16:23:26<14:51:03, 33.54s/it] 52%|█████▏    | 1760/3353 [16:24:00<14:49:40, 33.51s/it]                                                         {'loss': 1.1807, 'learning_rate': 2.304611194722248e-05, 'epoch': 0.52}
 52%|█████▏    | 1760/3353 [16:24:00<14:49:40, 33.51s/it] 53%|█████▎    | 1761/3353 [16:24:33<14:48:48, 33.50s/it] 53%|█████▎    | 1762/3353 [16:25:07<14:47:43, 33.48s/it] 53%|█████▎    | 1763/3353 [16:25:40<14:46:39, 33.46s/it] 53%|█████▎    | 1764/3353 [16:26:13<14:46:02, 33.46s/it] 53%|█████▎    | 1765/3353 [16:26:47<14:47:06, 33.52s/it] 53%|█████▎    | 1766/3353 [16:27:21<14:46:04, 33.50s/it] 53%|█████▎    | 1767/3353 [16:27:54<14:47:13, 33.56s/it] 53%|█████▎    | 1768/3353 [16:28:28<14:45:57, 33.54s/it] 53%|█████▎    | 1769/3353 [16:29:01<14:44:43, 33.51s/it] 53%|█████▎    | 1770/3353 [16:29:35<14:43:51, 33.50s/it]                                                         {'loss': 1.1734, 'learning_rate': 2.2812680169100693e-05, 'epoch': 0.53}
 53%|█████▎    | 1770/3353 [16:29:35<14:43:51, 33.50s/it] 53%|█████▎    | 1771/3353 [16:30:08<14:44:40, 33.55s/it] 53%|█████▎    | 1772/3353 [16:30:42<14:43:18, 33.52s/it] 53%|█████▎    | 1773/3353 [16:31:15<14:42:27, 33.51s/it] 53%|█████▎    | 1774/3353 [16:31:49<14:41:04, 33.48s/it] 53%|█████▎    | 1775/3353 [16:32:22<14:40:07, 33.47s/it] 53%|█████▎    | 1776/3353 [16:32:56<14:39:35, 33.47s/it] 53%|█████▎    | 1777/3353 [16:33:29<14:38:48, 33.46s/it] 53%|█████▎    | 1778/3353 [16:34:03<14:38:34, 33.47s/it] 53%|█████▎    | 1779/3353 [16:34:36<14:39:20, 33.52s/it] 53%|█████▎    | 1780/3353 [16:35:10<14:38:04, 33.49s/it]                                                         {'loss': 1.1809, 'learning_rate': 2.2579440408894854e-05, 'epoch': 0.53}
 53%|█████▎    | 1780/3353 [16:35:10<14:38:04, 33.49s/it] 53%|█████▎    | 1781/3353 [16:35:43<14:38:26, 33.53s/it] 53%|█████▎    | 1782/3353 [16:36:17<14:37:09, 33.50s/it] 53%|█████▎    | 1783/3353 [16:36:50<14:36:49, 33.51s/it] 53%|█████▎    | 1784/3353 [16:37:24<14:35:47, 33.49s/it] 53%|█████▎    | 1785/3353 [16:37:57<14:34:57, 33.48s/it] 53%|█████▎    | 1786/3353 [16:38:31<14:34:16, 33.48s/it] 53%|█████▎    | 1787/3353 [16:39:04<14:33:40, 33.47s/it] 53%|█████▎    | 1788/3353 [16:39:37<14:32:48, 33.46s/it] 53%|█████▎    | 1789/3353 [16:40:11<14:32:15, 33.46s/it] 53%|█████▎    | 1790/3353 [16:40:45<14:33:04, 33.52s/it]                                                         {'loss': 1.1799, 'learning_rate': 2.2346413141988606e-05, 'epoch': 0.53}
 53%|█████▎    | 1790/3353 [16:40:45<14:33:04, 33.52s/it] 53%|█████▎    | 1791/3353 [16:41:18<14:32:39, 33.52s/it] 53%|█████▎    | 1792/3353 [16:41:52<14:32:43, 33.54s/it] 53%|█████▎    | 1793/3353 [16:42:25<14:31:24, 33.52s/it] 54%|█████▎    | 1794/3353 [16:42:59<14:30:21, 33.50s/it] 54%|█████▎    | 1795/3353 [16:43:32<14:30:34, 33.53s/it] 54%|█████▎    | 1796/3353 [16:44:06<14:29:24, 33.50s/it] 54%|█████▎    | 1797/3353 [16:44:39<14:28:22, 33.49s/it] 54%|█████▎    | 1798/3353 [16:45:13<14:27:46, 33.48s/it] 54%|█████▎    | 1799/3353 [16:45:46<14:26:50, 33.47s/it] 54%|█████▎    | 1800/3353 [16:46:19<14:26:18, 33.47s/it]                                                         {'loss': 1.1805, 'learning_rate': 2.2113618825111474e-05, 'epoch': 0.54}
 54%|█████▎    | 1800/3353 [16:46:19<14:26:18, 33.47s/it] 54%|█████▎    | 1801/3353 [16:46:53<14:25:42, 33.47s/it] 54%|█████▎    | 1802/3353 [16:47:26<14:25:05, 33.47s/it] 54%|█████▍    | 1803/3353 [16:48:00<14:25:33, 33.51s/it] 54%|█████▍    | 1804/3353 [16:48:33<14:24:32, 33.49s/it] 54%|█████▍    | 1805/3353 [16:49:07<14:23:33, 33.47s/it] 54%|█████▍    | 1806/3353 [16:49:40<14:24:08, 33.52s/it] 54%|█████▍    | 1807/3353 [16:50:14<14:22:49, 33.49s/it] 54%|█████▍    | 1808/3353 [16:50:47<14:22:54, 33.51s/it] 54%|█████▍    | 1809/3353 [16:51:21<14:21:45, 33.49s/it] 54%|█████▍    | 1810/3353 [16:51:54<14:20:46, 33.47s/it]                                                         {'loss': 1.1779, 'learning_rate': 2.1881077894543005e-05, 'epoch': 0.54}
 54%|█████▍    | 1810/3353 [16:51:54<14:20:46, 33.47s/it] 54%|█████▍    | 1811/3353 [16:52:28<14:20:39, 33.49s/it] 54%|█████▍    | 1812/3353 [16:53:01<14:20:21, 33.50s/it] 54%|█████▍    | 1813/3353 [16:53:35<14:19:27, 33.49s/it] 54%|█████▍    | 1814/3353 [16:54:08<14:20:08, 33.53s/it] 54%|█████▍    | 1815/3353 [16:54:42<14:18:53, 33.51s/it] 54%|█████▍    | 1816/3353 [16:55:16<14:19:18, 33.54s/it] 54%|█████▍    | 1817/3353 [16:55:49<14:18:02, 33.52s/it] 54%|█████▍    | 1818/3353 [16:56:22<14:16:42, 33.49s/it] 54%|█████▍    | 1819/3353 [16:56:56<14:15:44, 33.47s/it] 54%|█████▍    | 1820/3353 [16:57:29<14:16:15, 33.51s/it]                                                         {'loss': 1.1811, 'learning_rate': 2.164881076431881e-05, 'epoch': 0.54}
 54%|█████▍    | 1820/3353 [16:57:30<14:16:15, 33.51s/it] 54%|█████▍    | 1821/3353 [16:58:03<14:15:42, 33.51s/it] 54%|█████▍    | 1822/3353 [16:58:37<14:16:04, 33.55s/it] 54%|█████▍    | 1823/3353 [16:59:10<14:14:34, 33.51s/it] 54%|█████▍    | 1824/3353 [16:59:44<14:15:05, 33.55s/it] 54%|█████▍    | 1825/3353 [17:00:17<14:13:49, 33.53s/it] 54%|█████▍    | 1826/3353 [17:00:51<14:12:42, 33.51s/it] 54%|█████▍    | 1827/3353 [17:01:24<14:11:35, 33.48s/it] 55%|█████▍    | 1828/3353 [17:01:57<14:10:52, 33.48s/it] 55%|█████▍    | 1829/3353 [17:02:31<14:10:23, 33.48s/it] 55%|█████▍    | 1830/3353 [17:03:04<14:09:56, 33.48s/it]                                                         {'loss': 1.1778, 'learning_rate': 2.1416837824438373e-05, 'epoch': 0.55}
 55%|█████▍    | 1830/3353 [17:03:05<14:09:56, 33.48s/it] 55%|█████▍    | 1831/3353 [17:03:38<14:09:33, 33.49s/it] 55%|█████▍    | 1832/3353 [17:04:11<14:08:54, 33.49s/it] 55%|█████▍    | 1833/3353 [17:04:45<14:08:02, 33.48s/it] 55%|█████▍    | 1834/3353 [17:05:18<14:07:20, 33.47s/it] 55%|█████▍    | 1835/3353 [17:05:52<14:06:44, 33.47s/it] 55%|█████▍    | 1836/3353 [17:06:25<14:07:15, 33.51s/it] 55%|█████▍    | 1837/3353 [17:06:59<14:06:24, 33.50s/it] 55%|█████▍    | 1838/3353 [17:07:32<14:06:13, 33.51s/it] 55%|█████▍    | 1839/3353 [17:08:06<14:05:06, 33.49s/it] 55%|█████▍    | 1840/3353 [17:08:39<14:04:42, 33.50s/it]                                                         {'loss': 1.181, 'learning_rate': 2.1185179439075203e-05, 'epoch': 0.55}
 55%|█████▍    | 1840/3353 [17:08:39<14:04:42, 33.50s/it] 55%|█████▍    | 1841/3353 [17:09:13<14:04:23, 33.51s/it] 55%|█████▍    | 1842/3353 [17:09:46<14:03:13, 33.48s/it] 55%|█████▍    | 1843/3353 [17:10:20<14:02:38, 33.48s/it] 55%|█████▍    | 1844/3353 [17:10:54<14:03:41, 33.55s/it] 55%|█████▌    | 1845/3353 [17:11:27<14:02:23, 33.52s/it] 55%|█████▌    | 1846/3353 [17:12:00<14:01:31, 33.50s/it] 55%|█████▌    | 1847/3353 [17:12:34<14:02:12, 33.55s/it] 55%|█████▌    | 1848/3353 [17:13:08<14:00:36, 33.51s/it] 55%|█████▌    | 1849/3353 [17:13:41<14:01:22, 33.57s/it] 55%|█████▌    | 1850/3353 [17:14:15<14:00:06, 33.54s/it]                                                         {'loss': 1.1748, 'learning_rate': 2.095385594478899e-05, 'epoch': 0.55}
 55%|█████▌    | 1850/3353 [17:14:15<14:00:06, 33.54s/it] 55%|█████▌    | 1851/3353 [17:14:48<13:59:27, 33.53s/it] 55%|█████▌    | 1852/3353 [17:15:22<13:58:16, 33.51s/it] 55%|█████▌    | 1853/3353 [17:15:55<13:57:22, 33.49s/it] 55%|█████▌    | 1854/3353 [17:16:29<13:56:16, 33.47s/it] 55%|█████▌    | 1855/3353 [17:17:02<13:55:40, 33.47s/it] 55%|█████▌    | 1856/3353 [17:17:35<13:54:51, 33.46s/it] 55%|█████▌    | 1857/3353 [17:18:09<13:54:11, 33.46s/it] 55%|█████▌    | 1858/3353 [17:18:42<13:53:36, 33.46s/it] 55%|█████▌    | 1859/3353 [17:19:16<13:52:52, 33.45s/it] 55%|█████▌    | 1860/3353 [17:19:49<13:53:45, 33.51s/it]                                                         {'loss': 1.182, 'learning_rate': 2.0722887648740436e-05, 'epoch': 0.55}
 55%|█████▌    | 1860/3353 [17:19:49<13:53:45, 33.51s/it] 56%|█████▌    | 1861/3353 [17:20:23<13:52:57, 33.50s/it] 56%|█████▌    | 1862/3353 [17:20:56<13:52:18, 33.49s/it] 56%|█████▌    | 1863/3353 [17:21:30<13:53:04, 33.55s/it] 56%|█████▌    | 1864/3353 [17:22:04<13:52:07, 33.53s/it] 56%|█████▌    | 1865/3353 [17:22:37<13:52:27, 33.57s/it] 56%|█████▌    | 1866/3353 [17:23:11<13:51:16, 33.54s/it] 56%|█████▌    | 1867/3353 [17:23:44<13:50:03, 33.52s/it] 56%|█████▌    | 1868/3353 [17:24:18<13:50:17, 33.55s/it] 56%|█████▌    | 1869/3353 [17:24:51<13:49:05, 33.52s/it] 56%|█████▌    | 1870/3353 [17:25:25<13:47:59, 33.50s/it]                                                         {'loss': 1.1734, 'learning_rate': 2.049229482690849e-05, 'epoch': 0.56}
 56%|█████▌    | 1870/3353 [17:25:25<13:47:59, 33.50s/it] 56%|█████▌    | 1871/3353 [17:25:58<13:48:57, 33.56s/it] 56%|█████▌    | 1872/3353 [17:26:32<13:47:41, 33.53s/it] 56%|█████▌    | 1873/3353 [17:27:05<13:47:53, 33.56s/it] 56%|█████▌    | 1874/3353 [17:27:39<13:46:33, 33.53s/it] 56%|█████▌    | 1875/3353 [17:28:12<13:45:31, 33.51s/it] 56%|█████▌    | 1876/3353 [17:28:46<13:44:34, 33.50s/it] 56%|█████▌    | 1877/3353 [17:29:19<13:44:22, 33.51s/it] 56%|█████▌    | 1878/3353 [17:29:53<13:43:24, 33.49s/it] 56%|█████▌    | 1879/3353 [17:30:27<13:43:52, 33.54s/it] 56%|█████▌    | 1880/3353 [17:31:00<13:42:33, 33.51s/it]                                                         {'loss': 1.1732, 'learning_rate': 2.0262097722310418e-05, 'epoch': 0.56}
 56%|█████▌    | 1880/3353 [17:31:00<13:42:33, 33.51s/it] 56%|█████▌    | 1881/3353 [17:31:34<13:43:34, 33.57s/it] 56%|█████▌    | 1882/3353 [17:32:07<13:42:01, 33.53s/it] 56%|█████▌    | 1883/3353 [17:32:41<13:41:06, 33.51s/it] 56%|█████▌    | 1884/3353 [17:33:14<13:39:45, 33.48s/it] 56%|█████▌    | 1885/3353 [17:33:48<13:40:12, 33.52s/it] 56%|█████▌    | 1886/3353 [17:34:21<13:39:09, 33.50s/it] 56%|█████▋    | 1887/3353 [17:34:55<13:38:22, 33.49s/it] 56%|█████▋    | 1888/3353 [17:35:28<13:37:31, 33.48s/it] 56%|█████▋    | 1889/3353 [17:36:01<13:36:45, 33.47s/it] 56%|█████▋    | 1890/3353 [17:36:35<13:36:08, 33.47s/it]                                                         {'loss': 1.1815, 'learning_rate': 2.0032316543224694e-05, 'epoch': 0.56}
 56%|█████▋    | 1890/3353 [17:36:35<13:36:08, 33.47s/it] 56%|█████▋    | 1891/3353 [17:37:08<13:35:49, 33.48s/it] 56%|█████▋    | 1892/3353 [17:37:42<13:35:19, 33.48s/it] 56%|█████▋    | 1893/3353 [17:38:15<13:34:38, 33.48s/it] 56%|█████▋    | 1894/3353 [17:38:49<13:33:58, 33.47s/it] 57%|█████▋    | 1895/3353 [17:39:22<13:34:02, 33.50s/it] 57%|█████▋    | 1896/3353 [17:39:56<13:33:15, 33.49s/it] 57%|█████▋    | 1897/3353 [17:40:29<13:33:23, 33.52s/it] 57%|█████▋    | 1898/3353 [17:41:03<13:32:33, 33.51s/it] 57%|█████▋    | 1899/3353 [17:41:36<13:31:39, 33.49s/it] 57%|█████▋    | 1900/3353 [17:42:10<13:30:57, 33.49s/it]                                                         {'loss': 1.172, 'learning_rate': 1.9802971461417024e-05, 'epoch': 0.57}
 57%|█████▋    | 1900/3353 [17:42:10<13:30:57, 33.49s/it] 57%|█████▋    | 1901/3353 [17:42:44<13:31:44, 33.54s/it] 57%|█████▋    | 1902/3353 [17:43:17<13:30:46, 33.53s/it] 57%|█████▋    | 1903/3353 [17:43:50<13:29:46, 33.51s/it] 57%|█████▋    | 1904/3353 [17:44:24<13:30:32, 33.56s/it] 57%|█████▋    | 1905/3353 [17:44:58<13:29:13, 33.53s/it] 57%|█████▋    | 1906/3353 [17:45:31<13:29:31, 33.57s/it] 57%|█████▋    | 1907/3353 [17:46:05<13:28:17, 33.54s/it] 57%|█████▋    | 1908/3353 [17:46:38<13:27:23, 33.53s/it] 57%|█████▋    | 1909/3353 [17:47:12<13:27:51, 33.57s/it] 57%|█████▋    | 1910/3353 [17:47:45<13:26:52, 33.55s/it]                                                         {'loss': 1.1744, 'learning_rate': 1.9574082610369496e-05, 'epoch': 0.57}
 57%|█████▋    | 1910/3353 [17:47:45<13:26:52, 33.55s/it] 57%|█████▋    | 1911/3353 [17:48:19<13:26:13, 33.55s/it] 57%|█████▋    | 1912/3353 [17:48:52<13:25:26, 33.54s/it] 57%|█████▋    | 1913/3353 [17:49:26<13:24:22, 33.52s/it] 57%|█████▋    | 1914/3353 [17:49:59<13:23:26, 33.50s/it] 57%|█████▋    | 1915/3353 [17:50:33<13:22:44, 33.49s/it] 57%|█████▋    | 1916/3353 [17:51:06<13:22:10, 33.49s/it] 57%|█████▋    | 1917/3353 [17:51:40<13:21:40, 33.50s/it] 57%|█████▋    | 1918/3353 [17:52:13<13:21:15, 33.50s/it] 57%|█████▋    | 1919/3353 [17:52:47<13:20:40, 33.50s/it] 57%|█████▋    | 1920/3353 [17:53:21<13:21:19, 33.55s/it]                                                         {'loss': 1.162, 'learning_rate': 1.9345670083513147e-05, 'epoch': 0.57}
 57%|█████▋    | 1920/3353 [17:53:21<13:21:19, 33.55s/it] 57%|█████▋    | 1921/3353 [17:53:54<13:20:49, 33.55s/it] 57%|█████▋    | 1922/3353 [17:54:28<13:20:52, 33.58s/it] 57%|█████▋    | 1923/3353 [17:55:01<13:19:38, 33.55s/it] 57%|█████▋    | 1924/3353 [17:55:35<13:18:26, 33.52s/it] 57%|█████▋    | 1925/3353 [17:56:08<13:18:43, 33.56s/it] 57%|█████▋    | 1926/3353 [17:56:42<13:17:26, 33.53s/it] 57%|█████▋    | 1927/3353 [17:57:15<13:16:23, 33.51s/it] 58%|█████▊    | 1928/3353 [17:57:49<13:16:41, 33.55s/it] 58%|█████▊    | 1929/3353 [17:58:22<13:15:24, 33.51s/it] 58%|█████▊    | 1930/3353 [17:58:56<13:15:53, 33.56s/it]                                                         {'loss': 1.1692, 'learning_rate': 1.9117753932463992e-05, 'epoch': 0.58}
 58%|█████▊    | 1930/3353 [17:58:56<13:15:53, 33.56s/it] 58%|█████▊    | 1931/3353 [17:59:29<13:14:41, 33.53s/it] 58%|█████▊    | 1932/3353 [18:00:03<13:13:34, 33.51s/it] 58%|█████▊    | 1933/3353 [18:00:37<13:13:47, 33.54s/it] 58%|█████▊    | 1934/3353 [18:01:10<13:12:38, 33.52s/it] 58%|█████▊    | 1935/3353 [18:01:43<13:11:43, 33.50s/it] 58%|█████▊    | 1936/3353 [18:02:17<13:12:21, 33.55s/it] 58%|█████▊    | 1937/3353 [18:02:51<13:10:52, 33.51s/it] 58%|█████▊    | 1938/3353 [18:03:24<13:11:23, 33.56s/it] 58%|█████▊    | 1939/3353 [18:03:58<13:10:00, 33.52s/it] 58%|█████▊    | 1940/3353 [18:04:31<13:08:59, 33.50s/it]                                                         {'loss': 1.1652, 'learning_rate': 1.8890354165262808e-05, 'epoch': 0.58}
 58%|█████▊    | 1940/3353 [18:04:32<13:08:59, 33.50s/it] 58%|█████▊    | 1941/3353 [18:05:06<13:14:38, 33.77s/it] 58%|█████▊    | 1942/3353 [18:05:39<13:12:15, 33.69s/it] 58%|█████▊    | 1943/3353 [18:06:13<13:10:19, 33.63s/it] 58%|█████▊    | 1944/3353 [18:06:46<13:08:41, 33.58s/it] 58%|█████▊    | 1945/3353 [18:07:19<13:07:31, 33.56s/it] 58%|█████▊    | 1946/3353 [18:07:53<13:06:25, 33.54s/it] 58%|█████▊    | 1947/3353 [18:08:26<13:05:23, 33.52s/it] 58%|█████▊    | 1948/3353 [18:09:00<13:04:45, 33.51s/it] 58%|█████▊    | 1949/3353 [18:09:33<13:03:53, 33.50s/it] 58%|█████▊    | 1950/3353 [18:10:07<13:03:58, 33.53s/it]                                                         {'loss': 1.1636, 'learning_rate': 1.8663490744618635e-05, 'epoch': 0.58}
 58%|█████▊    | 1950/3353 [18:10:07<13:03:58, 33.53s/it] 58%|█████▊    | 1951/3353 [18:10:41<13:03:14, 33.52s/it] 58%|█████▊    | 1952/3353 [18:11:14<13:02:55, 33.53s/it] 58%|█████▊    | 1953/3353 [18:11:48<13:01:55, 33.51s/it] 58%|█████▊    | 1954/3353 [18:12:21<13:01:23, 33.51s/it] 58%|█████▊    | 1955/3353 [18:12:54<13:00:12, 33.49s/it] 58%|█████▊    | 1956/3353 [18:13:28<12:59:26, 33.48s/it] 58%|█████▊    | 1957/3353 [18:14:01<12:58:35, 33.46s/it] 58%|█████▊    | 1958/3353 [18:14:35<12:57:55, 33.46s/it] 58%|█████▊    | 1959/3353 [18:15:08<12:57:26, 33.46s/it] 58%|█████▊    | 1960/3353 [18:15:42<12:56:51, 33.46s/it]                                                         {'loss': 1.1646, 'learning_rate': 1.8437183586156365e-05, 'epoch': 0.58}
 58%|█████▊    | 1960/3353 [18:15:42<12:56:51, 33.46s/it] 58%|█████▊    | 1961/3353 [18:16:15<12:58:18, 33.55s/it] 59%|█████▊    | 1962/3353 [18:16:49<12:56:59, 33.52s/it] 59%|█████▊    | 1963/3353 [18:17:23<12:57:14, 33.55s/it] 59%|█████▊    | 1964/3353 [18:17:56<12:56:04, 33.52s/it] 59%|█████▊    | 1965/3353 [18:18:30<12:55:26, 33.52s/it] 59%|█████▊    | 1966/3353 [18:19:03<12:55:39, 33.55s/it] 59%|█████▊    | 1967/3353 [18:19:37<12:54:43, 33.54s/it] 59%|█████▊    | 1968/3353 [18:20:10<12:53:49, 33.52s/it] 59%|█████▊    | 1969/3353 [18:20:44<12:53:24, 33.53s/it] 59%|█████▉    | 1970/3353 [18:21:17<12:52:59, 33.54s/it]                                                         {'loss': 1.1671, 'learning_rate': 1.821145255666835e-05, 'epoch': 0.59}
 59%|█████▉    | 1970/3353 [18:21:17<12:52:59, 33.54s/it] 59%|█████▉    | 1971/3353 [18:21:51<12:52:36, 33.54s/it] 59%|█████▉    | 1972/3353 [18:22:24<12:51:47, 33.53s/it] 59%|█████▉    | 1973/3353 [18:22:58<12:51:08, 33.53s/it] 59%|█████▉    | 1974/3353 [18:23:32<12:51:45, 33.58s/it] 59%|█████▉    | 1975/3353 [18:24:05<12:50:34, 33.55s/it] 59%|█████▉    | 1976/3353 [18:24:39<12:49:33, 33.53s/it] 59%|█████▉    | 1977/3353 [18:25:12<12:49:58, 33.57s/it] 59%|█████▉    | 1978/3353 [18:25:46<12:48:48, 33.55s/it] 59%|█████▉    | 1979/3353 [18:26:19<12:49:08, 33.59s/it] 59%|█████▉    | 1980/3353 [18:26:53<12:47:58, 33.56s/it]                                                         {'loss': 1.1709, 'learning_rate': 1.7986317472370435e-05, 'epoch': 0.59}
 59%|█████▉    | 1980/3353 [18:26:53<12:47:58, 33.56s/it] 59%|█████▉    | 1981/3353 [18:27:26<12:47:28, 33.56s/it] 59%|█████▉    | 1982/3353 [18:28:00<12:46:27, 33.54s/it] 59%|█████▉    | 1983/3353 [18:28:33<12:45:40, 33.53s/it] 59%|█████▉    | 1984/3353 [18:29:07<12:44:45, 33.52s/it] 59%|█████▉    | 1985/3353 [18:29:41<12:45:16, 33.56s/it] 59%|█████▉    | 1986/3353 [18:30:14<12:44:05, 33.54s/it] 59%|█████▉    | 1987/3353 [18:30:48<12:44:39, 33.59s/it] 59%|█████▉    | 1988/3353 [18:31:21<12:43:36, 33.57s/it] 59%|█████▉    | 1989/3353 [18:31:55<12:42:33, 33.54s/it] 59%|█████▉    | 1990/3353 [18:32:28<12:42:47, 33.58s/it]                                                         {'loss': 1.1612, 'learning_rate': 1.776179809716228e-05, 'epoch': 0.59}
 59%|█████▉    | 1990/3353 [18:32:28<12:42:47, 33.58s/it] 59%|█████▉    | 1991/3353 [18:33:02<12:42:08, 33.57s/it] 59%|█████▉    | 1992/3353 [18:33:35<12:40:55, 33.55s/it] 59%|█████▉    | 1993/3353 [18:34:09<12:41:10, 33.58s/it] 59%|█████▉    | 1994/3353 [18:34:43<12:39:47, 33.54s/it] 59%|█████▉    | 1995/3353 [18:35:16<12:40:07, 33.58s/it] 60%|█████▉    | 1996/3353 [18:35:50<12:39:04, 33.56s/it] 60%|█████▉    | 1997/3353 [18:36:23<12:38:00, 33.54s/it] 60%|█████▉    | 1998/3353 [18:36:57<12:38:25, 33.58s/it] 60%|█████▉    | 1999/3353 [18:37:30<12:37:15, 33.56s/it] 60%|█████▉    | 2000/3353 [18:38:04<12:36:23, 33.54s/it]                                                         {'loss': 1.1656, 'learning_rate': 1.7537914140892416e-05, 'epoch': 0.6}
 60%|█████▉    | 2000/3353 [18:38:04<12:36:23, 33.54s/it] 60%|█████▉    | 2001/3353 [18:38:38<12:36:02, 33.55s/it] 60%|█████▉    | 2002/3353 [18:39:11<12:35:00, 33.53s/it] 60%|█████▉    | 2003/3353 [18:39:44<12:34:06, 33.52s/it] 60%|█████▉    | 2004/3353 [18:40:18<12:33:29, 33.51s/it] 60%|█████▉    | 2005/3353 [18:40:51<12:32:49, 33.51s/it] 60%|█████▉    | 2006/3353 [18:41:25<12:32:09, 33.50s/it] 60%|█████▉    | 2007/3353 [18:41:59<12:32:00, 33.52s/it] 60%|█████▉    | 2008/3353 [18:42:32<12:31:02, 33.50s/it] 60%|█████▉    | 2009/3353 [18:43:06<12:30:54, 33.52s/it] 60%|█████▉    | 2010/3353 [18:43:39<12:29:57, 33.51s/it]                                                         {'loss': 1.1665, 'learning_rate': 1.7314685257627904e-05, 'epoch': 0.6}
 60%|█████▉    | 2010/3353 [18:43:39<12:29:57, 33.51s/it] 60%|█████▉    | 2011/3353 [18:44:13<12:30:35, 33.56s/it] 60%|██████    | 2012/3353 [18:44:46<12:29:26, 33.53s/it] 60%|██████    | 2013/3353 [18:45:20<12:28:41, 33.52s/it] 60%|██████    | 2014/3353 [18:45:53<12:27:56, 33.51s/it] 60%|██████    | 2015/3353 [18:46:27<12:28:10, 33.55s/it] 60%|██████    | 2016/3353 [18:47:00<12:27:17, 33.54s/it] 60%|██████    | 2017/3353 [18:47:34<12:26:27, 33.52s/it] 60%|██████    | 2018/3353 [18:48:08<12:27:00, 33.57s/it] 60%|██████    | 2019/3353 [18:48:41<12:25:44, 33.54s/it] 60%|██████    | 2020/3353 [18:49:15<12:26:08, 33.58s/it]                                                         {'loss': 1.1625, 'learning_rate': 1.709213104392907e-05, 'epoch': 0.6}
 60%|██████    | 2020/3353 [18:49:15<12:26:08, 33.58s/it] 60%|██████    | 2021/3353 [18:49:48<12:25:19, 33.57s/it] 60%|██████    | 2022/3353 [18:50:22<12:24:08, 33.54s/it] 60%|██████    | 2023/3353 [18:50:55<12:23:02, 33.52s/it] 60%|██████    | 2024/3353 [18:51:29<12:22:04, 33.50s/it] 60%|██████    | 2025/3353 [18:52:02<12:21:11, 33.49s/it] 60%|██████    | 2026/3353 [18:52:36<12:20:44, 33.49s/it] 60%|██████    | 2027/3353 [18:53:09<12:20:00, 33.48s/it] 60%|██████    | 2028/3353 [18:53:43<12:19:34, 33.49s/it] 61%|██████    | 2029/3353 [18:54:16<12:18:52, 33.48s/it] 61%|██████    | 2030/3353 [18:54:49<12:18:14, 33.48s/it]                                                         {'loss': 1.1602, 'learning_rate': 1.6870271037129053e-05, 'epoch': 0.61}
 61%|██████    | 2030/3353 [18:54:50<12:18:14, 33.48s/it] 61%|██████    | 2031/3353 [18:55:23<12:19:14, 33.55s/it] 61%|██████    | 2032/3353 [18:55:57<12:18:12, 33.53s/it] 61%|██████    | 2033/3353 [18:56:30<12:17:16, 33.51s/it] 61%|██████    | 2034/3353 [18:57:04<12:17:33, 33.55s/it] 61%|██████    | 2035/3353 [18:57:37<12:16:24, 33.52s/it] 61%|██████    | 2036/3353 [18:58:11<12:16:24, 33.55s/it] 61%|██████    | 2037/3353 [18:58:44<12:15:13, 33.52s/it] 61%|██████    | 2038/3353 [18:59:18<12:14:18, 33.50s/it] 61%|██████    | 2039/3353 [18:59:51<12:14:50, 33.55s/it] 61%|██████    | 2040/3353 [19:00:25<12:13:45, 33.53s/it]                                                         {'loss': 1.169, 'learning_rate': 1.6649124713618833e-05, 'epoch': 0.61}
 61%|██████    | 2040/3353 [19:00:25<12:13:45, 33.53s/it] 61%|██████    | 2041/3353 [19:00:58<12:13:20, 33.54s/it] 61%|██████    | 2042/3353 [19:01:32<12:13:41, 33.58s/it] 61%|██████    | 2043/3353 [19:02:06<12:12:15, 33.54s/it] 61%|██████    | 2044/3353 [19:02:39<12:12:27, 33.57s/it] 61%|██████    | 2045/3353 [19:03:13<12:11:09, 33.54s/it] 61%|██████    | 2046/3353 [19:03:46<12:10:00, 33.51s/it] 61%|██████    | 2047/3353 [19:04:20<12:09:06, 33.50s/it] 61%|██████    | 2048/3353 [19:04:53<12:08:25, 33.49s/it] 61%|██████    | 2049/3353 [19:05:27<12:07:37, 33.48s/it] 61%|██████    | 2050/3353 [19:06:00<12:08:21, 33.54s/it]                                                         {'loss': 1.1622, 'learning_rate': 1.6428711487137306e-05, 'epoch': 0.61}
 61%|██████    | 2050/3353 [19:06:00<12:08:21, 33.54s/it] 61%|██████    | 2051/3353 [19:06:34<12:07:37, 33.53s/it] 61%|██████    | 2052/3353 [19:07:07<12:08:08, 33.58s/it] 61%|██████    | 2053/3353 [19:07:41<12:06:44, 33.54s/it] 61%|██████▏   | 2054/3353 [19:08:14<12:05:36, 33.52s/it] 61%|██████▏   | 2055/3353 [19:08:48<12:05:49, 33.55s/it] 61%|██████▏   | 2056/3353 [19:09:21<12:04:41, 33.52s/it] 61%|██████▏   | 2057/3353 [19:09:55<12:03:52, 33.51s/it] 61%|██████▏   | 2058/3353 [19:10:28<12:03:14, 33.51s/it] 61%|██████▏   | 2059/3353 [19:11:02<12:02:15, 33.49s/it] 61%|██████▏   | 2060/3353 [19:11:35<12:01:22, 33.47s/it]                                                         {'loss': 1.1644, 'learning_rate': 1.6209050707067163e-05, 'epoch': 0.61}
 61%|██████▏   | 2060/3353 [19:11:35<12:01:22, 33.47s/it] 61%|██████▏   | 2061/3353 [19:12:09<12:01:11, 33.49s/it] 61%|██████▏   | 2062/3353 [19:12:42<12:00:24, 33.48s/it] 62%|██████▏   | 2063/3353 [19:13:16<12:00:40, 33.52s/it] 62%|██████▏   | 2064/3353 [19:13:49<11:59:47, 33.50s/it] 62%|██████▏   | 2065/3353 [19:14:23<11:59:00, 33.49s/it] 62%|██████▏   | 2066/3353 [19:14:56<11:58:56, 33.52s/it] 62%|██████▏   | 2067/3353 [19:15:30<11:57:58, 33.50s/it] 62%|██████▏   | 2068/3353 [19:16:03<11:57:50, 33.52s/it] 62%|██████▏   | 2069/3353 [19:16:37<11:56:42, 33.49s/it] 62%|██████▏   | 2070/3353 [19:17:10<11:55:47, 33.47s/it]                                                         {'loss': 1.1583, 'learning_rate': 1.599016165673613e-05, 'epoch': 0.62}
 62%|██████▏   | 2070/3353 [19:17:10<11:55:47, 33.47s/it] 62%|██████▏   | 2071/3353 [19:17:44<11:55:30, 33.49s/it] 62%|██████▏   | 2072/3353 [19:18:17<11:55:13, 33.50s/it] 62%|██████▏   | 2073/3353 [19:18:51<11:54:22, 33.49s/it] 62%|██████▏   | 2074/3353 [19:19:24<11:53:29, 33.47s/it] 62%|██████▏   | 2075/3353 [19:19:58<11:53:52, 33.52s/it] 62%|██████▏   | 2076/3353 [19:20:31<11:53:01, 33.50s/it] 62%|██████▏   | 2077/3353 [19:21:05<11:53:17, 33.54s/it] 62%|██████▏   | 2078/3353 [19:21:38<11:52:22, 33.52s/it] 62%|██████▏   | 2079/3353 [19:22:12<11:51:22, 33.50s/it] 62%|██████▏   | 2080/3353 [19:22:46<11:51:47, 33.55s/it]                                                         {'loss': 1.1587, 'learning_rate': 1.5772063551724258e-05, 'epoch': 0.62}
 62%|██████▏   | 2080/3353 [19:22:46<11:51:47, 33.55s/it] 62%|██████▏   | 2081/3353 [19:23:19<11:51:04, 33.54s/it] 62%|██████▏   | 2082/3353 [19:23:53<11:50:02, 33.52s/it] 62%|██████▏   | 2083/3353 [19:24:26<11:49:19, 33.51s/it] 62%|██████▏   | 2084/3353 [19:25:00<11:48:30, 33.50s/it] 62%|██████▏   | 2085/3353 [19:25:33<11:48:15, 33.51s/it] 62%|██████▏   | 2086/3353 [19:26:07<11:47:23, 33.50s/it] 62%|██████▏   | 2087/3353 [19:26:40<11:46:36, 33.49s/it] 62%|██████▏   | 2088/3353 [19:27:13<11:45:46, 33.48s/it] 62%|██████▏   | 2089/3353 [19:27:47<11:45:07, 33.47s/it] 62%|██████▏   | 2090/3353 [19:28:20<11:44:34, 33.47s/it]                                                         {'loss': 1.1579, 'learning_rate': 1.5554775538176976e-05, 'epoch': 0.62}
 62%|██████▏   | 2090/3353 [19:28:20<11:44:34, 33.47s/it] 62%|██████▏   | 2091/3353 [19:28:54<11:45:49, 33.56s/it] 62%|██████▏   | 2092/3353 [19:29:28<11:44:46, 33.53s/it] 62%|██████▏   | 2093/3353 [19:30:01<11:44:33, 33.55s/it] 62%|██████▏   | 2094/3353 [19:30:35<11:43:18, 33.52s/it] 62%|██████▏   | 2095/3353 [19:31:08<11:42:23, 33.50s/it] 63%|██████▎   | 2096/3353 [19:31:42<11:42:21, 33.53s/it] 63%|██████▎   | 2097/3353 [19:32:15<11:41:21, 33.50s/it] 63%|██████▎   | 2098/3353 [19:32:49<11:40:27, 33.49s/it] 63%|██████▎   | 2099/3353 [19:33:22<11:40:40, 33.53s/it] 63%|██████▎   | 2100/3353 [19:33:56<11:39:28, 33.49s/it]                                                         {'loss': 1.1581, 'learning_rate': 1.533831669112435e-05, 'epoch': 0.63}
 63%|██████▎   | 2100/3353 [19:33:56<11:39:28, 33.49s/it] 63%|██████▎   | 2101/3353 [19:34:29<11:39:46, 33.54s/it] 63%|██████▎   | 2102/3353 [19:35:03<11:38:40, 33.51s/it] 63%|██████▎   | 2103/3353 [19:35:36<11:37:43, 33.49s/it] 63%|██████▎   | 2104/3353 [19:36:10<11:38:06, 33.54s/it] 63%|██████▎   | 2105/3353 [19:36:43<11:37:12, 33.52s/it] 63%|██████▎   | 2106/3353 [19:37:17<11:36:03, 33.49s/it] 63%|██████▎   | 2107/3353 [19:37:50<11:36:35, 33.54s/it] 63%|██████▎   | 2108/3353 [19:38:24<11:35:26, 33.52s/it] 63%|██████▎   | 2109/3353 [19:38:57<11:35:39, 33.55s/it] 63%|██████▎   | 2110/3353 [19:39:31<11:34:37, 33.53s/it]                                                         {'loss': 1.1575, 'learning_rate': 1.512270601280651e-05, 'epoch': 0.63}
 63%|██████▎   | 2110/3353 [19:39:31<11:34:37, 33.53s/it] 63%|██████▎   | 2111/3353 [19:40:04<11:33:52, 33.52s/it] 63%|██████▎   | 2112/3353 [19:40:38<11:32:50, 33.50s/it] 63%|██████▎   | 2113/3353 [19:41:11<11:31:57, 33.48s/it] 63%|██████▎   | 2114/3353 [19:41:45<11:31:19, 33.48s/it] 63%|██████▎   | 2115/3353 [19:42:18<11:30:36, 33.47s/it] 63%|██████▎   | 2116/3353 [19:42:52<11:29:54, 33.46s/it] 63%|██████▎   | 2117/3353 [19:43:25<11:29:27, 33.47s/it] 63%|██████▎   | 2118/3353 [19:43:59<11:28:58, 33.47s/it] 63%|██████▎   | 2119/3353 [19:44:32<11:28:23, 33.47s/it] 63%|██████▎   | 2120/3353 [19:45:06<11:28:54, 33.52s/it]                                                         {'loss': 1.1574, 'learning_rate': 1.4907962431005557e-05, 'epoch': 0.63}
 63%|██████▎   | 2120/3353 [19:45:09<11:28:54, 33.52s/it] 63%|██████▎   | 2121/3353 [19:45:43<11:49:25, 34.55s/it] 63%|██████▎   | 2122/3353 [19:46:16<11:41:58, 34.21s/it] 63%|██████▎   | 2123/3353 [19:46:50<11:37:41, 34.03s/it] 63%|██████▎   | 2124/3353 [19:47:23<11:33:35, 33.86s/it] 63%|██████▎   | 2125/3353 [19:47:57<11:30:57, 33.76s/it] 63%|██████▎   | 2126/3353 [19:48:30<11:28:30, 33.67s/it] 63%|██████▎   | 2127/3353 [19:49:04<11:26:35, 33.60s/it] 63%|██████▎   | 2128/3353 [19:49:37<11:26:05, 33.60s/it] 63%|██████▎   | 2129/3353 [19:50:11<11:24:38, 33.56s/it] 64%|██████▎   | 2130/3353 [19:50:44<11:23:27, 33.53s/it]                                                         {'loss': 1.1611, 'learning_rate': 1.4694104797383892e-05, 'epoch': 0.64}
 64%|██████▎   | 2130/3353 [19:50:44<11:23:27, 33.53s/it] 64%|██████▎   | 2131/3353 [19:51:18<11:23:13, 33.55s/it] 64%|██████▎   | 2132/3353 [19:51:51<11:23:25, 33.58s/it] 64%|██████▎   | 2133/3353 [19:52:25<11:22:00, 33.54s/it] 64%|██████▎   | 2134/3353 [19:52:59<11:22:09, 33.58s/it] 64%|██████▎   | 2135/3353 [19:53:32<11:20:44, 33.53s/it] 64%|██████▎   | 2136/3353 [19:54:05<11:19:37, 33.51s/it] 64%|██████▎   | 2137/3353 [19:54:39<11:19:18, 33.52s/it] 64%|██████▍   | 2138/3353 [19:55:12<11:18:22, 33.50s/it] 64%|██████▍   | 2139/3353 [19:55:46<11:17:31, 33.49s/it] 64%|██████▍   | 2140/3353 [19:56:19<11:17:07, 33.49s/it]                                                         {'loss': 1.1501, 'learning_rate': 1.4481151885829347e-05, 'epoch': 0.64}
 64%|██████▍   | 2140/3353 [19:56:19<11:17:07, 33.49s/it] 64%|██████▍   | 2141/3353 [19:56:53<11:17:05, 33.52s/it] 64%|██████▍   | 2142/3353 [19:57:26<11:16:19, 33.51s/it] 64%|██████▍   | 2143/3353 [19:58:00<11:15:32, 33.50s/it] 64%|██████▍   | 2144/3353 [19:58:33<11:14:42, 33.48s/it] 64%|██████▍   | 2145/3353 [19:59:07<11:15:18, 33.54s/it] 64%|██████▍   | 2146/3353 [19:59:40<11:14:06, 33.51s/it] 64%|██████▍   | 2147/3353 [20:00:14<11:13:06, 33.49s/it] 64%|██████▍   | 2148/3353 [20:00:47<11:13:10, 33.52s/it] 64%|██████▍   | 2149/3353 [20:01:21<11:12:17, 33.50s/it] 64%|██████▍   | 2150/3353 [20:01:55<11:12:22, 33.53s/it]                                                         {'loss': 1.1476, 'learning_rate': 1.4269122390807e-05, 'epoch': 0.64}
 64%|██████▍   | 2150/3353 [20:01:55<11:12:22, 33.53s/it] 64%|██████▍   | 2151/3353 [20:02:28<11:11:32, 33.52s/it] 64%|██████▍   | 2152/3353 [20:03:01<11:10:20, 33.49s/it] 64%|██████▍   | 2153/3353 [20:03:35<11:09:33, 33.48s/it] 64%|██████▍   | 2154/3353 [20:04:08<11:08:49, 33.47s/it] 64%|██████▍   | 2155/3353 [20:04:42<11:08:12, 33.47s/it] 64%|██████▍   | 2156/3353 [20:05:15<11:08:46, 33.52s/it] 64%|██████▍   | 2157/3353 [20:05:49<11:07:46, 33.50s/it] 64%|██████▍   | 2158/3353 [20:06:23<11:08:08, 33.55s/it] 64%|██████▍   | 2159/3353 [20:06:56<11:07:07, 33.52s/it] 64%|██████▍   | 2160/3353 [20:07:29<11:06:05, 33.50s/it]                                                         {'loss': 1.1555, 'learning_rate': 1.4058034925718183e-05, 'epoch': 0.64}
 64%|██████▍   | 2160/3353 [20:07:30<11:06:05, 33.50s/it] 64%|██████▍   | 2161/3353 [20:08:03<11:06:53, 33.57s/it] 64%|██████▍   | 2162/3353 [20:08:37<11:05:47, 33.54s/it] 65%|██████▍   | 2163/3353 [20:09:10<11:04:31, 33.51s/it] 65%|██████▍   | 2164/3353 [20:09:44<11:04:47, 33.55s/it] 65%|██████▍   | 2165/3353 [20:10:17<11:03:33, 33.51s/it] 65%|██████▍   | 2166/3353 [20:10:51<11:03:47, 33.55s/it] 65%|██████▍   | 2167/3353 [20:11:24<11:02:31, 33.52s/it] 65%|██████▍   | 2168/3353 [20:11:58<11:01:34, 33.50s/it] 65%|██████▍   | 2169/3353 [20:12:31<11:01:43, 33.53s/it] 65%|██████▍   | 2170/3353 [20:13:05<11:00:29, 33.50s/it]                                                         {'loss': 1.1553, 'learning_rate': 1.3847908021266309e-05, 'epoch': 0.65}
 65%|██████▍   | 2170/3353 [20:13:05<11:00:29, 33.50s/it] 65%|██████▍   | 2171/3353 [20:13:38<10:59:53, 33.50s/it] 65%|██████▍   | 2172/3353 [20:14:12<10:59:14, 33.49s/it] 65%|██████▍   | 2173/3353 [20:14:45<10:58:18, 33.47s/it] 65%|██████▍   | 2174/3353 [20:15:19<10:57:55, 33.48s/it] 65%|██████▍   | 2175/3353 [20:15:52<10:57:13, 33.48s/it] 65%|██████▍   | 2176/3353 [20:16:26<10:56:38, 33.47s/it] 65%|██████▍   | 2177/3353 [20:16:59<10:56:04, 33.47s/it] 65%|██████▍   | 2178/3353 [20:17:33<10:55:22, 33.47s/it] 65%|██████▍   | 2179/3353 [20:18:06<10:54:50, 33.47s/it] 65%|██████▌   | 2180/3353 [20:18:40<10:54:55, 33.50s/it]                                                         {'loss': 1.151, 'learning_rate': 1.3638760123830258e-05, 'epoch': 0.65}
 65%|██████▌   | 2180/3353 [20:18:40<10:54:55, 33.50s/it] 65%|██████▌   | 2181/3353 [20:19:13<10:54:32, 33.51s/it] 65%|██████▌   | 2182/3353 [20:19:47<10:54:10, 33.52s/it] 65%|██████▌   | 2183/3353 [20:20:20<10:53:29, 33.51s/it] 65%|██████▌   | 2184/3353 [20:20:54<10:52:43, 33.50s/it] 65%|██████▌   | 2185/3353 [20:21:27<10:53:10, 33.55s/it] 65%|██████▌   | 2186/3353 [20:22:01<10:52:05, 33.53s/it] 65%|██████▌   | 2187/3353 [20:22:34<10:51:27, 33.52s/it] 65%|██████▌   | 2188/3353 [20:23:08<10:50:36, 33.51s/it] 65%|██████▌   | 2189/3353 [20:23:41<10:51:15, 33.57s/it] 65%|██████▌   | 2190/3353 [20:24:15<10:50:09, 33.54s/it]                                                         {'loss': 1.1541, 'learning_rate': 1.3430609593844917e-05, 'epoch': 0.65}
 65%|██████▌   | 2190/3353 [20:24:15<10:50:09, 33.54s/it] 65%|██████▌   | 2191/3353 [20:24:49<10:51:10, 33.62s/it] 65%|██████▌   | 2192/3353 [20:25:22<10:49:33, 33.57s/it] 65%|██████▌   | 2193/3353 [20:25:56<10:49:19, 33.59s/it] 65%|██████▌   | 2194/3353 [20:26:29<10:47:59, 33.55s/it] 65%|██████▌   | 2195/3353 [20:27:03<10:47:07, 33.53s/it] 65%|██████▌   | 2196/3353 [20:27:36<10:46:15, 33.51s/it] 66%|██████▌   | 2197/3353 [20:28:10<10:45:30, 33.50s/it] 66%|██████▌   | 2198/3353 [20:28:43<10:44:42, 33.49s/it] 66%|██████▌   | 2199/3353 [20:29:17<10:44:06, 33.49s/it] 66%|██████▌   | 2200/3353 [20:29:50<10:43:32, 33.49s/it]                                                         {'loss': 1.1507, 'learning_rate': 1.3223474704189472e-05, 'epoch': 0.66}
 66%|██████▌   | 2200/3353 [20:29:50<10:43:32, 33.49s/it] 66%|██████▌   | 2201/3353 [20:30:24<10:43:11, 33.50s/it] 66%|██████▌   | 2202/3353 [20:30:57<10:42:53, 33.51s/it] 66%|██████▌   | 2203/3353 [20:31:31<10:42:00, 33.50s/it] 66%|██████▌   | 2204/3353 [20:32:04<10:41:07, 33.48s/it] 66%|██████▌   | 2205/3353 [20:32:38<10:41:25, 33.52s/it] 66%|██████▌   | 2206/3353 [20:33:11<10:40:32, 33.51s/it] 66%|██████▌   | 2207/3353 [20:33:45<10:40:28, 33.53s/it] 66%|██████▌   | 2208/3353 [20:34:18<10:39:19, 33.50s/it] 66%|██████▌   | 2209/3353 [20:34:52<10:38:58, 33.51s/it] 66%|██████▌   | 2210/3353 [20:35:25<10:39:09, 33.55s/it]                                                         {'loss': 1.1501, 'learning_rate': 1.3017373638583224e-05, 'epoch': 0.66}
 66%|██████▌   | 2210/3353 [20:35:25<10:39:09, 33.55s/it] 66%|██████▌   | 2211/3353 [20:35:59<10:38:09, 33.53s/it] 66%|██████▌   | 2212/3353 [20:36:32<10:37:11, 33.51s/it] 66%|██████▌   | 2213/3353 [20:37:06<10:37:29, 33.55s/it] 66%|██████▌   | 2214/3353 [20:37:39<10:36:24, 33.52s/it] 66%|██████▌   | 2215/3353 [20:38:13<10:36:27, 33.56s/it] 66%|██████▌   | 2216/3353 [20:38:47<10:35:14, 33.52s/it] 66%|██████▌   | 2217/3353 [20:39:20<10:34:32, 33.51s/it] 66%|██████▌   | 2218/3353 [20:39:53<10:33:41, 33.50s/it] 66%|██████▌   | 2219/3353 [20:40:27<10:33:01, 33.49s/it] 66%|██████▌   | 2220/3353 [20:41:00<10:32:13, 33.48s/it]                                                         {'loss': 1.1565, 'learning_rate': 1.281232448998933e-05, 'epoch': 0.66}
 66%|██████▌   | 2220/3353 [20:41:01<10:32:13, 33.48s/it] 66%|██████▌   | 2221/3353 [20:41:34<10:32:53, 33.55s/it] 66%|██████▋   | 2222/3353 [20:42:08<10:31:53, 33.52s/it] 66%|██████▋   | 2223/3353 [20:42:41<10:32:08, 33.57s/it] 66%|██████▋   | 2224/3353 [20:43:15<10:31:05, 33.54s/it] 66%|██████▋   | 2225/3353 [20:43:48<10:30:04, 33.51s/it] 66%|██████▋   | 2226/3353 [20:44:22<10:29:56, 33.54s/it] 66%|██████▋   | 2227/3353 [20:44:55<10:28:49, 33.51s/it] 66%|██████▋   | 2228/3353 [20:45:29<10:28:05, 33.50s/it] 66%|██████▋   | 2229/3353 [20:46:02<10:27:29, 33.50s/it] 67%|██████▋   | 2230/3353 [20:46:36<10:26:44, 33.49s/it]                                                         {'loss': 1.1463, 'learning_rate': 1.2608345259026438e-05, 'epoch': 0.67}
 67%|██████▋   | 2230/3353 [20:46:36<10:26:44, 33.49s/it] 67%|██████▋   | 2231/3353 [20:47:09<10:26:28, 33.50s/it] 67%|██████▋   | 2232/3353 [20:47:43<10:25:43, 33.49s/it] 67%|██████▋   | 2233/3353 [20:48:16<10:24:58, 33.48s/it] 67%|██████▋   | 2234/3353 [20:48:50<10:25:33, 33.54s/it] 67%|██████▋   | 2235/3353 [20:49:23<10:24:39, 33.52s/it] 67%|██████▋   | 2236/3353 [20:49:57<10:23:38, 33.50s/it] 67%|██████▋   | 2237/3353 [20:50:30<10:23:34, 33.53s/it] 67%|██████▋   | 2238/3353 [20:51:04<10:22:43, 33.51s/it] 67%|██████▋   | 2239/3353 [20:51:37<10:22:29, 33.53s/it] 67%|██████▋   | 2240/3353 [20:52:11<10:21:36, 33.51s/it]                                                         {'loss': 1.1546, 'learning_rate': 1.240545385238853e-05, 'epoch': 0.67}
 67%|██████▋   | 2240/3353 [20:52:11<10:21:36, 33.51s/it] 67%|██████▋   | 2241/3353 [20:52:44<10:21:15, 33.52s/it] 67%|██████▋   | 2242/3353 [20:53:18<10:20:40, 33.52s/it] 67%|██████▋   | 2243/3353 [20:53:51<10:19:52, 33.51s/it] 67%|██████▋   | 2244/3353 [20:54:25<10:19:06, 33.50s/it] 67%|██████▋   | 2245/3353 [20:54:58<10:18:24, 33.49s/it] 67%|██████▋   | 2246/3353 [20:55:32<10:18:53, 33.54s/it] 67%|██████▋   | 2247/3353 [20:56:06<10:18:17, 33.54s/it] 67%|██████▋   | 2248/3353 [20:56:39<10:18:27, 33.58s/it] 67%|██████▋   | 2249/3353 [20:57:13<10:17:24, 33.55s/it] 67%|██████▋   | 2250/3353 [20:57:46<10:17:24, 33.58s/it]                                                         {'loss': 1.1534, 'learning_rate': 1.2203668081272903e-05, 'epoch': 0.67}
 67%|██████▋   | 2250/3353 [20:57:46<10:17:24, 33.58s/it] 67%|██████▋   | 2251/3353 [20:58:20<10:16:22, 33.56s/it] 67%|██████▋   | 2252/3353 [20:58:53<10:15:16, 33.53s/it] 67%|██████▋   | 2253/3353 [20:59:27<10:14:11, 33.50s/it] 67%|██████▋   | 2254/3353 [21:00:00<10:13:35, 33.50s/it] 67%|██████▋   | 2255/3353 [21:00:34<10:12:58, 33.50s/it] 67%|██████▋   | 2256/3353 [21:01:07<10:12:15, 33.49s/it] 67%|██████▋   | 2257/3353 [21:01:41<10:11:33, 33.48s/it] 67%|██████▋   | 2258/3353 [21:02:14<10:11:51, 33.53s/it] 67%|██████▋   | 2259/3353 [21:02:48<10:10:48, 33.50s/it] 67%|██████▋   | 2260/3353 [21:03:21<10:10:00, 33.49s/it]                                                         {'loss': 1.1529, 'learning_rate': 1.2003005659816616e-05, 'epoch': 0.67}
 67%|██████▋   | 2260/3353 [21:03:21<10:10:00, 33.49s/it] 67%|██████▋   | 2261/3353 [21:03:55<10:09:36, 33.49s/it] 67%|██████▋   | 2262/3353 [21:04:28<10:10:05, 33.55s/it] 67%|██████▋   | 2263/3353 [21:05:02<10:08:55, 33.52s/it] 68%|██████▊   | 2264/3353 [21:05:35<10:09:09, 33.56s/it] 68%|██████▊   | 2265/3353 [21:06:09<10:08:06, 33.54s/it] 68%|██████▊   | 2266/3353 [21:06:42<10:06:58, 33.50s/it] 68%|██████▊   | 2267/3353 [21:07:16<10:06:29, 33.51s/it] 68%|██████▊   | 2268/3353 [21:07:49<10:05:41, 33.49s/it] 68%|██████▊   | 2269/3353 [21:08:23<10:04:46, 33.47s/it] 68%|██████▊   | 2270/3353 [21:08:56<10:05:11, 33.53s/it]                                                         {'loss': 1.1512, 'learning_rate': 1.1803484203541354e-05, 'epoch': 0.68}
 68%|██████▊   | 2270/3353 [21:08:57<10:05:11, 33.53s/it] 68%|██████▊   | 2271/3353 [21:09:30<10:04:51, 33.54s/it] 68%|██████▊   | 2272/3353 [21:10:04<10:04:58, 33.58s/it] 68%|██████▊   | 2273/3353 [21:10:37<10:03:50, 33.55s/it] 68%|██████▊   | 2274/3353 [21:11:11<10:02:49, 33.52s/it] 68%|██████▊   | 2275/3353 [21:11:44<10:02:59, 33.56s/it] 68%|██████▊   | 2276/3353 [21:12:18<10:01:54, 33.53s/it] 68%|██████▊   | 2277/3353 [21:12:51<10:01:01, 33.51s/it] 68%|██████▊   | 2278/3353 [21:13:25<10:01:21, 33.56s/it] 68%|██████▊   | 2279/3353 [21:13:58<10:00:13, 33.53s/it] 68%|██████▊   | 2280/3353 [21:14:32<10:00:05, 33.56s/it]                                                         {'loss': 1.1482, 'learning_rate': 1.1605121227807112e-05, 'epoch': 0.68}
 68%|██████▊   | 2280/3353 [21:14:32<10:00:05, 33.56s/it] 68%|██████▊   | 2281/3353 [21:15:05<9:59:08, 33.53s/it]  68%|██████▊   | 2282/3353 [21:15:39<9:58:12, 33.51s/it] 68%|██████▊   | 2283/3353 [21:16:12<9:57:22, 33.50s/it] 68%|██████▊   | 2284/3353 [21:16:46<9:56:31, 33.48s/it] 68%|██████▊   | 2285/3353 [21:17:19<9:55:54, 33.48s/it] 68%|██████▊   | 2286/3353 [21:17:53<9:55:36, 33.49s/it] 68%|██████▊   | 2287/3353 [21:18:26<9:55:04, 33.49s/it] 68%|██████▊   | 2288/3353 [21:19:00<9:54:33, 33.50s/it] 68%|██████▊   | 2289/3353 [21:19:33<9:53:44, 33.48s/it] 68%|██████▊   | 2290/3353 [21:20:07<9:52:50, 33.46s/it]                                                        {'loss': 1.1498, 'learning_rate': 1.1407934146274502e-05, 'epoch': 0.68}
 68%|██████▊   | 2290/3353 [21:20:07<9:52:50, 33.46s/it] 68%|██████▊   | 2291/3353 [21:20:40<9:53:08, 33.51s/it] 68%|██████▊   | 2292/3353 [21:21:14<9:52:23, 33.50s/it] 68%|██████▊   | 2293/3353 [21:21:47<9:51:41, 33.49s/it] 68%|██████▊   | 2294/3353 [21:22:21<9:51:37, 33.52s/it] 68%|██████▊   | 2295/3353 [21:22:54<9:50:45, 33.50s/it] 68%|██████▊   | 2296/3353 [21:23:28<9:50:28, 33.52s/it] 69%|██████▊   | 2297/3353 [21:24:01<9:49:36, 33.50s/it] 69%|██████▊   | 2298/3353 [21:24:35<9:48:47, 33.49s/it] 69%|██████▊   | 2299/3353 [21:25:08<9:49:22, 33.55s/it] 69%|██████▊   | 2300/3353 [21:25:42<9:48:27, 33.53s/it]                                                        {'loss': 1.1501, 'learning_rate': 1.1211940269376114e-05, 'epoch': 0.69}
 69%|██████▊   | 2300/3353 [21:25:42<9:48:27, 33.53s/it] 69%|██████▊   | 2301/3353 [21:26:15<9:47:57, 33.53s/it] 69%|██████▊   | 2302/3353 [21:26:49<9:46:55, 33.51s/it] 69%|██████▊   | 2303/3353 [21:27:23<9:47:16, 33.56s/it] 69%|██████▊   | 2304/3353 [21:27:56<9:46:15, 33.53s/it] 69%|██████▊   | 2305/3353 [21:28:30<9:46:20, 33.57s/it] 69%|██████▉   | 2306/3353 [21:29:03<9:45:26, 33.55s/it] 69%|██████▉   | 2307/3353 [21:29:37<9:44:26, 33.52s/it] 69%|██████▉   | 2308/3353 [21:30:10<9:43:32, 33.50s/it] 69%|██████▉   | 2309/3353 [21:30:44<9:42:45, 33.49s/it] 69%|██████▉   | 2310/3353 [21:31:17<9:42:08, 33.49s/it]                                                        {'loss': 1.148, 'learning_rate': 1.1017156802796824e-05, 'epoch': 0.69}
 69%|██████▉   | 2310/3353 [21:31:17<9:42:08, 33.49s/it] 69%|██████▉   | 2311/3353 [21:31:51<9:41:47, 33.50s/it] 69%|██████▉   | 2312/3353 [21:32:24<9:41:02, 33.49s/it] 69%|██████▉   | 2313/3353 [21:32:58<9:40:11, 33.47s/it] 69%|██████▉   | 2314/3353 [21:33:31<9:39:35, 33.47s/it] 69%|██████▉   | 2315/3353 [21:34:05<9:40:13, 33.54s/it] 69%|██████▉   | 2316/3353 [21:34:38<9:39:21, 33.52s/it] 69%|██████▉   | 2317/3353 [21:35:12<9:38:38, 33.51s/it] 69%|██████▉   | 2318/3353 [21:35:45<9:37:53, 33.50s/it] 69%|██████▉   | 2319/3353 [21:36:19<9:38:20, 33.56s/it] 69%|██████▉   | 2320/3353 [21:36:52<9:37:15, 33.53s/it]                                                        {'loss': 1.1441, 'learning_rate': 1.0823600845963439e-05, 'epoch': 0.69}
 69%|██████▉   | 2320/3353 [21:36:52<9:37:15, 33.53s/it] 69%|██████▉   | 2321/3353 [21:37:26<9:37:16, 33.56s/it] 69%|██████▉   | 2322/3353 [21:37:59<9:36:14, 33.54s/it] 69%|██████▉   | 2323/3353 [21:38:33<9:36:10, 33.56s/it] 69%|██████▉   | 2324/3353 [21:39:06<9:35:07, 33.53s/it] 69%|██████▉   | 2325/3353 [21:39:40<9:34:15, 33.52s/it] 69%|██████▉   | 2326/3353 [21:40:13<9:33:14, 33.49s/it] 69%|██████▉   | 2327/3353 [21:40:47<9:33:32, 33.54s/it] 69%|██████▉   | 2328/3353 [21:41:21<9:32:32, 33.51s/it] 69%|██████▉   | 2329/3353 [21:41:54<9:32:47, 33.56s/it] 69%|██████▉   | 2330/3353 [21:42:28<9:31:53, 33.54s/it]                                                        {'loss': 1.149, 'learning_rate': 1.0631289390543511e-05, 'epoch': 0.69}
 69%|██████▉   | 2330/3353 [21:42:28<9:31:53, 33.54s/it] 70%|██████▉   | 2331/3353 [21:43:01<9:31:12, 33.54s/it] 70%|██████▉   | 2332/3353 [21:43:35<9:30:55, 33.55s/it] 70%|██████▉   | 2333/3353 [21:44:08<9:30:11, 33.54s/it] 70%|██████▉   | 2334/3353 [21:44:42<9:29:20, 33.52s/it] 70%|██████▉   | 2335/3353 [21:45:15<9:29:28, 33.56s/it] 70%|██████▉   | 2336/3353 [21:45:49<9:28:16, 33.53s/it] 70%|██████▉   | 2337/3353 [21:46:23<9:28:30, 33.57s/it] 70%|██████▉   | 2338/3353 [21:46:56<9:27:14, 33.53s/it] 70%|██████▉   | 2339/3353 [21:47:29<9:26:26, 33.52s/it] 70%|██████▉   | 2340/3353 [21:48:03<9:26:23, 33.55s/it]                                                        {'loss': 1.1465, 'learning_rate': 1.0440239318953792e-05, 'epoch': 0.7}
 70%|██████▉   | 2340/3353 [21:48:03<9:26:23, 33.55s/it] 70%|██████▉   | 2341/3353 [21:48:37<9:25:37, 33.54s/it] 70%|██████▉   | 2342/3353 [21:49:10<9:24:58, 33.53s/it] 70%|██████▉   | 2343/3353 [21:49:44<9:24:10, 33.52s/it] 70%|██████▉   | 2344/3353 [21:50:17<9:23:22, 33.50s/it] 70%|██████▉   | 2345/3353 [21:50:51<9:22:37, 33.49s/it] 70%|██████▉   | 2346/3353 [21:51:24<9:21:53, 33.48s/it] 70%|██████▉   | 2347/3353 [21:51:57<9:21:16, 33.48s/it] 70%|███████   | 2348/3353 [21:52:31<9:20:26, 33.46s/it] 70%|███████   | 2349/3353 [21:53:04<9:19:52, 33.46s/it] 70%|███████   | 2350/3353 [21:53:38<9:19:24, 33.46s/it]                                                        {'loss': 1.1465, 'learning_rate': 1.025046740287807e-05, 'epoch': 0.7}
 70%|███████   | 2350/3353 [21:53:38<9:19:24, 33.46s/it] 70%|███████   | 2351/3353 [21:54:11<9:19:41, 33.51s/it] 70%|███████   | 2352/3353 [21:54:45<9:18:52, 33.50s/it] 70%|███████   | 2353/3353 [21:55:19<9:18:51, 33.53s/it] 70%|███████   | 2354/3353 [21:55:52<9:17:50, 33.50s/it] 70%|███████   | 2355/3353 [21:56:25<9:17:03, 33.49s/it] 70%|███████   | 2356/3353 [21:56:59<9:17:02, 33.52s/it] 70%|███████   | 2357/3353 [21:57:32<9:16:09, 33.50s/it] 70%|███████   | 2358/3353 [21:58:06<9:15:26, 33.49s/it] 70%|███████   | 2359/3353 [21:58:39<9:14:37, 33.48s/it] 70%|███████   | 2360/3353 [21:59:13<9:15:22, 33.56s/it]                                                        {'loss': 1.1536, 'learning_rate': 1.0061990301794919e-05, 'epoch': 0.7}
 70%|███████   | 2360/3353 [21:59:13<9:15:22, 33.56s/it] 70%|███████   | 2361/3353 [21:59:47<9:14:34, 33.54s/it] 70%|███████   | 2362/3353 [22:00:20<9:14:27, 33.57s/it] 70%|███████   | 2363/3353 [22:00:54<9:13:18, 33.53s/it] 71%|███████   | 2364/3353 [22:01:27<9:13:26, 33.58s/it] 71%|███████   | 2365/3353 [22:02:01<9:12:18, 33.54s/it] 71%|███████   | 2366/3353 [22:02:34<9:11:24, 33.52s/it] 71%|███████   | 2367/3353 [22:03:08<9:10:35, 33.50s/it] 71%|███████   | 2368/3353 [22:03:41<9:09:58, 33.50s/it] 71%|███████   | 2369/3353 [22:04:15<9:08:59, 33.47s/it] 71%|███████   | 2370/3353 [22:04:48<9:08:25, 33.47s/it]                                                        {'loss': 1.1391, 'learning_rate': 9.874824561515152e-06, 'epoch': 0.71}
 71%|███████   | 2370/3353 [22:04:48<9:08:25, 33.47s/it] 71%|███████   | 2371/3353 [22:05:22<9:08:01, 33.48s/it] 71%|███████   | 2372/3353 [22:05:55<9:07:14, 33.47s/it] 71%|███████   | 2373/3353 [22:06:29<9:06:44, 33.47s/it] 71%|███████   | 2374/3353 [22:07:02<9:06:01, 33.46s/it] 71%|███████   | 2375/3353 [22:07:35<9:05:16, 33.45s/it] 71%|███████   | 2376/3353 [22:08:09<9:05:38, 33.51s/it] 71%|███████   | 2377/3353 [22:08:43<9:04:58, 33.50s/it] 71%|███████   | 2378/3353 [22:09:16<9:04:48, 33.53s/it] 71%|███████   | 2379/3353 [22:09:50<9:03:58, 33.51s/it] 71%|███████   | 2380/3353 [22:10:23<9:04:06, 33.55s/it]                                                        {'loss': 1.1467, 'learning_rate': 9.688986612729387e-06, 'epoch': 0.71}
 71%|███████   | 2380/3353 [22:10:23<9:04:06, 33.55s/it] 71%|███████   | 2381/3353 [22:10:57<9:03:32, 33.55s/it] 71%|███████   | 2382/3353 [22:11:30<9:02:23, 33.52s/it] 71%|███████   | 2383/3353 [22:12:04<9:01:32, 33.50s/it] 71%|███████   | 2384/3353 [22:12:37<9:01:47, 33.55s/it] 71%|███████   | 2385/3353 [22:13:11<9:00:41, 33.51s/it] 71%|███████   | 2386/3353 [22:13:44<9:00:52, 33.56s/it] 71%|███████   | 2387/3353 [22:14:18<8:59:55, 33.54s/it] 71%|███████   | 2388/3353 [22:14:52<8:59:37, 33.55s/it] 71%|███████   | 2389/3353 [22:15:25<8:58:28, 33.52s/it] 71%|███████▏  | 2390/3353 [22:15:58<8:57:37, 33.50s/it]                                                        {'loss': 1.144, 'learning_rate': 9.504492769565584e-06, 'epoch': 0.71}
 71%|███████▏  | 2390/3353 [22:15:58<8:57:37, 33.50s/it] 71%|███████▏  | 2391/3353 [22:16:32<8:57:01, 33.49s/it] 71%|███████▏  | 2392/3353 [22:17:06<8:57:19, 33.55s/it] 71%|███████▏  | 2393/3353 [22:17:39<8:56:09, 33.51s/it] 71%|███████▏  | 2394/3353 [22:18:13<8:56:26, 33.56s/it] 71%|███████▏  | 2395/3353 [22:18:46<8:55:18, 33.53s/it] 71%|███████▏  | 2396/3353 [22:19:20<8:54:14, 33.49s/it] 71%|███████▏  | 2397/3353 [22:19:53<8:53:41, 33.50s/it] 72%|███████▏  | 2398/3353 [22:20:27<8:52:50, 33.48s/it] 72%|███████▏  | 2399/3353 [22:21:00<8:52:02, 33.46s/it] 72%|███████▏  | 2400/3353 [22:21:33<8:51:40, 33.47s/it]                                                        {'loss': 1.1477, 'learning_rate': 9.321359228156932e-06, 'epoch': 0.72}
 72%|███████▏  | 2400/3353 [22:21:34<8:51:40, 33.47s/it] 72%|███████▏  | 2401/3353 [22:22:07<8:51:20, 33.49s/it] 72%|███████▏  | 2402/3353 [22:22:40<8:50:35, 33.48s/it] 72%|███████▏  | 2403/3353 [22:23:14<8:49:52, 33.47s/it] 72%|███████▏  | 2404/3353 [22:23:47<8:49:12, 33.46s/it] 72%|███████▏  | 2405/3353 [22:24:21<8:49:22, 33.50s/it] 72%|███████▏  | 2406/3353 [22:24:54<8:48:30, 33.48s/it] 72%|███████▏  | 2407/3353 [22:25:28<8:47:46, 33.47s/it] 72%|███████▏  | 2408/3353 [22:26:01<8:47:39, 33.50s/it] 72%|███████▏  | 2409/3353 [22:26:35<8:46:39, 33.47s/it] 72%|███████▏  | 2410/3353 [22:27:08<8:46:27, 33.50s/it]                                                        {'loss': 1.141, 'learning_rate': 9.139602065219977e-06, 'epoch': 0.72}
 72%|███████▏  | 2410/3353 [22:27:08<8:46:27, 33.50s/it] 72%|███████▏  | 2411/3353 [22:27:42<8:46:00, 33.50s/it] 72%|███████▏  | 2412/3353 [22:28:15<8:45:13, 33.49s/it] 72%|███████▏  | 2413/3353 [22:28:49<8:44:38, 33.49s/it] 72%|███████▏  | 2414/3353 [22:29:22<8:43:51, 33.47s/it] 72%|███████▏  | 2415/3353 [22:29:56<8:43:13, 33.47s/it] 72%|███████▏  | 2416/3353 [22:30:29<8:42:33, 33.46s/it] 72%|███████▏  | 2417/3353 [22:31:03<8:42:48, 33.51s/it] 72%|███████▏  | 2418/3353 [22:31:36<8:41:56, 33.49s/it] 72%|███████▏  | 2419/3353 [22:32:10<8:42:05, 33.54s/it] 72%|███████▏  | 2420/3353 [22:32:43<8:41:08, 33.51s/it]                                                        {'loss': 1.1532, 'learning_rate': 8.959237236643362e-06, 'epoch': 0.72}
 72%|███████▏  | 2420/3353 [22:32:43<8:41:08, 33.51s/it] 72%|███████▏  | 2421/3353 [22:33:17<8:41:00, 33.54s/it] 72%|███████▏  | 2422/3353 [22:33:50<8:40:00, 33.51s/it] 72%|███████▏  | 2423/3353 [22:34:24<8:39:08, 33.49s/it] 72%|███████▏  | 2424/3353 [22:34:57<8:38:16, 33.47s/it] 72%|███████▏  | 2425/3353 [22:35:31<8:37:43, 33.47s/it] 72%|███████▏  | 2426/3353 [22:36:04<8:37:02, 33.47s/it] 72%|███████▏  | 2427/3353 [22:36:38<8:36:19, 33.45s/it] 72%|███████▏  | 2428/3353 [22:37:11<8:35:37, 33.45s/it] 72%|███████▏  | 2429/3353 [22:37:45<8:36:02, 33.51s/it] 72%|███████▏  | 2430/3353 [22:38:18<8:35:13, 33.49s/it]                                                        {'loss': 1.1471, 'learning_rate': 8.780280576087082e-06, 'epoch': 0.72}
 72%|███████▏  | 2430/3353 [22:38:18<8:35:13, 33.49s/it] 73%|███████▎  | 2431/3353 [22:38:52<8:34:50, 33.50s/it] 73%|███████▎  | 2432/3353 [22:39:25<8:34:01, 33.49s/it] 73%|███████▎  | 2433/3353 [22:39:59<8:34:06, 33.53s/it] 73%|███████▎  | 2434/3353 [22:40:32<8:33:10, 33.50s/it] 73%|███████▎  | 2435/3353 [22:41:06<8:33:02, 33.53s/it] 73%|███████▎  | 2436/3353 [22:41:39<8:32:12, 33.51s/it] 73%|███████▎  | 2437/3353 [22:42:13<8:31:17, 33.49s/it] 73%|███████▎  | 2438/3353 [22:42:46<8:30:34, 33.48s/it] 73%|███████▎  | 2439/3353 [22:43:20<8:29:54, 33.47s/it] 73%|███████▎  | 2440/3353 [22:43:53<8:29:04, 33.45s/it]                                                        {'loss': 1.1382, 'learning_rate': 8.602747793592502e-06, 'epoch': 0.73}
 73%|███████▎  | 2440/3353 [22:43:53<8:29:04, 33.45s/it] 73%|███████▎  | 2441/3353 [22:44:27<8:29:35, 33.53s/it] 73%|███████▎  | 2442/3353 [22:45:00<8:28:38, 33.50s/it] 73%|███████▎  | 2443/3353 [22:45:34<8:28:43, 33.54s/it] 73%|███████▎  | 2444/3353 [22:46:07<8:27:48, 33.52s/it] 73%|███████▎  | 2445/3353 [22:46:41<8:27:43, 33.55s/it] 73%|███████▎  | 2446/3353 [22:47:14<8:26:44, 33.52s/it] 73%|███████▎  | 2447/3353 [22:47:48<8:25:52, 33.50s/it] 73%|███████▎  | 2448/3353 [22:48:21<8:24:54, 33.47s/it] 73%|███████▎  | 2449/3353 [22:48:55<8:25:16, 33.54s/it] 73%|███████▎  | 2450/3353 [22:49:28<8:24:14, 33.50s/it]                                                        {'loss': 1.1458, 'learning_rate': 8.426654474203194e-06, 'epoch': 0.73}
 73%|███████▎  | 2450/3353 [22:49:28<8:24:14, 33.50s/it] 73%|███████▎  | 2451/3353 [22:50:02<8:24:31, 33.56s/it] 73%|███████▎  | 2452/3353 [22:50:35<8:23:23, 33.52s/it] 73%|███████▎  | 2453/3353 [22:51:09<8:23:16, 33.55s/it] 73%|███████▎  | 2454/3353 [22:51:42<8:22:10, 33.52s/it] 73%|███████▎  | 2455/3353 [22:52:16<8:21:23, 33.50s/it] 73%|███████▎  | 2456/3353 [22:52:49<8:20:40, 33.49s/it] 73%|███████▎  | 2457/3353 [22:53:23<8:20:02, 33.49s/it] 73%|███████▎  | 2458/3353 [22:53:56<8:19:18, 33.47s/it] 73%|███████▎  | 2459/3353 [22:54:30<8:18:37, 33.47s/it] 73%|███████▎  | 2460/3353 [22:55:03<8:18:09, 33.47s/it]                                                        {'loss': 1.1439, 'learning_rate': 8.252016076596827e-06, 'epoch': 0.73}
 73%|███████▎  | 2460/3353 [22:55:04<8:18:09, 33.47s/it] 73%|███████▎  | 2461/3353 [22:55:37<8:19:34, 33.60s/it] 73%|███████▎  | 2462/3353 [22:56:11<8:18:31, 33.57s/it] 73%|███████▎  | 2463/3353 [22:56:44<8:17:30, 33.54s/it] 73%|███████▎  | 2464/3353 [22:57:18<8:16:41, 33.52s/it] 74%|███████▎  | 2465/3353 [22:57:51<8:16:08, 33.52s/it] 74%|███████▎  | 2466/3353 [22:58:25<8:15:13, 33.50s/it] 74%|███████▎  | 2467/3353 [22:58:58<8:14:42, 33.50s/it] 74%|███████▎  | 2468/3353 [22:59:32<8:13:55, 33.49s/it] 74%|███████▎  | 2469/3353 [23:00:05<8:13:04, 33.47s/it] 74%|███████▎  | 2470/3353 [23:00:39<8:13:14, 33.52s/it]                                                        {'loss': 1.1467, 'learning_rate': 8.07884793172806e-06, 'epoch': 0.74}
 74%|███████▎  | 2470/3353 [23:00:39<8:13:14, 33.52s/it] 74%|███████▎  | 2471/3353 [23:01:12<8:12:31, 33.51s/it] 74%|███████▎  | 2472/3353 [23:01:46<8:11:42, 33.49s/it] 74%|███████▍  | 2473/3353 [23:02:19<8:10:57, 33.47s/it] 74%|███████▍  | 2474/3353 [23:02:53<8:10:59, 33.51s/it] 74%|███████▍  | 2475/3353 [23:03:26<8:10:04, 33.49s/it] 74%|███████▍  | 2476/3353 [23:04:00<8:10:15, 33.54s/it] 74%|███████▍  | 2477/3353 [23:04:33<8:09:12, 33.51s/it] 74%|███████▍  | 2478/3353 [23:05:07<8:08:28, 33.50s/it] 74%|███████▍  | 2479/3353 [23:05:40<8:07:37, 33.48s/it] 74%|███████▍  | 2480/3353 [23:06:13<8:06:53, 33.46s/it]                                                        {'loss': 1.1423, 'learning_rate': 7.907165241482704e-06, 'epoch': 0.74}
 74%|███████▍  | 2480/3353 [23:06:13<8:06:53, 33.46s/it] 74%|███████▍  | 2481/3353 [23:06:47<8:06:27, 33.47s/it] 74%|███████▍  | 2482/3353 [23:07:20<8:05:54, 33.47s/it] 74%|███████▍  | 2483/3353 [23:07:54<8:05:20, 33.47s/it] 74%|███████▍  | 2484/3353 [23:08:27<8:04:47, 33.47s/it] 74%|███████▍  | 2485/3353 [23:09:01<8:04:08, 33.47s/it] 74%|███████▍  | 2486/3353 [23:09:34<8:04:13, 33.51s/it] 74%|███████▍  | 2487/3353 [23:10:08<8:03:32, 33.50s/it] 74%|███████▍  | 2488/3353 [23:10:41<8:02:43, 33.48s/it] 74%|███████▍  | 2489/3353 [23:11:15<8:02:01, 33.47s/it] 74%|███████▍  | 2490/3353 [23:11:48<8:02:08, 33.52s/it]                                                        {'loss': 1.1402, 'learning_rate': 7.736983077343165e-06, 'epoch': 0.74}
 74%|███████▍  | 2490/3353 [23:11:48<8:02:08, 33.52s/it] 74%|███████▍  | 2491/3353 [23:12:22<8:01:28, 33.51s/it] 74%|███████▍  | 2492/3353 [23:12:56<8:01:24, 33.55s/it] 74%|███████▍  | 2493/3353 [23:13:29<8:00:36, 33.53s/it] 74%|███████▍  | 2494/3353 [23:14:03<8:00:29, 33.56s/it] 74%|███████▍  | 2495/3353 [23:14:36<7:59:21, 33.52s/it] 74%|███████▍  | 2496/3353 [23:15:10<7:58:28, 33.50s/it] 74%|███████▍  | 2497/3353 [23:15:43<7:57:41, 33.48s/it] 75%|███████▍  | 2498/3353 [23:16:17<7:57:55, 33.54s/it] 75%|███████▍  | 2499/3353 [23:16:50<7:57:09, 33.52s/it] 75%|███████▍  | 2500/3353 [23:17:24<7:57:07, 33.56s/it]                                                        {'loss': 1.1355, 'learning_rate': 7.568316379065421e-06, 'epoch': 0.75}
 75%|███████▍  | 2500/3353 [23:17:24<7:57:07, 33.56s/it] 75%|███████▍  | 2501/3353 [23:17:57<7:56:21, 33.55s/it] 75%|███████▍  | 2502/3353 [23:18:31<7:55:34, 33.53s/it] 75%|███████▍  | 2503/3353 [23:19:04<7:54:36, 33.50s/it] 75%|███████▍  | 2504/3353 [23:19:38<7:53:56, 33.49s/it] 75%|███████▍  | 2505/3353 [23:20:11<7:53:16, 33.49s/it] 75%|███████▍  | 2506/3353 [23:20:45<7:53:24, 33.54s/it] 75%|███████▍  | 2507/3353 [23:21:18<7:52:34, 33.52s/it] 75%|███████▍  | 2508/3353 [23:21:52<7:52:32, 33.55s/it] 75%|███████▍  | 2509/3353 [23:22:25<7:51:40, 33.53s/it] 75%|███████▍  | 2510/3353 [23:22:59<7:51:31, 33.56s/it]                                                        {'loss': 1.1451, 'learning_rate': 7.401179953367457e-06, 'epoch': 0.75}
 75%|███████▍  | 2510/3353 [23:22:59<7:51:31, 33.56s/it] 75%|███████▍  | 2511/3353 [23:23:32<7:50:36, 33.53s/it] 75%|███████▍  | 2512/3353 [23:24:06<7:49:55, 33.53s/it] 75%|███████▍  | 2513/3353 [23:24:39<7:49:11, 33.51s/it] 75%|███████▍  | 2514/3353 [23:25:13<7:48:33, 33.51s/it] 75%|███████▌  | 2515/3353 [23:25:46<7:47:51, 33.50s/it] 75%|███████▌  | 2516/3353 [23:26:20<7:47:07, 33.49s/it] 75%|███████▌  | 2517/3353 [23:26:53<7:46:33, 33.49s/it] 75%|███████▌  | 2518/3353 [23:27:27<7:46:46, 33.54s/it] 75%|███████▌  | 2519/3353 [23:28:01<7:45:54, 33.52s/it] 75%|███████▌  | 2520/3353 [23:28:34<7:45:10, 33.51s/it]                                                        {'loss': 1.1393, 'learning_rate': 7.235588472629473e-06, 'epoch': 0.75}
 75%|███████▌  | 2520/3353 [23:28:34<7:45:10, 33.51s/it] 75%|███████▌  | 2521/3353 [23:29:08<7:44:37, 33.51s/it] 75%|███████▌  | 2522/3353 [23:29:41<7:44:17, 33.52s/it] 75%|███████▌  | 2523/3353 [23:30:15<7:43:30, 33.51s/it] 75%|███████▌  | 2524/3353 [23:30:48<7:43:13, 33.53s/it] 75%|███████▌  | 2525/3353 [23:31:22<7:42:20, 33.50s/it] 75%|███████▌  | 2526/3353 [23:31:55<7:41:33, 33.49s/it] 75%|███████▌  | 2527/3353 [23:32:29<7:41:24, 33.52s/it] 75%|███████▌  | 2528/3353 [23:33:02<7:40:38, 33.50s/it] 75%|███████▌  | 2529/3353 [23:33:36<7:39:59, 33.49s/it] 75%|███████▌  | 2530/3353 [23:34:09<7:39:20, 33.49s/it]                                                        {'loss': 1.1411, 'learning_rate': 7.071556473605778e-06, 'epoch': 0.75}
 75%|███████▌  | 2530/3353 [23:34:09<7:39:20, 33.49s/it] 75%|███████▌  | 2531/3353 [23:34:43<7:39:38, 33.55s/it] 76%|███████▌  | 2532/3353 [23:35:16<7:38:50, 33.53s/it] 76%|███████▌  | 2533/3353 [23:35:50<7:38:43, 33.57s/it] 76%|███████▌  | 2534/3353 [23:36:23<7:37:49, 33.54s/it] 76%|███████▌  | 2535/3353 [23:36:57<7:37:39, 33.57s/it] 76%|███████▌  | 2536/3353 [23:37:31<7:37:08, 33.57s/it] 76%|███████▌  | 2537/3353 [23:38:04<7:36:13, 33.55s/it] 76%|███████▌  | 2538/3353 [23:38:38<7:35:25, 33.53s/it] 76%|███████▌  | 2539/3353 [23:39:11<7:34:56, 33.53s/it] 76%|███████▌  | 2540/3353 [23:39:45<7:34:06, 33.51s/it]                                                        {'loss': 1.14, 'learning_rate': 6.909098356148741e-06, 'epoch': 0.76}
 76%|███████▌  | 2540/3353 [23:39:45<7:34:06, 33.51s/it] 76%|███████▌  | 2541/3353 [23:40:18<7:33:39, 33.52s/it] 76%|███████▌  | 2542/3353 [23:40:52<7:32:57, 33.51s/it] 76%|███████▌  | 2543/3353 [23:41:25<7:32:13, 33.50s/it] 76%|███████▌  | 2544/3353 [23:41:59<7:31:39, 33.50s/it] 76%|███████▌  | 2545/3353 [23:42:32<7:31:03, 33.49s/it] 76%|███████▌  | 2546/3353 [23:43:05<7:30:21, 33.48s/it] 76%|███████▌  | 2547/3353 [23:43:39<7:30:20, 33.52s/it] 76%|███████▌  | 2548/3353 [23:44:13<7:29:33, 33.51s/it] 76%|███████▌  | 2549/3353 [23:44:46<7:29:26, 33.54s/it] 76%|███████▌  | 2550/3353 [23:45:20<7:28:29, 33.51s/it]                                                        {'loss': 1.1386, 'learning_rate': 6.748228381944583e-06, 'epoch': 0.76}
 76%|███████▌  | 2550/3353 [23:45:20<7:28:29, 33.51s/it] 76%|███████▌  | 2551/3353 [23:45:53<7:28:33, 33.56s/it] 76%|███████▌  | 2552/3353 [23:46:27<7:27:34, 33.53s/it] 76%|███████▌  | 2553/3353 [23:47:00<7:26:44, 33.51s/it] 76%|███████▌  | 2554/3353 [23:47:34<7:25:57, 33.49s/it] 76%|███████▌  | 2555/3353 [23:48:07<7:26:02, 33.54s/it] 76%|███████▌  | 2556/3353 [23:48:41<7:25:10, 33.51s/it] 76%|███████▋  | 2557/3353 [23:49:14<7:25:07, 33.55s/it] 76%|███████▋  | 2558/3353 [23:49:48<7:24:17, 33.53s/it] 76%|███████▋  | 2559/3353 [23:50:22<7:24:08, 33.56s/it] 76%|███████▋  | 2560/3353 [23:50:55<7:23:13, 33.54s/it]                                                        {'loss': 1.1412, 'learning_rate': 6.588960673261485e-06, 'epoch': 0.76}
 76%|███████▋  | 2560/3353 [23:50:55<7:23:13, 33.54s/it] 76%|███████▋  | 2561/3353 [23:51:29<7:22:47, 33.55s/it] 76%|███████▋  | 2562/3353 [23:52:02<7:21:53, 33.52s/it] 76%|███████▋  | 2563/3353 [23:52:36<7:21:56, 33.57s/it] 76%|███████▋  | 2564/3353 [23:53:09<7:21:11, 33.55s/it] 76%|███████▋  | 2565/3353 [23:53:43<7:21:07, 33.59s/it] 77%|███████▋  | 2566/3353 [23:54:16<7:20:13, 33.56s/it] 77%|███████▋  | 2567/3353 [23:54:50<7:19:14, 33.53s/it] 77%|███████▋  | 2568/3353 [23:55:23<7:18:29, 33.52s/it] 77%|███████▋  | 2569/3353 [23:55:57<7:17:36, 33.49s/it] 77%|███████▋  | 2570/3353 [23:56:30<7:17:01, 33.49s/it]                                                        {'loss': 1.143, 'learning_rate': 6.4313092117097325e-06, 'epoch': 0.77}
 77%|███████▋  | 2570/3353 [23:56:30<7:17:01, 33.49s/it] 77%|███████▋  | 2571/3353 [23:57:04<7:16:29, 33.49s/it] 77%|███████▋  | 2572/3353 [23:57:37<7:15:44, 33.48s/it] 77%|███████▋  | 2573/3353 [23:58:11<7:15:04, 33.47s/it] 77%|███████▋  | 2574/3353 [23:58:44<7:14:29, 33.47s/it] 77%|███████▋  | 2575/3353 [23:59:18<7:15:14, 33.57s/it] 77%|███████▋  | 2576/3353 [23:59:51<7:14:14, 33.53s/it] 77%|███████▋  | 2577/3353 [24:00:25<7:13:23, 33.51s/it] 77%|███████▋  | 2578/3353 [24:00:58<7:12:54, 33.52s/it] 77%|███████▋  | 2579/3353 [24:01:32<7:12:43, 33.54s/it] 77%|███████▋  | 2580/3353 [24:02:05<7:11:55, 33.53s/it]                                                        {'loss': 1.1435, 'learning_rate': 6.275287837014413e-06, 'epoch': 0.77}
 77%|███████▋  | 2580/3353 [24:02:05<7:11:55, 33.53s/it] 77%|███████▋  | 2581/3353 [24:02:39<7:11:40, 33.55s/it] 77%|███████▋  | 2582/3353 [24:03:13<7:10:59, 33.54s/it] 77%|███████▋  | 2583/3353 [24:03:46<7:10:51, 33.57s/it] 77%|███████▋  | 2584/3353 [24:04:20<7:09:50, 33.54s/it] 77%|███████▋  | 2585/3353 [24:04:53<7:09:04, 33.52s/it] 77%|███████▋  | 2586/3353 [24:05:27<7:08:12, 33.50s/it] 77%|███████▋  | 2587/3353 [24:06:00<7:07:25, 33.48s/it] 77%|███████▋  | 2588/3353 [24:06:34<7:07:30, 33.53s/it] 77%|███████▋  | 2589/3353 [24:07:07<7:06:40, 33.51s/it] 77%|███████▋  | 2590/3353 [24:07:41<7:06:35, 33.55s/it]                                                        {'loss': 1.1358, 'learning_rate': 6.120910245800385e-06, 'epoch': 0.77}
 77%|███████▋  | 2590/3353 [24:07:41<7:06:35, 33.55s/it] 77%|███████▋  | 2591/3353 [24:08:14<7:05:58, 33.54s/it] 77%|███████▋  | 2592/3353 [24:08:48<7:05:15, 33.53s/it] 77%|███████▋  | 2593/3353 [24:09:21<7:04:23, 33.51s/it] 77%|███████▋  | 2594/3353 [24:09:55<7:03:39, 33.49s/it] 77%|███████▋  | 2595/3353 [24:10:28<7:03:03, 33.49s/it] 77%|███████▋  | 2596/3353 [24:11:02<7:02:23, 33.48s/it] 77%|███████▋  | 2597/3353 [24:11:35<7:01:39, 33.46s/it] 77%|███████▋  | 2598/3353 [24:12:08<7:00:58, 33.45s/it] 78%|███████▊  | 2599/3353 [24:12:42<7:00:21, 33.45s/it] 78%|███████▊  | 2600/3353 [24:13:16<7:00:33, 33.51s/it]                                                        {'loss': 1.1384, 'learning_rate': 5.968189990389963e-06, 'epoch': 0.78}
 78%|███████▊  | 2600/3353 [24:13:16<7:00:33, 33.51s/it] 78%|███████▊  | 2601/3353 [24:13:49<6:59:52, 33.50s/it] 78%|███████▊  | 2602/3353 [24:14:22<6:59:04, 33.48s/it] 78%|███████▊  | 2603/3353 [24:14:56<6:58:22, 33.47s/it] 78%|███████▊  | 2604/3353 [24:15:30<6:58:25, 33.52s/it] 78%|███████▊  | 2605/3353 [24:16:03<6:57:33, 33.49s/it] 78%|███████▊  | 2606/3353 [24:16:37<6:57:19, 33.52s/it] 78%|███████▊  | 2607/3353 [24:17:10<6:56:30, 33.50s/it] 78%|███████▊  | 2608/3353 [24:17:43<6:55:44, 33.48s/it] 78%|███████▊  | 2609/3353 [24:18:17<6:55:02, 33.47s/it] 78%|███████▊  | 2610/3353 [24:18:50<6:54:25, 33.47s/it]                                                        {'loss': 1.1433, 'learning_rate': 5.81714047761317e-06, 'epoch': 0.78}
 78%|███████▊  | 2610/3353 [24:18:50<6:54:25, 33.47s/it] 78%|███████▊  | 2611/3353 [24:19:24<6:53:55, 33.47s/it] 78%|███████▊  | 2612/3353 [24:19:58<6:54:04, 33.53s/it] 78%|███████▊  | 2613/3353 [24:20:31<6:53:11, 33.50s/it] 78%|███████▊  | 2614/3353 [24:21:05<6:53:08, 33.54s/it] 78%|███████▊  | 2615/3353 [24:21:38<6:52:11, 33.51s/it] 78%|███████▊  | 2616/3353 [24:22:12<6:51:54, 33.53s/it] 78%|███████▊  | 2617/3353 [24:22:45<6:50:57, 33.50s/it] 78%|███████▊  | 2618/3353 [24:23:19<6:50:20, 33.50s/it] 78%|███████▊  | 2619/3353 [24:23:52<6:49:30, 33.48s/it] 78%|███████▊  | 2620/3353 [24:24:26<6:49:29, 33.52s/it]                                                        {'loss': 1.1328, 'learning_rate': 5.667774967630793e-06, 'epoch': 0.78}
 78%|███████▊  | 2620/3353 [24:24:26<6:49:29, 33.52s/it] 78%|███████▊  | 2621/3353 [24:24:59<6:48:48, 33.51s/it] 78%|███████▊  | 2622/3353 [24:25:33<6:48:38, 33.54s/it] 78%|███████▊  | 2623/3353 [24:26:06<6:47:43, 33.51s/it] 78%|███████▊  | 2624/3353 [24:26:40<6:47:44, 33.56s/it] 78%|███████▊  | 2625/3353 [24:27:13<6:46:47, 33.53s/it] 78%|███████▊  | 2626/3353 [24:27:47<6:45:58, 33.51s/it] 78%|███████▊  | 2627/3353 [24:28:20<6:45:05, 33.48s/it] 78%|███████▊  | 2628/3353 [24:28:54<6:44:30, 33.48s/it] 78%|███████▊  | 2629/3353 [24:29:27<6:43:57, 33.48s/it] 78%|███████▊  | 2630/3353 [24:30:01<6:43:23, 33.48s/it]                                                        {'loss': 1.1373, 'learning_rate': 5.520106572770309e-06, 'epoch': 0.78}
 78%|███████▊  | 2630/3353 [24:30:01<6:43:23, 33.48s/it] 78%|███████▊  | 2631/3353 [24:30:34<6:42:51, 33.48s/it] 78%|███████▊  | 2632/3353 [24:31:08<6:42:21, 33.48s/it] 79%|███████▊  | 2633/3353 [24:31:41<6:41:36, 33.47s/it] 79%|███████▊  | 2634/3353 [24:32:14<6:41:00, 33.46s/it] 79%|███████▊  | 2635/3353 [24:32:48<6:40:23, 33.46s/it] 79%|███████▊  | 2636/3353 [24:33:21<6:40:08, 33.49s/it] 79%|███████▊  | 2637/3353 [24:33:55<6:39:32, 33.48s/it] 79%|███████▊  | 2638/3353 [24:34:28<6:39:19, 33.51s/it] 79%|███████▊  | 2639/3353 [24:35:02<6:38:47, 33.51s/it] 79%|███████▊  | 2640/3353 [24:35:36<6:38:51, 33.56s/it]                                                        {'loss': 1.1391, 'learning_rate': 5.374148256374823e-06, 'epoch': 0.79}
 79%|███████▊  | 2640/3353 [24:35:36<6:38:51, 33.56s/it] 79%|███████▉  | 2641/3353 [24:36:09<6:38:10, 33.55s/it] 79%|███████▉  | 2642/3353 [24:36:43<6:37:18, 33.53s/it] 79%|███████▉  | 2643/3353 [24:37:16<6:36:28, 33.51s/it] 79%|███████▉  | 2644/3353 [24:37:50<6:35:47, 33.49s/it] 79%|███████▉  | 2645/3353 [24:38:23<6:35:46, 33.54s/it] 79%|███████▉  | 2646/3353 [24:38:57<6:34:58, 33.52s/it] 79%|███████▉  | 2647/3353 [24:39:30<6:34:55, 33.56s/it] 79%|███████▉  | 2648/3353 [24:40:04<6:34:40, 33.59s/it] 79%|███████▉  | 2649/3353 [24:40:37<6:33:44, 33.56s/it] 79%|███████▉  | 2650/3353 [24:41:11<6:32:56, 33.54s/it]                                                        {'loss': 1.1391, 'learning_rate': 5.2299128316650295e-06, 'epoch': 0.79}
 79%|███████▉  | 2650/3353 [24:41:11<6:32:56, 33.54s/it] 79%|███████▉  | 2651/3353 [24:41:45<6:32:25, 33.54s/it] 79%|███████▉  | 2652/3353 [24:42:18<6:31:55, 33.55s/it] 79%|███████▉  | 2653/3353 [24:42:52<6:31:25, 33.55s/it] 79%|███████▉  | 2654/3353 [24:43:25<6:30:47, 33.54s/it] 79%|███████▉  | 2655/3353 [24:43:59<6:30:16, 33.55s/it] 79%|███████▉  | 2656/3353 [24:44:32<6:29:39, 33.54s/it] 79%|███████▉  | 2657/3353 [24:45:06<6:29:15, 33.56s/it] 79%|███████▉  | 2658/3353 [24:45:39<6:28:45, 33.56s/it] 79%|███████▉  | 2659/3353 [24:46:13<6:28:02, 33.55s/it] 79%|███████▉  | 2660/3353 [24:46:46<6:27:30, 33.55s/it]                                                        {'loss': 1.1382, 'learning_rate': 5.0874129606144015e-06, 'epoch': 0.79}
 79%|███████▉  | 2660/3353 [24:46:47<6:27:30, 33.55s/it] 79%|███████▉  | 2661/3353 [24:47:20<6:27:37, 33.61s/it] 79%|███████▉  | 2662/3353 [24:47:54<6:26:48, 33.59s/it] 79%|███████▉  | 2663/3353 [24:48:27<6:26:32, 33.61s/it] 79%|███████▉  | 2664/3353 [24:49:01<6:25:49, 33.60s/it] 79%|███████▉  | 2665/3353 [24:49:35<6:25:52, 33.65s/it] 80%|███████▉  | 2666/3353 [24:50:08<6:25:01, 33.63s/it] 80%|███████▉  | 2667/3353 [24:50:42<6:24:23, 33.62s/it] 80%|███████▉  | 2668/3353 [24:51:16<6:23:37, 33.60s/it] 80%|███████▉  | 2669/3353 [24:51:49<6:23:32, 33.64s/it] 80%|███████▉  | 2670/3353 [24:52:23<6:22:47, 33.63s/it]                                                        {'loss': 1.1391, 'learning_rate': 4.946661152837609e-06, 'epoch': 0.8}
 80%|███████▉  | 2670/3353 [24:52:23<6:22:47, 33.63s/it] 80%|███████▉  | 2671/3353 [24:52:57<6:22:54, 33.69s/it] 80%|███████▉  | 2672/3353 [24:53:30<6:21:54, 33.65s/it] 80%|███████▉  | 2673/3353 [24:54:04<6:21:05, 33.63s/it] 80%|███████▉  | 2674/3353 [24:54:37<6:20:17, 33.61s/it] 80%|███████▉  | 2675/3353 [24:55:11<6:19:30, 33.59s/it] 80%|███████▉  | 2676/3353 [24:55:44<6:18:50, 33.58s/it] 80%|███████▉  | 2677/3353 [24:56:18<6:18:53, 33.63s/it] 80%|███████▉  | 2678/3353 [24:56:52<6:18:06, 33.61s/it] 80%|███████▉  | 2679/3353 [24:57:26<6:17:59, 33.65s/it] 80%|███████▉  | 2680/3353 [24:57:59<6:17:06, 33.62s/it]                                                        {'loss': 1.144, 'learning_rate': 4.807669764492365e-06, 'epoch': 0.8}
 80%|███████▉  | 2680/3353 [24:57:59<6:17:06, 33.62s/it] 80%|███████▉  | 2681/3353 [24:58:33<6:16:58, 33.66s/it] 80%|███████▉  | 2682/3353 [24:59:06<6:16:03, 33.63s/it] 80%|████████  | 2683/3353 [24:59:40<6:15:11, 33.60s/it] 80%|████████  | 2684/3353 [25:00:13<6:14:24, 33.58s/it] 80%|████████  | 2685/3353 [25:00:47<6:13:49, 33.58s/it] 80%|████████  | 2686/3353 [25:01:21<6:13:10, 33.57s/it] 80%|████████  | 2687/3353 [25:01:54<6:12:33, 33.56s/it] 80%|████████  | 2688/3353 [25:02:28<6:11:50, 33.55s/it] 80%|████████  | 2689/3353 [25:03:01<6:11:47, 33.60s/it] 80%|████████  | 2690/3353 [25:03:35<6:11:01, 33.58s/it]                                                        {'loss': 1.1393, 'learning_rate': 4.670450997194709e-06, 'epoch': 0.8}
 80%|████████  | 2690/3353 [25:03:35<6:11:01, 33.58s/it] 80%|████████  | 2691/3353 [25:04:08<6:10:25, 33.57s/it] 80%|████████  | 2692/3353 [25:04:42<6:09:49, 33.57s/it] 80%|████████  | 2693/3353 [25:05:16<6:09:33, 33.60s/it] 80%|████████  | 2694/3353 [25:05:49<6:08:49, 33.58s/it] 80%|████████  | 2695/3353 [25:06:23<6:08:21, 33.59s/it] 80%|████████  | 2696/3353 [25:06:56<6:07:41, 33.58s/it] 80%|████████  | 2697/3353 [25:07:30<6:07:12, 33.59s/it] 80%|████████  | 2698/3353 [25:08:04<6:06:33, 33.58s/it] 80%|████████  | 2699/3353 [25:08:37<6:06:01, 33.58s/it] 81%|████████  | 2700/3353 [25:09:11<6:05:29, 33.58s/it]                                                        {'loss': 1.1418, 'learning_rate': 4.535016896947864e-06, 'epoch': 0.81}
 81%|████████  | 2700/3353 [25:09:11<6:05:29, 33.58s/it] 81%|████████  | 2701/3353 [25:09:44<6:05:04, 33.60s/it] 81%|████████  | 2702/3353 [25:10:18<6:05:10, 33.66s/it] 81%|████████  | 2703/3353 [25:10:52<6:04:14, 33.62s/it] 81%|████████  | 2704/3353 [25:11:25<6:04:05, 33.66s/it] 81%|████████  | 2705/3353 [25:11:59<6:03:51, 33.69s/it] 81%|████████  | 2706/3353 [25:12:33<6:02:49, 33.65s/it] 81%|████████  | 2707/3353 [25:13:06<6:01:58, 33.62s/it] 81%|████████  | 2708/3353 [25:13:40<6:01:13, 33.60s/it] 81%|████████  | 2709/3353 [25:14:13<6:00:30, 33.59s/it] 81%|████████  | 2710/3353 [25:14:47<5:59:50, 33.58s/it]                                                        {'loss': 1.1358, 'learning_rate': 4.401379353084742e-06, 'epoch': 0.81}
 81%|████████  | 2710/3353 [25:14:47<5:59:50, 33.58s/it] 81%|████████  | 2711/3353 [25:15:21<5:59:22, 33.59s/it] 81%|████████  | 2712/3353 [25:15:54<5:58:48, 33.59s/it] 81%|████████  | 2713/3353 [25:16:28<5:58:45, 33.63s/it] 81%|████████  | 2714/3353 [25:17:01<5:57:57, 33.61s/it] 81%|████████  | 2715/3353 [25:17:35<5:57:17, 33.60s/it] 81%|████████  | 2716/3353 [25:18:09<5:56:32, 33.58s/it] 81%|████████  | 2717/3353 [25:18:42<5:55:53, 33.58s/it] 81%|████████  | 2718/3353 [25:19:16<5:55:54, 33.63s/it] 81%|████████  | 2719/3353 [25:19:49<5:55:07, 33.61s/it] 81%|████████  | 2720/3353 [25:20:23<5:54:56, 33.64s/it]                                                        {'loss': 1.1347, 'learning_rate': 4.269550097224248e-06, 'epoch': 0.81}
 81%|████████  | 2720/3353 [25:20:23<5:54:56, 33.64s/it] 81%|████████  | 2721/3353 [25:20:57<5:54:22, 33.64s/it] 81%|████████  | 2722/3353 [25:21:31<5:54:05, 33.67s/it] 81%|████████  | 2723/3353 [25:22:04<5:53:11, 33.64s/it] 81%|████████  | 2724/3353 [25:22:38<5:52:29, 33.62s/it] 81%|████████▏ | 2725/3353 [25:23:11<5:51:41, 33.60s/it] 81%|████████▏ | 2726/3353 [25:23:45<5:51:35, 33.65s/it] 81%|████████▏ | 2727/3353 [25:24:19<5:50:46, 33.62s/it] 81%|████████▏ | 2728/3353 [25:24:52<5:50:43, 33.67s/it] 81%|████████▏ | 2729/3353 [25:25:26<5:49:46, 33.63s/it] 81%|████████▏ | 2730/3353 [25:26:00<5:49:39, 33.67s/it]                                                        {'loss': 1.1402, 'learning_rate': 4.1395407022413734e-06, 'epoch': 0.81}
 81%|████████▏ | 2730/3353 [25:26:00<5:49:39, 33.67s/it] 81%|████████▏ | 2731/3353 [25:26:33<5:48:53, 33.65s/it] 81%|████████▏ | 2732/3353 [25:27:07<5:48:01, 33.63s/it] 82%|████████▏ | 2733/3353 [25:27:40<5:47:09, 33.60s/it] 82%|████████▏ | 2734/3353 [25:28:14<5:47:05, 33.64s/it] 82%|████████▏ | 2735/3353 [25:28:48<5:46:16, 33.62s/it] 82%|████████▏ | 2736/3353 [25:29:21<5:46:13, 33.67s/it] 82%|████████▏ | 2737/3353 [25:29:55<5:45:20, 33.64s/it] 82%|████████▏ | 2738/3353 [25:30:29<5:44:31, 33.61s/it] 82%|████████▏ | 2739/3353 [25:31:02<5:43:59, 33.61s/it] 82%|████████▏ | 2740/3353 [25:31:36<5:43:11, 33.59s/it]                                                        {'loss': 1.1339, 'learning_rate': 4.011362581251268e-06, 'epoch': 0.82}
 82%|████████▏ | 2740/3353 [25:31:36<5:43:11, 33.59s/it] 82%|████████▏ | 2741/3353 [25:32:09<5:42:38, 33.59s/it] 82%|████████▏ | 2742/3353 [25:32:43<5:42:02, 33.59s/it] 82%|████████▏ | 2743/3353 [25:33:16<5:41:25, 33.58s/it] 82%|████████▏ | 2744/3353 [25:33:50<5:40:43, 33.57s/it] 82%|████████▏ | 2745/3353 [25:34:24<5:40:03, 33.56s/it] 82%|████████▏ | 2746/3353 [25:34:57<5:39:57, 33.60s/it] 82%|████████▏ | 2747/3353 [25:35:31<5:39:17, 33.59s/it] 82%|████████▏ | 2748/3353 [25:36:04<5:38:35, 33.58s/it] 82%|████████▏ | 2749/3353 [25:36:38<5:37:55, 33.57s/it] 82%|████████▏ | 2750/3353 [25:37:12<5:37:42, 33.60s/it]                                                        {'loss': 1.1429, 'learning_rate': 3.885026986607282e-06, 'epoch': 0.82}
 82%|████████▏ | 2750/3353 [25:37:12<5:37:42, 33.60s/it] 82%|████████▏ | 2751/3353 [25:37:45<5:37:11, 33.61s/it] 82%|████████▏ | 2752/3353 [25:38:19<5:36:37, 33.61s/it] 82%|████████▏ | 2753/3353 [25:38:52<5:35:49, 33.58s/it] 82%|████████▏ | 2754/3353 [25:39:26<5:35:48, 33.64s/it] 82%|████████▏ | 2755/3353 [25:40:00<5:34:56, 33.61s/it] 82%|████████▏ | 2756/3353 [25:40:33<5:34:08, 33.58s/it] 82%|████████▏ | 2757/3353 [25:41:07<5:33:29, 33.57s/it] 82%|████████▏ | 2758/3353 [25:41:40<5:32:48, 33.56s/it] 82%|████████▏ | 2759/3353 [25:42:14<5:32:54, 33.63s/it] 82%|████████▏ | 2760/3353 [25:42:48<5:32:11, 33.61s/it]                                                        {'loss': 1.1398, 'learning_rate': 3.760545008913216e-06, 'epoch': 0.82}
 82%|████████▏ | 2760/3353 [25:42:48<5:32:11, 33.61s/it] 82%|████████▏ | 2761/3353 [25:43:21<5:32:09, 33.66s/it] 82%|████████▏ | 2762/3353 [25:43:55<5:31:19, 33.64s/it] 82%|████████▏ | 2763/3353 [25:44:29<5:30:32, 33.61s/it] 82%|████████▏ | 2764/3353 [25:45:02<5:29:46, 33.59s/it] 82%|████████▏ | 2765/3353 [25:45:36<5:29:09, 33.59s/it] 82%|████████▏ | 2766/3353 [25:46:09<5:28:36, 33.59s/it] 83%|████████▎ | 2767/3353 [25:46:43<5:28:01, 33.59s/it] 83%|████████▎ | 2768/3353 [25:47:16<5:27:20, 33.57s/it] 83%|████████▎ | 2769/3353 [25:47:50<5:26:51, 33.58s/it] 83%|████████▎ | 2770/3353 [25:48:24<5:26:43, 33.63s/it]                                                        {'loss': 1.1392, 'learning_rate': 3.6379275760496433e-06, 'epoch': 0.83}
 83%|████████▎ | 2770/3353 [25:48:24<5:26:43, 33.63s/it] 83%|████████▎ | 2771/3353 [25:48:57<5:26:11, 33.63s/it] 83%|████████▎ | 2772/3353 [25:49:31<5:25:23, 33.60s/it] 83%|████████▎ | 2773/3353 [25:50:04<5:24:39, 33.59s/it] 83%|████████▎ | 2774/3353 [25:50:38<5:23:56, 33.57s/it] 83%|████████▎ | 2775/3353 [25:51:12<5:23:49, 33.62s/it] 83%|████████▎ | 2776/3353 [25:51:45<5:22:57, 33.58s/it] 83%|████████▎ | 2777/3353 [25:52:19<5:22:44, 33.62s/it] 83%|████████▎ | 2778/3353 [25:52:53<5:22:32, 33.66s/it] 83%|████████▎ | 2779/3353 [25:53:26<5:21:42, 33.63s/it] 83%|████████▎ | 2780/3353 [25:54:03<5:29:22, 34.49s/it]                                                        {'loss': 1.1295, 'learning_rate': 3.5171854522146637e-06, 'epoch': 0.83}
 83%|████████▎ | 2780/3353 [25:54:03<5:29:22, 34.49s/it] 83%|████████▎ | 2781/3353 [25:54:40<5:37:36, 35.41s/it] 83%|████████▎ | 2782/3353 [25:55:14<5:31:39, 34.85s/it] 83%|████████▎ | 2783/3353 [25:55:48<5:27:58, 34.52s/it] 83%|████████▎ | 2784/3353 [25:56:23<5:29:17, 34.72s/it] 83%|████████▎ | 2785/3353 [25:56:57<5:26:05, 34.45s/it] 83%|████████▎ | 2786/3353 [25:57:32<5:27:43, 34.68s/it] 83%|████████▎ | 2787/3353 [25:58:06<5:24:32, 34.40s/it] 83%|████████▎ | 2788/3353 [25:58:39<5:21:43, 34.17s/it] 83%|████████▎ | 2789/3353 [25:59:14<5:23:44, 34.44s/it] 83%|████████▎ | 2790/3353 [25:59:48<5:20:46, 34.18s/it]                                                        {'loss': 1.1313, 'learning_rate': 3.398329236978867e-06, 'epoch': 0.83}
 83%|████████▎ | 2790/3353 [25:59:48<5:20:46, 34.18s/it] 83%|████████▎ | 2791/3353 [26:00:23<5:23:27, 34.53s/it] 83%|████████▎ | 2792/3353 [26:00:57<5:20:31, 34.28s/it] 83%|████████▎ | 2793/3353 [26:01:32<5:22:24, 34.54s/it] 83%|████████▎ | 2794/3353 [26:02:05<5:18:56, 34.23s/it] 83%|████████▎ | 2795/3353 [26:02:39<5:16:53, 34.07s/it] 83%|████████▎ | 2796/3353 [26:03:13<5:14:50, 33.92s/it] 83%|████████▎ | 2797/3353 [26:03:48<5:17:53, 34.30s/it] 83%|████████▎ | 2798/3353 [26:04:21<5:15:11, 34.08s/it] 83%|████████▎ | 2799/3353 [26:04:55<5:13:18, 33.93s/it] 84%|████████▎ | 2800/3353 [26:05:30<5:15:59, 34.28s/it]                                                        {'loss': 1.1351, 'learning_rate': 3.281369364354897e-06, 'epoch': 0.84}
 84%|████████▎ | 2800/3353 [26:05:30<5:15:59, 34.28s/it] 84%|████████▎ | 2801/3353 [26:06:04<5:13:23, 34.06s/it] 84%|████████▎ | 2802/3353 [26:06:37<5:11:14, 33.89s/it] 84%|████████▎ | 2803/3353 [26:07:11<5:09:56, 33.81s/it] 84%|████████▎ | 2804/3353 [26:07:44<5:08:40, 33.73s/it] 84%|████████▎ | 2805/3353 [26:08:18<5:07:35, 33.68s/it] 84%|████████▎ | 2806/3353 [26:08:52<5:06:51, 33.66s/it] 84%|████████▎ | 2807/3353 [26:09:25<5:06:17, 33.66s/it] 84%|████████▎ | 2808/3353 [26:09:59<5:05:27, 33.63s/it] 84%|████████▍ | 2809/3353 [26:10:32<5:04:56, 33.63s/it] 84%|████████▍ | 2810/3353 [26:11:06<5:04:08, 33.61s/it]                                                        {'loss': 1.1434, 'learning_rate': 3.1663161018814334e-06, 'epoch': 0.84}
 84%|████████▍ | 2810/3353 [26:11:06<5:04:08, 33.61s/it] 84%|████████▍ | 2811/3353 [26:11:40<5:04:02, 33.66s/it] 84%|████████▍ | 2812/3353 [26:12:13<5:03:06, 33.62s/it] 84%|████████▍ | 2813/3353 [26:12:47<5:02:24, 33.60s/it] 84%|████████▍ | 2814/3353 [26:13:20<5:01:41, 33.58s/it] 84%|████████▍ | 2815/3353 [26:13:54<5:01:03, 33.58s/it] 84%|████████▍ | 2816/3353 [26:14:28<5:00:56, 33.63s/it] 84%|████████▍ | 2817/3353 [26:15:01<5:00:14, 33.61s/it] 84%|████████▍ | 2818/3353 [26:15:35<5:00:05, 33.65s/it] 84%|████████▍ | 2819/3353 [26:16:09<4:59:51, 33.69s/it] 84%|████████▍ | 2820/3353 [26:16:44<5:03:19, 34.15s/it]                                                        {'loss': 1.1355, 'learning_rate': 3.053179549721874e-06, 'epoch': 0.84}
 84%|████████▍ | 2820/3353 [26:16:44<5:03:19, 34.15s/it] 84%|████████▍ | 2821/3353 [26:17:18<5:01:27, 34.00s/it] 84%|████████▍ | 2822/3353 [26:17:51<4:59:51, 33.88s/it] 84%|████████▍ | 2823/3353 [26:18:25<4:58:21, 33.78s/it] 84%|████████▍ | 2824/3353 [26:18:58<4:57:16, 33.72s/it] 84%|████████▍ | 2825/3353 [26:19:32<4:56:16, 33.67s/it] 84%|████████▍ | 2826/3353 [26:20:05<4:55:26, 33.64s/it] 84%|████████▍ | 2827/3353 [26:20:40<4:58:26, 34.04s/it] 84%|████████▍ | 2828/3353 [26:21:14<4:57:00, 33.94s/it] 84%|████████▍ | 2829/3353 [26:21:48<4:56:28, 33.95s/it] 84%|████████▍ | 2830/3353 [26:22:22<4:55:54, 33.95s/it]                                                        {'loss': 1.1323, 'learning_rate': 2.9419696397776504e-06, 'epoch': 0.84}
 84%|████████▍ | 2830/3353 [26:22:22<4:55:54, 33.95s/it] 84%|████████▍ | 2831/3353 [26:22:56<4:54:17, 33.83s/it] 84%|████████▍ | 2832/3353 [26:23:29<4:53:30, 33.80s/it] 84%|████████▍ | 2833/3353 [26:24:03<4:52:17, 33.73s/it] 85%|████████▍ | 2834/3353 [26:24:37<4:51:44, 33.73s/it] 85%|████████▍ | 2835/3353 [26:25:10<4:51:11, 33.73s/it] 85%|████████▍ | 2836/3353 [26:25:44<4:50:13, 33.68s/it] 85%|████████▍ | 2837/3353 [26:26:18<4:49:18, 33.64s/it] 85%|████████▍ | 2838/3353 [26:26:51<4:48:32, 33.62s/it] 85%|████████▍ | 2839/3353 [26:27:25<4:47:52, 33.60s/it] 85%|████████▍ | 2840/3353 [26:27:58<4:47:42, 33.65s/it]                                                        {'loss': 1.1386, 'learning_rate': 2.832696134816354e-06, 'epoch': 0.85}
 85%|████████▍ | 2840/3353 [26:27:59<4:47:42, 33.65s/it] 85%|████████▍ | 2841/3353 [26:28:34<4:51:09, 34.12s/it] 85%|████████▍ | 2842/3353 [26:29:08<4:51:28, 34.22s/it] 85%|████████▍ | 2843/3353 [26:29:42<4:49:42, 34.08s/it] 85%|████████▍ | 2844/3353 [26:30:16<4:50:32, 34.25s/it] 85%|████████▍ | 2845/3353 [26:30:51<4:51:07, 34.38s/it] 85%|████████▍ | 2846/3353 [26:31:25<4:48:56, 34.19s/it] 85%|████████▍ | 2847/3353 [26:32:00<4:51:46, 34.60s/it] 85%|████████▍ | 2848/3353 [26:32:34<4:49:05, 34.35s/it] 85%|████████▍ | 2849/3353 [26:33:10<4:51:28, 34.70s/it] 85%|████████▍ | 2850/3353 [26:33:44<4:49:27, 34.53s/it]                                                        {'loss': 1.1357, 'learning_rate': 2.725368627614666e-06, 'epoch': 0.85}
 85%|████████▍ | 2850/3353 [26:33:44<4:49:27, 34.53s/it] 85%|████████▌ | 2851/3353 [26:34:17<4:46:30, 34.24s/it] 85%|████████▌ | 2852/3353 [26:34:51<4:44:17, 34.05s/it] 85%|████████▌ | 2853/3353 [26:35:25<4:42:29, 33.90s/it] 85%|████████▌ | 2854/3353 [26:35:58<4:41:03, 33.79s/it] 85%|████████▌ | 2855/3353 [26:36:32<4:39:54, 33.72s/it] 85%|████████▌ | 2856/3353 [26:37:05<4:39:05, 33.69s/it] 85%|████████▌ | 2857/3353 [26:37:39<4:38:11, 33.65s/it] 85%|████████▌ | 2858/3353 [26:38:13<4:37:32, 33.64s/it] 85%|████████▌ | 2859/3353 [26:38:46<4:36:44, 33.61s/it] 85%|████████▌ | 2860/3353 [26:39:20<4:36:30, 33.65s/it]                                                        {'loss': 1.1406, 'learning_rate': 2.6199965401162735e-06, 'epoch': 0.85}
 85%|████████▌ | 2860/3353 [26:39:20<4:36:30, 33.65s/it] 85%|████████▌ | 2861/3353 [26:39:53<4:35:50, 33.64s/it] 85%|████████▌ | 2862/3353 [26:40:27<4:35:05, 33.62s/it] 85%|████████▌ | 2863/3353 [26:41:01<4:34:20, 33.59s/it] 85%|████████▌ | 2864/3353 [26:41:34<4:33:52, 33.60s/it] 85%|████████▌ | 2865/3353 [26:42:08<4:32:58, 33.56s/it] 85%|████████▌ | 2866/3353 [26:42:41<4:32:27, 33.57s/it] 86%|████████▌ | 2867/3353 [26:43:15<4:31:43, 33.55s/it] 86%|████████▌ | 2868/3353 [26:43:48<4:31:00, 33.53s/it] 86%|████████▌ | 2869/3353 [26:44:22<4:30:22, 33.52s/it] 86%|████████▌ | 2870/3353 [26:44:55<4:29:38, 33.50s/it]                                                        {'loss': 1.1291, 'learning_rate': 2.516589122604718e-06, 'epoch': 0.86}
 86%|████████▌ | 2870/3353 [26:44:56<4:29:38, 33.50s/it] 86%|████████▌ | 2871/3353 [26:45:30<4:31:19, 33.78s/it] 86%|████████▌ | 2872/3353 [26:46:03<4:29:57, 33.68s/it] 86%|████████▌ | 2873/3353 [26:46:37<4:29:18, 33.66s/it] 86%|████████▌ | 2874/3353 [26:47:10<4:28:14, 33.60s/it] 86%|████████▌ | 2875/3353 [26:47:44<4:27:46, 33.61s/it] 86%|████████▌ | 2876/3353 [26:48:17<4:27:10, 33.61s/it] 86%|████████▌ | 2877/3353 [26:48:51<4:26:13, 33.56s/it] 86%|████████▌ | 2878/3353 [26:49:24<4:25:31, 33.54s/it] 86%|████████▌ | 2879/3353 [26:49:58<4:24:47, 33.52s/it] 86%|████████▌ | 2880/3353 [26:50:31<4:24:07, 33.50s/it]                                                        {'loss': 1.1317, 'learning_rate': 2.415155452891363e-06, 'epoch': 0.86}
 86%|████████▌ | 2880/3353 [26:50:31<4:24:07, 33.50s/it] 86%|████████▌ | 2881/3353 [26:51:05<4:23:35, 33.51s/it] 86%|████████▌ | 2882/3353 [26:51:38<4:22:53, 33.49s/it] 86%|████████▌ | 2883/3353 [26:52:12<4:22:16, 33.48s/it] 86%|████████▌ | 2884/3353 [26:52:45<4:22:03, 33.53s/it] 86%|████████▌ | 2885/3353 [26:53:19<4:21:20, 33.50s/it] 86%|████████▌ | 2886/3353 [26:53:52<4:20:38, 33.49s/it] 86%|████████▌ | 2887/3353 [26:54:26<4:20:01, 33.48s/it] 86%|████████▌ | 2888/3353 [26:54:59<4:19:20, 33.46s/it] 86%|████████▌ | 2889/3353 [26:55:33<4:19:10, 33.51s/it] 86%|████████▌ | 2890/3353 [26:56:06<4:18:30, 33.50s/it]                                                        {'loss': 1.1331, 'learning_rate': 2.315704435518462e-06, 'epoch': 0.86}
 86%|████████▌ | 2890/3353 [26:56:08<4:18:30, 33.50s/it] 86%|████████▌ | 2891/3353 [26:56:41<4:21:51, 34.01s/it] 86%|████████▋ | 2892/3353 [26:57:15<4:19:56, 33.83s/it] 86%|████████▋ | 2893/3353 [26:57:48<4:18:31, 33.72s/it] 86%|████████▋ | 2894/3353 [26:58:22<4:17:20, 33.64s/it] 86%|████████▋ | 2895/3353 [26:58:55<4:16:16, 33.57s/it] 86%|████████▋ | 2896/3353 [26:59:28<4:15:23, 33.53s/it] 86%|████████▋ | 2897/3353 [27:00:02<4:15:03, 33.56s/it] 86%|████████▋ | 2898/3353 [27:00:36<4:14:11, 33.52s/it] 86%|████████▋ | 2899/3353 [27:01:09<4:13:54, 33.56s/it] 86%|████████▋ | 2900/3353 [27:01:43<4:13:34, 33.59s/it]                                                        {'loss': 1.135, 'learning_rate': 2.21824480097747e-06, 'epoch': 0.86}
 86%|████████▋ | 2900/3353 [27:01:43<4:13:34, 33.59s/it] 87%|████████▋ | 2901/3353 [27:02:16<4:12:47, 33.56s/it] 87%|████████▋ | 2902/3353 [27:02:50<4:11:53, 33.51s/it] 87%|████████▋ | 2903/3353 [27:03:23<4:11:08, 33.49s/it] 87%|████████▋ | 2904/3353 [27:03:57<4:10:26, 33.47s/it] 87%|████████▋ | 2905/3353 [27:04:30<4:10:33, 33.56s/it] 87%|████████▋ | 2906/3353 [27:05:04<4:09:46, 33.53s/it] 87%|████████▋ | 2907/3353 [27:05:37<4:09:30, 33.57s/it] 87%|████████▋ | 2908/3353 [27:06:11<4:09:03, 33.58s/it] 87%|████████▋ | 2909/3353 [27:06:45<4:08:13, 33.54s/it] 87%|████████▋ | 2910/3353 [27:07:18<4:07:25, 33.51s/it]                                                        {'loss': 1.1353, 'learning_rate': 2.1227851049426206e-06, 'epoch': 0.87}
 87%|████████▋ | 2910/3353 [27:07:18<4:07:25, 33.51s/it] 87%|████████▋ | 2911/3353 [27:07:51<4:06:43, 33.49s/it] 87%|████████▋ | 2912/3353 [27:08:28<4:12:08, 34.30s/it] 87%|████████▋ | 2913/3353 [27:09:05<4:19:07, 35.33s/it] 87%|████████▋ | 2914/3353 [27:09:39<4:14:20, 34.76s/it] 87%|████████▋ | 2915/3353 [27:10:12<4:10:53, 34.37s/it] 87%|████████▋ | 2916/3353 [27:10:46<4:08:25, 34.11s/it] 87%|████████▋ | 2917/3353 [27:11:19<4:06:37, 33.94s/it] 87%|████████▋ | 2918/3353 [27:11:53<4:05:01, 33.80s/it] 87%|████████▋ | 2919/3353 [27:12:26<4:03:45, 33.70s/it] 87%|████████▋ | 2920/3353 [27:13:00<4:02:38, 33.62s/it]                                                        {'loss': 1.1309, 'learning_rate': 2.0293337275198528e-06, 'epoch': 0.87}
 87%|████████▋ | 2920/3353 [27:13:00<4:02:38, 33.62s/it] 87%|████████▋ | 2921/3353 [27:13:33<4:01:52, 33.59s/it] 87%|████████▋ | 2922/3353 [27:14:07<4:01:02, 33.56s/it] 87%|████████▋ | 2923/3353 [27:14:40<4:00:25, 33.55s/it] 87%|████████▋ | 2924/3353 [27:15:14<3:59:42, 33.53s/it] 87%|████████▋ | 2925/3353 [27:15:47<3:59:18, 33.55s/it] 87%|████████▋ | 2926/3353 [27:16:21<3:58:32, 33.52s/it] 87%|████████▋ | 2927/3353 [27:16:54<3:57:54, 33.51s/it] 87%|████████▋ | 2928/3353 [27:17:28<3:57:42, 33.56s/it] 87%|████████▋ | 2929/3353 [27:18:01<3:56:58, 33.53s/it] 87%|████████▋ | 2930/3353 [27:18:35<3:56:32, 33.55s/it]                                                        {'loss': 1.1273, 'learning_rate': 1.9378988725111207e-06, 'epoch': 0.87}
 87%|████████▋ | 2930/3353 [27:18:35<3:56:32, 33.55s/it] 87%|████████▋ | 2931/3353 [27:19:08<3:55:46, 33.52s/it] 87%|████████▋ | 2932/3353 [27:19:42<3:55:35, 33.58s/it] 87%|████████▋ | 2933/3353 [27:20:16<3:54:51, 33.55s/it] 88%|████████▊ | 2934/3353 [27:20:49<3:54:12, 33.54s/it] 88%|████████▊ | 2935/3353 [27:21:23<3:53:27, 33.51s/it] 88%|████████▊ | 2936/3353 [27:21:56<3:52:46, 33.49s/it] 88%|████████▊ | 2937/3353 [27:22:29<3:52:09, 33.48s/it] 88%|████████▊ | 2938/3353 [27:23:03<3:51:31, 33.47s/it] 88%|████████▊ | 2939/3353 [27:23:36<3:50:53, 33.46s/it] 88%|████████▊ | 2940/3353 [27:24:10<3:50:24, 33.47s/it]                                                        {'loss': 1.1339, 'learning_rate': 1.8484885666942619e-06, 'epoch': 0.88}
 88%|████████▊ | 2940/3353 [27:24:10<3:50:24, 33.47s/it] 88%|████████▊ | 2941/3353 [27:24:44<3:50:15, 33.53s/it] 88%|████████▊ | 2942/3353 [27:25:17<3:49:31, 33.51s/it] 88%|████████▊ | 2943/3353 [27:25:50<3:48:52, 33.49s/it] 88%|████████▊ | 2944/3353 [27:26:24<3:48:35, 33.53s/it] 88%|████████▊ | 2945/3353 [27:26:58<3:47:52, 33.51s/it] 88%|████████▊ | 2946/3353 [27:27:31<3:47:25, 33.53s/it] 88%|████████▊ | 2947/3353 [27:28:05<3:46:39, 33.50s/it] 88%|████████▊ | 2948/3353 [27:28:38<3:46:21, 33.53s/it] 88%|████████▊ | 2949/3353 [27:29:12<3:46:01, 33.57s/it] 88%|████████▊ | 2950/3353 [27:29:45<3:45:12, 33.53s/it]                                                        {'loss': 1.1297, 'learning_rate': 1.7611106591182814e-06, 'epoch': 0.88}
 88%|████████▊ | 2950/3353 [27:29:45<3:45:12, 33.53s/it] 88%|████████▊ | 2951/3353 [27:30:19<3:44:38, 33.53s/it] 88%|████████▊ | 2952/3353 [27:30:52<3:44:20, 33.57s/it] 88%|████████▊ | 2953/3353 [27:31:26<3:43:36, 33.54s/it] 88%|████████▊ | 2954/3353 [27:31:59<3:43:08, 33.56s/it] 88%|████████▊ | 2955/3353 [27:32:33<3:42:21, 33.52s/it] 88%|████████▊ | 2956/3353 [27:33:07<3:42:02, 33.56s/it] 88%|████████▊ | 2957/3353 [27:33:40<3:41:19, 33.53s/it] 88%|████████▊ | 2958/3353 [27:34:13<3:40:35, 33.51s/it] 88%|████████▊ | 2959/3353 [27:34:47<3:39:58, 33.50s/it] 88%|████████▊ | 2960/3353 [27:35:21<3:39:44, 33.55s/it]                                                        {'loss': 1.1374, 'learning_rate': 1.6757728204143897e-06, 'epoch': 0.88}
 88%|████████▊ | 2960/3353 [27:35:21<3:39:44, 33.55s/it] 88%|████████▊ | 2961/3353 [27:35:54<3:39:22, 33.58s/it] 88%|████████▊ | 2962/3353 [27:36:28<3:39:09, 33.63s/it] 88%|████████▊ | 2963/3353 [27:37:02<3:39:04, 33.70s/it] 88%|████████▊ | 2964/3353 [27:37:36<3:38:55, 33.77s/it] 88%|████████▊ | 2965/3353 [27:38:10<3:39:03, 33.88s/it] 88%|████████▊ | 2966/3353 [27:38:44<3:38:21, 33.85s/it] 88%|████████▊ | 2967/3353 [27:39:18<3:37:40, 33.84s/it] 89%|████████▊ | 2968/3353 [27:39:51<3:36:56, 33.81s/it] 89%|████████▊ | 2969/3353 [27:40:25<3:36:24, 33.81s/it] 89%|████████▊ | 2970/3353 [27:40:59<3:35:38, 33.78s/it]                                                        {'loss': 1.1388, 'learning_rate': 1.5924825421225392e-06, 'epoch': 0.89}
 89%|████████▊ | 2970/3353 [27:40:59<3:35:38, 33.78s/it] 89%|████████▊ | 2971/3353 [27:41:33<3:35:23, 33.83s/it] 89%|████████▊ | 2972/3353 [27:42:07<3:34:40, 33.81s/it] 89%|████████▊ | 2973/3353 [27:42:41<3:34:27, 33.86s/it] 89%|████████▊ | 2974/3353 [27:43:14<3:33:44, 33.84s/it] 89%|████████▊ | 2975/3353 [27:43:48<3:33:04, 33.82s/it] 89%|████████▉ | 2976/3353 [27:44:22<3:32:29, 33.82s/it] 89%|████████▉ | 2977/3353 [27:44:56<3:31:48, 33.80s/it] 89%|████████▉ | 2978/3353 [27:45:29<3:30:58, 33.75s/it] 89%|████████▉ | 2979/3353 [27:46:03<3:30:43, 33.81s/it] 89%|████████▉ | 2980/3353 [27:46:37<3:30:01, 33.78s/it]                                                        {'loss': 1.1337, 'learning_rate': 1.5112471360338332e-06, 'epoch': 0.89}
 89%|████████▉ | 2980/3353 [27:46:37<3:30:01, 33.78s/it] 89%|████████▉ | 2981/3353 [27:47:11<3:29:15, 33.75s/it] 89%|████████▉ | 2982/3353 [27:47:45<3:28:58, 33.80s/it] 89%|████████▉ | 2983/3353 [27:48:18<3:28:25, 33.80s/it] 89%|████████▉ | 2984/3353 [27:48:52<3:27:49, 33.79s/it] 89%|████████▉ | 2985/3353 [27:49:26<3:27:31, 33.84s/it] 89%|████████▉ | 2986/3353 [27:50:00<3:26:54, 33.83s/it] 89%|████████▉ | 2987/3353 [27:50:34<3:26:34, 33.86s/it] 89%|████████▉ | 2988/3353 [27:51:08<3:25:44, 33.82s/it] 89%|████████▉ | 2989/3353 [27:51:41<3:25:15, 33.83s/it] 89%|████████▉ | 2990/3353 [27:52:15<3:25:06, 33.90s/it]                                                        {'loss': 1.1258, 'learning_rate': 1.4320737335486e-06, 'epoch': 0.89}
 89%|████████▉ | 2990/3353 [27:52:15<3:25:06, 33.90s/it] 89%|████████▉ | 2991/3353 [27:52:49<3:24:11, 33.84s/it] 89%|████████▉ | 2992/3353 [27:53:23<3:23:18, 33.79s/it] 89%|████████▉ | 2993/3353 [27:53:57<3:22:39, 33.78s/it] 89%|████████▉ | 2994/3353 [27:54:30<3:21:53, 33.74s/it] 89%|████████▉ | 2995/3353 [27:55:04<3:21:36, 33.79s/it] 89%|████████▉ | 2996/3353 [27:55:38<3:20:58, 33.78s/it] 89%|████████▉ | 2997/3353 [27:56:12<3:20:18, 33.76s/it] 89%|████████▉ | 2998/3353 [27:56:45<3:19:29, 33.72s/it] 89%|████████▉ | 2999/3353 [27:57:19<3:18:57, 33.72s/it] 89%|████████▉ | 3000/3353 [27:57:53<3:18:12, 33.69s/it]                                                        {'loss': 1.1327, 'learning_rate': 1.3549692850503864e-06, 'epoch': 0.89}
 89%|████████▉ | 3000/3353 [27:57:53<3:18:12, 33.69s/it] 90%|████████▉ | 3001/3353 [27:58:26<3:17:55, 33.74s/it] 90%|████████▉ | 3002/3353 [27:59:00<3:17:08, 33.70s/it] 90%|████████▉ | 3003/3353 [27:59:34<3:16:45, 33.73s/it] 90%|████████▉ | 3004/3353 [28:00:07<3:16:02, 33.70s/it] 90%|████████▉ | 3005/3353 [28:00:41<3:15:40, 33.74s/it] 90%|████████▉ | 3006/3353 [28:01:15<3:15:13, 33.76s/it] 90%|████████▉ | 3007/3353 [28:01:49<3:14:24, 33.71s/it] 90%|████████▉ | 3008/3353 [28:02:22<3:13:43, 33.69s/it] 90%|████████▉ | 3009/3353 [28:02:56<3:13:18, 33.72s/it] 90%|████████▉ | 3010/3353 [28:03:30<3:12:30, 33.68s/it]                                                        {'loss': 1.1302, 'learning_rate': 1.2799405592957698e-06, 'epoch': 0.9}
 90%|████████▉ | 3010/3353 [28:03:30<3:12:30, 33.68s/it] 90%|████████▉ | 3011/3353 [28:04:04<3:12:16, 33.73s/it] 90%|████████▉ | 3012/3353 [28:04:37<3:11:35, 33.71s/it] 90%|████████▉ | 3013/3353 [28:05:11<3:11:10, 33.74s/it] 90%|████████▉ | 3014/3353 [28:05:45<3:10:45, 33.76s/it] 90%|████████▉ | 3015/3353 [28:06:18<3:10:02, 33.74s/it] 90%|████████▉ | 3016/3353 [28:06:52<3:09:15, 33.70s/it] 90%|████████▉ | 3017/3353 [28:07:26<3:08:58, 33.74s/it] 90%|█████████ | 3018/3353 [28:08:00<3:08:12, 33.71s/it] 90%|█████████ | 3019/3353 [28:08:33<3:07:47, 33.73s/it] 90%|█████████ | 3020/3353 [28:09:07<3:07:06, 33.71s/it]                                                        {'loss': 1.1339, 'learning_rate': 1.2069941428201864e-06, 'epoch': 0.9}
 90%|█████████ | 3020/3353 [28:09:07<3:07:06, 33.71s/it] 90%|█████████ | 3021/3353 [28:09:41<3:06:45, 33.75s/it] 90%|█████████ | 3022/3353 [28:10:15<3:05:59, 33.71s/it] 90%|█████████ | 3023/3353 [28:10:48<3:05:17, 33.69s/it] 90%|█████████ | 3024/3353 [28:11:22<3:04:34, 33.66s/it] 90%|█████████ | 3025/3353 [28:11:55<3:03:59, 33.66s/it] 90%|█████████ | 3026/3353 [28:12:29<3:03:27, 33.66s/it] 90%|█████████ | 3027/3353 [28:13:03<3:02:45, 33.64s/it] 90%|█████████ | 3028/3353 [28:13:36<3:02:12, 33.64s/it] 90%|█████████ | 3029/3353 [28:14:10<3:01:45, 33.66s/it] 90%|█████████ | 3030/3353 [28:14:44<3:01:25, 33.70s/it]                                                        {'loss': 1.1313, 'learning_rate': 1.1361364393596836e-06, 'epoch': 0.9}
 90%|█████████ | 3030/3353 [28:14:44<3:01:25, 33.70s/it] 90%|█████████ | 3031/3353 [28:15:17<3:00:47, 33.69s/it] 90%|█████████ | 3032/3353 [28:15:51<3:00:05, 33.66s/it] 90%|█████████ | 3033/3353 [28:16:25<2:59:36, 33.68s/it] 90%|█████████ | 3034/3353 [28:16:58<2:59:00, 33.67s/it] 91%|█████████ | 3035/3353 [28:17:32<2:58:13, 33.63s/it] 91%|█████████ | 3036/3353 [28:18:06<2:57:39, 33.63s/it] 91%|█████████ | 3037/3353 [28:18:39<2:57:11, 33.64s/it] 91%|█████████ | 3038/3353 [28:19:13<2:56:52, 33.69s/it] 91%|█████████ | 3039/3353 [28:19:47<2:56:13, 33.67s/it] 91%|█████████ | 3040/3353 [28:20:20<2:55:39, 33.67s/it]                                                        {'loss': 1.1359, 'learning_rate': 1.0673736692887847e-06, 'epoch': 0.91}
 91%|█████████ | 3040/3353 [28:20:20<2:55:39, 33.67s/it] 91%|█████████ | 3041/3353 [28:20:54<2:54:58, 33.65s/it] 91%|█████████ | 3042/3353 [28:21:28<2:54:45, 33.71s/it] 91%|█████████ | 3043/3353 [28:22:01<2:54:00, 33.68s/it] 91%|█████████ | 3044/3353 [28:22:35<2:53:35, 33.71s/it] 91%|█████████ | 3045/3353 [28:23:09<2:52:55, 33.69s/it] 91%|█████████ | 3046/3353 [28:23:43<2:52:32, 33.72s/it] 91%|█████████ | 3047/3353 [28:24:16<2:51:59, 33.73s/it] 91%|█████████ | 3048/3353 [28:24:50<2:51:18, 33.70s/it] 91%|█████████ | 3049/3353 [28:25:24<2:50:37, 33.68s/it] 91%|█████████ | 3050/3353 [28:25:57<2:50:00, 33.66s/it]                                                        {'loss': 1.1311, 'learning_rate': 1.0007118690744167e-06, 'epoch': 0.91}
 91%|█████████ | 3050/3353 [28:25:57<2:50:00, 33.66s/it] 91%|█████████ | 3051/3353 [28:26:31<2:49:23, 33.65s/it] 91%|█████████ | 3052/3353 [28:27:04<2:48:35, 33.61s/it] 91%|█████████ | 3053/3353 [28:27:38<2:47:59, 33.60s/it] 91%|█████████ | 3054/3353 [28:28:12<2:47:28, 33.61s/it] 91%|█████████ | 3055/3353 [28:28:45<2:47:03, 33.64s/it] 91%|█████████ | 3056/3353 [28:29:19<2:46:24, 33.62s/it] 91%|█████████ | 3057/3353 [28:29:53<2:45:59, 33.65s/it] 91%|█████████ | 3058/3353 [28:30:26<2:45:42, 33.70s/it] 91%|█████████ | 3059/3353 [28:31:00<2:44:55, 33.66s/it] 91%|█████████▏| 3060/3353 [28:31:34<2:44:25, 33.67s/it]                                                        {'loss': 1.1377, 'learning_rate': 9.361568907459734e-07, 'epoch': 0.91}
 91%|█████████▏| 3060/3353 [28:31:34<2:44:25, 33.67s/it] 91%|█████████▏| 3061/3353 [28:32:07<2:43:50, 33.67s/it] 91%|█████████▏| 3062/3353 [28:32:41<2:43:35, 33.73s/it] 91%|█████████▏| 3063/3353 [28:33:15<2:42:50, 33.69s/it] 91%|█████████▏| 3064/3353 [28:33:48<2:42:05, 33.65s/it] 91%|█████████▏| 3065/3353 [28:34:22<2:41:27, 33.64s/it] 91%|█████████▏| 3066/3353 [28:34:56<2:41:07, 33.68s/it] 91%|█████████▏| 3067/3353 [28:35:29<2:40:23, 33.65s/it] 92%|█████████▏| 3068/3353 [28:36:03<2:39:48, 33.64s/it] 92%|█████████▏| 3069/3353 [28:36:37<2:39:10, 33.63s/it] 92%|█████████▏| 3070/3353 [28:37:10<2:38:39, 33.64s/it]                                                        {'loss': 1.1342, 'learning_rate': 8.737144013815923e-07, 'epoch': 0.92}
 92%|█████████▏| 3070/3353 [28:37:10<2:38:39, 33.64s/it] 92%|█████████▏| 3071/3353 [28:37:45<2:39:33, 33.95s/it] 92%|█████████▏| 3072/3353 [28:38:19<2:39:16, 34.01s/it] 92%|█████████▏| 3073/3353 [28:38:53<2:37:59, 33.85s/it] 92%|█████████▏| 3074/3353 [28:39:26<2:37:23, 33.85s/it] 92%|█████████▏| 3075/3353 [28:40:00<2:36:27, 33.77s/it] 92%|█████████▏| 3076/3353 [28:40:34<2:35:50, 33.76s/it] 92%|█████████▏| 3077/3353 [28:41:07<2:35:03, 33.71s/it] 92%|█████████▏| 3078/3353 [28:41:41<2:34:34, 33.72s/it] 92%|█████████▏| 3079/3353 [28:42:15<2:34:03, 33.73s/it] 92%|█████████▏| 3080/3353 [28:42:48<2:33:17, 33.69s/it]                                                        {'loss': 1.1321, 'learning_rate': 8.133898826106684e-07, 'epoch': 0.92}
 92%|█████████▏| 3080/3353 [28:42:48<2:33:17, 33.69s/it] 92%|█████████▏| 3081/3353 [28:43:22<2:32:53, 33.73s/it] 92%|█████████▏| 3082/3353 [28:43:57<2:33:58, 34.09s/it] 92%|█████████▏| 3083/3353 [28:44:34<2:37:38, 35.03s/it] 92%|█████████▏| 3084/3353 [28:45:11<2:39:18, 35.53s/it] 92%|█████████▏| 3085/3353 [28:45:45<2:36:07, 34.95s/it] 92%|█████████▏| 3086/3353 [28:46:18<2:33:40, 34.54s/it] 92%|█████████▏| 3087/3353 [28:46:52<2:31:45, 34.23s/it] 92%|█████████▏| 3088/3353 [28:47:25<2:30:18, 34.03s/it] 92%|█████████▏| 3089/3353 [28:47:59<2:29:01, 33.87s/it] 92%|█████████▏| 3090/3353 [28:48:32<2:28:11, 33.81s/it]                                                        {'loss': 1.1341, 'learning_rate': 7.551886301326306e-07, 'epoch': 0.92}
 92%|█████████▏| 3090/3353 [28:48:32<2:28:11, 33.81s/it] 92%|█████████▏| 3091/3353 [28:49:06<2:27:27, 33.77s/it] 92%|█████████▏| 3092/3353 [28:49:40<2:26:39, 33.71s/it] 92%|█████████▏| 3093/3353 [28:50:13<2:25:56, 33.68s/it] 92%|█████████▏| 3094/3353 [28:50:47<2:25:21, 33.67s/it] 92%|█████████▏| 3095/3353 [28:51:21<2:24:56, 33.71s/it] 92%|█████████▏| 3096/3353 [28:51:54<2:24:13, 33.67s/it] 92%|█████████▏| 3097/3353 [28:52:28<2:23:36, 33.66s/it] 92%|█████████▏| 3098/3353 [28:53:02<2:23:01, 33.65s/it] 92%|█████████▏| 3099/3353 [28:53:35<2:22:34, 33.68s/it] 92%|█████████▏| 3100/3353 [28:54:09<2:21:59, 33.67s/it]                                                        {'loss': 1.136, 'learning_rate': 6.991157532520498e-07, 'epoch': 0.92}
 92%|█████████▏| 3100/3353 [28:54:09<2:21:59, 33.67s/it] 92%|█████████▏| 3101/3353 [28:54:43<2:21:35, 33.71s/it] 93%|█████████▎| 3102/3353 [28:55:16<2:20:52, 33.67s/it] 93%|█████████▎| 3103/3353 [28:55:50<2:20:36, 33.74s/it] 93%|█████████▎| 3104/3353 [28:56:24<2:19:48, 33.69s/it] 93%|█████████▎| 3105/3353 [28:56:57<2:19:07, 33.66s/it] 93%|█████████▎| 3106/3353 [28:57:31<2:18:28, 33.64s/it] 93%|█████████▎| 3107/3353 [28:58:05<2:17:50, 33.62s/it] 93%|█████████▎| 3108/3353 [28:58:38<2:17:19, 33.63s/it] 93%|█████████▎| 3109/3353 [28:59:12<2:16:43, 33.62s/it] 93%|█████████▎| 3110/3353 [28:59:45<2:16:06, 33.61s/it]                                                        {'loss': 1.1359, 'learning_rate': 6.451761744301038e-07, 'epoch': 0.93}
 93%|█████████▎| 3110/3353 [28:59:45<2:16:06, 33.61s/it] 93%|█████████▎| 3111/3353 [29:00:19<2:15:35, 33.62s/it] 93%|█████████▎| 3112/3353 [29:00:53<2:15:02, 33.62s/it] 93%|█████████▎| 3113/3353 [29:01:26<2:14:25, 33.60s/it] 93%|█████████▎| 3114/3353 [29:02:00<2:13:52, 33.61s/it] 93%|█████████▎| 3115/3353 [29:02:34<2:13:27, 33.65s/it] 93%|█████████▎| 3116/3353 [29:03:07<2:12:42, 33.60s/it] 93%|█████████▎| 3117/3353 [29:03:41<2:12:16, 33.63s/it] 93%|█████████▎| 3118/3353 [29:04:14<2:11:35, 33.60s/it] 93%|█████████▎| 3119/3353 [29:04:48<2:11:08, 33.63s/it] 93%|█████████▎| 3120/3353 [29:05:22<2:10:43, 33.66s/it]                                                        {'loss': 1.1368, 'learning_rate': 5.933746288524583e-07, 'epoch': 0.93}
 93%|█████████▎| 3120/3353 [29:05:22<2:10:43, 33.66s/it] 93%|█████████▎| 3121/3353 [29:05:55<2:10:05, 33.64s/it] 93%|█████████▎| 3122/3353 [29:06:29<2:09:30, 33.64s/it] 93%|█████████▎| 3123/3353 [29:07:03<2:09:04, 33.67s/it] 93%|█████████▎| 3124/3353 [29:07:36<2:08:19, 33.62s/it] 93%|█████████▎| 3125/3353 [29:08:10<2:07:51, 33.65s/it] 93%|█████████▎| 3126/3353 [29:08:44<2:07:09, 33.61s/it] 93%|█████████▎| 3127/3353 [29:09:17<2:06:45, 33.65s/it] 93%|█████████▎| 3128/3353 [29:09:51<2:06:06, 33.63s/it] 93%|█████████▎| 3129/3353 [29:10:24<2:05:28, 33.61s/it] 93%|█████████▎| 3130/3353 [29:10:58<2:04:52, 33.60s/it]                                                        {'loss': 1.1337, 'learning_rate': 5.437156640135832e-07, 'epoch': 0.93}
 93%|█████████▎| 3130/3353 [29:11:00<2:04:52, 33.60s/it] 93%|█████████▎| 3131/3353 [29:11:33<2:06:19, 34.14s/it] 93%|█████████▎| 3132/3353 [29:12:07<2:05:03, 33.95s/it] 93%|█████████▎| 3133/3353 [29:12:41<2:04:12, 33.87s/it] 93%|█████████▎| 3134/3353 [29:13:14<2:03:20, 33.79s/it] 93%|█████████▎| 3135/3353 [29:13:48<2:02:48, 33.80s/it] 94%|█████████▎| 3136/3353 [29:14:22<2:02:07, 33.77s/it] 94%|█████████▎| 3137/3353 [29:14:55<2:01:20, 33.71s/it] 94%|█████████▎| 3138/3353 [29:15:29<2:00:34, 33.65s/it] 94%|█████████▎| 3139/3353 [29:16:02<1:59:55, 33.63s/it] 94%|█████████▎| 3140/3353 [29:16:36<1:59:17, 33.60s/it]                                                        {'loss': 1.1354, 'learning_rate': 4.962036393175301e-07, 'epoch': 0.94}
 94%|█████████▎| 3140/3353 [29:16:36<1:59:17, 33.60s/it] 94%|█████████▎| 3141/3353 [29:17:10<1:58:50, 33.63s/it] 94%|█████████▎| 3142/3353 [29:17:43<1:58:11, 33.61s/it] 94%|█████████▎| 3143/3353 [29:18:17<1:57:35, 33.60s/it] 94%|█████████▍| 3144/3353 [29:18:50<1:57:10, 33.64s/it] 94%|█████████▍| 3145/3353 [29:19:24<1:56:27, 33.59s/it] 94%|█████████▍| 3146/3353 [29:19:58<1:55:51, 33.58s/it] 94%|█████████▍| 3147/3353 [29:20:31<1:55:17, 33.58s/it] 94%|█████████▍| 3148/3353 [29:21:05<1:54:41, 33.57s/it] 94%|█████████▍| 3149/3353 [29:21:38<1:54:05, 33.56s/it] 94%|█████████▍| 3150/3353 [29:22:12<1:53:27, 33.54s/it]                                                        {'loss': 1.1342, 'learning_rate': 4.508427256952413e-07, 'epoch': 0.94}
 94%|█████████▍| 3150/3353 [29:22:12<1:53:27, 33.54s/it] 94%|█████████▍| 3151/3353 [29:22:45<1:53:07, 33.60s/it] 94%|█████████▍| 3152/3353 [29:23:19<1:52:27, 33.57s/it] 94%|█████████▍| 3153/3353 [29:23:53<1:52:00, 33.60s/it] 94%|█████████▍| 3154/3353 [29:24:26<1:51:20, 33.57s/it] 94%|█████████▍| 3155/3353 [29:25:00<1:50:41, 33.54s/it] 94%|█████████▍| 3156/3353 [29:25:33<1:50:20, 33.61s/it] 94%|█████████▍| 3157/3353 [29:26:07<1:49:40, 33.57s/it] 94%|█████████▍| 3158/3353 [29:26:40<1:49:08, 33.58s/it] 94%|█████████▍| 3159/3353 [29:27:14<1:48:30, 33.56s/it] 94%|█████████▍| 3160/3353 [29:27:48<1:48:15, 33.66s/it]                                                        {'loss': 1.1328, 'learning_rate': 4.076369052383983e-07, 'epoch': 0.94}
 94%|█████████▍| 3160/3353 [29:27:48<1:48:15, 33.66s/it] 94%|█████████▍| 3161/3353 [29:28:21<1:47:41, 33.65s/it] 94%|█████████▍| 3162/3353 [29:28:55<1:47:04, 33.64s/it] 94%|█████████▍| 3163/3353 [29:29:29<1:46:26, 33.62s/it] 94%|█████████▍| 3164/3353 [29:30:02<1:45:51, 33.61s/it] 94%|█████████▍| 3165/3353 [29:30:36<1:45:08, 33.56s/it] 94%|█████████▍| 3166/3353 [29:31:09<1:44:35, 33.56s/it] 94%|█████████▍| 3167/3353 [29:31:43<1:44:01, 33.56s/it] 94%|█████████▍| 3168/3353 [29:32:16<1:43:34, 33.59s/it] 95%|█████████▍| 3169/3353 [29:32:50<1:42:57, 33.57s/it] 95%|█████████▍| 3170/3353 [29:33:23<1:42:20, 33.55s/it]                                                        {'loss': 1.1386, 'learning_rate': 3.6658997084983716e-07, 'epoch': 0.95}
 95%|█████████▍| 3170/3353 [29:33:24<1:42:20, 33.55s/it] 95%|█████████▍| 3171/3353 [29:33:57<1:41:44, 33.54s/it] 95%|█████████▍| 3172/3353 [29:34:31<1:41:25, 33.62s/it] 95%|█████████▍| 3173/3353 [29:35:04<1:40:46, 33.59s/it] 95%|█████████▍| 3174/3353 [29:35:38<1:40:12, 33.59s/it] 95%|█████████▍| 3175/3353 [29:36:11<1:39:33, 33.56s/it] 95%|█████████▍| 3176/3353 [29:36:45<1:39:03, 33.58s/it] 95%|█████████▍| 3177/3353 [29:37:19<1:38:30, 33.58s/it] 95%|█████████▍| 3178/3353 [29:37:52<1:37:54, 33.57s/it] 95%|█████████▍| 3179/3353 [29:38:26<1:37:16, 33.54s/it] 95%|█████████▍| 3180/3353 [29:38:59<1:36:52, 33.60s/it]                                                        {'loss': 1.1364, 'learning_rate': 3.2770552591060153e-07, 'epoch': 0.95}
 95%|█████████▍| 3180/3353 [29:38:59<1:36:52, 33.60s/it] 95%|█████████▍| 3181/3353 [29:39:33<1:36:15, 33.58s/it] 95%|█████████▍| 3182/3353 [29:40:07<1:35:51, 33.64s/it] 95%|█████████▍| 3183/3353 [29:40:40<1:35:12, 33.61s/it] 95%|█████████▍| 3184/3353 [29:41:14<1:34:44, 33.64s/it] 95%|█████████▍| 3185/3353 [29:41:48<1:34:14, 33.66s/it] 95%|█████████▌| 3186/3353 [29:42:21<1:33:32, 33.61s/it] 95%|█████████▌| 3187/3353 [29:42:55<1:32:55, 33.59s/it] 95%|█████████▌| 3188/3353 [29:43:28<1:32:31, 33.64s/it] 95%|█████████▌| 3189/3353 [29:44:02<1:31:52, 33.61s/it] 95%|█████████▌| 3190/3353 [29:44:36<1:31:19, 33.62s/it]                                                        {'loss': 1.1363, 'learning_rate': 2.9098698396358426e-07, 'epoch': 0.95}
 95%|█████████▌| 3190/3353 [29:44:36<1:31:19, 33.62s/it] 95%|█████████▌| 3191/3353 [29:45:09<1:30:43, 33.60s/it] 95%|█████████▌| 3192/3353 [29:45:43<1:30:17, 33.65s/it] 95%|█████████▌| 3193/3353 [29:46:16<1:29:38, 33.62s/it] 95%|█████████▌| 3194/3353 [29:46:50<1:29:00, 33.59s/it] 95%|█████████▌| 3195/3353 [29:47:23<1:28:22, 33.56s/it] 95%|█████████▌| 3196/3353 [29:47:57<1:27:50, 33.57s/it] 95%|█████████▌| 3197/3353 [29:48:31<1:27:13, 33.55s/it] 95%|█████████▌| 3198/3353 [29:49:04<1:26:36, 33.52s/it] 95%|█████████▌| 3199/3353 [29:49:38<1:26:05, 33.55s/it] 95%|█████████▌| 3200/3353 [29:50:11<1:25:32, 33.55s/it]                                                        {'loss': 1.1385, 'learning_rate': 2.5643756841389477e-07, 'epoch': 0.95}
 95%|█████████▌| 3200/3353 [29:50:11<1:25:32, 33.55s/it] 95%|█████████▌| 3201/3353 [29:50:45<1:25:27, 33.74s/it] 95%|█████████▌| 3202/3353 [29:51:25<1:29:13, 35.45s/it] 96%|█████████▌| 3203/3353 [29:51:59<1:27:23, 34.96s/it] 96%|█████████▌| 3204/3353 [29:52:32<1:25:46, 34.54s/it] 96%|█████████▌| 3205/3353 [29:53:06<1:24:24, 34.22s/it] 96%|█████████▌| 3206/3353 [29:53:39<1:23:19, 34.01s/it] 96%|█████████▌| 3207/3353 [29:54:13<1:22:22, 33.85s/it] 96%|█████████▌| 3208/3353 [29:54:46<1:21:36, 33.77s/it] 96%|█████████▌| 3209/3353 [29:55:20<1:21:01, 33.76s/it] 96%|█████████▌| 3210/3353 [29:55:53<1:20:16, 33.68s/it]                                                        {'loss': 1.1332, 'learning_rate': 2.240603122458551e-07, 'epoch': 0.96}
 96%|█████████▌| 3210/3353 [29:55:54<1:20:16, 33.68s/it] 96%|█████████▌| 3211/3353 [29:56:27<1:19:37, 33.64s/it] 96%|█████████▌| 3212/3353 [29:57:01<1:18:57, 33.60s/it] 96%|█████████▌| 3213/3353 [29:57:34<1:18:31, 33.65s/it] 96%|█████████▌| 3214/3353 [29:58:08<1:17:54, 33.63s/it] 96%|█████████▌| 3215/3353 [29:58:42<1:17:26, 33.67s/it] 96%|█████████▌| 3216/3353 [29:59:15<1:16:43, 33.61s/it] 96%|█████████▌| 3217/3353 [29:59:49<1:16:14, 33.64s/it] 96%|█████████▌| 3218/3353 [30:00:22<1:15:34, 33.59s/it] 96%|█████████▌| 3219/3353 [30:00:56<1:14:54, 33.54s/it] 96%|█████████▌| 3220/3353 [30:01:29<1:14:18, 33.52s/it]                                                        {'loss': 1.1392, 'learning_rate': 1.9385805775677114e-07, 'epoch': 0.96}
 96%|█████████▌| 3220/3353 [30:01:29<1:14:18, 33.52s/it] 96%|█████████▌| 3221/3353 [30:02:03<1:13:46, 33.53s/it] 96%|█████████▌| 3222/3353 [30:02:36<1:13:11, 33.52s/it] 96%|█████████▌| 3223/3353 [30:03:10<1:12:37, 33.52s/it] 96%|█████████▌| 3224/3353 [30:03:43<1:12:05, 33.53s/it] 96%|█████████▌| 3225/3353 [30:04:17<1:11:39, 33.59s/it] 96%|█████████▌| 3226/3353 [30:04:50<1:11:02, 33.56s/it] 96%|█████████▌| 3227/3353 [30:05:24<1:10:26, 33.55s/it] 96%|█████████▋| 3228/3353 [30:05:57<1:09:50, 33.52s/it] 96%|█████████▋| 3229/3353 [30:06:31<1:09:21, 33.56s/it] 96%|█████████▋| 3230/3353 [30:07:05<1:08:44, 33.53s/it]                                                        {'loss': 1.1283, 'learning_rate': 1.6583345630740156e-07, 'epoch': 0.96}
 96%|█████████▋| 3230/3353 [30:07:05<1:08:44, 33.53s/it] 96%|█████████▋| 3231/3353 [30:07:38<1:08:15, 33.57s/it] 96%|█████████▋| 3232/3353 [30:08:12<1:07:39, 33.55s/it] 96%|█████████▋| 3233/3353 [30:08:46<1:07:15, 33.63s/it] 96%|█████████▋| 3234/3353 [30:09:19<1:06:38, 33.60s/it] 96%|█████████▋| 3235/3353 [30:09:53<1:06:01, 33.57s/it] 97%|█████████▋| 3236/3353 [30:10:26<1:05:25, 33.55s/it] 97%|█████████▋| 3237/3353 [30:11:00<1:04:57, 33.60s/it] 97%|█████████▋| 3238/3353 [30:11:33<1:04:20, 33.57s/it] 97%|█████████▋| 3239/3353 [30:12:07<1:03:48, 33.59s/it] 97%|█████████▋| 3240/3353 [30:12:40<1:03:13, 33.57s/it]                                                        {'loss': 1.1419, 'learning_rate': 1.3998896808920248e-07, 'epoch': 0.97}
 97%|█████████▋| 3240/3353 [30:12:40<1:03:13, 33.57s/it] 97%|█████████▋| 3241/3353 [30:13:14<1:02:45, 33.62s/it] 97%|█████████▋| 3242/3353 [30:13:48<1:02:11, 33.62s/it] 97%|█████████▋| 3243/3353 [30:14:21<1:01:33, 33.57s/it] 97%|█████████▋| 3244/3353 [30:14:55<1:00:58, 33.57s/it] 97%|█████████▋| 3245/3353 [30:15:29<1:00:30, 33.62s/it] 97%|█████████▋| 3246/3353 [30:16:02<59:54, 33.59s/it]   97%|█████████▋| 3247/3353 [30:16:36<59:23, 33.62s/it] 97%|█████████▋| 3248/3353 [30:17:09<58:46, 33.59s/it] 97%|█████████▋| 3249/3353 [30:17:43<58:17, 33.63s/it] 97%|█████████▋| 3250/3353 [30:18:17<57:46, 33.65s/it]                                                      {'loss': 1.1323, 'learning_rate': 1.1632686190836129e-07, 'epoch': 0.97}
 97%|█████████▋| 3250/3353 [30:18:17<57:46, 33.65s/it] 97%|█████████▋| 3251/3353 [30:18:50<57:14, 33.67s/it] 97%|█████████▋| 3252/3353 [30:19:24<56:36, 33.63s/it] 97%|█████████▋| 3253/3353 [30:19:57<55:58, 33.59s/it] 97%|█████████▋| 3254/3353 [30:20:31<55:23, 33.57s/it] 97%|█████████▋| 3255/3353 [30:21:05<54:47, 33.55s/it] 97%|█████████▋| 3256/3353 [30:21:38<54:12, 33.53s/it] 97%|█████████▋| 3257/3353 [30:22:12<53:39, 33.53s/it] 97%|█████████▋| 3258/3353 [30:22:45<53:04, 33.52s/it] 97%|█████████▋| 3259/3353 [30:23:19<52:30, 33.52s/it] 97%|█████████▋| 3260/3353 [30:23:52<51:55, 33.50s/it]                                                      {'loss': 1.1396, 'learning_rate': 9.484921498662535e-08, 'epoch': 0.97}
 97%|█████████▋| 3260/3353 [30:23:52<51:55, 33.50s/it] 97%|█████████▋| 3261/3353 [30:24:26<51:25, 33.54s/it] 97%|█████████▋| 3262/3353 [30:24:59<50:50, 33.53s/it] 97%|█████████▋| 3263/3353 [30:25:33<50:16, 33.51s/it] 97%|█████████▋| 3264/3353 [30:26:06<49:42, 33.51s/it] 97%|█████████▋| 3265/3353 [30:26:40<49:11, 33.54s/it] 97%|█████████▋| 3266/3353 [30:27:13<48:40, 33.57s/it] 97%|█████████▋| 3267/3353 [30:27:47<48:04, 33.54s/it] 97%|█████████▋| 3268/3353 [30:28:20<47:30, 33.54s/it] 97%|█████████▋| 3269/3353 [30:28:54<46:55, 33.52s/it] 98%|█████████▊| 3270/3353 [30:29:27<46:25, 33.56s/it]                                                      {'loss': 1.1315, 'learning_rate': 7.555791277894242e-08, 'epoch': 0.98}
 98%|█████████▊| 3270/3353 [30:29:28<46:25, 33.56s/it] 98%|█████████▊| 3271/3353 [30:30:01<45:53, 33.58s/it] 98%|█████████▊| 3272/3353 [30:30:35<45:22, 33.61s/it] 98%|█████████▊| 3273/3353 [30:31:08<44:46, 33.58s/it] 98%|█████████▊| 3274/3353 [30:31:42<44:19, 33.67s/it] 98%|█████████▊| 3275/3353 [30:32:16<43:42, 33.62s/it] 98%|█████████▊| 3276/3353 [30:32:49<43:04, 33.57s/it] 98%|█████████▊| 3277/3353 [30:33:23<42:29, 33.55s/it] 98%|█████████▊| 3278/3353 [30:33:56<41:54, 33.53s/it] 98%|█████████▊| 3279/3353 [30:34:30<41:19, 33.51s/it] 98%|█████████▊| 3280/3353 [30:35:03<40:46, 33.51s/it]                                                      {'loss': 1.1323, 'learning_rate': 5.845464880795126e-08, 'epoch': 0.98}
 98%|█████████▊| 3280/3353 [30:35:03<40:46, 33.51s/it] 98%|█████████▊| 3281/3353 [30:35:37<40:13, 33.52s/it] 98%|█████████▊| 3282/3353 [30:36:10<39:39, 33.51s/it] 98%|█████████▊| 3283/3353 [30:36:44<39:05, 33.51s/it] 98%|█████████▊| 3284/3353 [30:37:17<38:31, 33.50s/it] 98%|█████████▊| 3285/3353 [30:37:51<37:57, 33.49s/it] 98%|█████████▊| 3286/3353 [30:38:24<37:26, 33.53s/it] 98%|█████████▊| 3287/3353 [30:38:58<36:51, 33.50s/it] 98%|█████████▊| 3288/3353 [30:39:31<36:18, 33.52s/it] 98%|█████████▊| 3289/3353 [30:40:05<35:46, 33.53s/it] 98%|█████████▊| 3290/3353 [30:40:39<35:19, 33.64s/it]                                                      {'loss': 1.1322, 'learning_rate': 4.3540924515300674e-08, 'epoch': 0.98}
 98%|█████████▊| 3290/3353 [30:40:39<35:19, 33.64s/it] 98%|█████████▊| 3291/3353 [30:41:12<34:44, 33.62s/it] 98%|█████████▊| 3292/3353 [30:41:46<34:08, 33.58s/it] 98%|█████████▊| 3293/3353 [30:42:19<33:33, 33.56s/it] 98%|█████████▊| 3294/3353 [30:42:53<33:01, 33.59s/it] 98%|█████████▊| 3295/3353 [30:43:26<32:25, 33.54s/it] 98%|█████████▊| 3296/3353 [30:44:00<31:53, 33.57s/it] 98%|█████████▊| 3297/3353 [30:44:33<31:18, 33.54s/it] 98%|█████████▊| 3298/3353 [30:45:07<30:49, 33.63s/it] 98%|█████████▊| 3299/3353 [30:45:41<30:14, 33.60s/it] 98%|█████████▊| 3300/3353 [30:46:14<29:38, 33.56s/it]                                                      {'loss': 1.1328, 'learning_rate': 3.081804912985764e-08, 'epoch': 0.98}
 98%|█████████▊| 3300/3353 [30:46:14<29:38, 33.56s/it] 98%|█████████▊| 3301/3353 [30:46:48<29:04, 33.54s/it] 98%|█████████▊| 3302/3353 [30:47:21<28:32, 33.58s/it] 99%|█████████▊| 3303/3353 [30:47:55<27:57, 33.55s/it] 99%|█████████▊| 3304/3353 [30:48:28<27:24, 33.56s/it] 99%|█████████▊| 3305/3353 [30:49:02<26:49, 33.53s/it] 99%|█████████▊| 3306/3353 [30:49:36<26:18, 33.58s/it] 99%|█████████▊| 3307/3353 [30:50:09<25:44, 33.57s/it] 99%|█████████▊| 3308/3353 [30:50:43<25:09, 33.54s/it] 99%|█████████▊| 3309/3353 [30:51:16<24:35, 33.54s/it] 99%|█████████▊| 3310/3353 [30:51:50<24:01, 33.53s/it]                                                      {'loss': 1.1334, 'learning_rate': 2.0287139552765955e-08, 'epoch': 0.99}
 99%|█████████▊| 3310/3353 [30:51:50<24:01, 33.53s/it] 99%|█████████▊| 3311/3353 [30:52:23<23:28, 33.54s/it] 99%|█████████▉| 3312/3353 [30:52:57<22:54, 33.53s/it] 99%|█████████▉| 3313/3353 [30:53:30<22:20, 33.50s/it] 99%|█████████▉| 3314/3353 [30:54:04<21:46, 33.50s/it] 99%|█████████▉| 3315/3353 [30:54:37<21:14, 33.53s/it] 99%|█████████▉| 3316/3353 [30:55:11<20:41, 33.54s/it] 99%|█████████▉| 3317/3353 [30:55:44<20:07, 33.55s/it] 99%|█████████▉| 3318/3353 [30:56:18<19:34, 33.57s/it] 99%|█████████▉| 3319/3353 [30:56:52<19:00, 33.54s/it] 99%|█████████▉| 3320/3353 [30:57:25<18:26, 33.53s/it]                                                      {'loss': 1.1328, 'learning_rate': 1.1949120259391322e-08, 'epoch': 0.99}
 99%|█████████▉| 3320/3353 [30:57:25<18:26, 33.53s/it] 99%|█████████▉| 3321/3353 [30:57:59<17:53, 33.53s/it] 99%|█████████▉| 3322/3353 [30:58:32<17:19, 33.54s/it] 99%|█████████▉| 3323/3353 [30:59:06<16:45, 33.52s/it] 99%|█████████▉| 3324/3353 [30:59:39<16:11, 33.50s/it] 99%|█████████▉| 3325/3353 [31:00:13<15:38, 33.50s/it] 99%|█████████▉| 3326/3353 [31:00:46<15:04, 33.49s/it] 99%|█████████▉| 3327/3353 [31:01:20<14:32, 33.55s/it] 99%|█████████▉| 3328/3353 [31:01:53<13:57, 33.52s/it] 99%|█████████▉| 3329/3353 [31:02:27<13:24, 33.53s/it] 99%|█████████▉| 3330/3353 [31:03:00<12:50, 33.50s/it]                                                      {'loss': 1.1391, 'learning_rate': 5.804723218177932e-09, 'epoch': 0.99}
 99%|█████████▉| 3330/3353 [31:03:00<12:50, 33.50s/it] 99%|█████████▉| 3331/3353 [31:03:34<12:19, 33.62s/it] 99%|█████████▉| 3332/3353 [31:04:08<11:45, 33.58s/it] 99%|█████████▉| 3333/3353 [31:04:41<11:10, 33.54s/it] 99%|█████████▉| 3334/3353 [31:05:14<10:36, 33.51s/it] 99%|█████████▉| 3335/3353 [31:05:48<10:03, 33.52s/it] 99%|█████████▉| 3336/3353 [31:06:21<09:29, 33.52s/it]100%|█████████▉| 3337/3353 [31:06:55<08:55, 33.49s/it]100%|█████████▉| 3338/3353 [31:07:28<08:22, 33.47s/it]100%|█████████▉| 3339/3353 [31:08:02<07:49, 33.51s/it]100%|█████████▉| 3340/3353 [31:08:35<07:15, 33.49s/it]                                                      {'loss': 1.1359, 'learning_rate': 1.8544878263832e-09, 'epoch': 1.0}
100%|█████████▉| 3340/3353 [31:08:36<07:15, 33.49s/it]100%|█████████▉| 3341/3353 [31:09:09<06:43, 33.65s/it]100%|█████████▉| 3342/3353 [31:09:43<06:09, 33.59s/it]100%|█████████▉| 3343/3353 [31:10:17<05:36, 33.62s/it]100%|█████████▉| 3344/3353 [31:10:50<05:02, 33.58s/it]100%|█████████▉| 3345/3353 [31:11:24<04:28, 33.57s/it]100%|█████████▉| 3346/3353 [31:11:57<03:54, 33.53s/it]100%|█████████▉| 3347/3353 [31:12:31<03:21, 33.55s/it]100%|█████████▉| 3348/3353 [31:13:04<02:47, 33.53s/it]100%|█████████▉| 3349/3353 [31:13:38<02:14, 33.51s/it]100%|█████████▉| 3350/3353 [31:14:11<01:40, 33.49s/it]                                                      {'loss': 1.1339, 'learning_rate': 9.876086272120333e-11, 'epoch': 1.0}
100%|█████████▉| 3350/3353 [31:14:11<01:40, 33.49s/it]100%|█████████▉| 3351/3353 [31:14:45<01:07, 33.56s/it]100%|█████████▉| 3352/3353 [31:15:18<00:33, 33.54s/it]100%|██████████| 3353/3353 [31:15:52<00:00, 33.57s/it][INFO|trainer.py:1988] 2024-03-26 23:12:10,682 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                      {'train_runtime': 112552.3592, 'train_samples_per_second': 9.533, 'train_steps_per_second': 0.03, 'train_loss': 1.2432719229087523, 'epoch': 1.0}
100%|██████████| 3353/3353 [31:15:52<00:00, 33.57s/it]100%|██████████| 3353/3353 [31:15:52<00:00, 33.57s/it]
[INFO|trainer.py:2979] 2024-03-26 23:12:14,789 >> Saving model checkpoint to /home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b
[INFO|configuration_utils.py:473] 2024-03-26 23:12:15,260 >> Configuration saved in /home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b/config.json
[INFO|configuration_utils.py:595] 2024-03-26 23:12:15,327 >> Configuration saved in /home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b/generation_config.json
[2024-03-26 23:12:17,519] [INFO] [launch.py:347:main] Process 3510175 exits successfully.
[2024-03-26 23:12:17,520] [INFO] [launch.py:347:main] Process 3510173 exits successfully.
[2024-03-26 23:12:17,520] [INFO] [launch.py:347:main] Process 3510176 exits successfully.
[2024-03-26 23:12:17,520] [INFO] [launch.py:347:main] Process 3510174 exits successfully.
[INFO|modeling_utils.py:2540] 2024-03-26 23:13:30,936 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-03-26 23:13:31,002 >> tokenizer config file saved in /home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-03-26 23:13:31,061 >> Special tokens file saved in /home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b/special_tokens_map.json
[INFO|tokenization_utils_base.py:2495] 2024-03-26 23:13:31,062 >> added tokens file saved in /home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b/added_tokens.json
***** train metrics *****
  epoch                    =               1.0
  train_loss               =            1.2433
  train_runtime            = 1 day, 7:15:52.35
  train_samples_per_second =             9.533
  train_steps_per_second   =              0.03
Figure saved: /home/nfs03/wangzj/checkpoints/mot/phi-nonexpanded-ar1b/training_loss.png
03/26/2024 23:13:32 - WARNING - llmtuner.extras.ploting - No metric eval_loss to plot.
[INFO|modelcard.py:452] 2024-03-26 23:13:32,219 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
[2024-03-26 23:13:34,607] [INFO] [launch.py:347:main] Process 3510172 exits successfully.
